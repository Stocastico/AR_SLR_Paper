
@ARTICLE{Yilmaz2016240,
author={Yilmaz, R.M.},
title={Educational magic toys developed with augmented reality technology for early childhood education},
journal={Computers in Human Behavior},
year={2016},
volume={54},
pages={240-248},
doi={10.1016/j.chb.2015.07.040},
note={cited By 82},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84990916693&doi=10.1016%2fj.chb.2015.07.040&partnerID=40&md5=5ba840625f803c580de74a44139cc0ac},
affiliation={Department of Computer Education & Instructional Technology, Kazim Karabekir Faculty of Education, Ataturk University, Erzurum, 25240, Turkey},
abstract={Shaping children's experience, enhancing their imagination and affecting their behaviors, toys have great importance. Recently, toys have gained a digital characteristic and many children have tended to use them. For this reason, educational magic toys (EMT) were developed with augmented reality technology in this study. It is called as EMT because virtual objects such as story animations, 3D objects and flash animations appear on the toys. EMT has included puzzles, flash cards and match cards to teach animals, fruits, vegetables, vehicles, objects, professions, colors, numbers and shapes for average 5–6 age children in Early Childhood Education. The aim of this study is to reveal teachers’ and children's opinions on EMT, to determine children's behavioral patterns and their cognitive attainment, and the relationship between them while playing EMT. Mix method was used and the sample consisted of 30 teachers and 33 children aged 5–6 in early childhood education. As data collection tools, a survey, an observation and interview form were used. This study revealed that teachers and children liked EMT activity. In addition, children interactively played with these toys but not had high cognitive attainment. From this point, we can say that these toys can be effectively used in early childhood education. However, collaborative and interactive learning with these toys should be provided. Moreover, this study will provide an important contribution, present a new educational AR application, and fill the gap in the educational technology field. © 2015 Elsevier Ltd},
author_keywords={Augmented reality;  Early childhood education;  Toys},
keywords={Augmented reality;  Educational technology, Augmented reality technology;  Behavioral patterns;  Data collection tools;  Digital characteristics;  Early childhood educations;  Flash animations;  Interactive learning;  Toys, Teaching, article;  child;  childhood;  clinical article;  educational technology;  female;  fruit;  human;  human experiment;  infant;  information processing;  interview;  learning;  male;  mental capacity;  occupation;  preschool child;  teacher;  vegetable},
publisher={Elsevier Ltd},
issn={07475632},
coden={CHBEE},
language={English},
abbrev_source_title={Comput. Hum. Behav.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Huang201672,
author={Huang, T.-C. and Chen, C.-C. and Chou, Y.-W.},
title={Animating eco-education: To see, feel, and discover in an augmented reality-based experiential learning environment},
journal={Computers and Education},
year={2016},
volume={96},
pages={72-82},
doi={10.1016/j.compedu.2016.02.008},
note={cited By 77},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84959271903&doi=10.1016%2fj.compedu.2016.02.008&partnerID=40&md5=7380cd0a1c420dc74957811874dadc89},
affiliation={Department of Information Management, National Taichung University of Science and Technology, Taiwan, No.129, Sec. 3, Sanmin Rd., Taichung, 40444, Taiwan; Department of Management Information Systems, National Chung Hsing University, Taiwan, No.250, Kuo Kuang Rd., Taichung City, 402, Taiwan},
abstract={An antagonistic relationship is traditionally seen as existing between eco-education and technology, with conventional instructional approaches usually characterized by a commentator guiding students in field learning. Unfortunately, in this passive learning approach, the discovery of rich ecological resources in eco-environments to stimulate positive emotions and experiences is often condensed into a "sightseeing". Therefore, precise and systematic guidance focused on providing a rich learning experience is needed in field learning and eco-education. Based on Kolb's experiential learning theory, the current study develops an eco-discovery AR-based learning model (EDALM) which is implemented in an eco-discovery AR-based learning system (EDALS). In a field experiment at a botanical garden, 21 middle school students constitute three groups participated in a learning activity using different learning types and media. Quantitative results indicate that, compared to the human-guidance-only model, EDALS successfully stimulates positive emotions and improved learning outcomes among learners. In post-activity interviews, students indicated they found the exploration mode provided by the proposed system to be more interesting and helpful to their learning in school. The use of attractive technologies increase students' willingness not only to learn more about the environment, but also to develop a more positive emotional attachment to it. © 2016 Published by Elsevier Ltd.},
author_keywords={Applications in subject areas;  Interactive learning environments;  Media in education;  Secondary education;  Teaching/learning strategies},
keywords={Augmented reality;  Computer aided instruction;  Education;  Education computing;  Learning systems;  Students, Applications in subject areas;  Experiential learning;  Interactive learning environment;  Kolb's Experiential Learning;  Media in education;  Middle school students;  Rich learning experiences;  Teaching/learning strategy, Engineering education},
correspondence_address1={Chen, C.-C.; Department of Management Information Systems, National Chung Hsing University, Taiwan, No.250, Kuo Kuang Rd., Taiwan; email: emily@nchu.edu.tw},
publisher={Elsevier Ltd},
issn={03601315},
coden={COMED},
language={English},
abbrev_source_title={Comput Educ},
document_type={Article},
source={Scopus},
}

@ARTICLE{Valentin2015,
author={Valentin, J. and Vineet, V. and Cheng, M.-M. and Kim, D. and Shotton, J. and Kohli, P. and Nießner, M. and Criminisi, A. and Izadi, S. and Torr, P.},
title={SemanticPaint: Interactive 3D labeling and learning at your fingertips},
journal={ACM Transactions on Graphics},
year={2015},
volume={34},
number={5},
doi={10.1145/2751556},
art_number={154},
note={cited By 53},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84947424191&doi=10.1145%2f2751556&partnerID=40&md5=ef812aca972f2a7fc03080e082856c71},
affiliation={Department of Engineering Science, University of Oxford, Manor Rd, Oxford, OX1 3PJ, United Kingdom; Nankai University, 94 Weijin Rd, Nankai, Tianjin, 300071, China; Microsoft Research Cambridge, 21 Station Rd, Cambridge, CB1 2FB, United Kingdom; Stanford University, 450 Serra Mall, Stanford, CA  94305, United States},
abstract={We present a new interactive and online approach to 3D scene understanding. Our system, SemanticPaint, allows users to simultaneously scan their environment whilst interactively segmenting the scene simply by reaching out and touching any desired object or surface. Our system continuously learns from these segmentations, and labels new unseen parts of the environment. Unlike offline systems where capture, labeling, and batch learning often take hours or even days to perform, our approach is fully online. This provides users with continuous live feedback of the recognition during capture, allowing to immediately correct errors in the segmentation and/or learning-a feature that has so far been unavailable to batch and offline methods. This leads to models that are tailored or personalized specifically to the user's environments and object classes of interest, opening up the potential for new applications in augmented reality, interior design, and human/robot navigation. It also provides the ability to capture substantial labeled 3D datasets for training large-scale visual recognition systems. © 2015 ACM.},
author_keywords={3D features;  3D scene understanding;  Depth camera;  Interactive;  Learning;  Online;  Segmentation},
keywords={Architectural design;  Augmented reality;  Image segmentation;  Three dimensional computer graphics, 3D features;  3D scenes;  Depth camera;  Interactive;  Learning;  Online, Online systems},
correspondence_address1={Valentin, J.; Department of Engineering Science, University of Oxford, Manor Rd, United Kingdom; email: julien.valentin@eng.ox.ac.uk},
publisher={Association for Computing Machinery},
issn={07300301},
coden={ATGRD},
language={English},
abbrev_source_title={ACM Trans Graphics},
document_type={Article},
source={Scopus},
}

@ARTICLE{Fonseca2015311,
author={Fonseca, D. and Redondo, E. and Villagrasa, S.},
title={Mixed-methods research: a new approach to evaluating the motivation and satisfaction of university students using advanced visual technologies},
journal={Universal Access in the Information Society},
year={2015},
volume={14},
number={3},
pages={311-332},
doi={10.1007/s10209-014-0361-4},
note={cited By 37},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84938958022&doi=10.1007%2fs10209-014-0361-4&partnerID=40&md5=d06cc88d81cd0377e91f3021a6fc8fff},
affiliation={La Salle Barcelona Campus, Ramon Llull University, C/Quatre Camins 2, Barcelona, 08022, Spain; ETSAB, Universitat Politècnica de Catalunya-BarcelonaTech, Avda. Diagonal 649, Barcelona, 08028, Spain},
abstract={A mixed-methods study evaluating the motivation and satisfaction of Architecture degree students using interactive visualization methods is presented in this paper. New technology implementations in the teaching field have been largely extended to all types of levels and educational frameworks. However, these innovations require approval validation and evaluation by the final users, the students. In this paper, the advantages and disadvantages of applying mixed evaluation technology are discussed in a case study of the use of interactive and collaborative tools for the visualization of 3D architectonical models. The main objective was to evaluate Architecture and Building Science students’ the motivation to use and satisfaction with this type of technology and to obtain adequate feedback that allows for the optimization of this type of experiment in future iterations. © 2014, Springer-Verlag Berlin Heidelberg.},
author_keywords={Augmented reality;  Mixed method research;  Motivation;  Satisfaction;  Teaching innovation;  User experience},
keywords={Augmented reality;  Motivation;  Students;  Three dimensional computer graphics;  Visualization, Architecture and buildings;  Interactive visualizations;  Mixed method;  Mixed-methods research;  New technology implementations;  Satisfaction;  Teaching innovations;  User experience, Education},
correspondence_address1={Fonseca, D.; La Salle Barcelona Campus, Ramon Llull University, C/Quatre Camins 2, Spain},
publisher={Springer Verlag},
issn={16155289},
language={English},
abbrev_source_title={Univers. Access Inf. Soc.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Ibáñez2018109,
author={Ibáñez, M.-B. and Delgado-Kloos, C.},
title={Augmented reality for STEM learning: A systematic review},
journal={Computers and Education},
year={2018},
volume={123},
pages={109-123},
doi={10.1016/j.compedu.2018.05.002},
note={cited By 35},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047097680&doi=10.1016%2fj.compedu.2018.05.002&partnerID=40&md5=6d7c3f5cea1add97c9a5d4bee350f0cc},
affiliation={Universidad Carlos III de Madrid, Madrid, Spain},
abstract={This study presents a systematic review of the literature on the use of augmented reality technology to support science, technology, engineering and mathematics (STEM) learning. It synthesizes a set of 28 publications from 2010 to 2017. A qualitative content analysis is used to investigate the general characteristics of augmented reality applications in STEM education, the instructional strategies and techniques deployed in the studies reviewed, and the evaluation approaches followed in the interventions. This review found that most augmented reality applications for STEM learning offered exploration or simulation activities. The applications reviewed offered a number of similar design features based on digital knowledge discovery mechanisms to consume information through the interaction with digital elements. However, few studies provided students with assistance in carrying out learning activities. Most of the studies reviewed evaluated the effects of augmented reality technology in fostering students’ conceptual understanding, followed by those that investigated affective learning outcomes. A number of suggestions for future research arose from this review. Researchers need to design features that allow students to acquire basic competences related with STEM disciplines, and future applications need to include metacognitive scaffolding and experimental support for inquiry-based learning activities. Finally, it would be useful to explore how augmented reality learning activities can be part of blended instructional strategies such as the flipped classroom. © 2018 Elsevier Ltd},
author_keywords={Applications in STEM education;  Augmented reality;  Interactive learning environments;  Systematic review},
keywords={Augmented reality;  Computer aided instruction;  Engineering education;  Scaffolds;  Students, Augmented reality applications;  Augmented reality technology;  Interactive learning environment;  Knowledge discovery mechanism;  Metacognitive scaffoldings;  Science , Technology , Engineering and Mathematics;  STEM education;  Systematic Review, STEM (science, technology, engineering and mathematics)},
correspondence_address1={Ibáñez, M.-B.; Universidad Carlos III de MadridSpain; email: mbibanez@it.uc3m.es},
publisher={Elsevier Ltd},
issn={03601315},
coden={COMED},
language={English},
abbrev_source_title={Comput Educ},
document_type={Article},
source={Scopus},
}

@ARTICLE{Cai2017778,
author={Cai, S. and Chiang, F.-K. and Sun, Y. and Lin, C. and Lee, J.J.},
title={Applications of augmented reality-based natural interactive learning in magnetic field instruction},
journal={Interactive Learning Environments},
year={2017},
volume={25},
number={6},
pages={778-791},
doi={10.1080/10494820.2016.1181094},
note={cited By 33},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84969883824&doi=10.1080%2f10494820.2016.1181094&partnerID=40&md5=86801bab9c54f47728f6069eecc4b165},
affiliation={School of Educational Technology, Faculty of Education, Beijing Normal University, Beijing, China; Advanced Technology Innovation Center for Future Education, Beijing Normal University, China; Department of Mathematics, Science & Technology at Teachers College, Columbia University, New York, United States},
abstract={Educators must address several challenges inherent to the instruction of scientific disciplines such as physics -- expensive or insufficient laboratory equipment, equipment error, difficulty in simulating certain experimental conditions. Augmented reality (AR) can be a promising approach to address these challenges. In this paper, we discuss the design and implementation of an AR and motion-sensing learning technology that teaches magnetic fields in a junior high school physics course. The purpose of this study is to explore the effects of using natural interaction on students’ physics learning and deep understanding compared to traditional learning tools. The 38 eighth graders who participated in this study were assigned to either an experimental group or a control group. Analysis of the results shows that the AR-based motion-sensing software can improve students’ learning attitude and learning outcome. This study provides a case for the application of AR technology in secondary physics education. © 2016 Informa UK Limited, trading as Taylor & Francis Group.},
author_keywords={Augmented reality;  learning environment;  magnetic field;  motion sensing;  natural interaction},
correspondence_address1={Cai, S.; School of Educational Technology, Faculty of Education, Beijing Normal UniversityChina; email: caisu@bnu.edu.cn},
publisher={Routledge},
issn={10494820},
language={English},
abbrev_source_title={Interact. Learn. Environ.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Chang2018226,
author={Chang, S.-C. and Hwang, G.-J.},
title={Impacts of an augmented reality-based flipped learning guiding approach on students’ scientific project performance and perceptions},
journal={Computers and Education},
year={2018},
volume={125},
pages={226-239},
doi={10.1016/j.compedu.2018.06.007},
note={cited By 31},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048713518&doi=10.1016%2fj.compedu.2018.06.007&partnerID=40&md5=e3a96bf84ff79d08b58e3b1a93c17f4a},
affiliation={National Taiwan University of Science and Technology, Graduate Institute of Digital Learning and Education, Taiwan},
abstract={In recent years, flipped learning has received increasing emphasis; it engages students in deriving basic knowledge through instructional videos before the class, and hence more time is available for practicing, applying knowledge, or student-teacher interaction in class. Many scholars have pointed out that, with such a learning approach, teachers can design more effective in-class activities by guiding students to have higher order thinking as well as interactions with peers and teachers. In the meantime, researchers have also indicated that employing proper educational technologies or learning strategies could further improve students’ performance. Therefore, in this study, an Augmented Reality (AR)-based learning guiding mode is proposed for developing a flipped learning system. To examine the effectiveness of the proposed approach, an experiment was conducted in a natural science learning activity of an elementary school using the developed system. The participants were four classes of 111 fifth graders. Two classes were assigned to the experimental group, while the others were the control group. Those learning in the experimental group used the AR-based flipped learning mode, while those in the control group learned with the conventional flipped learning mode. From the experimental results, it was found that the AR-based flipped learning guiding approach not only benefited the students in terms of promoting their project performance, but also improved their learning motivation, critical thinking tendency, and group self-efficacy. © 2018 Elsevier Ltd},
author_keywords={Applications in subject areas;  Interactive learning environments;  Pedagogical issues;  Teaching/learning strategies},
keywords={Augmented reality;  Educational technology;  Learning systems;  Students;  Teaching, Applications in subject areas;  Higher-order thinkings;  Instructional videos;  Interactive learning environment;  Learning motivation;  Pedagogical issues;  Scientific projects;  Teaching/learning strategy, Computer aided instruction},
correspondence_address1={Hwang, G.-J.; National Taiwan University of Science and Technology, Graduate Institute of Digital Learning and EducationTaiwan; email: gjhwang.academic@gmail.com},
publisher={Elsevier Ltd},
issn={03601315},
coden={COMED},
language={English},
abbrev_source_title={Comput Educ},
document_type={Article},
source={Scopus},
}

@ARTICLE{Hsu2017137,
author={Hsu, T.-C.},
title={Learning English with Augmented Reality: Do learning styles matter?},
journal={Computers and Education},
year={2017},
volume={106},
pages={137-149},
doi={10.1016/j.compedu.2016.12.007},
note={cited By 30},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85006757593&doi=10.1016%2fj.compedu.2016.12.007&partnerID=40&md5=32966ed3b65cef0efcf4320fc905ba67},
affiliation={Department of Technology Application and Human Resource Development, National Taiwan Normal University, 162, Sec. 1, East Heping Rd, Taipei City, 10610, Taiwan},
abstract={This study attempted to develop and compare two Augmented Reality (AR) educational game systems for third graders to learn English vocabulary in free and situated surroundings. One system was developed based on a self-directed learning approach which did not restrict the learning sequence, while the other was based on a task-based learning approach which limited the learning sequence. The flow experience, cognitive load, foreign language learning anxiety, and learning effectiveness of the students with different learning styles (i.e., serial or global) were assessed. The results showed that the students using the self-directed or task-based AR educational game system had similar and high learning effectiveness, although those using the self-directed system revealed higher flow experience. However, the students with a serial learning style had lower mental effort and foreign language learning anxiety regardless of using the self-directed or the task-based AR educational game system. It was found that the challenge and control of the system conformed to the students' proficiency. The learning objects (e.g., pen, pencil, book, chair, desk, eraser, ruler, etc.) did not have a restrictive learning sequence. Providing free learning steps was preferable, and restricting which step to begin with was not necessary. This study confirms that the mental efforts of students are greater when they experience more learning anxiety at the same time; however, it is not the case that lower learning anxiety and mental effort is better for learning. On the contrary, a little learning anxiety and mental effort, but not too much, is helpful for learning. © 2016},
author_keywords={Elementary education;  Evaluation of CAL systems;  Interactive learning environments;  Media in education},
keywords={Augmented reality;  Education;  Students, Elementary education;  Evaluation of CAL systems;  Foreign language learning;  Interactive learning environment;  Learning effectiveness;  Media in education;  Self-directed learning;  Task-based learning, Computer aided instruction},
publisher={Elsevier Ltd},
issn={03601315},
coden={COMED},
language={English},
abbrev_source_title={Comput Educ},
document_type={Article},
source={Scopus},
}

@ARTICLE{Lin201651,
author={Lin, C.-Y. and Chai, H.-C. and Wang, J.-Y. and Chen, C.-J. and Liu, Y.-H. and Chen, C.-W. and Lin, C.-W. and Huang, Y.-M.},
title={Augmented reality in educational activities for children with disabilities},
journal={Displays},
year={2016},
volume={42},
pages={51-54},
doi={10.1016/j.displa.2015.02.004},
note={cited By 27},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84969335462&doi=10.1016%2fj.displa.2015.02.004&partnerID=40&md5=3280c206012294afdbc62de68b6064b8},
affiliation={Department of Special Education, National University of Tainan, Shu-Lin St., 33, Sec. 2, Tainan, 700, Taiwan},
abstract={This study explores a new way to integrate advanced display technology into educational activities for children with different disabilities. A free interactive mobile augmented reality (AR) application was developed to facilitate the learning of geometry. Twenty-one elementary school children participated in an experiment. The results show that the AR system could help the school children to finish puzzle game activities independent of teacher's assistance. With the use of AR display technology, the participants demonstrated improved ability to complete puzzle game tasks when compared to the use of traditional paper-based methods. Performance data indicated that the use of AR technology could enhance learning motivation and frustration tolerance in children with special needs. © 2015 Elsevier B.V. All rights reserved.},
author_keywords={Augmented reality;  Children;  Free application;  Mobile;  Tangram},
keywords={Augmented reality;  Display devices;  Teaching, Children;  Children with disabilities;  Display technologies;  Educational activities;  Frustration tolerances;  Mobile;  Mobile augmented reality;  Tangram, Education},
correspondence_address1={Lin, C.-Y.; Department of Special Education, National University of Tainan, Shu-Lin St., 33, Sec. 2, Taiwan; email: linchienyu@mail.nutn.edu.tw},
publisher={Elsevier B.V.},
issn={01419382},
coden={DISPD},
language={English},
abbrev_source_title={Disp},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Funk2017222,
author={Funk, M. and Bachler, A. and Bachler, L. and Kosch, T. and Heidenreich, T. and Schmidt, A.},
title={Working with augmented reality? A long-term analysis of in-situ instructions at the assembly workplace},
journal={ACM International Conference Proceeding Series},
year={2017},
volume={Part F128530},
pages={222-229},
doi={10.1145/3056540.3056548},
note={cited By 26},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85024847836&doi=10.1145%2f3056540.3056548&partnerID=40&md5=5907a1730903b51ab8dcf24fd1779443},
affiliation={University of Stuttgart, Pfaffenwaldring 5a, Stuttgart, 70569, Germany; University of Applied Sciences Esslingen, Kanalstrae 33, Esslingen am Neckar, 73728, Germany},
abstract={Due to increasing complexity of products and the demographic change at manual assembly workplaces, interactive and context-aware instructions for assembling products are becoming more and more important. Over the last years, many systems using head-mounted displays (HMDs) and insitu projection have been proposed. We are observing a trend in assistive systems using in-situ projection for supporting workers during work tasks. Recent advances in technology enable robust detection of almost every work step, which is done at workplaces. With this improvement in robustness, a continuous usage of assistive systems at the workplace becomes possible. In this work, we provide results of a longterm study in an industrial workplace with an overall runtime of 11 full workdays. In our study, each participant assembled at least three full workdays using in-situ projected instructions. We separately considered two different user groups comprising expert and untrained workers. Our results show a decrease in performance for expert workers and a learning success for untrained workers. © 2017 ACM.},
author_keywords={Assistive technology;  Augmented Reality;  In-situ projection;  Long-term evaluation},
keywords={Augmented reality, Assistive system;  Assistive technology;  Demographic changes;  Head mounted displays;  Long term analysis;  Long-term evaluation;  Manual assembly;  Robust detection, Assembly},
publisher={Association for Computing Machinery},
isbn={9781450352277},
language={English},
abbrev_source_title={ACM Int. Conf. Proc. Ser.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Miksik20153317,
author={Miksik, O. and Vineet, V. and Lidegaard, M. and Prasaath, R. and Nießner, M. and Golodetz, S. and Hicks, S.L. and Pérez, P. and Izadi, S. and Torr, P.H.S.},
title={The semantic paintbrush: Interactive 3D mapping and recognition in large outdoor spaces},
journal={Conference on Human Factors in Computing Systems - Proceedings},
year={2015},
volume={2015-April},
pages={3317-3326},
doi={10.1145/2702123.2702222},
note={cited By 23},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84951059759&doi=10.1145%2f2702123.2702222&partnerID=40&md5=c775c8b28e6c331896f1d27fb0ff0efe},
affiliation={Department of Engineering Science, University of Oxford, United Kingdom; Nuffield Department of Clinical Neurosciences, University of Oxford, United Kingdom; Stanford University, United States; Technicolor R and I, United States; Microsoft Research, United States},
abstract={We present an augmented reality system for large scale 3D reconstruction and recognition in outdoor scenes. Unlike existing prior work, which tries to reconstruct scenes using active depth cameras, we use a purely passive stereo setup, allowing for outdoor use and extended sensing range. Our system not only produces a map of the 3D environment in real-time, it also allows the user to draw (or 'paint') with a laser pointer directly onto the reconstruction to segment the model into objects. Given these examples our system then learns to segment other parts of the 3D map during online acquisition. Unlike typical object recognition systems, ours therefore very much places the user 'in the loop' to segment particular objects of interest, rather than learning from predefined databases. The laser pointer additionally helps to 'clean up' the stereo reconstruction and final 3D map, interactively. Using our system, within minutes, a user can capture a full 3D map, segment it into objects of interest, and refine parts of the model during capture. We provide full technical details of our system to aid replication, as well as quantitative evaluation of system components. We demonstrate the possibility of using our system for helping the visually impaired navigate through spaces. Beyond this use, our system can be used for playing large-scale augmented reality games, shared online to augment streetview data, and used for more detailed car and person navigation. © Copyright 2015 ACM.},
author_keywords={3D reconstruction;  Augmented reality;  Laser pointer interaction;  Semantic segmentation;  Stereo;  Visually impaired},
keywords={Augmented reality;  Facsimile;  Human computer interaction;  Human engineering;  Image reconstruction;  Laser applications;  Object recognition;  Semantics, 3D reconstruction;  Laser pointer interaction;  Semantic segmentation;  Stereo;  Visually impaired, Three dimensional computer graphics},
publisher={Association for Computing Machinery},
isbn={9781450331456},
language={English},
abbrev_source_title={Conf Hum Fact Comput Syst Proc},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Grajewski2015359,
author={Grajewski, D. and Górski, F. and Hamrol, A. and Zawadzki, P.},
title={Immersive and Haptic Educational Simulations of Assembly Workplace Conditions},
journal={Procedia Computer Science},
year={2015},
volume={75},
pages={359-368},
doi={10.1016/j.procs.2015.12.258},
note={cited By 23},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964076339&doi=10.1016%2fj.procs.2015.12.258&partnerID=40&md5=68418c68cc45af74bcc0be15b0c95744},
affiliation={Poznań University of Technology, Department of Management and Production Engineering, Piotrowo Str. 3, Poznan, 60-965, Poland},
abstract={The paper presents a number of different approaches for creation of realistic immersive educational simulations of conditions of a workplace for assembly operations with aid of haptic and Virtual Reality systems. Such simulations can be used for effective training of future operators of a given workplace and testing its ergonomic quality without need of building a physical prototype. The authors have devised several different approaches to preparation of virtual workplace prototypes for training. The basic approach is utilization of immersive VR systems (Head-Mounted Devices combined with user tracking solutions) to create an interactive simulation of a workplace, on the basis of its CAD model and specification of a realized process. The second approach is using a haptic manipulator with force feedback for interaction with a virtual workplace, for more realistic feeling of a realized activity. The third, novel approach is combination of the two previous approaches. A special system was designed and built for this purpose. It uses a large-space robot to allow haptic feedback for a user equipped with an immersive set of devices. More and more often virtual prototypes of the workplaces replace the physical ones as an innovative training solutions that allow to train the future operators or improve ergonomic quality of the workplace. The reason for that is the reduction of costs needed to develop the real prototype of the workstation as well as ability of complex virtual workplaces to change the variants in order to investigate different situations. Usually such workplaces - created as interactive Virtual Reality applications - consist of a visualization operated with aid of advanced Virtual Reality systems and devices. Implementation of an immersive equipment increases sense of user's presence and use of haptic devices with force feedback makes the experience more similar to reality. The level of realism is a very important factor in an immersive and haptic simulations of workstations for training purposes. As a form of instructional simulation, also called educational simulation, immersive and haptic simulations are a powerful learning tools that require trained users to complete tasks or to solve specific problems within VR environment that replicates the real workplace conditions19. Trainings conducted is this way are particularly beneficial when real activities and task conducted at the workplace is too dangerous, too costly or even almost impossible to do. The two basic approaches presented by the authors are innovative and important on their own, but they usually do not mix, as state-of-the-art haptic devices are stationary. Their application heavily limits spatial freedom of a user, which does not affect the level of realism of presented simulations in a positive way. In order to fully simulate the conditions of an assembly workplace, tactile input must be available, with simultaneous immersion of a user into a Virtual Environment (VE) using a HMD or a CAVE system combined with the user tracking solution. The third approach to simulation of workplace conditions, proposed by the authors, allows to bring a realistic force feedback into an immersive visualization. Thanks to this, operations like assembling a threaded joint between two parts can be trained more realistically than before, without need of building a full physical workplace. © 2015 The Authors.},
author_keywords={haptic devices;  immersive simulations;  virtual reality;  virtual workplaces},
keywords={Augmented reality;  Computer aided design;  Ergonomics;  Haptic interfaces;  Personnel training;  Virtual reality;  Visualization, Educational simulations;  Haptic devices;  Immersive;  Immersive visualization;  Instructional simulations;  Interactive simulations;  Interactive virtual reality;  Virtual workplace, Education},
correspondence_address1={Grajewski, D.; Poznań University of Technology, Department of Management and Production Engineering, Piotrowo Str. 3, Poland; email: damian.grajewski@put.poznan.pl},
editor={Ramirez Flores P.G., Martin Gutierrez J., Mendivil E.G., Ginters E.},
publisher={Elsevier},
issn={18770509},
language={English},
abbrev_source_title={Procedia Comput. Sci.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Hsiao2016205,
author={Hsiao, H.-S. and Chang, C.-S. and Lin, C.-Y. and Wang, Y.-Z.},
title={Weather observers: a manipulative augmented reality system for weather simulations at home, in the classroom, and at a museum},
journal={Interactive Learning Environments},
year={2016},
volume={24},
number={1},
pages={205-223},
doi={10.1080/10494820.2013.834829},
note={cited By 22},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84955182892&doi=10.1080%2f10494820.2013.834829&partnerID=40&md5=22ac96c8e0b9ea193b0ff102cbf61e7f},
affiliation={Department of Technology Application and Human Resource Development, National Taiwan Normal University, Taipei, Taiwan},
abstract={This study focused on how to enhance the interactivity and usefulness of augmented reality (AR) by integrating manipulative interactive tools with a real-world environment. A manipulative AR (MAR) system, which included 3D interactive models and manipulative aids, was designed and developed to teach the unit “Understanding Weather” in a natural science course, and to bridge a formal learning environment (i.e. school), non-formal (i.e. at a museum), and informal learning environments (i.e. home). Sixty-four sixth-grade students (12–13 years old) from four classes in Taipei City were enrolled in a seven-week general studies course entitled “Natural and Life Science and Technology”, and they were divided into an experimental group (31 students who used the MAR system) and a control group (33 students who used multimedia teaching resources). After seven weeks of experiments, the results revealed that integrating the MAR system into inquiry-based field study made a greater positive impact on the students' academic achievement and motivation compared to the multimedia teaching resources installed on a tablet PC. Additionally, there were two interesting findings: (1) the MAR system offered effective learning materials relative to the multimedia teaching resources and (2) manipulative aids were an effective learning tool for interactivity and usefulness of AR. Besides, there were two meaningful suggestions associated with designing and developing the AR educational system for future researchers and designers, namely make it easy to use and include manipulative aids. © 2013 Taylor & Francis.},
author_keywords={academic achievement;  augmented reality;  bridging different learning environments;  evaluation of multimedia resources;  learning motivation;  manipulative aids},
correspondence_address1={Chang, C.-S.; Department of Technology Application and Human Resource Development, National Taiwan Normal UniversityTaiwan; email: chengsian1117@gmail.com},
publisher={Routledge},
issn={10494820},
language={English},
abbrev_source_title={Interact. Learn. Environ.},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Liu201595,
author={Liu, D. and Valdiviezo-Díaz, P. and Riofrio, G. and Sun, Y.-M. and Barba, R.},
title={Integration of Virtual Labs into Science E-learning},
journal={Procedia Computer Science},
year={2015},
volume={75},
pages={95-102},
doi={10.1016/j.procs.2015.12.224},
note={cited By 22},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964047127&doi=10.1016%2fj.procs.2015.12.224&partnerID=40&md5=73e9a161ea44eeedd9483a6c46281e04},
affiliation={Department of Computer Science and Electronics, Universidad Técnica Particular de Loja, Loja, Ecuador; School of Information Engineering, Guangdong University of Technology, Guangzhou, China; Proyecto Prometeo de la Secretaría Nacional de Ciencia, Tecnología e Innovación (SENESCYT), Quito, Ecuador},
abstract={Students can obtain lab content information equally well from two types of laboratories: a virtual and a physical lab. There is great potential in applying a 3D virtual lab based games to support teaching and learning in science. Moreover, it is significant to find practical ways to design and develop intelligent systems based on 3D games with limited complexity forms. 3D virtual environments provide an immersion into the learning contents, and interactions within the virtual world of the game, which are governed by established scientific principles. Therefore, people are looking for the forms of computer simulation - training that require fewer organizational and logistic efforts. Among them, three-dimension virtual environment is the important part of this system in enhancing the learning process. This paper aims to design and implement 3D virtual labs, which are considered as a low-cost alternative to educators and students, in science E-learning. This study focuses on the virtual assembly of instruments, the realization of dynamic 3D gauges, and the setup of emulation-based systems, which are key factors to provide students with the high-immersion 3D virtual lab. It also describes the setup of the network environment of this virtual lab; in this network, the server controls the options, user operations and the processes of experiments. Finally, this research involves designing and deploying a complex application that combines advanced visualization, interactive management through complex virtual devices and intelligent components. © 2015 The Authors.},
author_keywords={e-learning;  science;  Virtual instrument assembly;  virtual laboratory},
keywords={Augmented reality;  Complex networks;  Design;  E-learning;  Education;  Intelligent systems;  Students;  Virtual reality, 3-D virtual environment;  Advanced visualizations;  Design and implements;  Intelligent components;  science;  Scientific principles;  Virtual instrument;  Virtual laboratories, Laboratories},
correspondence_address1={Liu, D.; Department of Computer Science and Electronics, Universidad Técnica Particular de LojaEcuador; email: liudf@gdut.edu.cn},
editor={Ramirez Flores P.G., Martin Gutierrez J., Mendivil E.G., Ginters E.},
publisher={Elsevier},
issn={18770509},
language={English},
abbrev_source_title={Procedia Comput. Sci.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Chang20161245,
author={Chang, R.-C. and Chung, L.-Y. and Huang, Y.-M.},
title={Developing an interactive augmented reality system as a complement to plant education and comparing its effectiveness with video learning},
journal={Interactive Learning Environments},
year={2016},
volume={24},
number={6},
pages={1245-1264},
doi={10.1080/10494820.2014.982131},
note={cited By 21},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84916910726&doi=10.1080%2f10494820.2014.982131&partnerID=40&md5=c27608f386dd9c870eb55bdd18b31c12},
affiliation={Department of Digital Media Design, Asia University, Taichung City, Taiwan; Department of Medical Research, China Medical University Hospital, China Medical University, Taichung City, Taiwan; Department of Applied English, Chihlee Institute of Technology, New Taipei City, Taiwan; Department of Applied Informatics and Multimedia, Chia Nan University of Pharmacy and Science, Tainan City, Taiwan},
abstract={The learning of plants has garnered considerable attention in recent years, but students often lack the motivation to learn about the process of plant growth. Also, students are not able to apply what they have learned in class in the form of observation, since plant growth takes a long time. In this study, we use augmented reality (AR) technology to develop the ARFlora system, which can assist students in observing the changes in plant growth while in the classroom. More specifically, students are able to use AR markers to manipulate various virtual objects (e.g. sunlight) and observe the changes they have on plant growth. Meanwhile, a quasi-experimental evaluation is in place to substantiate the effectiveness of ARFlora in the learning of plants and to compare it with digital video learning. In the quasi-experimental design, 55 elementary-school students participated in the study. The participants are divided into two groups, an “experimental group” and a “control group.” The experimental group was taught using the ARFlora system, while the control group was taught by employing the digital video. Results show that (1) ARFlora and digital video have the same effectiveness on student's learning outcomes; (2) ARFlora is more effective in helping students retain learned knowledge; and (3) ARFlora is comparatively more useful in motivating students to learn about plants. © 2014 Informa UK Limited, trading as Taylor & Francis Group.},
author_keywords={augmented reality;  constructivist learning;  digital video;  plant education curriculum},
correspondence_address1={Huang, Y.-M.; Department of Applied Informatics and Multimedia, Chia Nan University of Pharmacy and ScienceTaiwan; email: ym.huang.tw@gmail.com},
publisher={Routledge},
issn={10494820},
language={English},
abbrev_source_title={Interact. Learn. Environ.},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Zünd2015,
author={Zünd, F. and Ryffel, M. and Magnenat, S. and Marra, A. and Nitti, M. and Kapadia, M. and Noris, G. and Mitchell, K. and Gross, M. and Sumner, R.W.},
title={Augmented creativity: Bridging the real and virtual worlds to enhance creative play},
journal={SIGGRAPH Asia 2015 Mobile Graphics and Interactive Applications, SA 2015},
year={2015},
doi={10.1145/2818427.2818460},
art_number={2818460},
note={cited By 21},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84960933793&doi=10.1145%2f2818427.2818460&partnerID=40&md5=a332e326dadc0c22923f5c9bfe1f8532},
affiliation={ETH Zürich, Switzerland; Disney Research Zurich, Switzerland; Rutgers University, United States},
abstract={Augmented Reality (AR) holds unique and promising potential to bridge between real-world activities and digital experiences, allowing users to engage their imagination and boost their creativity. We propose the concept of Augmented Creativity as employing AR on modern mobile devices to enhance real-world creative activities, support education, and open new interaction possibilities. We present six prototype applications that explore and develop Augmented Creativity in different ways, cultivating creativity through AR interactivity. Our coloring book app bridges coloring and computer-generated animation by allowing children to create their own character design in an AR setting. Our music apps provide a tangible way for children to explore different music styles and instruments in order to arrange their own version of popular songs. In the gaming domain, we show how to transform passive game interaction into active real-world movement that requires coordination and cooperation between players, and how AR can be applied to city-wide gaming concepts. We employ the concept of Augmented Creativity to authoring interactive narratives with an interactive storytelling framework. Finally, we examine how Augmented Creativity can provide a more compelling way to understand complex concepts, such as computer programming.},
author_keywords={Animation;  Augmented reality;  Games;  Storytelling;  User interaction},
keywords={Augmented reality;  Computer programming;  Interactive computer graphics;  Mobile devices;  Software prototyping;  Virtual reality, Computer-generated animations;  Creative activity;  Games;  Interactive narrative;  Interactive storytelling;  Real-world activities;  Storytelling;  User interaction, Animation},
publisher={Association for Computing Machinery, Inc},
isbn={9781450339285},
language={English},
abbrev_source_title={SIGGRAPH Asia Mobile Graph. Interact. Appl., SA},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Liou2016460,
author={Liou, W.-K. and Bhagat, K.K. and Chang, C.-Y.},
title={Beyond the Flipped Classroom: A Highly Interactive Cloud-Classroom (HIC) Embedded into Basic Materials Science Courses},
journal={Journal of Science Education and Technology},
year={2016},
volume={25},
number={3},
pages={460-473},
doi={10.1007/s10956-016-9606-8},
note={cited By 19},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84973891633&doi=10.1007%2fs10956-016-9606-8&partnerID=40&md5=50e60e1c8b531b247a7d6fa8ffbe157e},
affiliation={Science Education Center, National Taiwan Normal University, 88 Sec. 4, Ting-Chou Rd., Taipei, 116, Taiwan; Graduate Institute of Science Education, National Taiwan Normal University, Taipei, Taiwan; Department of Earth Sciences, National Taiwan Normal University, Taipei, Taiwan},
abstract={The present study compares the highly interactive cloud-classroom (HIC) system with traditional methods of teaching materials science that utilize crystal structure picture or real crystal structure model, in order to examine its learning effectiveness across three dimensions: knowledge, comprehension and application. The aim of this study was to evaluate the (HIC) system, which incorporates augmented reality, virtual reality and cloud-classroom to teach basic materials science courses. The study followed a pretest–posttest quasi-experimental research design. A total of 92 students (aged 19–20 years), in a second-year undergraduate program, participated in this 18-week-long experiment. The students were divided into an experimental group and a control group. The experimental group (36 males and 10 females) was instructed utilizing the HIC system, while the control group (34 males and 12 females) was led through traditional teaching methods. Pretest, posttest, and delayed posttest scores were evaluated by multivariate analysis of covariance. The results indicated that participants in the experimental group who used the HIC system outperformed the control group, in the both posttest and delayed posttest, across three learning dimensions. Based on these results, the HIC system is recommended to be incorporated in formal materials science learning settings. © 2016, Springer Science+Business Media New York.},
author_keywords={Augmented reality;  Cloud-classroom;  Highly interactive cloud-classroom;  Virtual reality},
correspondence_address1={Chang, C.-Y.; Science Education Center, National Taiwan Normal University, 88 Sec. 4, Ting-Chou Rd., Taiwan; email: changcy@ntnu.edu.tw},
publisher={Springer Netherlands},
issn={10590145},
language={English},
abbrev_source_title={J. Sci. Educ. Technol.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Wang2017162,
author={Wang, Y.-H.},
title={Exploring the effectiveness of integrating augmented reality-based materials to support writing activities},
journal={Computers and Education},
year={2017},
volume={113},
pages={162-176},
doi={10.1016/j.compedu.2017.04.013},
note={cited By 18},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020469165&doi=10.1016%2fj.compedu.2017.04.013&partnerID=40&md5=6631be82289fba42299179999b6ea276},
affiliation={Department of Educational Technology, Tamkang University, Taiwan},
abstract={In this study, whether using Augment Reality (AR)-based learning materials could benefit high school students in the process of Chinese writing was explored, along with the pros and cons of using AR for acquiring Chinese writing skills. In order to reduce the gap between the designers and practitioner teachers, Chinese instructors were invited to co-design the AR-based writing materials to achieve the integration of learners, teachers and educational system technology developers in a collaborative process. The AR-based writing support system was provided to a total of 30 twelfth-grade students who participated in the experiment. The students in the experimental group participated in the writing activity using both AR-based learning material and paper-based supports, while the control group worked with only paper-based writing support materials. The results revealed that the AR techniques helped the intermediate-level students the most in their writing performance of content control, article structure and wording. The students, especially the low-achievers, reflected that the functions of the AR system supported them to start writing the first paragraph more quickly, and enriched their ideas. A possible mode for integrating AR techniques in writing courses is proposed. This paper could serve as a reference for educators and learning technology researchers who wish to design AR-guided writing learning materials or courses with the goal of encouraging learners to experience the writing process in a variety of settings. © 2017 Elsevier Ltd},
author_keywords={Applications in subject areas;  Improving classroom teaching;  Interactive learning environments;  Interdisciplinary projects},
keywords={Augmented reality;  Computer aided instruction;  Curricula;  Education;  Learning systems;  Students, Applications in subject areas;  Collaborative process;  Experimental groups;  High school students;  Improving classroom teaching;  Interactive learning environment;  Interdisciplinary project;  Writing support system, Teaching},
publisher={Elsevier Ltd},
issn={03601315},
coden={COMED},
language={English},
abbrev_source_title={Comput Educ},
document_type={Article},
source={Scopus},
}

@ARTICLE{CózarGutiérrez2015138,
author={Cózar Gutiérrez, R. and Del Valle De Moya Martínez, M. and Hernández Bravo, J.A. and Hernández Bravo, J.R.},
title={Emerging technologies in social sciences teaching. An experience using Augmented Reality in teacher training [Tecnologías emergentes para la enseñanza de las Ciencias Sociales. Una experiencia con el uso de Realidad Aumentada en la formación inicial de maestros]},
journal={Digital Education Review},
year={2015},
number={27},
pages={138-153},
note={cited By 18},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84937468824&partnerID=40&md5=812dbb551dd348d2409fc909f63186ad},
affiliation={Universidad de Castilla-La Mancha, Spain},
abstract={Augmented Reality is considered one of the emerging technologies with the highest impact on teaching. The current paper shows a research about an educative experience carried out in university students, future teachers, in the field of social sciences, in order to know their opinion about Augmented Reality and its educational application. This study, which followed a mixed approach (quantitative and qualitative), was conducted among students in the Master Degree at the Faculty of Education in Albacete (University of Castilla-La Mancha) in the first term of academic year 2014/2015. LabinTic-RA Questionnaire (Cozar, De Moya, Hernandez and Hernandez, 2014) was administered to analyse students' perceptions about Augmented Reality. Thus, students' use in the teaching and learning process and their knowledge of this tool were taking into account for our research. Results revealed that students give a highly positive assessment to ICT and Augmented Reality for its educative benefits: motivation, interactive learning or significant acquisition of knowledge, among others. The virtualization of education is a reality, so it is necessary the teacher training in order to know and to use emerging educational technologies. © 2015 Digital Education Review.},
author_keywords={Augmented reality;  Emerging technologies;  Social sciences;  Teacher training},
publisher={Research Group Education and Virtual Learning (GREAV)},
issn={20139144},
language={Spanish},
abbrev_source_title={Digit. Educ. Rev.},
document_type={Review},
source={Scopus},
}

@ARTICLE{Flotyński20151287,
author={Flotyński, J. and Walczak, K.},
title={Conceptual knowledge-based modeling of interactive 3D content},
journal={Visual Computer},
year={2015},
volume={31},
number={10},
pages={1287-1306},
doi={10.1007/s00371-014-1011-9},
note={cited By 17},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84941024348&doi=10.1007%2fs00371-014-1011-9&partnerID=40&md5=9a60e3347dba106fc59e1d3fb845dce3},
affiliation={Department of Information Technology, Poznań University of Economics, Niepodległości 10, Poznañ, 61-875, Poland},
abstract={Three-dimensional content offers a powerful medium enabling rich, interactive visualization in virtual and augmented reality systems, which are increasingly used in a variety of application domains, such as education, training, tourism and cultural heritage. The creation of interactive 3D presentations is typically a complex process covering diverse aspects of the content such as geometry, structure, space, appearance, animation and behavior. Recent trends in the development of the semantic web provide new opportunities for simplifying 3D content creation, which may be performed at different levels of abstraction and may encompass the inference of hidden knowledge, which may influence the created content. However, the available approaches to 3D content creation do not enable conceptual knowledge-based modeling of 3D content. The main contribution of this paper is an approach to semantic creation of 3D content. The proposed solution leverages the semantic web techniques to enable conceptual, knowledge-driven content creation. The proposed approach has been implemented and evaluated. It has been shown that the approach can significantly simplify modeling of advanced 3D content presentations in comparison with the available approaches. © 2014, The Author(s).},
author_keywords={3D content;  3D web;  Ontology;  Semantic 3D;  Semantic web;  Virtual and augmented reality},
keywords={Augmented reality;  Knowledge based systems;  Ontology;  Semantic Web;  Social networking (online);  Visualization, 3D content;  3D web;  Conceptual knowledge;  Cultural heritages;  Interactive visualizations;  Levels of abstraction;  Semantic-Web techniques;  Virtual and augmented reality, Three dimensional computer graphics},
correspondence_address1={Flotyński, J.; Department of Information Technology, Poznań University of Economics, Niepodległości 10, Poland},
publisher={Springer Verlag},
issn={01782789},
coden={VICOE},
language={English},
abbrev_source_title={Visual Comput},
document_type={Article},
source={Scopus},
}

@ARTICLE{Frank201788,
author={Frank, J.A. and Kapila, V.},
title={Mixed-reality learning environments: Integrating mobile interfaces with laboratory test-beds},
journal={Computers and Education},
year={2017},
volume={110},
pages={88-104},
doi={10.1016/j.compedu.2017.02.009},
note={cited By 15},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016059169&doi=10.1016%2fj.compedu.2017.02.009&partnerID=40&md5=6788d601c127787091b21097bd1667d0},
affiliation={NYU Tandon School of Engineering, Mechanical and Aerospace Engineering Department, 6 MetroTech Center, Brooklyn, NY  11201, United States},
abstract={Even as mobile devices have become increasingly powerful and popular among learners and instructors alike, research involving their comprehensive integration into educational laboratory activities remains largely unexplored. This paper discusses efforts to integrate vision-based measurement and control, augmented reality (AR), and multi-touch interaction on mobile devices in the development of Mixed-Reality Learning Environments (MRLE) that enhance interactions with laboratory test-beds for science and engineering education. A learner points her device at a laboratory test-bed fitted with visual markers while a mobile application supplies a live view of the experiment augmented with interactive media that aid in the visualization of concepts and promote learner engagement. As the learner manipulates the augmented media, her gestures are mapped to commands that alter the behavior of the test-bed on the fly. Running in the background of the mobile application are algorithms performing vision-based estimation and wireless control of the test-bed. In this way, the sensing, storage, computation, and communication (SSCC) capabilities of mobile devices are leveraged to relieve the need for laboratory-grade equipment, improving the cost-effectiveness and portability of platforms to conduct hands-on laboratories. We hypothesize that students using the MRLE platform demonstrate improvement in their knowledge of dynamic systems and control concepts and have generally favorable experiences using the platform. To validate the hypotheses concerning the educational effectiveness and user experience of the MRLEs, an evaluation was conducted with two classes of undergraduate students using an illustrative platform incorporating a tablet computer and motor test-bed to teach concepts of dynamic systems and control. Results of the evaluation validate the hypotheses. The benefits and drawbacks of the MRLEs observed throughout the study are discussed with respect to the traditional hands-on, virtual, and remote laboratory formats. © 2017 Elsevier Ltd},
author_keywords={Applications in subject areas;  Architectures for educational technology system;  Improving classroom teaching;  Interactive learning environments;  Virtual reality},
keywords={Augmented reality;  Computer aided instruction;  Computer control systems;  Cost effectiveness;  Education;  Educational technology;  Equipment testing;  Human computer interaction;  Laboratories;  Mobile computing;  Mobile devices;  Mobile telecommunication systems;  Teaching;  Virtual reality, Applications in subject areas;  Architectures for educational technology system;  Comprehensive integrations;  Dynamic systems and controls;  Educational effectiveness;  Improving classroom teaching;  Interactive learning environment;  Vision-based measurements, Students},
correspondence_address1={Kapila, V.email: vkapila@nyu.edu},
publisher={Elsevier Ltd},
issn={03601315},
coden={COMED},
language={English},
abbrev_source_title={Comput Educ},
document_type={Article},
source={Scopus},
}

@ARTICLE{Laine2016548,
author={Laine, T.H. and Suk, H.J.},
title={Designing mobile augmented reality exergames},
journal={Games and Culture},
year={2016},
volume={11},
number={5},
pages={548-580},
doi={10.1177/1555412015572006},
note={cited By 15},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84974817898&doi=10.1177%2f1555412015572006&partnerID=40&md5=363222863033331b3a5185991972319a},
affiliation={Department of Information and Computer Engineering, Ajou University, Suwon, South Korea; Department of Digital Media, Ajou University, Sanhak Hall 414, San 5, Woncheon-dong, Yeongtong-gu, Suwon, 443-749, South Korea},
abstract={Exergames aim to make exercise more enjoyable, especially for children and young adults who are accustomed to digital technologies. Calory Battle augmented reality (AR) is a mobile exergame that utilizes context awareness and AR to enable interaction with virtual content. Designing mobile exergames and AR interaction has received little scholarly attention. This article has several contributions to the design discussion: (1) implementation of a mobile AR exergame, (2) discourse on the game design process, (3) evaluation with 29 South Korean elementary school children and university students who suggested a good reception of the game and generated ideas for improvements of usability and AR interaction, (4) analysis of the game with respect to established game motivators and the Immersion, Scientificalness, Competitiveness, Adaptability, and Learning (ISCAL) exergame design model, (5) design principles and lessons learned, and (6) discussion of the flow experience in exergames. These results can be used by designers to create motivating and interactive mobile AR games. © The Author(s) 2015.},
author_keywords={augmented reality;  context aware;  design;  exercise;  mobile game},
correspondence_address1={Suk, H.J.; Department of Digital Media, Ajou University, Sanhak Hall 414, San 5, Woncheon-dong, South Korea; email: dbdip@ajou.ac.kr},
publisher={SAGE Publications Inc.},
issn={15554120},
language={English},
abbrev_source_title={Games Cult.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Mota2018250,
author={Mota, J.M. and Ruiz-Rube, I. and Dodero, J.M. and Arnedillo-Sánchez, I.},
title={Augmented reality mobile app development for all},
journal={Computers and Electrical Engineering},
year={2018},
volume={65},
pages={250-260},
doi={10.1016/j.compeleceng.2017.08.025},
note={cited By 14},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028610028&doi=10.1016%2fj.compeleceng.2017.08.025&partnerID=40&md5=cfc9dde307c412429c80f4549ce23802},
affiliation={Department of Computer Engineering, University of Cádiz, Puerto Real (Cádiz), Spain; School of Computer Science and Statistics, Trinity College, Dublin, Ireland},
abstract={Lack of programming skills is a barrier to the engagement of teachers in the development and customisation of their own applications. Visual Environment for Designing Interactive Learning Scenarios (VEDILS), a visual tool for designing, customising and deploying learning technologies, provides teachers with a development environment with a low entry threshold. Current mobile devices are equipped with sensors and have sufficient processing power to use augmented reality technologies. Despite the heavy use of mobile devices in students’ lives, the use of augmented reality mobile applications as learning tools is not widespread among teachers. The current work presents a framework comprising the development tool and a method for designing and deploying learning activities. It focuses on the augmented reality components of the authoring tools, which allow users to create their own mobile augmented reality learning apps. It also present the results of the evaluation of the framework with 47 third-level educators, and two case studies of classroom implementations of mobile augmented reality apps developed by these educators. The results illustrate the suitability of the framework and authoring tool for supporting users without programming skills in developing their own apps. © 2017 Elsevier Ltd},
author_keywords={Augmented reality;  Learning activities;  Mobile learning;  Programming skills;  Visual language},
keywords={Augmented reality;  Teaching;  Visual languages, Augmented reality technology;  Classroom implementation;  Development environment;  Interactive learning;  Learning Activity;  Mobile augmented reality;  Mobile Learning;  Programming skills, Education},
correspondence_address1={Mota, J.M.; Department of Computer Engineering, University of Cádiz, Puerto Real (Cádiz), Spain; email: josemiguel.mota@uca.es},
publisher={Elsevier Ltd},
issn={00457906},
coden={CPEEB},
language={English},
abbrev_source_title={Comput Electr Eng},
document_type={Article},
source={Scopus},
}

@ARTICLE{FerreiradosSantos2016,
author={Ferreira dos Santos, L. and Christ, O. and Mate, K. and Schmidt, H. and Krüger, J. and Dohle, C.},
title={Movement visualisation in virtual reality rehabilitation of the lower limb: A systematic review},
journal={BioMedical Engineering Online},
year={2016},
volume={15},
doi={10.1186/s12938-016-0289-4},
art_number={144},
note={cited By 12},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85006511733&doi=10.1186%2fs12938-016-0289-4&partnerID=40&md5=5149159c4db43747e5582583d725751c},
affiliation={Technische Universität Berlin, Rehabilitation Robotics Group (TU Berlin/ Fraunhofer IPK), Department of Industrial Automation Technology, Pascalstr. 8-9, Berlin, 10587, Germany; Technische Universität Berlin, DFG Research Training Group Prometei, Marchstr. 23, Berlin, 10587, Germany; University of Applied Sciences and Arts Nortwestern Switzerland, Institute Humans in Complex Systems, School of Applied Psychology, Riggenbachstrasse 16, Olten, Switzerland; McGill University, School of Physical and Occupational Therapy, 3654 Promenade Sir William Osler Montreal, Quebec, H3G 1Y5, Canada; Fraunhofer Institute for Production Systems and Design Technology (IPK), Rehabilitation Robotics Group (Fraunhofer IPK/ TU Berlin), Department of Automation Technology, Pascalstr. 8-9, Berlin, 10587, Germany; MEDIAN Klinik Berlin-Kladow, Department of Neurological Rehabilitation, Kladower Damm 223, Berlin, 14089, Germany; Charité-University Medicine Berlin, Center for Stroke Research Berlin, Charitéplatz 1, Berlin, 10117, Germany},
abstract={Background: Virtual reality (VR) based applications play an increasing role in motor rehabilitation. They provide an interactive and individualized environment in addition to increased motivation during motor tasks as well as facilitating motor learning through multimodal sensory information. Several previous studies have shown positive effect of VR-based treatments for lower extremity motor rehabilitation in neurological conditions, but the characteristics of these VR applications have not been systematically investigated. The visual information on the user's movement in the virtual environment, also called movement visualisation (MV), is a key element of VR-based rehabilitation interventions. The present review proposes categorization of Movement Visualisations of VR-based rehabilitation therapy for neurological conditions and also summarises current research in lower limb application. Methods: A systematic search of literature on VR-based intervention for gait and balance rehabilitation in neurological conditions was performed in the databases namely; MEDLINE (Ovid), AMED, EMBASE, CINAHL, and PsycInfo. Studies using non-virtual environments or applications to improve cognitive function, activities of daily living, or psychotherapy were excluded. The VR interventions of the included studies were analysed on their MV. Results: In total 43 publications were selected based on the inclusion criteria. Seven distinct MV groups could be differentiated: indirect MV (N = 13), abstract MV (N = 11), augmented reality MV (N = 9), avatar MV (N = 5), tracking MV (N = 4), combined MV (N = 1), and no MV (N = 2). In two included articles the visualisation conditions included different MV groups within the same study. Additionally, differences in motor performance could not be analysed because of the differences in the study design. Three studies investigated different visualisations within the same MV group and hence limited information can be extracted from one study. Conclusions: The review demonstrates that individuals' movements during VR-based motor training can be displayed in different ways. Future studies are necessary to fundamentally explore the nature of this VR information and its effect on motor outcome. © 2016 The Author(s).},
keywords={Augmented reality;  Neurology;  Virtual reality;  Visualization, Activities of Daily Living;  Balance rehabilitations;  Cognitive functions;  Limited information;  Motor rehabilitation;  Rehabilitation therapy;  Sensory information;  Systematic searches, Neuromuscular rehabilitation, body movement;  gait;  human;  limb movement;  lower limb;  motor learning;  outcome assessment;  priority journal;  rehabilitation care;  Review;  robotics;  systematic review;  task performance;  virtual reality;  visual information;  visual stimulation;  body equilibrium;  computer interface;  computer simulation;  convalescence;  daily life activity;  lower limb;  motor performance;  movement (physiology);  Nervous System Diseases;  pathophysiology;  procedures;  stroke rehabilitation;  video game, Activities of Daily Living;  Computer Simulation;  Gait;  Humans;  Lower Extremity;  Motor Skills;  Movement;  Nervous System Diseases;  Postural Balance;  Recovery of Function;  Stroke Rehabilitation;  User-Computer Interface;  Video Games},
correspondence_address1={Ferreira dos Santos, L.; Technische Universität Berlin, Rehabilitation Robotics Group (TU Berlin/ Fraunhofer IPK), Department of Industrial Automation Technology, Pascalstr. 8-9, Germany; email: luara.santos@iwf.tu-berlin.de},
publisher={BioMed Central Ltd.},
issn={1475925X},
coden={BEOIB},
pubmed_id={28105952},
language={English},
abbrev_source_title={Biomed. Eng. Online},
document_type={Review},
source={Scopus},
}

@CONFERENCE{Wozniak2016,
author={Wozniak, P. and Vauderwange, O. and Mandal, A. and Javahiraly, N. and Curticapean, D.},
title={Possible applications of the LEAP motion controller for more interactive simulated experiments in augmented or virtual reality},
journal={Proceedings of SPIE - The International Society for Optical Engineering},
year={2016},
volume={9946},
doi={10.1117/12.2237673},
art_number={99460P},
note={cited By 11},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85006867007&doi=10.1117%2f12.2237673&partnerID=40&md5=2737a8aa0396e8dab541cc3b9a8938ce},
affiliation={Offenburg University, Badstr. 24, Offenburg, 77652, Germany; University of Strasbourg, ICube, Boulevard Sébasten Brant, BP 10413, Illkirch, F-67412, France},
abstract={Practical exercises are a crucial part of many curricula. Even simple exercises can improve the understanding of the underlying subject. Most experimental setups require special hardware. To carry out e. g. a lens experiments the students need access to an optical bench, various lenses, light sources, apertures and a screen. In our previous publication we demonstrated the use of augmented reality visualization techniques in order to let the students prepare with a simulated experimental setup. Within the context of our intended blended learning concept we want to utilize augmented or virtual reality techniques for stationary laboratory exercises. Unlike applications running on mobile devices, stationary setups can be extended more easily with additional interfaces and thus allow for more complex interactions and simulations in virtual reality (VR) and augmented reality (AR). The most significant difference is the possibility to allow interactions beyond touching a screen. The LEAP Motion controller is a small inexpensive device that allows for the tracking of the user's hands and fingers in three dimensions. It is conceivable to allow the user to interact with the simulation's virtual elements by the user's very hand position, movement and gesture. In this paper we evaluate possible applications of the LEAP Motion controller for simulated experiments in augmented and virtual reality. We pay particular attention to the devices strengths and weaknesses and want to point out useful and less useful application scenarios. © 2016 SPIE.},
author_keywords={Augmented reality;  Blended learning;  Education;  Human-computer interaction;  LEAP motion;  Practical lectures;  Virtual reality},
keywords={Augmented reality;  Controllers;  Education;  Human computer interaction;  Lenses;  Light sources;  Motion control;  Students;  Touch screens, Application scenario;  Augmented and virtual realities;  Blended learning;  LEAP motion;  Practical lectures;  Reality visualization;  Simulated experiments;  Virtual reality techniques, Virtual reality},
editor={Gregory G.G.},
publisher={SPIE},
issn={0277786X},
isbn={9781510602830},
coden={PSISD},
language={English},
abbrev_source_title={Proc SPIE Int Soc Opt Eng},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Orlosky201557,
author={Orlosky, J. and Weber, M. and Gu, Y. and Sonntag, D. and Sosnovsky, S.},
title={An interactive pedestrian environment simulator for cognitive monitoring and evaluation},
journal={International Conference on Intelligent User Interfaces, Proceedings IUI},
year={2015},
volume={29-March-2015},
pages={57-60},
doi={10.1145/2732158.2732175},
note={cited By 11},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84944709344&doi=10.1145%2f2732158.2732175&partnerID=40&md5=2d9bcab8646f94f2d99316d89381d453},
affiliation={German Research Center for Artificial Intelligence (DFKI), Stuhlsatzenhausweg 3, Saarbruecken, D-66123, Germany},
abstract={Recent advances in virtual and augmented reality have led to the development of a number of simulations for different applications. In particular, simulations for monitoring, evaluation, training, and education have started to emerge for the consumer market due to the availability and affordability of immersive display technology. In this work, we introduce a virtual reality environment that provides an immersive traffic simulation designed to observe behavior and monitor relevant skills and abilities of pedestrians who may be at risk, such as elderly persons with cognitive impairments. The system provides basic reactive functionality, such as display of navigation instructions and notifications of dangerous obstacles during navigation tasks. Methods for interaction using hand and arm gestures are also implemented to allow users explore the environment in a more natural manner. © Copyright 2015 by the Association for Computing Machinery, Inc. (ACM).},
author_keywords={Cognitive Monitoring;  Evaluation;  Interaction;  Simulation;  Virtual Reality},
keywords={Augmented reality;  User interfaces, Cognitive monitoring;  Environment simulators;  Evaluation;  Interaction;  Reactive functionality;  Simulation;  Virtual and augmented reality;  Virtual-reality environment, Virtual reality},
publisher={Association for Computing Machinery},
isbn={9781450333085},
language={English},
abbrev_source_title={Int Conf Intell User Interfaces Proc IUI},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{BarrazaCastillo2015,
author={Barraza Castillo, R.I. and Cruz Sánchez, V.G. and Vergara Villegas, O.O.},
title={A pilot study on the Use of mobile augmented reality for interactive experimentation in quadratic equations},
journal={Mathematical Problems in Engineering},
year={2015},
volume={2015},
doi={10.1155/2015/946034},
art_number={946034},
note={cited By 11},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84924559814&doi=10.1155%2f2015%2f946034&partnerID=40&md5=18d5cf9b25d5c2bb2b1bd7e0706b4398},
affiliation={Engineering and Technology Institute, Ciudad Juárez Autonomous University, Avenida del Charro 450 Norte, Colonia Partido Romero, Ciudad Juárez, 32310, Mexico},
abstract={Recent studies have reported that the inclusion of new technological elements such as augmented reality (AR), for educational purposes, increases the learning interest and motivation of students. However, developing AR applications, especially with mobile content, is still a rather technical subject; thus the dissemination of the technology in the classroom has been rather limited. This paper presents a new software architecture for AR application development based on freely available components; it provides a detailed view of the subsystems and tasks that encompass the creation of a mobile AR application. The typical task of plotting a quadratic equation was selected as a case study to obtain feasibility insights on how AR could support the teaching-learning process and to observe the student's reaction to the technology and the particular application. The pilot study was conducted with 59 students at a Mexican undergraduate school. A questionnaire was created in order to obtain information about the students' experience using the AR application and the analysis of the results obtained is presented. The comments expressed by the users after the AR experience are positive, supporting the premise that AR can be, in the future, a valuable complimentary teaching tool for topics that benefit from contextual learning experience and multipoint visualization, such as the quadratic equation. © 2015 Ramón Iván Barraza Castillo et al.},
keywords={Application programs;  Augmented reality;  Education;  Engineering education;  Teaching, Contextual learning;  Mobile augmented reality;  Mobile content;  Quadratic equations;  Teaching-learning process;  Technical subjects;  Technology in the classroom;  Undergraduate schools, Students},
correspondence_address1={Vergara Villegas, O.O.; Engineering and Technology Institute, Ciudad Juárez Autonomous University, Avenida del Charro 450 Norte, Mexico},
publisher={Hindawi Publishing Corporation},
issn={1024123X},
language={English},
abbrev_source_title={Math. Probl. Eng.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Turkan201790,
author={Turkan, Y. and Radkowski, R. and Karabulut-Ilgu, A. and Behzadan, A.H. and Chen, A.},
title={Mobile augmented reality for teaching structural analysis},
journal={Advanced Engineering Informatics},
year={2017},
volume={34},
pages={90-100},
doi={10.1016/j.aei.2017.09.005},
note={cited By 10},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031736734&doi=10.1016%2fj.aei.2017.09.005&partnerID=40&md5=cb3b4172b50b4fd746d6d03db9ae1c40},
affiliation={School of Civil and Construction Engineering, Oregon State University, Corvallis, OR  97331, United States; Department of Mechanical Engineering, Iowa State University, Ames, IA  50011, United States; Department of Civil, Construction and Environmental Engineering, Iowa State University, Ames, IA  50011, United States; Department of Construction Science, Texas A&M University, College Station, TX  77843, United States},
abstract={Structural analysis is an introductory core course that is taught in every civil engineering program as well as in most architectural and construction engineering programs. Previous research unveils students' deficits in understanding the behavior of structural elements in a three-dimensional (3D) context due to the shortcomings of traditional lecturing approaches, which put too much emphasis on the analysis of individual structural members, thereby falling short in providing a solid, easy-to-follow, and holistic approach to analyzing complex structures with a large number of interconnected elements. In this paper, the authors introduce a new pedagogy for teaching structural analysis that incorporates mobile augmented reality (AR) and interactive 3D visualization technology. The goal of this study is to enhance the contents used in structural analysis textbooks and on worksheets by visualizing discrete structural members employing AR along with interactive 3D models in order to illustrate how the structures behave under different loading conditions. Students can interactively change the load and observe the reaction resulting from this change with the instant feedback provided by the AR interface. The feasibility of AR concepts and interaction metaphors, as well as the potential of using AR for teaching structural analysis are investigated, specifically by focusing on challenges regarding content integration and interaction. An AR application is designed and developed, and a pilot study is conducted in a junior level structural analysis class to assess the pedagogical impact and the design concepts employed by the AR tool. Control and test groups are deployed, and students’ performance is measured using pre- and post-tests. The results of the pilot study indicate that the utilized AR design concepts have potential to contribute to students’ learning by providing interactive and 3D visualization features, which support constructive engagement and retention of information in students. © 2017 Elsevier Ltd},
keywords={Augmented reality;  Education;  Structural members;  Students;  Teaching;  Three dimensional computer graphics;  Visualization, Civil engineering programs;  Construction engineering;  Interaction metaphors;  Interactive 3-D models;  Interactive 3d visualizations;  Mobile augmented reality;  Structural elements;  Threedimensional (3-d), Structural analysis},
correspondence_address1={Turkan, Y.; School of Civil and Construction Engineering, Oregon State UniversityUnited States; email: yelda.turkan@oregonstate.edu},
publisher={Elsevier Ltd},
issn={14740346},
language={English},
abbrev_source_title={Adv. Eng. Inf.},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Ibáñiez2016307,
author={Ibáñiez, M.-B. and Di Scrio, A. and Villarán, D. and Delgado-Kloos, C.},
title={The acceptance of learning augmented reality environments: A case study},
journal={Proceedings - IEEE 16th International Conference on Advanced Learning Technologies, ICALT 2016},
year={2016},
pages={307-311},
doi={10.1109/ICALT.2016.124},
art_number={7756984},
note={cited By 10},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85006942600&doi=10.1109%2fICALT.2016.124&partnerID=40&md5=34129962fb36cc7b0fc710331ab4fdbb},
affiliation={Departamento de Ingenieria Telematica, Universidad Carlos III de Madrid, Madrid, Spain; Dpto. de Computation Y Teenologia de la Informacion, Universidad Simon Bolivar, Caracas, Venezuela},
abstract={The aim of this study was to investigate the attitude of learners toward an augmented reality learning activity designed to help engineering students to solve an electromagnetic problem. The sample was 122 students. Students were asked to complete a survey questionnaire based on the Technology Acceptance Model (TAM) enhanced with perceived enjoyment items. The results of the evaluation show that intention of use the system is dependent of perceived enjoyment hut not from perceived usefulness of the learning tool. © 2016 IEEE.},
author_keywords={Assessment;  Augmented reality;  Interactive learning environments;  Technology acceptance model},
keywords={Augmented reality;  Computer aided instruction;  Knowledge acquisition;  Learning systems;  Students;  Surveys, Assessment;  Electromagnetic problems;  Interactive learning environment;  Learning tool;  Perceived enjoyment;  Perceived usefulness;  Reality learning;  Technology acceptance model, Engineering education},
editor={Spector J.M., Tsai C.-C., Huang R., Resta P., Sampson D.G., Kinshuk, Chen N.-S.},
publisher={Institute of Electrical and Electronics Engineers Inc.},
isbn={9781467390415},
language={English},
abbrev_source_title={Proc. - IEEE Int. Conf. Adv. Learn. Technol., ICALT},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{deRavé20169641,
author={de Ravé, E.G. and Jiménez-Hornero, F.J. and Ariza-Villaverde, A.B. and Taguas-Ruiz, J.},
title={DiedricAR: a mobile augmented reality system designed for the ubiquitous descriptive geometry learning},
journal={Multimedia Tools and Applications},
year={2016},
volume={75},
number={16},
pages={9641-9663},
doi={10.1007/s11042-016-3384-4},
note={cited By 10},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84960078835&doi=10.1007%2fs11042-016-3384-4&partnerID=40&md5=7a109722a93dc7cab79691f6f50f7d51},
affiliation={Department of Graphic Engineering, University of Córdoba, Gregor Mendel Building, Campus Rabanales, Córdoba, 14071, Spain},
abstract={This article presents a mobile Augmented Reality system, called DiedricAR, aimed at the learning of Descriptive Geometry. Thanks to its ability to recreate virtual models in real space, Augmented Reality is a technology suitable for making Descriptive Geometry comprehension and interpretation easier. The DiedricAR application allows students to learn in autonomously way by using their own mobile devices (smartphones and tablets), that work as Augmented Reality displays over training material (DiedricAR exercise workbook) specially designed for the new learning model defined by the European Higher Education System. Compared to some of the existing Augmented Reality systems used to learn Descriptive Geometry, DiedricAR offers the advantage of being specifically developed for mobile devices giving the students the possibility of using ubiquitous learning to its ultimate extent by interacting with the didactical content (i.e. showing the desired intermediate step when solving dihedral exercises). The presentation of DiedricAR is completed by exploring some key items such as the potential benefits for students’ spatial ability, the relationship between application design and user experience, and software performance on several mobile devices. © 2016, Springer Science+Business Media New York.},
author_keywords={Descriptive geometry;  Interactive learning environments;  Mobile augmented reality},
keywords={Application programs;  Computer aided instruction;  Display devices;  Education;  Education computing;  Geometry;  Mobile devices;  Students, Augmented reality systems;  Descriptive geometry;  Higher education system;  Interactive learning environment;  Mobile augmented reality;  Potential benefits;  Software performance;  Ubiquitous learning, Augmented reality},
correspondence_address1={de Ravé, E.G.; Department of Graphic Engineering, University of Córdoba, Gregor Mendel Building, Campus Rabanales, Spain; email: eduardo@uco.es},
publisher={Springer New York LLC},
issn={13807501},
coden={MTAPF},
language={English},
abbrev_source_title={Multimedia Tools Appl},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Kraut2015755,
author={Kraut, B. and Jeknić, J.},
title={Improving education experience with augmented reality (AR)},
journal={2015 38th International Convention on Information and Communication Technology, Electronics and Microelectronics, MIPRO 2015 - Proceedings},
year={2015},
pages={755-760},
doi={10.1109/MIPRO.2015.7160372},
art_number={7160372},
note={cited By 10},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84946121617&doi=10.1109%2fMIPRO.2015.7160372&partnerID=40&md5=6265fb01402d67b6940d455bd210ec7a},
affiliation={Alcyone D. O. O., Maribor, Slovenia},
abstract={In the modern world, information is everything. It is important that it can be accessed from anywhere and at any time. What is even more important is that information must be relevant to the user and presented in such a manner that it is easily understood. Emerging technologies, such as augmented reality (AR) might within short period of time be widely accepted, as smart-phones are today. If this happens, it will probably change the way we perceive information and our reality. AR is not hype any more - it is a solid technology that is already used in some creative applications. One area which might significantly benefit in the future from this technology is the education process. AR tools could guide students through learning process in enhanced way, as AR can upgrade traditional books with a digital layer. We think it will improve both, teaching and learning experience, and bring interactive dimension into the whole picture. We also predict that this new layer will encompass several senses which could speed up memorization process. Furthermore, AR learning method might raise common understanding of the learning material. Moreover, learning activities could be supervised by a mentor or automated process which might also lead to a lower school dropout rate. Our still-in-progress ARAVET project is exploring mentioned predictions about AR learning method. We will present the results we have so far. © 2015 MIPRO.},
keywords={Automation;  Learning systems;  Microelectronics;  Smartphones, Automated process;  Education process;  Emerging technologies;  Learning Activity;  Learning materials;  Learning methods;  Learning process;  Teaching and learning, Augmented reality},
editor={Sruk V., Butkovic Z., Vrdoljak B., Sokolic A., Gros S., Biljanovic P., Skala K., Ribaric S., Mikac B., Cicin-Sain M., Mauher M.},
publisher={Institute of Electrical and Electronics Engineers Inc.},
isbn={9789532330854},
language={English},
abbrev_source_title={Int. Conv. Inf. Commun. Technol., Electron. Microelectron., MIPRO - Proc.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Shirazi2015,
author={Shirazi, A. and Behzadan, A.H.},
title={Design and assessment of a mobile augmented reality-based information delivery tool for construction and civil engineering curriculum},
journal={Journal of Professional Issues in Engineering Education and Practice},
year={2015},
volume={141},
number={3},
doi={10.1061/(ASCE)EI.1943-5541.0000229},
art_number={4014012},
note={cited By 10},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84931480438&doi=10.1061%2f%28ASCE%29EI.1943-5541.0000229&partnerID=40&md5=8a634c6d655bc2bcc9e70868f5ef4976},
affiliation={Dept. of Civil, Environmental, and Construction Engineering, Univ. of Central Florida, Orlando, FL  32816-2450, United States},
abstract={The goal of the research reported in this paper is to design and systematically assess the effectiveness of a collaborative context-aware mobile augmented reality tool (CAM-ART) in construction and civil engineering curriculum. To achieve this goal, an augmented reality (AR)-based information delivery tool, CAM-ART, was implemented in classroom-scale experiments to enhance traditional lecture-based instruction and information delivery methods. In the research reported in this paper, the contents of an ordinary textbook were enhanced using computer-generated three-dimensional (3D) objects and other virtual multimedia (e.g., sound, video, and graphs), and delivered to students through an AR application running on their smartphones or tablet computers. The sample consisted of construction and civil engineering students, who were randomly assigned to Group A (control group) and Group B (test group). The designed learning tool was tested in a collaborative and interactive environment, preperformance and postperformance data was collected, and student perception of using the AR-based tool was elicited through a feedback questionnaire. Data analysis showed that CAM-ART had a measurable and positive impact on students' learning both in short-term and long-term. Moreover, results of the feedback questionnaire indicated that students found CAM-ART to be an interesting, helpful, and motivational approach in the classroom that helped them gain more in-depth and long-lasting knowledge beyond what is normally expected from traditional lecture-based teaching methods. © 2014 American Society of Civil Engineers.},
author_keywords={Assessment;  Augmented reality;  Construction and civil engineering;  Curriculum;  Engineering education},
keywords={Augmented reality;  Cams;  Curricula;  Education;  Engineering education;  Surveys;  Teaching;  Three dimensional computer graphics, Assessment;  Civil engineering curricula;  Civil engineering students;  Information delivery;  Interactive Environments;  Mobile augmented reality;  Student perceptions;  Three-dimensional (3D) objects, Students},
correspondence_address1={Behzadan, A.H.; Dept. of Civil, Environmental, and Construction Engineering, Univ. of Central FloridaUnited States},
publisher={American Society of Civil Engineers (ASCE)},
issn={10523928},
coden={JPEPE},
language={English},
abbrev_source_title={J Prof Issues Eng Educ Pract},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Bazzaza2015495,
author={Bazzaza, M.W. and Al Delail, B. and Zemerly, M.J. and Ng, J.W.P.},
title={IARBook: An Immersive Augmented Reality system for education},
journal={Proceedings of IEEE International Conference on Teaching, Assessment and Learning for Engineering: Learning for the Future Now, TALE 2014},
year={2015},
pages={495-498},
doi={10.1109/TALE.2014.7062576},
art_number={7062576},
note={cited By 10},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84928252376&doi=10.1109%2fTALE.2014.7062576&partnerID=40&md5=6f9dbfb136932bb4e6e817d6c36070b1},
affiliation={Electrical and Computer Engineering Department, Khalifa University of Science, Technology and Research, Abu Dhabi, United Arab Emirates; Etisalat BT Innovation Center (EBTIC), BT Innovate and Design, Abu Dhabi, United Arab Emirates},
abstract={The advancement in technology nowadays has improved learning methods that are beginning to override the traditional methods. Augmented Reality (AR) is one such technology that has seen many applications in education. This paper describes how an Immersive Augmented Reality (iAR) application in conjunction with a book, can act as a new smart learning method by engaging as many of the user's senses and human functions as possible. In addition, a survey was conducted on students and educators who have tested the application. The purpose of the survey is to study the effectiveness of the application in enhancing the user's learning experience and help to devise plans to improve the system. © 2014 IEEE.},
author_keywords={Augmented Reality;  Edutainment;  Immersive Augmented Reality;  Interactive Learning;  Smart Education},
keywords={Educational technology;  Learning systems;  Surveys, Applications in educations;  Edutainment;  Immersive augmented realities;  Interactive learning;  Learning experiences;  Learning methods, Augmented reality},
publisher={Institute of Electrical and Electronics Engineers Inc.},
isbn={9781479976720},
language={English},
abbrev_source_title={Proc. IEEE Int. Conf. Teach., Assess. Learn. Eng.: Learn. Future Now, TALE},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{AlvesFernandes2016907,
author={Alves Fernandes, L.M. and Cruz Matos, G. and Azevedo, D. and Rodrigues Nunes, R. and Paredes, H. and Morgado, L. and Barbosa, L.F. and Martins, P. and Fonseca, B. and Cristóvão, P. and de Carvalho, F. and Cardoso, B.},
title={Exploring educational immersive videogames: an empirical study with a 3D multimodal interaction prototype},
journal={Behaviour and Information Technology},
year={2016},
volume={35},
number={11},
pages={907-918},
doi={10.1080/0144929X.2016.1232754},
note={cited By 9},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84989225680&doi=10.1080%2f0144929X.2016.1232754&partnerID=40&md5=eaf4dcc94e748b1207b24a161fe731d9},
affiliation={Engineering Department, Universidade de Trás-os-Montes, Vila Real, Portugal; INESC TEC, Porto, Portugal; Science and Technology Department, Universidade Aberta, Lisboa, Portugal; Communication, Art and Design Department, Universidade do Algarve, Faro, Portugal; Altice Labs, Aveiro, Portugal},
abstract={Gestural interaction devices emerged and originated various studies on multimodal human–computer interaction to improve user experience (UX). However, there is a knowledge gap regarding the use of these devices to enhance learning. We present an exploratory study which analysed the UX with a multimodal immersive videogame prototype, based on a Portuguese historical/cultural episode. Evaluation tests took place in high school environments and public videogaming events. Two users would be present simultaneously in the same virtual reality (VR) environment: one as the helmsman aboard Vasco da Gama’s fifteenth-century Portuguese ship and the other as the mythical Adamastor stone giant at the Cape of Good Hope. The helmsman player wore a VR headset to explore the environment, whereas the giant player used body motion to control the giant, and observed results on a screen, with no headset. This allowed a preliminary characterisation of UX, identifying challenges and potential use of these devices in multi-user virtual learning contexts. We also discuss the combined use of such devices, towards future development of similar systems, and its implications on learning improvement through multimodal human–computer interaction. © 2016 Informa UK Limited, trading as Taylor & Francis Group.},
author_keywords={augmented reality;  digital game-based learning;  gesture interaction;  Multimodal interaction;  user experience;  virtual reality},
keywords={Augmented reality;  E-learning;  Interactive computer systems;  User interfaces;  Virtual reality, Computer interaction;  Digital game-based learning;  Exploratory studies;  Gestural interaction;  Gesture interaction;  Multi-Modal Interactions;  User experience;  User experiences (ux), Human computer interaction, body movement;  empiricism;  exploratory research;  gesture;  high school;  human;  human experiment;  learning;  video game;  virtual reality},
correspondence_address1={Alves Fernandes, L.M.; Engineering Department, Universidade de Trás-os-MontesPortugal; email: lfernandes@utad.pt},
publisher={Taylor and Francis Ltd.},
issn={0144929X},
coden={BEITD},
language={English},
abbrev_source_title={Behav Inf Technol},
document_type={Article},
source={Scopus},
}

@ARTICLE{Kim201726001,
author={Kim, H. and Matuszka, T. and Kim, J.-I. and Kim, J. and Woo, W.},
title={Ontology-based mobile augmented reality in cultural heritage sites: information modeling and user study},
journal={Multimedia Tools and Applications},
year={2017},
volume={76},
number={24},
pages={26001-26029},
doi={10.1007/s11042-017-4868-6},
note={cited By 8},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020656902&doi=10.1007%2fs11042-017-4868-6&partnerID=40&md5=7960f90629179b009c6ff14fcacf341b},
affiliation={Graduate School of Culture Technology, KAIST, Daejeon, South Korea; Department of Information Systems, Eötvös Loránd University, Budapest, Hungary},
abstract={Augmented reality (AR) has received much attention in the cultural heritage domain as an interactive medium for requesting and accessing information regarding heritage sites. In this study, we developed a mobile AR system based on Semantic Web technology to provide contextual information about cultural heritage sites. Most location-based AR systems are designed to present simple information about a point of interest (POI), but the proposed system offers information related to various aspects of cultural heritage, both tangible and intangible, linked to the POI. This is achieved via an information modeling framework where a cultural heritage ontology is used to aggregate heterogeneous data and semantically connect them with each other. We extracted cultural heritage data from five web databases and modeled contextual information for a target heritage site (Injeongjeon Hall and its vicinity in Changdeokgung Palace in South Korea) using the selected ontology. We then implemented a mobile AR application and conducted a user study to assess the learning and engagement impacts of the proposed system. We found that the application provides an agreeable user experience in terms of its affective, cognitive, and operative features. The results of our analysis showed that specific usage patterns were significant with regard to learning outcomes. Finally, we explored how the study’s key findings can provide practical design guidance for system designers to enhance mobile AR information systems for heritage sites, and to show system designers how to support particular usage patterns in order to accommodate specific user experiences better. © 2017, Springer Science+Business Media New York.},
author_keywords={Augmented reality;  Contextual information;  Cultural heritage;  Heritage site;  Mobile application;  Ontology},
keywords={Augmented reality;  Data mining;  Information systems;  Information theory;  Systems analysis, Contextual information;  Cultural heritages;  Heritage sites;  Information Modeling;  Information modeling frameworks;  Mobile applications;  Mobile augmented reality;  Semantic Web technology, Ontology},
correspondence_address1={Kim, H.; Graduate School of Culture Technology, KAISTSouth Korea; email: hayunkim@kaist.ac.kr},
publisher={Springer New York LLC},
issn={13807501},
coden={MTAPF},
language={English},
abbrev_source_title={Multimedia Tools Appl},
document_type={Article},
source={Scopus},
}

@ARTICLE{Lin2016103,
author={Lin, C.-Y. and Yu, W.-J. and Chen, W.-J. and Huang, C.-W. and Lin, C.-C.},
title={The effect of literacy learning via mobile augmented reality for the students with ADHD and reading disabilities},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2016},
volume={9739},
pages={103-111},
doi={10.1007/978-3-319-40238-3_11},
note={cited By 8},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84978924607&doi=10.1007%2f978-3-319-40238-3_11&partnerID=40&md5=54a80065ab748357b4b52dd29bd21294},
affiliation={Department of Special Education, National University of Tainan, Tainan, 70005, Taiwan; National University, Tainan Affiliated Primary School, Tainan, 70005, Taiwan; Department of Tourism, Food and Beverage Management, Chang Jung Christian University, Tainan, 711, Taiwan},
abstract={This study focuses on the effects of mobile augmented reality (MAR) on word recognition learning. The study developed an interactive effect and corresponding video on word learning in MAR. MAR uses the camera of the mobile phone. It is installed in to interpose virtual objects on the real life view through the camera. The study participants were two fifth-grade elementary school children with Attention Deficit Hyperactivity Disorder (ADHD) and reading disabilities. The study followed a single-case design using ABA’ models in which A indicated the baseline, B indicated the intervention and A’ indicated the maintenance phrase. The experiment period was almost 3 months. The independent variable was word recognition teaching with MAR on Chinese literacy ability of ‘read the words’ and ‘select the correct the word to blank line’. The experimental results demonstrated that the scores for 2 children with ADHD and reading disabilities increased considerably during the intervention and maintenance phrases. The developmental applications of these results are also discussed. © Springer International Publishing Switzerland 2016.},
author_keywords={ADHD;  Mobile augmented reality;  Performance of word recognition;  Reading disability},
keywords={Augmented reality;  Cameras;  E-learning;  Vocabulary control, ADHD;  Attention deficit hyperactivity disorder;  Elementary schools;  Independent variables;  Interactive effect;  Mobile augmented reality;  Reading disability;  Word recognition, Human computer interaction},
correspondence_address1={Lin, C.-Y.; Department of Special Education, National University of TainanTaiwan; email: linchienyu@mail.nutn.edu.tw},
editor={Antona M., Stephanidis C.},
publisher={Springer Verlag},
issn={03029743},
isbn={9783319402376},
language={English},
abbrev_source_title={Lect. Notes Comput. Sci.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Alhumaidan2015427,
author={Alhumaidan, H. and Lo, K.P.Y. and Selby, A.},
title={Co-design of augmented reality book for collaborative learning experience in primary education},
journal={IntelliSys 2015 - Proceedings of 2015 SAI Intelligent Systems Conference},
year={2015},
pages={427-430},
doi={10.1109/IntelliSys.2015.7361175},
art_number={7361175},
note={cited By 8},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84962755729&doi=10.1109%2fIntelliSys.2015.7361175&partnerID=40&md5=0230d78b9a98dcef635860583604c822},
affiliation={School of the Arts, University Lougborough, Loughborough, United Kingdom},
abstract={Through co-design of Augmented Reality (AR) based teaching material, this research aims to enhance collaborative learning experience in primary school education. It will introduce an interactive AR Book based on primary school textbook using tablets as the real time interface. The development of this AR Book employs co-design methods to involve children, teachers, educators and HCI experts from the early stages of the design process. Research insights from the co-design phase will be implemented in the AR Book design. The final outcome of the AR Book will be evaluated in the classroom to explore its effect on the collaborative experience of primary school students. The research aims to answer the question-Can Augmented Books be designed for primary school students in order to support collaboration? This main research question is divided into two sub-questions as follows-How can co-design methods be applied in designing Augmented Book with and for primary school children? And what is the effect of the proposed Augmented Book on primary school students' collaboration? This research will not only present a practical application of co-designing AR Book for and with primary school children, it will also clarify the benefit of AR for education in terms of collaborative experience. © 2015 IEEE.},
author_keywords={augmented book;  Augmented reality;  child-computer-interaction;  co-design;  collaborative learning;  cooperative inquiry},
keywords={Augmented reality;  Design;  Intelligent systems;  Students;  Teaching, Augmented book;  Child-computer interactions;  Co-designs;  Collaborative learning;  Cooperative Inquiry, Education},
publisher={Institute of Electrical and Electronics Engineers Inc.},
isbn={9781467376068},
language={English},
abbrev_source_title={IntelliSys - Proc. SAI Intell. Syst. Conf.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Joda201993,
author={Joda, T. and Gallucci, G.O. and Wismeijer, D. and Zitzmann, N.U.},
title={Augmented and virtual reality in dental medicine: A systematic review},
journal={Computers in Biology and Medicine},
year={2019},
volume={108},
pages={93-100},
doi={10.1016/j.compbiomed.2019.03.012},
note={cited By 7},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064214534&doi=10.1016%2fj.compbiomed.2019.03.012&partnerID=40&md5=801fa48a3c824ae774ee788588a04c6d},
affiliation={Department of Reconstructive Dentistry, University Center for Dental Medicine Basel, University of Basel, Switzerland, Hebelstr. 3, Basel, CH-4056, Switzerland; Department of Restorative Dentistry and Biomaterials Sciences, Harvard School of Dental Medicine Boston, USA, 188 Longwood Ave, Boston, MA  02115, United States; Department of Oral Implantology and Prosthetic Dentistry, Academic Center for Dentistry Amsterdam, The Netherlands, Gustav Mahlerlaan 3004, Amsterdam, LA  1081, Netherlands},
abstract={Background: The aim of this systematic review was to provide an update on the contemporary knowledge and scientific development of augmented reality (AR) and virtual reality (VR) in dental medicine, and to identify future research needs to accomplish its clinical translation. Method: A modified PICO-strategy was performed using an electronic (MEDLINE, EMBASE, CENTRAL) plus manual search up to 12/2018 exploring AR/VR in dentistry in the last 5 years. Inclusion criteria were limited to human studies focusing on the clinical application of AR/VR and associated field of interest in dental medicine. Results: The systematic search identified 315 titles, whereas 87 abstracts and successively 32 full-texts were selected for review, resulting in 16 studies for final inclusion. AR/VR-technologies were predominantly used for educational motor skill training (n = 9 studies), clinical testing of maxillofacial surgical protocols (n = 5), investigation of human anatomy (n = 1), and the treatment of patients with dental phobia (n = 1). Due to the heterogeneity of the included studies, meta-analyses could not be performed. Conclusions: The overall number of includable studies was low; and scientifically proven recommendations for clinical protocols could not be given at this time. However, AR/VR-applications are of increasing interest and importance in dental under- and postgraduate education offering interactive learning concepts with 24/7-access and objective evaluation. In maxillofacial surgery, AR/VR-technology is a promising tool for complex procedures and can help to deliver predictable and safe therapy outcomes. Future research should focus on establishing technological standards with high data quality and developing approved applications for dental AR/VR-devices for clinical routine. © 2019 Elsevier Ltd},
author_keywords={Augmented reality (AR);  Computer simulation;  Dentistry;  Oral medicine;  Systematic review;  Virtual reality (VR)},
keywords={Augmented reality;  Computer simulation;  Dentistry;  Surgery;  Virtual reality, Augmented and virtual realities;  Clinical application;  Maxillofacial surgery;  Objective evaluation;  Postgraduate education;  Scientific development;  Systematic Review;  Technological standards, Clinical research, dental phobia;  dentistry;  functional anatomy;  human;  maxillofacial surgery;  motor performance;  postgraduate education;  priority journal;  Review;  systematic review;  virtual reality},
correspondence_address1={Joda, T.; Department of Reconstructive Dentistry, University Center for Dental Medicine Basel, UZB, University of Basel, Switzerland, Hebelstr. 3, Switzerland; email: tim.joda@unibas.ch},
publisher={Elsevier Ltd},
issn={00104825},
coden={CBMDA},
pubmed_id={31003184},
language={English},
abbrev_source_title={Comput. Biol. Med.},
document_type={Review},
source={Scopus},
}

@CONFERENCE{Ferrer2017,
author={Ferrer, V. and Perdomo, A. and Ali, H.R. and Fies, C. and Quarles, J.},
title={Virtual humans for temperature visualization in a tangible augmented reality educational game},
journal={2017 IEEE Virtual Reality Workshop on K-12 Embodied Learning through Virtual and Augmented Reality, KELVAR 2017},
year={2017},
doi={10.1109/KELVAR.2017.7961559},
art_number={7961559},
note={cited By 7},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026413057&doi=10.1109%2fKELVAR.2017.7961559&partnerID=40&md5=d8f25c80f52a141d27d41e926cd27720},
affiliation={University of Texas at San Antonio, United States},
abstract={Our primary objective is to enable effective game based learning approaches in tangible augmented reality. In game based learning there is often a tradeoff in motivation between the educational aspects and game aspects. For example, consider our previous work - a tangible augmented reality application for passive solar energy education (AR-SEE), in which users learn about the science behind architectural design by interacting with a tangible model house and an augmented reality-based visualization of energy transfer within the house. This research extends AR-SEE to begin to convert this educational simulation into an effective educational game by introducing gaming elements, such as interactive virtual humans. Although it is known that AR-SEE does enable learning, it is unknown how the addition of interactive virtual humans will affect user perception of temperature data and learning. In this paper, the goal was to compare user perception of two approaches to temperature data visualization in in tangible augmented reality on mobile phones: 1) the current particle-based visualization (i.e., based on the science of energy transfer) and 2) novel virtual human-based visualizations. The game was intended for high school students. However, as a preliminary study, we conducted a user study with 27 3rd and 4th year architecture students that compared these two visualization approaches and their impact on temperature estimation, motivation, and perceived learning effectiveness. In the future, we plan to integrate this game into high school curricula. © 2017 IEEE.},
author_keywords={Augmented reality;  education;  visualization},
keywords={Augmented reality;  Data visualization;  Education;  Education computing;  Energy transfer;  Flow visualization;  Motivation;  Solar energy;  Students;  Virtual reality;  Visualization, Augmented reality applications;  Educational aspects;  Educational simulations;  Energy educations;  Game-based Learning;  High school students;  Perceived learning;  Temperature estimation, E-learning},
publisher={Institute of Electrical and Electronics Engineers Inc.},
isbn={9781538618929},
language={English},
abbrev_source_title={IEEE Virtual Real. Workshop K-12 Embodied Learn. Virtual Augment. Real., KELVAR},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Zhao2017,
author={Zhao, J. and LaFemina, P. and Wallgrün, J.O. and Oprean, D. and Klippel, A.},
title={IVR for the geosciences},
journal={2017 IEEE Virtual Reality Workshop on K-12 Embodied Learning through Virtual and Augmented Reality, KELVAR 2017},
year={2017},
doi={10.1109/KELVAR.2017.7961557},
art_number={7961557},
note={cited By 7},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026381324&doi=10.1109%2fKELVAR.2017.7961557&partnerID=40&md5=a09460f44d16d74b12d9487780b9cc9f},
affiliation={Pennsylvania State University, United States},
abstract={Field trips are an essential part in many disciplines taught in K12 STEM (Science, Technology, Engineering, and Math) education inside and outside the US such as geography, geosciences, and architecture. Field trips foster embodied experiences of places where students can be situated into an informal learning environment. However, field trips are underutilized due to numerous constraints, a situation that current mass development in immersive technologies promises to eliminate. This paper presents an educational project that aims at creating and empirically evaluating virtual reality (VR) experiences for the geosciences: an interactive volcano experience based on LiDAR (Light Detection And Ranging) and image data of Iceland's Thrihnukar volcano. This work-in-progress prototype addresses the lack of content and tools for immersive virtual reality (iVR) in geoscientific education and research and how to make it easier to integrate iVR into classroom experiences. It makes use of environmentally sensed data such that interaction and linked content can be integrated into a single experience. We discuss our workflows as well as methods and authoring tools for iVR analysis and creation of virtual educational experiences. These methods and tools aim to enhance the utility of geospatial data from repositories such as OpenTopography.org through unlocking treasure-troves of geospatial data for VR applications. Their enhanced accessibility in education and research for the geosciences and beyond will benefit geoscientists and educators who cannot be expected to be VR and 3D application experts. © 2017 IEEE.},
author_keywords={3D modeling;  geoscience education;  Immersive virtual reality;  volcano},
keywords={Augmented reality;  Computer aided instruction;  Engineering education;  Engineering research;  Optical radar;  Virtual addresses;  Virtual reality;  Volcanoes, 3-d modeling;  Education and researches;  Educational experiences;  Geoscience education;  Immersive virtual reality;  Informal learning environments;  LIDAR (light detection and ranging);  Science , technology , engineering , and maths, E-learning},
publisher={Institute of Electrical and Electronics Engineers Inc.},
isbn={9781538618929},
language={English},
abbrev_source_title={IEEE Virtual Real. Workshop K-12 Embodied Learn. Virtual Augment. Real., KELVAR},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Antoniou2015229,
author={Antoniou, A. and O'Brien, J. and Bardon, T. and Barnes, A. and Virk, D.},
title={Micro-augmentations: Situated calibration of a novel nontactile, peripheral museum technology},
journal={ACM International Conference Proceeding Series},
year={2015},
volume={01-03-October-2015},
pages={229-234},
doi={10.1145/2801948.2801959},
note={cited By 7},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84962513623&doi=10.1145%2f2801948.2801959&partnerID=40&md5=3bfb05309c35100cb30d0bfe5b7707a0},
affiliation={Department of Informatics and Telecommunications, University of Peloponnese, Greece; Centre for Virtual Environments, Interaction and Visualisation, University College London, United Kingdom},
abstract={Micro-augmentations provide novel ways to interact directly with the past. This is a new concept that uses minimum stimulation to achieve maximum effects in spaces of cultural heritage. We experiment with new implicitly interactive and almost transparent museum technologies to create a holistic emotional visitor experience and solve a number of museum problems (i.e. misconceptions, intra-group communications, and visitor engagement). The paper presents the rationale for the design decisions, as well as the technical challenges faced during implementation. Audio micro-augmentations were firstly used at the UCL Grant Museum of Zoology. Initial user testing data from the system's calibration phase at that museum revealed the entertaining and learning potential of the application, together with issues for future development. © 2015 ACM.},
author_keywords={Augmented reality;  Museum},
keywords={Augmented reality;  Calibration;  Distributed computer systems;  Information science;  Museums, Cultural heritages;  Design decisions;  Intra-group;  Learning potential;  Museum technology;  Technical challenges;  User testing;  Visitor experiences, Computer peripheral equipment},
editor={Akoumianakis D., Karanikolas N.N., Nikolaidou M., Xenos M., Vergados D.},
publisher={Association for Computing Machinery},
isbn={9781450335515},
language={English},
abbrev_source_title={ACM Int. Conf. Proc. Ser.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Pombo20171,
author={Pombo, L. and Marques, M.M.},
title={Marker-based augmented reality application for mobile learning in an urban park: Steps to make it real under the edupark project},
journal={2017 International Symposium on Computers in Education, SIIE 2017},
year={2017},
volume={2018-January},
pages={1-5},
doi={10.1109/SIIE.2017.8259669},
note={cited By 6},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049498303&doi=10.1109%2fSIIE.2017.8259669&partnerID=40&md5=e8440c1a45b260f729c60ba0087a063c},
affiliation={Research Centre Didactics and Technology in the Education of Trainers (CIDTFF), Department of Education and Psychology, University of Aveiro, Aveiro, Portugal},
abstract={The gap between the use of mobile devices inside and outside school can lead to students' disengagement with learning activities in formal education. To fill this gap, educators can take advantage of mobile devices' dissemination to give students access to educational Augmented reality (AR) systems. However, this type of exploration is relatively new, and researchers are still studying AR's advantages and challenges in education. In that line, the EduPARK project is developing an interactive AR mobile application to support geocaching activities in outdoor environments, thus creating situated learning opportunities. It is to be explored by students and teachers from basic to higher education, but also by the public. The project follows a design-based research methodology, with several cycles of AR application development, user testing and evaluation. This manuscript is a work-in-progress report of the EduPARK project's options regarding the AR content and triggers, and points out some future directions. The EduPARK's option was to use image-based AR, with marker-based tracking, to display mainly botanical content. In a first implementation experience, 74 pupils (aged 9-10 and 13-14) from two schools tested a beta version of the application and AR markers in an urban park. Some technical issues, related to the markers' recognition, were observed and registered by both pupils and monitors, leading to the revision of the markers' purposes, structure, and content. Examples of refined AR markers and content are presented and discussed in this manuscript. Future work will include developing markerless tracking for this application in the selected urban park. Additionally, a proposal for the installation of the refined markers will be presented to the Park's management entity and the fully developed application will be freely offered to the public, promoting the autonomous exploration of this resource. This work is useful for teachers and both educational technology developers and researchers, as an example of how to successfully develop image-based AR for outdoor settings. © 2017 IEEE.},
author_keywords={Augmented reality;  Marker-based;  Mobile learning;  Outdoor learning environments;  Science education},
keywords={Augmented reality;  Computer aided instruction;  E-learning;  Mobile devices;  Teaching, Augmented reality applications;  Augmented reality systems;  Developed applications;  Marker-based;  Mobile Learning;  Outdoor learning;  Science education;  User testing and evaluations, Students},
editor={Silva M.J., Ponte C., Dodero J.M.},
publisher={Institute of Electrical and Electronics Engineers Inc.},
isbn={9781538606483},
language={English},
abbrev_source_title={Int. Symp. Comput. Educ., SIIE},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Zulkifli2016145,
author={Zulkifli, A.N. and Alnagrat, A.J.A. and Mat, R.C.},
title={Development and evaluation of i-Brochure: A mobile augmented reality application},
journal={Journal of Telecommunication, Electronic and Computer Engineering},
year={2016},
volume={8},
number={10},
pages={145-150},
note={cited By 6},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85011392508&partnerID=40&md5=5db924b2691e8685ba8148f96f2fc179},
affiliation={School of Multimedia Technology and Communication, Universiti Utara Malaysia, Malaysia; Information Technology Centre, Sebha University, Libyan Arab Jamahiriya},
abstract={Brochure is a typical promotional tool that has been used by most higher learning institutions to disseminate information to their prospective international students. However, some drawbacks of brochure include; information consisting of only text and images, non-interactive and if updated, the brochure will be obsolete. With the advent of mobile technology, Mobile Augmented Reality has been introduced to facilitate human in their daily lives. This paper discusses the development and evaluation of a Mobile Augmented Reality interactive brochure application. The aim of this application is to provide interactive information beyond that of a typical brochure in promoting higher learning institutions amongst the international students. By using the Mobile Augmented Reality application, the students will be able to access information in the form of virtual contents which cannot be acquired from a typical paper brochure. The results of user evaluation towards the use of the application indicated that they agreed with all the measurements which include Usefulness, Ease of use, Functionality and effectiveness, Outcome/future use and Satisfaction.},
author_keywords={Advertising;  Higher institution;  I-Brochure;  Mobile Augmented Reality},
publisher={Universiti Teknikal Malaysia Melaka},
issn={21801843},
language={English},
abbrev_source_title={J. Telecommun. Electron. Comput. Eng.},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Markouzis20154,
author={Markouzis, D. and Fessakis, G.},
title={Interactive storytelling and mobile augmented reality applications for learning and entertainment - A rapid prototyping perspective},
journal={Proceedings of 2015 International Conference on Interactive Mobile Communication Technologies and Learning, IMCL 2015},
year={2015},
pages={4-8},
doi={10.1109/IMCTL.2015.7359544},
art_number={7359544},
note={cited By 6},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84962449982&doi=10.1109%2fIMCTL.2015.7359544&partnerID=40&md5=0a7802d865af95436c60c2e55e38f107},
affiliation={Learning Technology and Educational Engineering Lab, University of the Aegean, Rhodes, Greece},
abstract={Mobile Augmented Reality (MAR) Technology in combination with Interactive Storytelling (IS) enables the design of new kinds of technology enhanced learning and entertainment applications. The existing pedagogical research as well as the available Interactive Storytelling MAR (ISMAR) Serious Games are rather limited. This is mainly because of the difficulties of MAR applications development and the complexity of IS authoring. The paper works on the direction to improve this situation exploring the combination of a) rapid prototype development methodology based on MAR authoring tools and b) the definition of IS genres which could serve as templates and guide the ISMAR design. In the paper, key concepts are presented, existing successful examples of MAR Serious Games are analyzed in order to extract their narration genre features, available tools for MAR rapid authoring are introduced, and afterwards the design and development of a prototype ISMAR Serious Game is presented. The paper contributes to the bridging of learning design, IS, and AR technology research communities and facilitates feature interdisciplinary research. © 2015 IEEE.},
author_keywords={Augmented reality;  Interactive storytelling;  Mobile learning;  Rapid prototyping;  Serious games},
keywords={Augmented reality;  Design;  Mobile telecommunication systems;  Rapid prototyping, Applications development;  Entertainment application;  Interactive storytelling;  Interdisciplinary research;  Mobile augmented reality;  Mobile Learning;  Serious games;  Technology enhanced learning, Engineering education},
publisher={Institute of Electrical and Electronics Engineers Inc.},
isbn={9781467382434},
language={English},
abbrev_source_title={Proc. Int. Conf. Interact. Mob. Commun. Technol. Learn., IMCL},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Rau2018240,
author={Rau, P.-L.P. and Zheng, J. and Guo, Z. and Li, J.},
title={Speed reading on virtual reality and augmented reality},
journal={Computers and Education},
year={2018},
volume={125},
pages={240-245},
doi={10.1016/j.compedu.2018.06.016},
note={cited By 5},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048805393&doi=10.1016%2fj.compedu.2018.06.016&partnerID=40&md5=524837db75789f3bd1e896b626a3afa1},
affiliation={Department of Industrial Engineering, Tsinghua University, Beijing, China; State Key Laboratory of Cognitive Neuroscience and Learning, Beijing Normal University, Beijing, China},
abstract={Many virtual reality (VR) and augmented reality (AR) applications in education require speed reading. The current study aimed to explore whether the reading performance on VR and AR is different from that on traditional desktop display, and whether the difference is moderated by the reading speed. Sixty-three college students read Chinese passages at normal (650–750 characters per minute [cpm]) or fast speeds (1000–1400 cpm), and then answered multiple-choice questions. They spent approximately 10% more time in making choice on VR and AR than they did on the desktop display. Teachers should be aware of this difference and allow 10% more time when using VR and AR applications containing text components. © 2018},
author_keywords={Augmented reality;  Human-computer interface;  Interactive learning environments;  Reading performance;  Virtual reality},
keywords={Augmented reality;  Computer aided instruction;  Human computer interaction;  Students;  Teaching, Applications in educations;  AR application;  College students;  Desktop displays;  Human computer interfaces;  Interactive learning environment;  Multiple choice questions;  Reading performance, Virtual reality},
correspondence_address1={Rau, P.-L.P.; Department of Industrial Engineering, Tsinghua UniversityChina; email: rpl@tsinghua.edu.cn},
publisher={Elsevier Ltd},
issn={03601315},
coden={COMED},
language={English},
abbrev_source_title={Comput Educ},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Dass2018156,
author={Dass, N. and Kim, J. and Ford, S. and Agarwal, S. and Chau, D.H.P.},
title={Augmenting Coding: Augmented reality for learning programming},
journal={ACM International Conference Proceeding Series},
year={2018},
pages={156-159},
doi={10.1145/3202667.3202695},
note={cited By 5},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049385491&doi=10.1145%2f3202667.3202695&partnerID=40&md5=be8b3a857a801083a09605cfb541bd8a},
affiliation={College of Computing, Georgia Tech, Georgia, United States},
abstract={Augmented reality (AR) is breaking into every industry and is finding a home in many unique and novel applications, due in part to its ability to engage users and their physical surroundings in potentially immersive means. We present our early investigation into whether these qualities of AR may be leveraged to help people learn coding more easily and with more fun. Using a within-subjects design with 12 participants, our pilot study evaluated two interactive AR coding environments: (1) head-mounted AR with Microsoft HoloLens, (2) mobile AR with ARKit on an iPhone; together with a conventional 2D touch interface using Swift Playground on an iPad as baseline. Participants enjoyed using mobile AR the most, and they also completed programming tasks the fastest when using it. Our current results suggest AR may have potential in enhancing beginners' learning experience for coding, especially for tasks that are more interactive and benefit from visual feedback. Copyright © 2018 is held by the owner/author(s).},
author_keywords={ARKit;  Augmented reality;  HoloLens;  Teaching},
keywords={Augmented reality;  Teaching;  Visual communication, ARKit;  HoloLens;  Learning experiences;  Learning programming;  Novel applications;  Programming tasks;  Touch interfaces;  Visual feedback, Codes (symbols)},
publisher={Association for Computing Machinery},
isbn={9781450365086},
language={English},
abbrev_source_title={ACM Int. Conf. Proc. Ser.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Pombo201823,
author={Pombo, L. and Marques, M.M.},
title={The EduPARK mobile augmented reality game: Learning value and usability},
journal={Proceedings of the 14th International Conference on Mobile Learning 2018, ML 2018},
year={2018},
pages={23-30},
note={cited By 5},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052242466&partnerID=40&md5=be40fa2bea420ba838ebfae04933b2fe},
affiliation={Research Centre Didactics and Technology in Education of Trainers (CIDTFF), Department of Education and Psychology, University of Aveiro, Campus Universitário de Santiago, Aveiro, 3810-193, Portugal},
abstract={Augmented Reality (AR) technology and games can enhance motivation for learning. When combined with mobile devices, AR technology can promote authentic learning in outdoor environments, such as urban parks. These spaces can be used for Science Education, particularly, for environmental education and nature conservation. The EduPARK project combines these elements and follows a design-based research approach to develop an interactive mobile AR game to be explored by students, teachers and the general public, as visitors, in a specific urban park, integrating four interdisciplinary educational guides. The app development involved four cycles of user testing and evaluation for progressive refinement, according to the users’ feedback in each cycle. The focus of this paper is to analyze the users’ perceptions in the two last cycles of the app refinement, regarding its learning value and usability. The users were students of different school levels (24 of Basic Education; and 46 of Higher Education). Data collection involved a focus group interview, a questionnaire and the app’s usage data. Content analysis, descriptive statistics, and System Usability Scale (SUS) computing were conducted. Results revealed that the EduPARK app promotes learning, enjoyment and is easy to use. It achieved an excellent usability, according to younger students (85.8 of average SUS) and a good usability according to older students (70.9). From the last refinement cycle, the app’s final version has emerged, which is freely available to the public in the Google Store. In the future, more evaluation experiences are needed to better understand the benefits of this mobile AR game for learning in urban parks. Copyright © 2018 IADIS Press. All rights reserved.},
author_keywords={Augmented reality;  Authentic learning;  Gamification;  Mobile learning;  Outdoor;  Science education},
keywords={Augmented reality;  Conservation;  Human computer interaction;  Students;  Surveys;  Teaching;  Usability engineering, Authentic learning;  Gamification;  Mobile Learning;  Outdoor;  Science education, E-learning},
editor={Sanchez I.A., Rodrigues L., Isaias P.},
publisher={IADIS},
isbn={9789898533760},
language={English},
abbrev_source_title={Proc. Int. Conf. Mob. Learn., ML},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Nguyen2017315,
author={Nguyen, V.T. and Dang, T.},
title={Setting up Virtual Reality and Augmented Reality Learning Environment in Unity},
journal={Adjunct Proceedings of the 2017 IEEE International Symposium on Mixed and Augmented Reality, ISMAR-Adjunct 2017},
year={2017},
pages={315-320},
doi={10.1109/ISMAR-Adjunct.2017.97},
art_number={8088512},
note={cited By 5},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040247028&doi=10.1109%2fISMAR-Adjunct.2017.97&partnerID=40&md5=d2f6de643d0411158b05e8d1db9e0929},
affiliation={Texas Tech University, United States},
abstract={We propose a framework and a setup for presenting complex models for curriculum contents in both augmented reality and virtual reality environment. After constructing some three-dimensional models representing real world objects such as trees, stones, rivers, dams, and buildings, our workflow uses the Unity engine in combination with Virtual Reality headset devices to create interactive applications for both Virtual Reality and Augmented Reality environments to support students understanding the curriculum contents through their surrounding. Typical challenges are addressed when creating 3D curriculum contents, integrating these models into Unity and solutions are proposed where possible. The overall structure of the project is described with some functionalities added to Unity for visualization and interaction with the models. © 2017 IEEE.},
author_keywords={Computational thinking;  Curriculum contents;  Mixed reality;  Unity engine;  Watershed},
keywords={Augmented reality;  Computer aided instruction;  Curricula;  E-learning;  Education;  Engines;  Virtual reality;  Watersheds, Computational thinkings;  Interactive applications;  Mixed reality;  Real-world objects;  Reality learning;  Three-dimensional model;  Virtual-reality environment;  Virtual-reality headsets, Three dimensional computer graphics},
editor={Broll W., Regenbrecht H., Bruder G., Servieres M., Sugimoto M., Swan J.E.},
publisher={Institute of Electrical and Electronics Engineers Inc.},
isbn={9780769563275},
language={English},
abbrev_source_title={Adjun. Proc. IEEE Int. Symp. Mixed Augment. Real., ISMAR-Adjunct},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Chang20171673,
author={Chang, R.-C. and Yu, Z.-S.},
title={Application of Augmented Reality technology to promote interactive learning},
journal={Proceedings of the 2017 IEEE International Conference on Applied System Innovation: Applied System Innovation for Modern Technology, ICASI 2017},
year={2017},
pages={1673-1674},
doi={10.1109/ICASI.2017.7988257},
art_number={7988257},
note={cited By 5},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028567173&doi=10.1109%2fICASI.2017.7988257&partnerID=40&md5=add9ea8410d8e94a4d2bbaebfafb31b3},
affiliation={Taiwan Police College, Taipei, Taiwan; Department of Digital Media Design, Asia University, Taichung, Taiwan},
abstract={In recent years, the learning tools based on AR (Augmented Reality) technology have been highly recommended to be applied in educational sites. Teachers display abstract scientific changes in specific images by applying AR technology. By way of applying AR inter-operation to enhance students' interests in learning as well as reduce their cognitive load. This study has applied AR technology to establish a virtual biological laboratory App to be provided for college freshmen to carry out biological experiments as a curriculum preview and experiencing. The content of Virtual biology laboratory App includes units such as virtual microscope, biological anatomy concept, cell division process, and frog's bones. Through the introduction of digital technology into the general biology curriculums are then emerged with AR technology so as to confer how AR technology affects students study effects and biological experimental knowledge recognition. The study has implemented an experiment in object to college freshmen and the experiment results indicate that the integration of AR technology with teaching has made students' attitude towards learning more positive. Through interactive operation and learning, students are better able to master knowledge of fundamental biological experiments. Through the process of the study, the researcher has found the importance that students study scientific knowledge with interactive technology. Consequently, the Institute has designed a virtual biology laboratory App to achieve the benefits of action learning, situational simulation and interactive experiencing. © 2017 IEEE.},
author_keywords={Augmented Reality;  Biology Experimental Curriculum;  Interactive learning},
keywords={Augmented reality;  Biology;  Cell proliferation;  Curricula;  E-learning;  Educational technology;  Engineering education;  Innovation;  Laboratories;  Learning systems;  Students;  Teaching, Augmented reality technology;  Biological experiments;  Cell division process;  Experimental knowledge;  Interactive learning;  Interactive operations;  Interactive technology;  Situational simulation, Education},
editor={Meen T.-H., Lam A.D.K.-T., Prior S.D.},
publisher={Institute of Electrical and Electronics Engineers Inc.},
isbn={9781509048977},
language={English},
abbrev_source_title={Proc. IEEE Int. Conf. Appl. Syst. Innov.: Appl. Syst. Innov. Modern Technol., ICASI},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Widiaty201712,
author={Widiaty, I. and Riza, L.S. and Danuwijaya, A.A. and Hurriyati, R. and Mubaroq, S.R.},
title={Mobile-based augmented reality for learning 3-dimensional spatial Batik-based objects},
journal={Journal of Engineering Science and Technology},
year={2017},
volume={12},
number={Special Issue 10},
pages={12-22},
note={cited By 5},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85038822386&partnerID=40&md5=6b6d59a8b722133d4f9f3019dcb03286},
affiliation={Departement of Home Economics, Universitas Pendidikan Indonesia, Jl. Dr. Setiabudhi No.229, Bandung, 40154, Indonesia; Departement of Computer Science Education, Universitas Pendidikan Indonesia, Jl. Dr. Setiabudhi No.229, Bandung, 40154, Indonesia; Departement of English Education, Universitas Pendidikan Indonesia, Jl. Dr. Setiabudhi No.229, Bandung, 40154, Indonesia; Departement of Business Management Education, Universitas Pendidikan Indonesia, Jl. Dr. Setiabudhi No.229, Bandung, 40154, Indonesia},
abstract={This study aims to develop an Android-based application in learning Batik to improve spatial intelligence of students in Indonesia. Along with the application development, pre-test and post-test are also administered to see whether students’ spatial intelligence improves or not. The results show that the application is user-friendly since almost all students have Android-based smartphones so that they have no problems in using the application. They already understand that to use the App, the first thing they have to do is login with matching using usernames and passwords. Camera will be automatically activated once the login is successful. 2D and 3D objects will be reflected into Batik patterns by this App; however, if the object is only in a 2D form, the pattern will be unidentified. Considering those results, it can be concluded that the application is such a user-friendly learning medium for the students. The application also contributes to the learning process to become more interactive so that it is no longer teacher-centered. © School of Engineering, Taylor’s University.},
author_keywords={Augmented reality;  Batik Indonesia;  Local wisdom of batik;  Vocational high school},
correspondence_address1={Widiaty, I.; Departement of Home Economics, Universitas Pendidikan Indonesia, Jl. Dr. Setiabudhi No.229, Indonesia; email: isma@upi.edu},
publisher={Taylor's University},
issn={18234690},
language={English},
abbrev_source_title={J. Eng. Sci. Technol.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Sadik20172098,
author={Sadik, M.J. and Chun, L.M.},
title={Stereoscopic vision mobile augmented reality system archite cture in assembly tasks},
journal={Journal of Engineering and Applied Sciences},
year={2017},
volume={12},
number={8},
pages={2098-2105},
doi={10.3923/jeasci.2017.2098.2105},
note={cited By 5},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021817864&doi=10.3923%2fjeasci.2017.2098.2105&partnerID=40&md5=7f69becbb5256c87d489fdd877d82c8a},
affiliation={Faculty of Information Science and Technology, Universiti Kebangsaan Malaysia, Bangi, Selangor, 43600, Malaysia},
abstract={Augmented Reality (AR) technology has great potential to be applied in different fields like education, medical surgeries, manufacturing and etc. Assembly process is an important process in manufacturing field and it is happening in our daily life too such as put furniture's pieces together. Therefore, an assembly training is essential for a person who has no or simple knowledge about the product assembly process. Conventionally, the assembly task training is conducted through study-based manual to guide and train the participant to understand the assembly steps. This traditional method is costly and time consuming. Stereoscopic vision has shown to be more beneficial over the monocular vision which it can provide depth information to the users. AR could combine with the stereoscopic vision to present the virtual object in a better way for the users to judge the distance of the virtual object in assembly system. Thus, it will be more closely to the real assembly situation. This study proposed a new system architecture which consists of the necessary components that are needed for stereoscopic-based mobile augmented reality system. It can be a reference for others who want to create a mobile type augmented reality with stereoscopic vision applications for assembly processes. The components of the system architecture include the hardware, different type of target and the AR environment part. Various interaction modes have shown and explained in the AR environment part to allow users to interact with the system. At the end of the study, a mobile augmented reality assembly system for PlayStation 3 console was successfully developed according to the proposed stereoscopic-based mobile AR assembly system architecture. © Medwell Journals, 2017.},
author_keywords={Augmented reality system architecture;  Human computer interactive assembly task;  Mobile augmented reality;  PlayStation;  Stereoscopic},
correspondence_address1={Sadik, M.J.; Faculty of Information Science and Technology, Universiti Kebangsaan MalaysiaMalaysia},
publisher={Medwell Journals},
issn={1816949X},
language={English},
abbrev_source_title={J. Eng. Appl. Sci.},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Frank201685,
author={Frank, J.A. and Brill, A. and Kapila, V.},
title={Interactive mobile interface with augmented reality for learning digital control concepts},
journal={2016 Indian Control Conference, ICC 2016 - Proceedings},
year={2016},
pages={85-92},
doi={10.1109/INDIANCC.2016.7441110},
art_number={7441110},
note={cited By 5},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84965176712&doi=10.1109%2fINDIANCC.2016.7441110&partnerID=40&md5=fed10af236ce1513d0c3fc4608cf8606},
affiliation={Mechatronics and Control Lab, Mechanical and Aerospace Engineering, NYU Tandon School of Engineering, Brooklyn, NY  11201, United States},
abstract={The use of augmented reality (AR) and mobile applications has recently been investigated in the teaching of advanced concepts and training of skills in a variety of fields. By developing educational mobile applications that incorporate augmented reality, unique interactive learning experiences can be provided to learners on their personal smartphones and tablet computers. This paper presents the development of an immersive user interface on a tablet device that can be used by engineering students to interact with a motor test-bed as they examine the effects of discrete-time pole locations on the closed-loop dynamic response of the test-bed. Specifically, users point the rear-facing camera of the tablet at the test-bed on which colored markers are affixed to enable an image processing routine running on the tablet to measure the angular position of an arm attached to the motor. To perform vision-based control of the angular position of motor arm, a discrete-time Kalman filter and a full-state feedback controller are implemented in the background of the application. As the user taps on the touchscreen of the device, s/he adjusts the angular position of a 3D semi-transparent virtual arm that represents the set point to the system. An interactive pole-zero plot allows users to tap at any desired location for the closed-loop pole-placement, in turn triggering the application code to redesign a new controller for driving the test-bed. Real-time plots enable the user to explore the resulting closed-loop response of the test-bed. Experimental results show several responses of the test-bed to demonstrate the efficacy of the proposed system. © 2016 IEEE.},
keywords={Augmented reality;  Controllers;  Digital control systems;  Equipment testing;  Feedback;  Image processing;  Mobile computing;  Mobile telecommunication systems;  Personal computers;  Personnel training;  State feedback;  Testing;  User interfaces, Closed loop dynamic;  Closed loop response;  Discrete-time Kalman filters;  Full state feedback;  Immersive user interfaces;  Interactive learning;  Mobile applications;  Vision based control, Learning systems},
publisher={Institute of Electrical and Electronics Engineers Inc.},
isbn={9781467379939},
language={English},
abbrev_source_title={Indian Control Conf., ICC - Proc.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Oh2016539,
author={Oh, S. and Park, K. and Kwon, S. and So, H.-J.},
title={Designing a multi-user interactive simulation using AR glasses},
journal={TEI 2016 - Proceedings of the 10th Anniversary Conference on Tangible Embedded and Embodied Interaction},
year={2016},
pages={539-544},
doi={10.1145/2839462.2856521},
note={cited By 5},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964911450&doi=10.1145%2f2839462.2856521&partnerID=40&md5=121e1e375578b5f45ab11166fc9df342},
affiliation={Dept. of Creative IT Engineering, POSTECH, Chungamro 77, South Korea},
abstract={In this research, we present the design and formative evaluation of an interactive simulation for informal learning environments. The wearable feature of Augmented Reality(AR) glasses enables full-body movement and embodied interactions in digitally augmented physical environments. The interactive simulation was developed to engage and immerse users to understand an abstract scientific concept about the refraction of light. To design playful and meaningful learning experiences, several design features related to social interaction, multi-user interaction, and embodied interaction were unpacked and integrated in the design process. Through the formative evaluation with participants in the laboratory setting, we found several possibilities and challenges about designing an interactive simulation in informal learning contexts using AR glasses. © 2016 ACM.},
author_keywords={AR glasses;  Augmented reality;  Computer-supported collaborative learning;  Embodied interaction;  Interactive simulation;  Optical see-though displays;  Projected AR},
keywords={Augmented reality;  Design;  Glass, Computer Supported Collaborative Learning;  Embodied interaction;  Formative evaluation;  Informal learning environments;  Interactive simulations;  Learning experiences;  Multi-user interaction;  Physical environments, Computer aided instruction},
publisher={Association for Computing Machinery, Inc},
isbn={9781450335829},
language={English},
abbrev_source_title={TEI - Proc. Anniv. Conf. Tangible Embed. Embodied Interact.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Limsukhawat2016483,
author={Limsukhawat, S. and Kaewyoun, S. and Wongwatkit, C. and Wongta, J.},
title={A development of augmented reality-supported mobile game application based on Jolly Phonics approach to enhancing English phonics learning performance of ESL learners},
journal={ICCE 2016 - 24th International Conference on Computers in Education: Think Global Act Local - Main Conference Proceedings},
year={2016},
pages={483-488},
note={cited By 5},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018948298&partnerID=40&md5=f2ac247068212b5548a769de761d758d},
affiliation={Department of Computer and Information Technology, Faculty of Industrial Education and Technology, King Mongkut's University of Technology, Thonburi, Thailand; Engineering Science Classroom, King Mongkut's University of Technology, Thonburi, Thailand},
abstract={Phonics is an essential foundation for English learning, particularly in reading and writing. However, most students who learned English as a second language have not learned phonics appropriately when they were young, resulting in failed pronunciation in reading and writing English words. With Jolly Phonics approach, students could develop their phonics learning performance effectively regardless of memorization. In addition, game has been considered to be an engaging platform, while augmented reality can provide students more interactive learning environment. Therefore, in this study, an augmented reality supported mobile game application was developed based on Jolly Phonics approach in order to improve students' phonics learning performance. In addition, an experiment has been conducted with primary school students to examine the effectiveness of the proposed mobile game application. Consequently, it was found that students who learned with this application could improve their phonics learning performance, also revealed positive attitudes towards the application. The findings of this study could provide an effective learning approach to improve phonics efficiency for English as a second language learners.},
author_keywords={Augmented reality;  English learning;  ESL;  Jolly Phonics;  L2;  Mobile game application;  Phonics learning},
keywords={Augmented reality;  Computer aided instruction;  Education;  Students, Effective learning;  English as a second language;  English Learning;  Interactive learning environment;  Jolly Phonics;  Learning performance;  Mobile games;  Phonics learning, Learning systems},
editor={Wong S.L., Barrera A.G., Mitsuhara H., Biswas G., Jia J., Yang J.-C., Banawan M.P., Demirbilek M., Gaydos M., Lin C.-P., Shon J.G., Iyer S., Gulz A., Holden C., Kessler G., Rodrigo M.M.T., Sengupta P., Taalas P., Chen W., Murthy S., Kim B., Ochoa X., Sun D., Baloian N., Hoel T., Hoppe U., Hsu T.-C., Kukulska-Hulme A., Chu H.-C., Gu X., Chen W., Huang J.S., Jan M.-F., Wong L.-H., Yin C.},
publisher={Asia-Pacific Society for Computers in Education},
isbn={9789868473577},
language={English},
abbrev_source_title={ICCE - Int. Conf. Comput. Educ.: Think Glob. Act Local - Main Conf. Proc.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Zikas2016805,
author={Zikas, P. and Bachlitzanakis, V. and Papaefthymiou, M. and Kateros, S. and Georgiou, S. and Lydatakis, N. and Papagiannakis, G.},
title={Mixed reality serious games and gamification for smart education},
journal={Proceedings of the European Conference on Games-based Learning},
year={2016},
volume={2016-January},
pages={805-812},
note={cited By 5},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84996606770&partnerID=40&md5=8044618b388cb350682760849ea01241},
affiliation={Foundation for Research and Technology Hellas, University of Crete, Heraklion, Greece},
abstract={The appeal of Mixed Reality (MR) digital games arouses interest among researchers and education specialists who since their recent proliferation, they have been trying to introduce their motivating potential in learning contexts. Our main research question in this work focuses on whether MR digital games can, via novel Presence (feeling of 'being and doing there' in a virtual or augmented world) and MR gamification (dynamics, mechanics, components) support and foster future learning and teaching, to address a wide variety and variation of educational contexts. To accomplish the above, a consistent computational framework that supports new types of Mixed-Reality Serious Games and Gamification (MRSGs) is established in this work that features MR gesture-based and game-based learning. The introduced term Mixed Reality Serious Games (MRSGs), refers to digital mini game-shells that allow the learners and teachers to sense the feeling of 'Presence' experienced under a novel MR educational learning framework, in both Virtual Reality (VR) as well as Augmented Reality (AR) formal and informal learning. The former (VR) allows for the unique feeling of 'being there' and 'doing there' in the virtual world, that will be transforming the overall game-based learning experience, via latest innovations as well as recent progress in low-cost h/w Head Mounted Displays (HMDs). The latter (AR) blends real and virtual elements so that the 3D virtual element is registered accurately in the real world and interacted freely by the learner via various mobile displays, including smart glasses, natural, gesture-based interaction (mobile RGB and RGB-D), MR virtual characters and gamified learning processes. Game-based learning also involves the incorporation of games into lessons. The principal aim of applying games in education is to increase students' engagement and motivation. In our case studies we provide two mini MRSGs in VR and AR that accompany the primary school history class and particular the period of the Minoan Civilization, as manifested by the archaeological site of Ancient Knossos in Heraklion, Greece. The AR MRSG implements a desktop-based holographic application using the Meta-AR glasses. This MRSG consist of three mini game shells in which the student has to complete various learning tasks by using gesture-based interaction. These tasks consist of puzzle-based and constructional games tasks. The VR MRSG implements a similar approach of a Virtual tour in Knossos with quests that student need to accomplish to collect rewards. The student has to fully explore the palace, interact with special characters and complete their quests.These MRSGs are a first attempt to formally study latest h/w and s/w advances in Mixed Reality technologies, applied in gesture-based and game-based learning in both formal and informal educational contexts. Moreover we compared the gamification elements for each enabling technology and define the gamification dynamics, mechanics and components that need to be utilized in each MR environment. © The Authors, 2016. All Rights Reserved.},
author_keywords={Game-based learning;  Game-based learning;  Gamification;  Gesturebased learning;  Mixed reality;  Serious games;  Virtual - augmented reality games},
keywords={Augmented reality;  Education computing;  Glass;  Helmet mounted displays;  Interactive computer graphics;  Learning systems;  Mixed reality;  Motivation;  Students;  Teaching;  Virtual addresses, Computational framework;  Game-based Learning;  Gamification;  Gesture-based interaction;  Gesturebased learning;  Holographic applications;  Mixed reality technologies;  Virtual - augmented reality games, Serious games},
editor={Boyle L., Boyle L., Connolly T.M., Connolly T.M.},
publisher={Dechema e.V.},
issn={20490992},
isbn={9781911218098},
language={English},
abbrev_source_title={Proc. European Conf. Games-based Learn.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Champney2016363,
author={Champney, R. and Salcedo, J.N. and Lackey, S.J. and Serge, S. and Sinagra, M.},
title={Mixed reality training of military tasks: Comparison of two approaches through reactions from subject matter experts},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2016},
volume={9740},
pages={363-374},
doi={10.1007/978-3-319-39907-2_35},
note={cited By 5},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84978794707&doi=10.1007%2f978-3-319-39907-2_35&partnerID=40&md5=514d832087fb54fd59bc938e95d46d63},
affiliation={Design Interactive Inc, Orlando, United States; Institute for Simulation and Training, University of Central Florida, Orlando, United States},
abstract={This paper discusses a training-based comparison of two mixed reality military trainers utilizing simulation elements that are categorized on different areas of the virtuality continuum. The comparison encompassed exposing subject matter experts (SMEs) to the training systems. Independent groups of SMEs interacted with each system through conducting expert system evaluations. Independent groups of military officers experienced each system for call for fire/close air support training. Following these exposures, participants were queried on the constructs of simulator sickness, training utility, simulator fidelity, usability, and immersion. The results are contrasted and discussed. The outcomes of this comparison serve to promote discussion among the scientific community concerning the training tradeoffs affected by the virtuality continuum. © Springer International Publishing Switzerland 2016.},
author_keywords={Augmented reality;  Augmented virtuality;  Call for fire;  Close air support;  Immersive training;  Joint forward observer;  Learning;  Mixed reality;  Simulation-based training;  Simulator fidelity;  Training;  Training systems;  Virtual reality;  Wearable technology},
keywords={Augmented reality;  Expert systems;  Human computer interaction;  Interactive computer graphics;  Military operations;  Personnel training;  Simulators;  Wearable technology, Augmented virtualities;  Close air support;  Immersive;  Learning;  Mixed reality;  Simulation-based training;  Simulator fidelity;  Training Systems, Virtual reality},
correspondence_address1={Champney, R.; Design Interactive IncUnited States; email: roberto@designinteractive.net},
editor={Lackey S., Shumaker R.},
publisher={Springer Verlag},
issn={03029743},
isbn={9783319399065},
language={English},
abbrev_source_title={Lect. Notes Comput. Sci.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Buń2015398,
author={Buń, P. and Górski, F. and Wichniarek, R. and Kuczko, W. and Hamrol, A. and Zawadzki, P.},
title={Application of Low-cost Tracking Systems in Educational Training Applications},
journal={Procedia Computer Science},
year={2015},
volume={75},
pages={398-407},
doi={10.1016/j.procs.2015.12.263},
note={cited By 5},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964068062&doi=10.1016%2fj.procs.2015.12.263&partnerID=40&md5=fa71d4bf72df71d71cff8c6cc1991da7},
affiliation={Poznań University of Technology, Department of Management and Production Engineering, Piotrowo Str. 3, Poznan, 60-965, Poland},
abstract={The paper presents problems related to measurement accuracy of tracking systems, which are widely used in immersive simulations based on Virtual Reality technology. Possibility of tracking movements of the user makes the simulation in virtual environment more realistic. This is very important in case of training simulations of situations, where mistake of an operator would threaten the life and health of himself or other people or could lead to substantial material losses. The authors' many years of experience in creating interactive Virtual Reality applications allows them to conclude, that possibility of use of professional tracking systems is often not possible for educational facilities like schools or universities due to budget reasons. Professional tracking systems are usually more accurate and have more programming support of their use in Virtual Reality applications than the low-cost solutions. However, low-cost devices are often tens of times cheaper than the professional systems. The research presented in the paper is an attempt of answering the question - how the immersion level related to accuracy of position and orientation representation of real object in a virtual environment influences the evaluation of usefulness of a given tracking system for training applications. A particular attention was paid to tracking of user's movement, which allows him to naturally interact with the computer generated environment. Displaying a simulation reacting properly and smoothly to real movements performed by the user will allow him to develop the most necessary reflexes, which would not be possible using only non-natural interaction devices, such as mouse or keyboard. On the other hand, development of improper reflexes related to user's position being wrongly read can bring more harm than benefit to the training process. The paper presents results of study of accuracy of one of the tracking systems available on the market - the PST 55 system. This device uses retro-active markers, which are widely used also in measurement systems not dedicated to use in the VR system. The real position of tracked objects was verified using an industrial photogrammetric measurement system TRITOP from GOM company. The results of the comparative study allowed to determine how accurate is the studied tracking system and how the accuracy affects the feeling of immersion. © 2015 The Authors.},
author_keywords={immersion;  optical tracking;  photogrammetry;  Virtual Reality},
keywords={Augmented reality;  Budget control;  Costs;  Education;  Neurophysiology;  Personnel training;  Photogrammetry;  Professional aspects;  Tracking (position);  Virtual reality, Environment influence;  immersion;  Interactive virtual reality;  Optical tracking;  Photogrammetric measurements;  Position and orientations;  Training applications;  Virtual reality technology, Computer systems programming},
correspondence_address1={Buń, P.; Poznań University of Technology, Department of Management and Production Engineering, Piotrowo Str. 3, Poland; email: pawel.k.bun@doctorate.put.poznan.pl},
editor={Ramirez Flores P.G., Martin Gutierrez J., Mendivil E.G., Ginters E.},
publisher={Elsevier B.V.},
issn={18770509},
language={English},
abbrev_source_title={Procedia Comput. Sci.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Gutierrez2015390,
author={Gutierrez, J.M. and Molinero, M.A. and Soto-Martín, O. and Medina, C.R.},
title={Augmented Reality Technology Spreads Information about Historical Graffiti in Temple of Debod},
journal={Procedia Computer Science},
year={2015},
volume={75},
pages={390-397},
doi={10.1016/j.procs.2015.12.262},
note={cited By 5},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964027523&doi=10.1016%2fj.procs.2015.12.262&partnerID=40&md5=e671683803851734a9fbb54f0deb9ba0},
affiliation={Universidad de la Laguna, San Critóbal de La Laguna, 38202, Spain},
abstract={Learning can occur at anytime and anywhere, even when you are travelling. In this article, we explain how augmented reality (AR) can be used to better educate tourists and visitors about the sites they choose to visit. Using the Temple of Debod in Madrid and its structures as an example, we focus on applying AR to the engravings on the walls of the temple. Through AR, these engravings take on a new life, giving visitors a more interesting and interactive experience that better educates them about the temple itself and about the different historical periods in which the 'graffiti' were engraved. Augmented reality, combined with audio commentary in different languages, will help visitors to locate the different graffiti more easily and appreciate the true wonder of the site and the motives behind the engravings. © 2015 The Authors.},
author_keywords={apps;  Augmented Reality;  education;  museums;  video tours},
keywords={Application programs;  Education;  Etching;  Museums, Augmented reality technology;  Historical periods;  video tours, Augmented reality},
correspondence_address1={Gutierrez, J.M.; Universidad de la LagunaSpain; email: jmargu@ull.edu.es},
editor={Ramirez Flores P.G., Martin Gutierrez J., Mendivil E.G., Ginters E.},
publisher={Elsevier},
issn={18770509},
language={English},
abbrev_source_title={Procedia Comput. Sci.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{daSilva2019,
author={da Silva, M.M.O. and Teixeira, J.M.X.N. and Cavalcante, P.S. and Teichrieb, V.},
title={Perspectives on how to evaluate augmented reality technology tools for education: a systematic review},
journal={Journal of the Brazilian Computer Society},
year={2019},
volume={25},
number={1},
doi={10.1186/s13173-019-0084-8},
art_number={3},
note={cited By 4},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062427751&doi=10.1186%2fs13173-019-0084-8&partnerID=40&md5=08f5e35127cb8d42df3b48ba8e66c18a},
affiliation={Voxar Labs, Centro de Informática, Universidade Federal de Pernambuco, Recife, Brazil; Departamento de Eletrônica e Sistemas, Universidade Federal de Pernambuco, Recife, Brazil; EDUMATEC, Centro de Educação, Universidade Federal de Pernambuco, Recife, Brazil},
abstract={Education has benefited from augmented reality’s (AR) potential to promote interactive experiences both inside and outside the classroom. A systematic review was conducted on how AR’s impact in the learning process has been evaluated. We selected papers from 2009 to 2017 in three databases, IEEE, ACM, and Science Direct, using an open-source crawler, and in one Brazilian Conference, SBIE. We followed the PRISMA protocol. Forty-five works were selected and used to extract data for our research. They were also analyzed according to quantitative and qualitative criteria. The results from all the papers are available in an online database. Results evidenced an increase in the number of papers evaluating the AR’s impact in education. They also showed that AR has been applied in different areas and contexts. Most papers reported positive outcomes as a result of AR insertion. However, most studies lacked the involvement of the teacher and the use of multiple metrics to evaluate educational gains. © 2019, The Author(s).},
author_keywords={Augmented reality;  Educational systems;  Evaluation},
keywords={Paper, Augmented reality technology;  Educational systems;  Evaluation;  Learning process;  Online database;  Open sources;  Qualitative criteria;  Systematic Review, Augmented reality},
correspondence_address1={da Silva, M.M.O.; Voxar Labs, Centro de Informática, Universidade Federal de PernambucoBrazil; email: mmos@cin.ufpe.br},
publisher={Springer London},
issn={01046500},
language={English},
abbrev_source_title={J. Braz. Comput. Soc.},
document_type={Review},
source={Scopus},
}

@ARTICLE{Diao2019,
author={Diao, P.-H. and Shih, N.-J.},
title={Trends and research issues of augmented reality studies in architectural and civil engineering education-A review of academic journal publications},
journal={Applied Sciences (Switzerland)},
year={2019},
volume={9},
number={9},
doi={10.3390/app9091840},
art_number={1840},
note={cited By 4},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067184874&doi=10.3390%2fapp9091840&partnerID=40&md5=151fbc044f8bd668b9d1848d0878439e},
affiliation={Department of Architecture, National Taiwan University of Science and Technology, 43, Section 4, Keelung Road, Taipei, 106, Taiwan},
abstract={Architectural and civil engineering (ACE) education is inextricably connected to real-world practice. The application of augmented reality (AR) technology can help to establish a link between virtual and real-world information for students. Studies of applying AR in ACE education have increased annually, and numerous research have indicated that AR possesses immense application potential. To address and analyze pertinent research issues, published studies in the Scopus database were explored, and revealed that problems persist and are worthy of attention, such as the selection of system types and devices, the application of research methods, and appropriate learning strategies and teaching methods. Courses with objective grading standards should be given priority in AR experimental courses for a meticulous investigation of AR influence on students' learning outcomes and ultimately improvement of classroom quality. Suitable types of AR systems should be selected based on course content, prior to the design and development of the system. It is recommended to develop markerless systems for a larger application range to benefit students with additional convenience. Systems can also be accompanied by functions, such as instant online assessments, synchronized assessments, and exchange capabilities to assist learning what has been taught and develop critical thinking abilities. The combination of AR and building information modeling (BIM) in architectural and civil practice, which has immense application potential, has become an emerging research trend. Collaboration between academics and practice should be enhanced with roles and knowledge of instructors, engineers, designers, and computer experts integrated for an optimal connection between general pedagogy and domain-specific learning. Teaching methods that emphasize "locations", as well as "roles", can be adopted in order to create a superior reality learning environment with diversified learning methods. The trends and research have become an integration and collaboration issue that should be performed interactively with pedagogical findings, and resources integrated across roles, fields, and university departments. © 2019 by the authors.},
author_keywords={Architecture and civil engineering;  Augmented reality;  Interactive learning environments;  Mobile technology;  Pedagogical issues;  Teaching/learning strategies},
correspondence_address1={Shih, N.-J.; Department of Architecture, National Taiwan University of Science and Technology, 43, Section 4, Keelung Road, Taiwan; email: shihnj@mail.ntust.edu.tw},
publisher={MDPI AG},
issn={20763417},
language={English},
abbrev_source_title={Appl. Sci.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Huang201910,
author={Huang, L. and Feng, X. and Zhang, C. and Qian, L. and Wu, Y.},
title={Deep reinforcement learning-based joint task offloading and bandwidth allocation for multi-user mobile edge computing},
journal={Digital Communications and Networks},
year={2019},
volume={5},
number={1},
pages={10-17},
doi={10.1016/j.dcan.2018.10.003},
note={cited By 4},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056834725&doi=10.1016%2fj.dcan.2018.10.003&partnerID=40&md5=4e60eda8f838f61aff81027755392988},
affiliation={College of Information Engineering, Zhejiang University of Technology, Hangzhou, 310023, China},
abstract={The rapid growth of mobile internet services has yielded a variety of computation-intensive applications such as virtual/augmented reality. Mobile Edge Computing (MEC), which enables mobile terminals to offload computation tasks to servers located at the edge of the cellular networks, has been considered as an efficient approach to relieve the heavy computational burdens and realize an efficient computation offloading. Driven by the consequent requirement for proper resource allocations for computation offloading via MEC, in this paper, we propose a Deep-Q Network (DQN) based task offloading and resource allocation algorithm for the MEC. Specifically, we consider a MEC system in which every mobile terminal has multiple tasks offloaded to the edge server and design a joint task offloading decision and bandwidth allocation optimization to minimize the overall offloading cost in terms of energy cost, computation cost, and delay cost. Although the proposed optimization problem is a mixed integer nonlinear programming in nature, we exploit an emerging DQN technique to solve it. Extensive numerical results show that our proposed DQN-based approach can achieve the near-optimal performance. © 2018 Chongqing University of Posts and Telecommunications},
author_keywords={Deep-Q network;  Joint computation offloading and resource allocation;  Mobile edge computing},
correspondence_address1={Wu, Y.; College of Information Engineering, Zhejiang University of TechnologyChina; email: iewuy@zjut.edu.cn},
publisher={Chongqing University of Posts and Telecommunications},
issn={24685925},
language={English},
abbrev_source_title={Digit. Commun Netw.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Rusiñol201813773,
author={Rusiñol, M. and Chazalon, J. and Diaz-Chito, K.},
title={Augmented songbook: an augmented reality educational application for raising music awareness},
journal={Multimedia Tools and Applications},
year={2018},
volume={77},
number={11},
pages={13773-13798},
doi={10.1007/s11042-017-4991-4},
note={cited By 4},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85023181639&doi=10.1007%2fs11042-017-4991-4&partnerID=40&md5=bcaec072f6ae2001fe94468737a8857d},
affiliation={Computer Vision Center, Departamento de Ciències de la Computació, Edifici O, Universitat Autònoma de Barcelona, 08193 Bellaterra, Barcelona, Spain; L3i Laboratory, Université de La Rochelle, Avenue Michel Crépeau, La Rochelle cedex 1, 17042, France; EPITA Research and Development Laboratory (LRDE), 14-16 rue Voltaire, Le Kremlin-Bicêtre, 94270, France},
abstract={This paper presents the development of an Augmented Reality mobile application which aims at sensibilizing young children to abstract concepts of music. Such concepts are, for instance, the musical notation or the idea of rhythm. Recent studies in Augmented Reality for education suggest that such technologies have multiple benefits for students, including younger ones. As mobile document image acquisition and processing gains maturity on mobile platforms, we explore how it is possible to build a markerless and real-time application to augment the physical documents with didactic animations and interactive virtual content. Given a standard image processing pipeline, we compare the performance of different local descriptors at two key stages of the process. Results suggest alternatives to the SIFT local descriptors, regarding result quality and computational efficiency, both for document model identification and perspective transform estimation. All experiments are performed on an original and public dataset we introduce here. © 2017, Springer Science+Business Media, LLC.},
author_keywords={Augmented reality;  Document image matching;  Educational applications},
keywords={Augmented reality;  Computational efficiency;  Education computing;  Pipeline processing systems, Abstract concept;  Document image matching;  Educational Applications;  Local descriptors;  Mobile applications;  Perspective transforms;  Physical documents;  Real-time application, Image processing},
correspondence_address1={Rusiñol, M.; Computer Vision Center, Departamento de Ciències de la Computació, Edifici O, Universitat Autònoma de Barcelona, 08193 Bellaterra, Spain; email: marcal@cvc.uab.es},
publisher={Springer New York LLC},
issn={13807501},
coden={MTAPF},
language={English},
abbrev_source_title={Multimedia Tools Appl},
document_type={Article},
source={Scopus},
}

@ARTICLE{Wang2018701,
author={Wang, T. and Zhang, H. and Xue, X. and Cai, S.},
title={Augmented reality-based interactive simulation application in double-slit experiment},
journal={Lecture Notes in Networks and Systems},
year={2018},
volume={22},
pages={701-707},
doi={10.1007/978-3-319-64352-6_66},
note={cited By 4},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061932149&doi=10.1007%2f978-3-319-64352-6_66&partnerID=40&md5=635f2a85ef4c2ce79c8641ff305be950},
affiliation={Faculty of Education, School of Educational Technology, Beijing Normal University, Beijing, 100875, China; Beijing Advanced Innovation Center for Future Education, Beijing Normal University, Beijing, 100875, China},
abstract={Experimental teaching is an essential link in teaching and learning activities, holding an important position in the modern education. However, it is impossible or difficult for some physical phenomena to be carried out in the classroom. With the advantages of portability and combining both the real and virtual world, mobile device and Augmented Reality (AR) technology are having a positive influence on the creating of cognitive tools. In this paper, we develop DSIAR, an AR-based interactive application on mobile devices, to simulate a physical experiment, double-slit experiment. DSIAR allows students to control and interact with a set of 3D models of laboratory apparatus through markers, to change the parameters to observe the dynamic variable phenomenon which is not easy to observe in the real world. The results of pilot testing show that DSIAR can have a positive impact on assisting teaching and learning, attracting students’ attention and stimulating their interest, suggesting significant potential for this learning application in practice. © Springer International Publishing AG 2018.},
author_keywords={Augmented reality;  Double-slit experiment;  Mobile device;  Simulation experiment},
correspondence_address1={Cai, S.; Faculty of Education, School of Educational Technology, Beijing Normal UniversityChina; email: caisu@bnu.edu.cn},
publisher={Springer},
issn={23673370},
language={English},
abbrev_source_title={Lect. Notes Networks Syst.},
document_type={Book Chapter},
source={Scopus},
}

@CONFERENCE{Kurniawan201880,
author={Kurniawan, M.H. and Suharjito and Diana and Witjaksono, G.},
title={Human Anatomy Learning Systems Using Augmented Reality on Mobile Application},
journal={Procedia Computer Science},
year={2018},
volume={135},
pages={80-88},
doi={10.1016/j.procs.2018.08.152},
note={cited By 4},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053125308&doi=10.1016%2fj.procs.2018.08.152&partnerID=40&md5=f23829c53b7060c5ca17d125c02c7ce3},
affiliation={Computer Science Department, BINUS Graduate Program, Master of Computer Science, Bina Nusantara University, Jakarta, 11480, Indonesia; Computer Science Department, School of Computer Science, Bina Nusantara University, Jakarta, 11480, Indonesia},
abstract={Students generally experience difficulties in learning human body anatomy due to constraints to visualize the body anatomy from 2D into 3D image. This research aims to develop a human anatomy learning system using augmented reality technology. By using this system, it is expected that students can easily understand the anatomy of the human body using a 3D image visualization. The method used in this system is augmented reality marker on mobile computing platform. The marker is captured by taking a picture. Then, the captured image is divided into pieces and the pattern is matched with images stored in the database. In this research, we use Floating Euphoria Framework and combine it with the SQLite database. Augmented reality anatomy system of the human body has features that can interactively display the whole body or parts of the human organs. To evaluate the usefulness of the application, we tested the augmented reality anatomy system with high school students and medical students for learning the anatomy of the human body. The results show that the human anatomy learning system with interactive augmented reality visualization helps students learn human anatomy more easily. © 2018 The Authors. Published by Elsevier Ltd.},
author_keywords={Android Application;  Augmented Reality;  Human Anatomy Learning},
keywords={Artificial intelligence;  Augmented reality;  Learning systems;  Mobile computing;  Students;  Three dimensional computer graphics;  Visualization, Android applications;  Augmented reality technology;  High school students;  Human anatomy;  Human organs;  Medical students;  Mobile applications;  Reality visualization, Engineering education},
correspondence_address1={Suharjito; Computer Science Department, BINUS Graduate Program, Master of Computer Science, Bina Nusantara UniversityIndonesia; email: suharjito@binus.edu},
editor={Meiliana, Arifin Y., Budiharto W., Wulandhari L.A., Sutoyo R., Faisal, Gunawan A.A.S., Williem, Suryani D.},
publisher={Elsevier B.V.},
issn={18770509},
language={English},
abbrev_source_title={Procedia Comput. Sci.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Ortiz2018516,
author={Ortiz, J.S. and Sánchez, J.S. and Velasco, P.M. and Quevedo, W.X. and Carvajal, C.P. and Morales, V. and Ayala, P.X. and Andaluz, V.H.},
title={Virtual Training for Industrial Automation Processes Through Pneumatic Controls},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2018},
volume={10851 LNCS},
pages={516-532},
doi={10.1007/978-3-319-95282-6_37},
note={cited By 4},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050258219&doi=10.1007%2f978-3-319-95282-6_37&partnerID=40&md5=0ad0dd579baca4acf5339dcef58c60ae},
affiliation={Univeridad de las Fuerzas Armadas ESPE, Sangolquí, Ecuador; Universidad Técnica de Ambato, Ambato, Ecuador},
abstract={This work presents the implementation of virtual environments oriented to managing pneumatic controls applied to industrial processes in order to strengthen training and teaching-learning processes. The implemented application enables the multi-user immersion and interaction with the aim to accomplish predefined tasks to be developed within lab environments and virtualized sceneries for industrial processes. Obtained results show how easy it is to interact with the proposed multi-user environment. © 2018, Springer International Publishing AG, part of Springer Nature.},
author_keywords={Capacitation;  Industrial processes;  Multi-user;  Training;  Virtual Reality},
keywords={Augmented reality;  E-learning;  Personnel training;  Pneumatic control;  Virtual reality, Capacitation;  Industrial automation;  Industrial processs;  Multi-user;  Multiuser environments;  Teaching-learning process;  Virtual training, Process control},
correspondence_address1={Ortiz, J.S.; Univeridad de las Fuerzas Armadas ESPEEcuador; email: jsortiz@espe.edu.ec},
editor={De Paolis L.T., Bourdot P.},
publisher={Springer Verlag},
issn={03029743},
isbn={9783319952819},
language={English},
abbrev_source_title={Lect. Notes Comput. Sci.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Lee201753,
author={Lee, L.-K. and Chau, C.-H. and Chau, C.-H. and Ng, C.-T.},
title={Using augmented reality to teach kindergarten students english vocabulary},
journal={Proceedings - 2017 International Symposium on Educational Technology, ISET 2017},
year={2017},
pages={53-57},
doi={10.1109/ISET.2017.20},
art_number={8005387},
note={cited By 4},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85034431034&doi=10.1109%2fISET.2017.20&partnerID=40&md5=2de02ff9666aa0e308f3b2b221624fdf},
affiliation={School of Science and Technology, Open University of Hong Kong, Ho Man Tin, Kowloon, Hong Kong},
abstract={Augmented Reality (AR) is a technology that augments the real physical world with computer-generated 3D virtual objects such that the users can interact with them using the screen of their mobile devices. This paper studies how to effectively use AR to enhance the learning experience of kindergarten students, while addressing parents' concern that a long-time usage of electronic devices may affect their child's health. We developed an AR mobile application prototype to teach kindergarten students English vocabulary in an interactive and attractive way. It allows kindergarten students to learn English vocabulary in any place and at any time using a mobile device. To address the parents' concern on health, we integrate a monitoring system into the application, which allows the parents to monitor their child's usage and stop the application in real time online. Preliminary evaluation shows that the effectiveness of the application is satisfactory. It is beneficial to use augmented reality for early childhood education if the usage time of the students is well monitored. © 2017 IEEE.},
author_keywords={Augmented reality;  Early childhood education;  Educational games;  English learning;  Parental perspectives},
keywords={Augmented reality;  Education;  Educational technology;  Mobile devices;  Software prototyping, Computer generated;  Early childhood educations;  Educational game;  Electronic device;  English Learning;  Learning experiences;  Mobile applications;  Parental perspectives, Students},
editor={Kwan R., Wang F.L., Shang J., Au O., Ng K.K.},
publisher={Institute of Electrical and Electronics Engineers Inc.},
isbn={9781509030309},
language={English},
abbrev_source_title={Proc. - Int. Symp. Educ. Technol., ISET},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Bratitsis2017485,
author={Bratitsis, T. and Bardanika, P. and Ioannou, M.},
title={Science Education and Augmented Reality Content: The Case of the Water Circle},
journal={Proceedings - IEEE 17th International Conference on Advanced Learning Technologies, ICALT 2017},
year={2017},
pages={485-489},
doi={10.1109/ICALT.2017.64},
art_number={8001839},
note={cited By 4},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030230757&doi=10.1109%2fICALT.2017.64&partnerID=40&md5=9c801923f72cd213d369253e0f4053c1},
affiliation={Early Childhood Education Department, University of Western Macedonia, Florina, Greece},
abstract={Augmented Reality (AR) is a live, direct or indirect projection of the physical-real world which allows users to experience the surrounding environment as it is, in real-time, enhanced with digital and/or interactive content. It seems that AR can be exploited for teaching various disciplines. In this paper, the preliminary results of a study regarding a teaching intervention about science education in primary school and specifically the topic of the water circle are presented. The AR content was deployed through the ENTITI creator application. © 2017 IEEE.},
author_keywords={augmented reality;  ENTITI creator;  primary school;  science education;  water circle},
keywords={Augmented reality, Augmented reality content;  ENTITI creator;  Interactive contents;  Primary schools;  Real-world;  Science education;  Surrounding environment;  Teaching intervention, Education},
editor={Huang R., Vasiu R., Kinshuk, Sampson D.G., Chen N.-S., Chang M.},
publisher={Institute of Electrical and Electronics Engineers Inc.},
isbn={9781538638705},
language={English},
abbrev_source_title={Proc. - IEEE Int. Conf. Adv. Learn. Technol., ICALT},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Dalim2017344,
author={Dalim, C.S.C. and Piumsomboon, T. and Dey, A. and Billinghurst, M. and Sunar, S.},
title={TeachAR: An Interactive Augmented Reality Tool for Teaching Basic English to Non-native Children},
journal={Adjunct Proceedings of the 2016 IEEE International Symposium on Mixed and Augmented Reality, ISMAR-Adjunct 2016},
year={2017},
pages={344-345},
doi={10.1109/ISMAR-Adjunct.2016.0113},
art_number={7836534},
note={cited By 4},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85015259626&doi=10.1109%2fISMAR-Adjunct.2016.0113&partnerID=40&md5=edaaf50e3b7a26bd0095c1a2b917e0ae},
affiliation={Empathic Computing Lab, University of South Australia, Australia; MaGIC-X UTM-IRDA, Universiti Teknologi Malaysia, Malaysia; Faculty of Computer Science and Information Technology, Universiti Tun Hussein Onn Malaysia, Malaysia},
abstract={TeachAR is an Augmented Reality (AR) tool for teaching English colors, shapes, and spatial relationships to young children aged 4 to 6 years old who are non-native speakers of English. TeachAR utilizes the ARToolkit plugin for the Unity game engine for square marker tracking and game development. The Microsoft Kinect's microphone and speech API is used for isolated word speech recognition, a webcam for image capturing and a desktop monitor for viewing the AR scene. Previous language learning AR applications usually use audio output, however TeachAR uses speech as input for language learning. This paper describes the TeachAR demonstration and user experience with the application. © 2016 IEEE.},
author_keywords={Augmented Reality;  Children;  English Language;  Non-Native Speakers;  Teaching and Learning},
keywords={Augmented reality;  Software design;  Speech recognition;  Teaching, Augmented reality tools;  Children;  English languages;  Isolated word speech recognition;  Language learning;  Non-native speakers;  Spatial relationships;  Teaching and learning, Education},
editor={Veas E., Grasset R., Langlotz T., Martin A., Martinez-Carranza J., Sugimoto M.},
publisher={Institute of Electrical and Electronics Engineers Inc.},
isbn={9781509037407},
language={English},
abbrev_source_title={Adjun. Proc. IEEE Int. Symp. Mixed Augment. Real., ISMAR-Adjunct},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{DaSilva2017469,
author={Da Silva, I.C.S. and Klein, G. and Brandão, D.M.},
title={Segmented and detailed visualization of anatomical structures based on augmented reality for health education and knowledge discovery},
journal={Advances in Science, Technology and Engineering Systems},
year={2017},
volume={2},
number={3},
pages={469-478},
doi={10.25046/aj020360},
note={cited By 4},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045080612&doi=10.25046%2faj020360&partnerID=40&md5=72c1fa2cf6927d9668f3cf1978d98ed9},
affiliation={Informatics Faculty, Exacts and Technology School, UniRitter Laureate International Universities91849-440, Brazil},
abstract={The evolution of technology has changed the face of education, especially when combined with appropriate pedagogical bases. This combination has created innovation opportunities in order to add quality to teaching through new perspectives for traditional methods applied in the classroom. In the Health field, particularly, augmented reality and interaction design techniques can assist the teacher in the exposition of theoretical concepts and/or concepts that need of training at specific medical procedures. Besides, visualization and interaction with Health data, from different sources and in different formats, helps to identify hidden patterns or anomalies, increases the flexibility in the search for certain values, allows the comparison of different units to obtain relative difference in quantities, provides human interaction in real time, etc. At this point, it is noted that the use of interactive visualization techniques such as augmented reality and virtual can collaborate with the process of knowledge discovery in medical and biomedical databases. This work discuss aspects related to the use of augmented reality and interaction design as a tool for teaching anatomy and knowledge discovery, with the proposition of an case study based on mobile application that can display targeted anatomical parts in high resolution and with detail of its parts. © 2017 ASTES Publishers. All rights reserved.},
author_keywords={Anatomy visualization;  Augmented reality;  Health education;  Interaction design;  Knowledge Discovery},
correspondence_address1={Da Silva, I.C.S.; Informatics Faculty, Exacts and Technology School, UniRitter Laureate International UniversitiesBrazil; email: isabel.siqueira@gmail.com},
publisher={ASTES Publishers},
issn={24156698},
language={English},
abbrev_source_title={Adv. Sci., Technol. Eng. Syst.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Tsai2017199,
author={Tsai, T.-H. and Shen, C.-Y. and Lin, Z.-S. and Liu, H.-R. and Chiou, W.-K.},
title={Exploring location-based augmented reality experience in museums},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2017},
volume={10278 LNCS},
pages={199-209},
doi={10.1007/978-3-319-58703-5_15},
note={cited By 4},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025127512&doi=10.1007%2f978-3-319-58703-5_15&partnerID=40&md5=e9922da1b0b9bad40d925feaaff55394},
affiliation={Department of Industrial Design, Chang Gung University, Taoyuan, Taiwan; Formosa Plastics Group Museum, Taoyuan, Taiwan},
abstract={Augmented reality and beacon technology have gradually attracted considerable attention as the technology has matured, and is now applied in many areas, including museums. This study uses AR and beacons to develop a new museum tour guide app and then design the content and functions of the app based on media richness theory. The tour guide app is expected to provide immediate information guiding service and various education and entertainment functions that are more interactive. Finally, the present study measured the usability of the system by a mobile-specific heuristic evaluation checklist. © Springer International Publishing AG 2017.},
author_keywords={Augmented reality;  Beacon;  Media richness theory;  Mobilespecific heuristic guideline;  Museums;  Tour guide app},
keywords={Augmented reality;  Museums, Beacon;  Heuristic evaluation;  Location based;  Media richness theory;  Mobilespecific heuristic guideline;  Tour guide, Human computer interaction},
correspondence_address1={Tsai, T.-H.; Department of Industrial Design, Chang Gung UniversityTaiwan; email: ttsai.cgu@gmail.com},
editor={Stephanidis C., Antona M.},
publisher={Springer Verlag},
issn={03029743},
isbn={9783319587028},
language={English},
abbrev_source_title={Lect. Notes Comput. Sci.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Srivastava2016572,
author={Srivastava, A.},
title={Enriching student learning experience using augmented reality and smart learning objects},
journal={ICMI 2016 - Proceedings of the 18th ACM International Conference on Multimodal Interaction},
year={2016},
pages={572-576},
doi={10.1145/2993148.2997623},
note={cited By 4},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016634556&doi=10.1145%2f2993148.2997623&partnerID=40&md5=a416b503ceb7e0e169c5bc6bd6bbada5},
affiliation={Department of Design, Indian Institute of Technology, Guwahati Assam, India},
abstract={Physical laboratories in Electronic Engineering curriculum play a crucial role in enabling students to gain "hands-on" learning experience to get a feel for problem-solving. However, students often feel frustrated in these laboratories due to procedural difficulties and disconnects that exist between theory and practice. This impedes their learning and causes them to lose interest in the practical experiment. This research considers the approach of ubiquitous computing to address this issue by embedding computational capabilities into commonly used physical objects in electronics lab (e.g. breadboard) and making use of mobile Augmented Reality application to assist students. Two working prototypes have been proposed as a proof-of-concept. These are (i) an AR based lab manual and circuit building application, and, (ii) Intelligent Breadboard - which is capable of sensing errors made by students. It is posited that such systems can help reduce cognitive load and bridge gaps between theory and practical applications that students face in laboratories. © 2016 ACM.},
author_keywords={Augmented reality;  Education;  Embedded intelligence;  Smart learning objects},
keywords={Augmented reality;  Cognitive systems;  Computation theory;  Education;  Interactive computer systems;  Laboratories;  Problem solving;  Ubiquitous computing, Building applications;  Computational capability;  Electronic engineering curricula;  Embedded intelligence;  Learning experiences;  Learning objects;  Mobile augmented reality;  Student learning experiences, Students},
correspondence_address1={Srivastava, A.; Department of Design, Indian Institute of TechnologyIndia; email: anmol.srivastava@iitg.ernet.in},
editor={Pelachaud C., Nakano Y.I., Nishida T., Busso C., Morency L.-P., Andre E.},
publisher={Association for Computing Machinery, Inc},
isbn={9781450345569},
language={English},
abbrev_source_title={ICMI - Proc. ACM Int. Conf. Multimodal Interact.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Konrad2016,
author={Konrad, R. and Padmanaban, N. and Cooper, E. and Wetzstein, G.},
title={Computational focus-tunable near-eye displays},
journal={ACM SIGGRAPH 2016 Emerging Technologies, SIGGRAPH 2016},
year={2016},
doi={10.1145/2929464.2929470},
art_number={2929470},
note={cited By 4},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84984666835&doi=10.1145%2f2929464.2929470&partnerID=40&md5=783782161a8a09bb12fb70e629f02f08},
affiliation={Stanford University, United States; Dartmouth College, United States},
abstract={Immersive virtual and augmented reality systems (VR/AR) are entering the consumer market and have the potential to profoundly impact our society. Applications of these systems range from communication, entertainment, education, collaborative work, simulation and training to telesurgery, phobia treatment, and basic vision research. In every immersive experience, the primary interface between the user and the digital world is the near-eye display. Thus, developing near-eye display systems that provide a high-quality user experience is of the utmost importance. Many characteristics of near-eye displays that define the quality of an experience, such as resolution, refresh rate, contrast, and field of view, have been significantly improved in recent years. However, a significant source of visual discomfort prevails: the vergence-accommodation conflict (VAC). This visual conflict results from the fact that vergence cues, but not focus cues, are simulated in near-eye display systems. Indeed, natural focus cues are not supported by any existing near-eye display. Afforded by focus-tunable optics, we explore unprecedented display modes that tackle this issue in multiple ways with the goal of increasing visual comfort and providing more realistic visual experiences. © 2016 Copyright held by the owner/author(s).},
author_keywords={Augmented reality;  Computational displays;  Virtual reality},
keywords={Augmented reality;  Computer graphics;  Display devices;  Virtual reality, Collaborative Work;  Eye-display systems;  Simulation and training;  User experience;  Virtual and augmented reality;  Vision research;  Visual discomfort;  Visual experiences, Interactive computer graphics},
publisher={Association for Computing Machinery, Inc},
isbn={9781450343725},
language={English},
abbrev_source_title={ACM SIGGRAPH Emerg. Technol., SIGGRAPH},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Al-Ali2016741,
author={Al-Ali, H. and Bazzaza, M.W. and Zemerly, M.J. and Ng, J.W.P.},
title={MyVision AIR: An augmented interactive reality book mobile application},
journal={IEEE Global Engineering Education Conference, EDUCON},
year={2016},
volume={10-13-April-2016},
pages={741-745},
doi={10.1109/EDUCON.2016.7474634},
art_number={7474634},
note={cited By 4},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84994662815&doi=10.1109%2fEDUCON.2016.7474634&partnerID=40&md5=cded0bf06d8b548cae659ef69936362f},
affiliation={Dept. Electrical and Computer Engineering, Khalifa University of Science, Technology and Research, Abu Dhabi, United Arab Emirates; Etisalat BT Innovation Center (EBTIC), BT Innovate and Design, Abu Dhabi, United Arab Emirates},
abstract={This paper presents an Augmented Interactive Reality book (AIR) application, aimed to enhance the reading experience of adult-learners by incorporating Augmented Reality (AR) technology to improve the interaction of normal books. Various features and characteristics of Augmented Reality (AR) were applied to the chosen book, "My Vision" written by H.H. Sheikh Mohammed Bin Rashid Al Maktoum, Vice-President and Prime Minister of the UAE and Ruler of Dubai. The project is a joint-collaboration between Etisalat British Telecommunication Innovation Center (EBTIC) and Khalifa University, as part of the iCampus project on "Smart Learning-Edutainment". The project has received a number of positive feedbacks from the field study conducted with the general public, and has also been presented to H.H. Sheikh Mohammed Bin Rashid Al Maktoum - Ruler of Dubai, H.H. Sheikh Saif Bin Zayed Al Nahyan - Deputy Prime Minister and Minister of Interior, and several others. © 2016 IEEE.},
keywords={Aluminum;  Augmented reality;  Bins, Adult learners;  British telecommunications;  Edutainment;  Field studies;  General publics;  Innovation centers;  Mobile applications;  Vice president, Engineering education},
publisher={IEEE Computer Society},
issn={21659559},
isbn={9781467386333},
language={English},
abbrev_source_title={IEEE Global Eng. Edu. Conf., EDUCON},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Redondo201664,
author={Redondo, E. and Fonsec, D. and Vall, F. and Olivares, A.},
title={Mobile device based teaching. New challenges in architectural representation education. Case of study: The "tianguis" in Tonalá, Jalisco, Mexico [Enseñanza basada en dispositivos móviles. Nuevos retos en la docencia de la representación arquitectónica. Caso de estudio: Los Tianguis de Tonalá, Jalisco, México]},
journal={EGA Revista de Expression Grafica Arquitectonica},
year={2016},
volume={21},
number={27},
pages={64-73},
doi={10.4995/ega.2016.4730},
note={cited By 4},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84982099082&doi=10.4995%2fega.2016.4730&partnerID=40&md5=41909c77477dd5af8a458b313e420202},
abstract={TIn this paper we discuss an educational research case of study centered on the visualization and ubiquitous access to educational material on multimedia mobile devices. The object of the study is the urban development and improvement project and the design of new street market stalls in Tonalá, Jalisco, Mexico. The educational experiment was conducted in a course of the Masters Degree in Graphical Processes at the University of Guadalajara. In its evaluation, BLA (Bipolar Laddering Assessment) qualitative surveys, originated in user experience studies, were used as complementary methodologies to the quantitative analysis. After its development, analysis and evaluation, the authors can conclude that these new interactive visualization strategies are proven to motivate students, despite the requirement of a greater dedication time as a result of their complexity and technological novelty.},
author_keywords={Augmented reality;  Digital freehand drawing;  Educational research;  Mobile learning;  VR objects},
publisher={Universitat Politecnica de Valencia},
issn={11336137},
language={English; Spanish},
abbrev_source_title={EGA Riv. Expr. Graf. Arquit.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Smith201645,
author={Smith, M. and Maiti, A. and Maxwell, A.D. and Kist, A.A.},
title={Augmented and mixed reality features and tools for remote laboratory experiments},
journal={International Journal of Online Engineering},
year={2016},
volume={12},
number={7},
pages={45-52},
doi={10.3991/ijoe.v12i07.5851},
note={cited By 4},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84981341464&doi=10.3991%2fijoe.v12i07.5851&partnerID=40&md5=9c330fae5e38cca3b78a1f3caa9fdbff},
affiliation={University of Southern Queensland, Toowoomba, 4350, Australia},
abstract={Augmented Reality (AR) is the process of overlaying meaningful interactive information in a live video stream for creating an enriched visual experience for users. Within Remote Access Laboratories (RAL) this enables users to gain design experience along with gaining knowledge about the particular experiment in question and potentially collaborate on design experiences. This paper focuses on the issues related to the applications of AR in RAL, the levels of AR in context of RAL and their effect on the learning tools. This paper also discusses the challenges of integrating a Natural User interface into the AR for RAL experiments. Finally it presents two example applications for AR in RAL experiment - Virtual Objects Creation and Object Identification and Tagging.},
author_keywords={Augmentated reality;  Computer vision;  Digital image processing;  Object tracking;  Remote laboratories},
keywords={Augmented reality;  Computer vision;  Image processing;  Laboratories;  User interfaces;  Video streaming;  Virtual reality, Augmentated reality;  Interactive informations;  Natural user interfaces;  Object identification;  Object Tracking;  Remote access laboratories (RAL);  Remote laboratories;  Visual experiences, Mixed reality;  Image processing},
publisher={Kassel University Press GmbH},
issn={18681646},
language={English},
abbrev_source_title={Int. J. Online Eng.},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Silva2015160,
author={Silva, E.S. and Rodrigues, M.A.F.},
title={Gesture Interaction and Evaluation Using the Leap Motion for Medical Visualization [Interacao Gestual e Avaliacao usando o Leap Motion para Visualizacao Medica]},
journal={Proceedings - 2015 17th Symposium on Virtual and Augmented Reality, SVR 2015},
year={2015},
pages={160-169},
doi={10.1109/SVR.2015.31},
art_number={7300743},
note={cited By 4},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84959282254&doi=10.1109%2fSVR.2015.31&partnerID=40&md5=1c8ab7df5047026878700e0b54f91ad2},
affiliation={Programa de Pos-Graduacao em Informatica Aplicada, Universidade de Fortaleza, Fortaleza, CE, 60811-905, Brazil},
abstract={In this paper, we present and evaluate an interactive gesture controlled application using the Leap Motion for medical visualization, focusing on user satisfaction as an important component in the composition of the application success factors. Usability testings were conducted to verify important application requirements, among which, the asepsis in the working environment, accuracy of the interaction gestures, interaction time, level of interactivity, naturalness, effectiveness, ease of use and of learning, visual quality of the interface, utility, satisfaction and the non-occurrence of fatigue (physical and mental). The results show the effectiveness of the application in the recognition process of the modeled gestures and a very high level of overall satisfaction of the participants, indicating its strong potential as a touchless support tool in medical tasks guided by radiological images conducted in operating rooms. © 2015 IEEE.},
author_keywords={Gesture Interaction;  Leap Motion;  Medical Visualization;  Usability Testing},
keywords={Augmented reality;  Human computer interaction;  Visualization, Application requirements;  Gesture interaction;  Leap Motion;  Medical visualization;  Radiological images;  Recognition process;  Usability testing;  Working environment, Medical imaging},
publisher={Institute of Electrical and Electronics Engineers Inc.},
isbn={9781467372046},
language={Portuguese},
abbrev_source_title={Proc. - Symp. Virtual Augment. Real., SVR},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Gabellone20153,
author={Gabellone, F.},
title={Integrated technologies for museum communication and interactive apps in the PON DiCet Project},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2015},
volume={9254},
pages={3-16},
doi={10.1007/978-3-319-22888-4_1},
note={cited By 4},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84944684937&doi=10.1007%2f978-3-319-22888-4_1&partnerID=40&md5=6b415b79e3de052841aa94139b46d0c7},
affiliation={IBAM CNR, Istituto per i Beni Archeologici e Monumentali, Lecce, Italy},
abstract={This paper illustrates some results obtained by the IBAM ITLab in the Cultura e Turismo: DiCet project financed with National Operational Program (Programmi Operativi Nazionali – PON) funds. In this project procedures were developed to produce technical models for an efficient management of 3D and 2D resources, and to define best practices and methodical protocols for quality certification and process standardization, capable of increase cross-sector dialogue. The sites were identified as a function of a supply-and-demand analysis with regard to a placement on the market of innovative models and services based on the creation of hyper-realistic digital models and virtual scenarios. Particular attention was given to those uses that permit greater visibility, protection, and conservation of cultural assets characterized by difficult access, vulnerability, seismic risk, hydro-geological risk, etc. In view of this, innovative models and tools were designed and developed for capitalizing on and exploiting cultural heritage, understood as an integrated and complex system conceived as a holistic model strongly based on the use of ICT technologies. Virtual enjoyment is understood here as a form of representing reality that accelerates and strengthens cognitive capacities, which is to say it becomes capable of generating extremely sensitive, “virtuous” learning processes based on metaphors of the real world, and thus easy to use and understand. Operationally, our working group has made some Augmented Reality solutions available; these enable the interactive display – directly in situ and especially on mobile devices – of archaeological monuments integrated within the urban fabric. A simple solution allows the user to display an interactive 3D reconstruction directly on the real site, using the latest-generation gyroscope function. In addition to this, certain inaccessible monuments of the cities of Lecce and Catania have been virtualized, mainly using image-based technologies and ultra-realistic laser scanning, to allow them to be visited remotely both via smartphone and on large virtual theatres. In any case the virtual reconstruction of the ancient monuments is the starting point of communication process and represent the point of interest around which every technological solution is proposed. © 2015, Springer International Publishing Switzerland.},
author_keywords={3D reconstruction;  Image-based;  Laser scanning;  Lecce;  Palmieri;  Virtual heritage},
keywords={Augmented reality;  Display devices;  Economics;  Historic preservation;  Laser applications;  Mobile devices;  Mobile telecommunication systems;  Surface analysis;  Virtual reality, 3D reconstruction;  Image-based;  Laser scanning;  Lecce;  Palmieri;  Virtual heritage, Image reconstruction},
correspondence_address1={Gabellone, F.; IBAM CNR, Istituto per i Beni Archeologici e MonumentaliItaly},
editor={De Paolis L.T., Mongelli A.},
publisher={Springer Verlag},
issn={03029743},
isbn={9783319228877},
language={English},
abbrev_source_title={Lect. Notes Comput. Sci.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Mylonas201943,
author={Mylonas, G. and Amaxilatis, D. and Pocero, L. and Markelis, I. and Hofstaetter, J. and Koulouris, P.},
title={An educational IoT lab kit and tools for energy awareness in European schools},
journal={International Journal of Child-Computer Interaction},
year={2019},
volume={20},
pages={43-53},
doi={10.1016/j.ijcci.2019.03.003},
note={cited By 3},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064275545&doi=10.1016%2fj.ijcci.2019.03.003&partnerID=40&md5=166932e82528face36f786466903a111},
affiliation={Computer Technology Institute and Press “Diophantus”, Patras, Greece; ovos media, Vienna, Austria; Ellinogermaniki Agogi, Athens, Greece},
abstract={The use of maker community tools and IoT technologies inside classrooms is spreading to an ever-increasing number of education and science fields. GAIA is a European research project focused on achieving behavior change for sustainability and energy awareness in schools. In this work, we report on how a large IoT deployment in a number of educational buildings and real-world data from this infrastructure, are utilized to support a “maker” lab kit activity inside the classroom. We also provide some insights to the integration of these activities in the school curriculum, along with a discussion on feedback produced through a series of workshop activities in a number of schools in Greece. Moreover, we discuss the application of the lab kit framework towards implementing an interactive installation. We also report on how the lab kit is paired with a serious game and an augmented reality app for smartphones and tablets, supporting the in-class activities. Our initial evaluation results show a very positive first reaction by the school community. © 2019 Elsevier B.V.},
author_keywords={Augmented reality;  Empirical studies;  Energy awareness;  Gamification;  Internet of things;  Sustainability},
correspondence_address1={Mylonas, G.; Computer Technology Institute and Press “Diophantus”Greece; email: mylonasg@cti.gr},
publisher={Elsevier B.V.},
issn={22128689},
language={English},
abbrev_source_title={Int. J. Child-Computer Interact.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Kularbphettong2019125,
author={Kularbphettong, K. and Roonrakwit, P. and Chutrtong, J.},
title={Effectiveness of enhancing classroom by using augmented reality technology},
journal={Advances in Intelligent Systems and Computing},
year={2019},
volume={785},
pages={125-133},
doi={10.1007/978-3-319-93882-0_13},
note={cited By 3},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049612235&doi=10.1007%2f978-3-319-93882-0_13&partnerID=40&md5=e5c4ed8208a601796b0ef27e0308ff8f},
affiliation={Science and Technology Faculty, Suan Sunandha Rajabhat University, Bangkok, Thailand; Faculty of Information and Communication Technology, Silpakorn University, Bangkok, Thailand},
abstract={The use of augmented reality (AR) has become an opportunity to enhance teaching approach. AR is an amalgamation of multimedia information with 3D graphics, images, animations and sound to support the user’s perception. The aim of this study is to design and evaluate classroom learning through AR technique for teaching science subject to secondary school students. The proposed study integrated AR learning application in an interactive learning environment. A quasi-experimental design of the pre-test and post-test for non-randomized control group was employed for this project and the participants consisted of students of secondary schools in Thailand. The results indicates that students were satisfied at the highest level by the learning activities and acquired the target knowledge as well. © Springer International Publishing AG, part of Springer Nature 2019.},
author_keywords={Augmented Reality;  Blended learning;  Students’ achievements;  The efficient},
keywords={Augmented reality;  Computer aided instruction;  Human engineering;  Metals;  Teaching, Augmented reality technology;  Blended learning;  Classroom learning;  Interactive learning environment;  Multimedia information;  Quasi-experimental designs;  Teaching approaches;  The efficient, Students},
correspondence_address1={Kularbphettong, K.; Science and Technology Faculty, Suan Sunandha Rajabhat UniversityThailand; email: kunyanuth.ku@ssru.ac.th},
editor={Polak-Sopinska A., Nazir S., Teperi A.-M.},
publisher={Springer Verlag},
issn={21945357},
isbn={9783319938813},
language={English},
abbrev_source_title={Adv. Intell. Sys. Comput.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Sun2018,
author={Sun, C.-H. and Chiang, P.-Y.},
title={Mr. Piano: A Portable Piano Tutoring System},
journal={Proceedings of the 2018 IEEE 25th International Conference on Electronics, Electrical Engineering and Computing, INTERCON 2018},
year={2018},
doi={10.1109/INTERCON.2018.8526423},
art_number={8526423},
note={cited By 3},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058062102&doi=10.1109%2fINTERCON.2018.8526423&partnerID=40&md5=315a7b33cb685bcc1974a5f1b4ebd5c1},
affiliation={National Taipei University of Technology, Taipei, Taiwan},
abstract={We present a portable piano-tutoring system that facilitates piano learning without the spatial limitations and unaffordable cost. Our proposed system is able to simultaneously project an interactive piano on the table while displaying a music sheet with animated instruction on the smartphone. By detecting the user's hand movements with our efficient approach, visual and sound feedbacks can be given in real time. Mr. Piano gives instructions and feedbacks that helps a beginner to learn fundamental piano skills. The user can play with demonstration, instruction, or practice mode with different level of instructions. Unlike other mobile piano-tutoring system, the key of our projected piano is equivalent in size to a standard one that makes users adjust themselves to play a actual piano better. The user evaluation shows our proposed system helps users to learn piano effectively. © 2018 IEEE.},
author_keywords={Augmented reality;  human computer interaction;  piano learning interface},
keywords={Augmented reality;  Human computer interaction, Hand movement;  Real time;  Sound feedback;  Tutoring system;  User evaluations, Musical instruments},
publisher={Institute of Electrical and Electronics Engineers Inc.},
isbn={9781538654903},
language={English},
abbrev_source_title={Proc. IEEE Int. Conf. Electron., Electri. Eng. Comput., INTERCON},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Saeedi20182020,
author={Saeedi, S. and Bodin, B. and Wagstaff, H. and Nisbet, A. and Nardi, L. and Mawer, J. and Melot, N. and Palomar, O. and Vespa, E. and Spink, T. and Gorgovan, C. and Webb, A. and Clarkson, J. and Tomusk, E. and Debrunner, T. and Kaszyk, K. and Gonzalez-De-Aledo, P. and Rodchenko, A. and Riley, G. and Kotselidis, C. and Franke, B. and O Boyle, M.F.P. and Davison, A.J. and Kelly, P.H.J. and Lujan, M. and Furber, S.},
title={Navigating the Landscape for Real-Time Localization and Mapping for Robotics and Virtual and Augmented Reality},
journal={Proceedings of the IEEE},
year={2018},
volume={106},
number={11},
pages={2020-2039},
doi={10.1109/JPROC.2018.2856739},
art_number={8436423},
note={cited By 3},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051650765&doi=10.1109%2fJPROC.2018.2856739&partnerID=40&md5=22b075746ddb506ab97e4c8345827c4d},
affiliation={Department of Computing, Imperial College London, London, SW72AZ, United Kingdom; School of Informatics, University of Edinburgh, Edinburgh, EH8 9AB, United Kingdom; School of Computer Science, University of Manchester, Manchester, M139PL, United Kingdom; Division of Electrical Engineering - Computer Systems, Stanford University, Stanford, CA  94305-9025, United States},
abstract={Visual understanding of 3-D environments in real time, at low power, is a huge computational challenge. Often referred to as simultaneous localization and mapping (SLAM), it is central to applications spanning domestic and industrial robotics, autonomous vehicles, and virtual and augmented reality. This paper describes the results of a major research effort to assemble the algorithms, architectures, tools, and systems software needed to enable delivery of SLAM, by supporting applications specialists in selecting and configuring the appropriate algorithm and the appropriate hardware, and compilation pathway, to meet their performance, accuracy, and energy consumption goals. The major contributions we present are: 1) tools and methodology for systematic quantitative evaluation of SLAM algorithms; 2) automated, machine-learning-guided exploration of the algorithmic and implementation design space with respect to multiple objectives; 3) end-to-end simulation tools to enable optimization of heterogeneous, accelerated architectures for the specific algorithmic requirements of the various SLAM algorithmic approaches; and 4) tools for delivering, where appropriate, accelerated, adaptive SLAM solutions in a managed, JIT-compiled, adaptive runtime context. © 1963-2012 IEEE.},
author_keywords={Automatic performance tuning;  hardware simulation;  scheduling;  simultaneous localization and mapping (SLAM)},
keywords={Application programs;  Augmented reality;  Automatic guided vehicles;  Computer architecture;  Computer hardware;  Energy utilization;  Hardware;  Interactive computer systems;  Learning systems;  Mapping;  Real time systems;  Scheduling;  Tools, Automatic performance tuning;  Hardware simulation;  Runtimes;  Simultaneous localization and mapping;  Software algorithms, Robotics},
correspondence_address1={Saeedi, S.; Department of Computing, Imperial College LondonUnited Kingdom; email: s.saeedi@imperial.ac.uk},
publisher={Institute of Electrical and Electronics Engineers Inc.},
issn={00189219},
coden={IEEPA},
language={English},
abbrev_source_title={Proc. IEEE},
document_type={Article},
source={Scopus},
}

@ARTICLE{Lorusso2018,
author={Lorusso, M.L. and Giorgetti, M. and Travellini, S. and Greci, L. and Zangiacomi, A. and Mondellini, M. and Sacco, M. and Reni, G.},
title={Giok the alien: An AR-based integrated system for the empowerment of problem-solving, pragmatic, and social skills in pre-school children},
journal={Sensors (Switzerland)},
year={2018},
volume={18},
number={7},
doi={10.3390/s18072368},
art_number={2368},
note={cited By 3},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050605455&doi=10.3390%2fs18072368&partnerID=40&md5=4dabcef8bea14612aa1b49d895899374},
affiliation={Scientific Institute IRCCS E. Medea, Via don Luigi Monza 20, Bosisio Parini, LC  23842, Italy; Istituto di Tecnologie Industriali e Automazione-Consiglio Nazionale delle Ricerche, Via Corti 12, Milano, 20133, Italy},
abstract={The use of technology for educational purposes is a consolidated reality, and many new tools are constantly being devised and offered for use with both normally developing children and children with special needs. Nonetheless, a detailed analysis of the processes being stimulated and of the goals being pursued is often lacking or absent. In this work we describe the design, development and preliminary testing of an integrated system which combines the use of smart devices, a physical cube, augmented reality (AR) technology, a smart TV, and a software application especially designed to stimulate cognitive and social functions in pre-school children. The system was tested with three groups of children (25 children in total) during kindergarten activities. The results show that the system is easy to understand, elicits high levels of participation and social interaction, favors strategic behaviors, and can be used by the children with limited need of instruction and support by the adult. The implications for empowerment in typically developing children and the possibilities for use with children who have specific impairments in social communication are discussed. © 2018 by the authors. Licensee MDPI, Basel, Switzerland.},
author_keywords={Augmented reality;  Children;  Communication disorders;  Cooperative games;  Empowerment;  Interactive learning environments;  Pragmatic skills},
keywords={Application programs;  Augmented reality;  Computer aided instruction;  Cooperative communication;  Integrated control;  Software testing, Children;  Communication disorders;  Cooperative game;  Empowerment;  Interactive learning environment;  Pragmatic skills, Problem solving, adult;  behavior;  female;  human;  human relation;  interpersonal communication;  Italy;  male;  preschool child;  problem solving;  social competence, Adult;  Child, Preschool;  Communication;  Female;  Humans;  Interpersonal Relations;  Italy;  Male;  Power (Psychology);  Problem Solving;  Social Skills},
correspondence_address1={Greci, L.; Istituto di Tecnologie Industriali e Automazione-Consiglio Nazionale delle Ricerche, Via Corti 12, Italy; email: luca.greci@itia.cnr.it},
publisher={MDPI AG},
issn={14248220},
pubmed_id={30037067},
language={English},
abbrev_source_title={Sensors},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Vasylevska2017,
author={Vasylevska, K. and Podkosova, I. and Kaufmann, H.},
title={Teaching virtual reality with HTC Vive and leap motion},
journal={SIGGRAPH Asia 2017 Symposium on Education, SA 2017},
year={2017},
doi={10.1145/3134368.3139221},
art_number={a2},
note={cited By 3},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040165509&doi=10.1145%2f3134368.3139221&partnerID=40&md5=97cf5acaa4ac04a317c8d58a7e6c3f2b},
affiliation={Vienna University of Technology, Favoritenstrasse 9-11, Vienna, A-1040, Austria},
abstract={Creating high quality virtual reality (VR) experience takes time and requires extensive practice. Although, multiple virtual and augmented reality courses existed for years all over the world, high costs of the equipment were always in the way of building up the up to date knowledge. Rapid development of the technology caused the new VR boom and exposed a serious lack of the experienced VR/AR developers. In this paper, we present our introductory VR courses for master students. The aim of the courses is to provide introduction to the basics of VR and AR and supporting technology. We move the teaching focus from the specifics of a particular VR system to the skill build-up and development of the VR user experience. For that we provide the access to the up to date consumer hardware, such as HTC Vive and Leap Motion. We discuss the structure of the courses and methodology, and provide the teaching materials. Moreover, we discuss in details our updated practical course that unites the development of a low-cost desktop and a high-quality immersive VR applications using only off-the-shelf consumer equipment. Furthermore, we discuss the overall course evaluation by the students and further opportunities for their professional growth, as well as consecutive changes that will be made next. © 2017 Copyright held by the owner/author(s).},
author_keywords={Course;  Teaching;  Virtual reality},
keywords={Augmented reality;  Curricula;  E-learning;  Education;  Interactive computer graphics;  Students;  Virtual reality, Consumer equipment;  Course;  Course evaluations;  Professional growth;  Supporting technology;  Teaching materials;  User experience;  Virtual and augmented reality, Teaching},
correspondence_address1={Vasylevska, K.; Vienna University of Technology, Favoritenstrasse 9-11, Austria; email: khrystyna.vasylevska@tuwien.ac.at},
publisher={Association for Computing Machinery, Inc},
isbn={9781450354097},
language={English},
abbrev_source_title={SIGGRAPH Asia Symp. Educ., SA},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Sunil2017279,
author={Sunil, S. and Nair, S.S.K.},
title={An Educational Augmented Reality App to Facilitate Learning Experience},
journal={2017 International Conference on Computer and Applications, ICCA 2017},
year={2017},
pages={279-282},
doi={10.1109/COMAPP.2017.8079771},
art_number={8079771},
note={cited By 3},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85039997018&doi=10.1109%2fCOMAPP.2017.8079771&partnerID=40&md5=1315c3c62d52755e0d0d37353ad03f92},
affiliation={Indian School, Al Seeb Muscat Sultanate of Oman, Oman; Department of Computing, Middle East College Affiliated to Coventry University, United Kingdom},
abstract={Augmented Reality is changing education in a dramatic way and it brings a new dimension to teaching and learning practices through amazing visualization of the real world in an interactive environment. The aim of this research is focused at developing a prototype of mobile based Augmented Reality application using Vuforia and Unity which will be helpful and valuable for students in reinforcing their learning experience. Responses from students indicate that this application is very beneficial to improve their learning curiosity and their passion to learn. © 2017 IEEE.},
author_keywords={Augmented Reality;  experience;  Learning;  Unity;  Vuforia},
keywords={Augmented reality;  Software prototyping;  Students, Augmented reality applications;  experience;  Interactive Environments;  Learning;  Learning experiences;  Teaching and learning;  Unity;  Vuforia, Education},
publisher={Institute of Electrical and Electronics Engineers Inc.},
isbn={9781538627525},
language={English},
abbrev_source_title={Int. Conf. Comput. Appl., ICCA},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Zielke2017,
author={Zielke, M.A. and Zakhidov, D. and Hardee, G. and Evans, L. and Lenox, S. and Orr, N. and Fino, D. and Mathialagan, G.},
title={Developing Virtual Patients with VR/AR for a natural user interface in medical teaching},
journal={2017 IEEE 5th International Conference on Serious Games and Applications for Health, SeGAH 2017},
year={2017},
doi={10.1109/SeGAH.2017.7939285},
art_number={7939285},
note={cited By 3},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021768142&doi=10.1109%2fSeGAH.2017.7939285&partnerID=40&md5=4bb4cf262ca43012cc2fb20e4f4792c8},
affiliation={Center for Modeling and Simulation, Virtual Humans and Synthetic Societies Lab, University of Texas at Dallas, Richardson, TX  75080, United States},
abstract={Professionalism and communication skills are important aspects of medical training, and virtual patient applications can offer cost effective, easily accessible platforms for communication practice which complement flexible, student-driven medical school curriculum design. Further, numerous virtual and augmented reality platforms have been introduced recently. This paper explores potential advantages and disadvantages Virtual and Augmented Reality (VR/AR) technologies offer to the development of a virtual patient application specifically for communication practice-the Emotive Virtual Patients-with a natural user interface. VR/AR technologies may offer highly interactive, immersive virtual patient experiences that tie to our research goals, improve presence and create a more fertile environment to practice empathy, however they may also present platform-specific challenges. A potential virtual patient design framework is discussed, and the unique benefits and limitations of VR/AR devices are analyzed. We put our research in the context of other virtual patient research, and hypothesize what benefits in terms of presence and natural user interfaces VR/AR may provide. © 2017 IEEE.},
author_keywords={augmented reality;  HoloLens;  natural interface;  natural language processing;  virtual patients;  virtual reality},
keywords={Augmented reality;  E-learning;  Natural language processing systems;  Serious games;  Students;  Virtual reality, Communication practices;  Communication skills;  Curriculum designs;  HoloLens;  Natural interfaces;  Natural user interfaces;  Virtual and augmented reality;  Virtual patients, User interfaces},
correspondence_address1={Zielke, M.A.; Center for Modeling and Simulation, Virtual Humans and Synthetic Societies Lab, University of Texas at DallasUnited States; email: margez@utdallas.edu},
editor={Rodrigues N., Vilaca J.L., Dias N., Wong K., de Freitas S., Duque D.},
publisher={Institute of Electrical and Electronics Engineers Inc.},
isbn={9781509054824},
language={English},
abbrev_source_title={IEEE Int. Conf. Serious Games Appl. Health, SeGAH},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{VidelaRodríguez201761,
author={Videla Rodríguez, J.J. and Sanjuán Pérez, A. and Martínez Costa, S. and Seoane Nolasco, A.},
title={Usability and design for augmented reality learning interfaces [Diseño y usabilidad de interfaces para entornos educativos de realidad aumentada]},
journal={Digital Education Review},
year={2017},
number={31},
pages={61-79},
note={cited By 3},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045629820&partnerID=40&md5=7745ba89aace7032196101e3f8d1dc16},
affiliation={Universidade da Coruña, Spain},
abstract={The aim of the paper is to determine the elements, components and key facts to design interactive interfaces for augmented reality environments, focusing on the design and development of virtual worlds for educational applications. The article focuses on the usability study of three augmented reality applications interfaces developed for non touchable natural environments. The aim is to determine the menu and interactive items the user accesses without difficulty and also their navigation patterns. The most viewed elements and the ones that cańt be seen by the user, generating problems of navigation and usability, are analyzed too. The research results indicate that applications developed for non-touch environments can be stressful for the user, especially because of the time they spend with their hands up. The space around the student is also important for the learning process, and all the applications must be designed with some educational, rather than leisure tasks, or a fully open navigation. © 2018 Research Group Education and Virtual Learning (GREAV).All Recived.},
author_keywords={Augmented reality;  Gamification;  Interaction;  Natural interfaces;  Usability},
publisher={Research Group Education and Virtual Learning (GREAV)},
issn={20139144},
language={Spanish},
abbrev_source_title={Digit. Educ. Rev.},
document_type={Review},
source={Scopus},
}

@CONFERENCE{Moro2016,
author={Moro, C. and Stromberga, Z. and Raikos, A. and Stirling, A.},
title={Combining virtual (Oculus Rift & Gear VR) and augmented reality with interactive applications to enhance tertiary medical and biomedical curricula},
journal={SA 2016 - SIGGRAPH ASIA 2016 Symposium on Education: Talks},
year={2016},
doi={10.1145/2993363.2993364},
art_number={2993364},
note={cited By 3},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85006815864&doi=10.1145%2f2993363.2993364&partnerID=40&md5=c0b64323b9ec29345d89805fc21cdf94},
affiliation={Faculty of Health Sciences and Medicine, Bond University, Australia},
abstract={In order to experience the inner-workings and anatomy of the human body, Bond University has developed a number of teaching resources where students rotate between a variety of modes: including Virtual Reality, using the Gear VR and Oculus Rift devices; Augmented Reality, using Samsung S7 Edge mobile devices and Galaxy Tab S2; and interactive applications running on laptops. These modules now form part of the Medical Program's Anatomy, and Biomedical Sciences Physiology curriculum. This Education Talk will detail our current research into the effectiveness of this program and its benefits to students, negative effects experienced from utilizing these devices, and provide bestpractice information as to how other institutions could go about incorporating this technology into their STEM curricula. In addition, the presentation will describe the "10 tips regarding the integration of VR, AR and interactive software applications in University curricula", based on our research and experiences.},
author_keywords={Augmented reality;  STEM education;  Virtual reality},
keywords={Application programs;  Augmented reality;  Curricula;  Education;  Interactive computer graphics;  Interactive devices;  Students, Biomedical curricula;  Biomedical science;  Human bodies;  Interactive applications;  Interactive software;  STEM education;  Teaching resources;  University curricula, Virtual reality},
publisher={Association for Computing Machinery, Inc},
isbn={9781450345453},
language={English},
abbrev_source_title={SA - SIGGRAPH ASIA Symp. Educ.: Talks},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Balderas20161043,
author={Balderas, A. and Ruiz-Rube, I. and Mota, J.M. and Dodero, J.M. and Palomo-Duarte, M.},
title={A Development Environment to Customize Assessment through Students Interaction with Multimodal Applications},
journal={ACM International Conference Proceeding Series},
year={2016},
volume={02-04-November-2016},
pages={1043-1048},
doi={10.1145/3012430.3012644},
note={cited By 3},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85008185868&doi=10.1145%2f3012430.3012644&partnerID=40&md5=70187805825089f7b4e4299c71a2aab7},
affiliation={University of Cadiz, Av. Universidad de Cádiz 10, P. Real, CP 11519, Spain},
abstract={Learning experiences based on multimodal interactive applications are becoming common at all educational levels. Designing assessments for learning applications is often addressed through learning analytics. Multimodal interactive applications generate a large amount of data about students' interaction that can provide insights about their profile, behavior and performance. Unfortunately, this information is usually not accessible or difficult to collect from such applications, especially for teachers without computer programming skills. In this work, we present a visual development environment that supports the creation of multimodal interactive applications for learning with nonintrusive monitoring capacities, thus providing teachers the opportunity to create their own learning analytics tools even if they are not skilled in computer programming. © 2016 ACM.},
author_keywords={Augmented reality;  Learning analytics;  Mobile learning;  Nonintrusive monitoring},
keywords={Augmented reality;  Ecology;  Ecosystems;  Education;  Interactive devices;  Teaching, Computer programming skills;  Development environment;  Interactive applications;  Learning analytics;  Learning experiences;  Mobile Learning;  Multimodal application;  Non-intrusive monitoring, Computer programming},
editor={Garcia-Penalvo F.J.},
publisher={Association for Computing Machinery},
isbn={9781450347471},
language={English},
abbrev_source_title={ACM Int. Conf. Proc. Ser.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Franza201661,
author={Franza, N.P.S. and Oka Sudana, A.A.K. and Wibawa, K.S.},
title={Application of basic Balinese dance using augmented reality on android},
journal={Journal of Theoretical and Applied Information Technology},
year={2016},
volume={90},
number={1},
pages={61-66},
note={cited By 3},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84982091053&partnerID=40&md5=fafed6346523a4df9dcb984713bc2aff},
affiliation={Information Technology Department, University of Udayana, Bali, Indonesia},
abstract={Balinese dance is a regional culture in Bali that must be preserved. Balinese dance can be conserved by using Augmented Reality technology. Augmented Reality technology is a combination of two-dimensional or three-dimensional virtual objects into a real environment. This Android-based applications combine with technology of Augmented Reality can be a media application to learn basic Balinese dance movement which can access by the users of smartphone. Augmented Reality technology is able to make the application of learning basic Balinese dance movements become more interactive and interesting. This application uses vuforia which is capable to play sound and display 3D objects of picture basic balinese dance as a marker, into a real environment. The result of this research is a book which contains information and images related to basic movements of Balinese dance which functioned as a marker. This Androidbased application capable to display object dancer in 3D with the position and movement of Balinese Dance above the marker and play sound which contain information about the movements of Balinese dance. This application can be used as a media to introduce Balinese culture to other countries. Balinese dance in this application also helps to maintain the culture of Bali which has became an interesting attraction for tourists both local and foreign. © 2005 - 2016 JATIT & LLS. All rights reserved.},
author_keywords={Android;  Augmented Reality;  Balinese Dance;  Vuforia},
publisher={Asian Research Publishing Network},
issn={19928645},
language={English},
abbrev_source_title={J. Theor. Appl. Inf. Technol.},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Wei2016307,
author={Wei, X. and Weng, D. and Liu, Y. and Wang, Y.},
title={A tour guiding system of historical relics based on augmented reality},
journal={Proceedings - IEEE Virtual Reality},
year={2016},
volume={2016-July},
pages={307-308},
doi={10.1109/VR.2016.7504776},
art_number={7504776},
note={cited By 3},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84979737359&doi=10.1109%2fVR.2016.7504776&partnerID=40&md5=35d1aee1ba18822be080cb4de2d2d37a},
affiliation={Beijing Engineering Research Center of Mixed Reality and Advanced Display, Beijing Institute of Technology100081, China},
abstract={Yuanmingyuan is a relic park and only few cultural relics are left due to the looting and burning down in history, which makes that most of the scenic spots of the park look boring. To address such issue, a game-based guidance system for Yuanmingyuan and a time travel game called MAGIC-EYES has been proposed with Augmented Reality technology. Six interactive modes are designed in the proposed system to guide tourists to visit the specified place. The evaluation results of a pilot study shows that the proposed guidance system has significantly improved the tourist experiences. © 2016 IEEE.},
author_keywords={Augmented reality;  Game-based learning;  Guidance system;  Location-based},
keywords={History;  Remote control;  Virtual reality, Augmented reality technology;  Cultural relics;  Evaluation results;  Game-based Learning;  Guidance system;  Guiding systems;  Interactive mode;  Location based, Augmented reality},
editor={Interrante V., Hollerer T., Suma E., Lecuyer A.},
publisher={IEEE Computer Society},
isbn={9781509008360},
language={English},
abbrev_source_title={Proc. IEEE Virtual Real.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Tang2016236,
author={Tang, J.K.T. and Duong, T.-Y.A. and Ng, Y.-W. and Luk, H.-K.},
title={Learning to create 3D models via an augmented reality smartphone interface},
journal={Proceedings of 2015 IEEE International Conference on Teaching, Assessment and Learning for Engineering, TALE 2015},
year={2016},
pages={236-241},
doi={10.1109/TALE.2015.7386050},
art_number={7386050},
note={cited By 3},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84963600268&doi=10.1109%2fTALE.2015.7386050&partnerID=40&md5=21dfad2b783ba6556731f0c114ee13e4},
affiliation={School of Computing and Information Sciences, Caritas Institute of Higher Education, Hong Kong, Hong Kong; School of Science and Technology, Open University of Hong Kong, Hong Kong, Hong Kong},
abstract={The ordinary way of creating 3D models (a.k.a. 3D modeling) requires people to sit in front of the computer for a long time working with professional software. The license fees of these software are expensive, and it is very time consuming and not easy to learn. Teachers sometimes find difficult to teach students the concept of 3D modeling because the newbies need to spend a lot of time to familiarize with the tool interface beforehand. In this paper, we introduce a mobile application that assists students to learn 3D modeling skills and concepts. We provide a natural modeling style with the aid of Augmented Reality (AR). Through a smartphone user interface, the user builds a model with primitive blocks in a "bottom-up" manner like "LEGO" bricks. These blocks are visualized on the printed marker cards that allow users to manipulate (rotate, translate, etc.) them in the same way of manipulating real building blocks. User studies have been conducted and we have identified some aspects that help people to model 3D objects. © 2015 IEEE.},
author_keywords={3D Modeling;  Augmented Reality;  Interactive Learning;  Mobile Learning;  Smart Education},
keywords={Augmented reality;  Content based retrieval;  Education;  Education computing;  Engineering education;  Signal encoding;  Smartphones;  Students;  Teaching;  User interfaces, 3-d modeling;  Building blockes;  Interactive learning;  Mobile applications;  Mobile Learning;  Natural models;  Professional software;  Tool interface, Three dimensional computer graphics},
publisher={Institute of Electrical and Electronics Engineers Inc.},
isbn={9781467392266},
language={English},
abbrev_source_title={Proc. IEEE Int. Conf. Teach., Assess. Learn. Eng., TALE},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Ortwein2016,
author={Ortwein, A. and Graw, V. and Heinemann, S. and Menz, G. and Schultz, J. and Selg, F. and Rienowg, A.},
title={Beyond the pixel - Interdisciplinary Earth observation education from the ISS in schools},
journal={Proceedings of the International Astronautical Congress, IAC},
year={2016},
note={cited By 3},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016466167&partnerID=40&md5=2429001f0f811bcb304462632603e8eb},
affiliation={Department of Geography, University of Bonn, Meckenheimer Allee 166, Bonn, 53115, Germany; Center for Remote Sensing of Land Surfaces (ZfL), University of Bonn, Walter-Flex-Str. 3, Bonn, 53113, Germany},
abstract={"Man must rise above the Earth - to the top of the atmosphere and beyond - for only thus will he fully understand the world in which he lives". This famous quote by Socrates anticipates the importance of space travels and earth observation techniques for research on coupled human-environment systems. There is an undoubtedly wide-spread use of remote sensing techniques and image processing analyses for scientific and societal purposes such as weather forecasting, ecological monitoring, or disaster management. Nevertheless, applying earth observing products in everyday school lessons is rare and narrowed only to a visual supplement. The project 'Columbus Eye - Live-Imagery from the ISS in Schools' aims at the sustainable integration of earth observation in schools. Columbus Eye is sponsored by the German Aerospace Center (DLR) Space Administration and acts as the exclusive European partner of NASA's High Definition Earth Viewing (HDEV) experiment, which features four cameras on the International Space Station (ISS) observing the earth 24/7. During the IAC 2015, we presented the implementation of a concept on how the fascination of technology and environment can be bundled in order to ignite the pupil's interest on space flight and earth observation. The corresponding learning portal (www.columbuseye.uni-bonn.de) provides a live-stream to observe our earth from the astronaut's perspective while applying professional remote sensing analysis tools. Following up on this, we are proud to present the extensions of the interactive learning materials. The e-learning section now comprises three kinds of interactivity: working sheets, classification tools, and comprehensive teaching units. The paper explains how geographic information applications build the canvas for explaining physical and mathematical curricular knowledge. Background information, quizzes, and informative animations encourage pupils to solve a given problem on their own virtue in order to foster their methodological competences. Finally, the contribution presents the shift of the didactical paradigm from computer aided e-learning to smartphone supported m-learning. Regular topographic maps are augmented by the fascinating views from above. Hence, the tangible dimensions of pens papers are virtually lifted into the fascinating environment of space. Copyright © 2016 by the International Astronautical Federation (IAF). All rights reserved.},
author_keywords={Augmented reality;  Earth observation;  Education;  HDEV experiment;  ISS;  Media literacy},
correspondence_address1={Ortwein, A.; Department of Geography, University of Bonn, Meckenheimer Allee 166, Germany; email: s3anortw@uni-bonn.de},
publisher={International Astronautical Federation, IAF},
issn={00741795},
language={English},
abbrev_source_title={Proc. Int. Astronaut. Congr., IAC},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Lai2015281,
author={Lai, A.S.Y. and Wong, C.Y.K. and Lo, O.C.H.},
title={Applying Augmented Reality Technology to Book Publication Business},
journal={Proceedings - 12th IEEE International Conference on E-Business Engineering, ICEBE 2015},
year={2015},
pages={281-286},
doi={10.1109/ICEBE.2015.55},
art_number={7349981},
note={cited By 3},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964878748&doi=10.1109%2fICEBE.2015.55&partnerID=40&md5=cecc74c090e00117f87151036e2cc86d},
affiliation={Department of Information and Communications Technology, Hong Kong Institute of Vocational Education, Hong Kong},
abstract={Augmented Reality is an emerging technology and the applications of technology are still not fully unveiled. This paper explores a new application of augmented reality for a new direction in educational book publishing, which aims to bring interactive learning experience to life. The project takes printed images on book to the next level by applying Augmented Reality technology to provide a unique fascinating experience to its readers on mobile devices. Augmented Reality (AR) technology composing with animation brings new digital entertainment experience to the reader of books. The key feature of this paper uses the technology presents auxiliary information in the field of view of an object printed on book automatically without human intervention. The project uses the technology with iPad mobile device to display 3D models, 3D animations, video splaying, websites and web server connectivity for children education. The results and evaluation of the project shows the interactive 3D animation and self-assessment functions significantly support students to improve their learning experience and performance. The software product of this project, from the business perspective, creates a new business marketing dimension in digital publishing and increases the selling profits in the book publication business. © 2015 IEEE.},
author_keywords={Augmented Reality;  E-Learning;  Mobile Computing;  Multimedia Services},
keywords={Animation;  Display devices;  E-learning;  Education;  Education computing;  Electronic commerce;  Mobile computing;  Mobile devices;  Multimedia services, Augmented reality technology;  Auxiliary information;  Business perspective;  Digital entertainment;  Emerging technologies;  Interactive 3D animations;  Interactive learning;  Learning experiences, Augmented reality},
editor={Li Y., Chao K.-M., Chung J.-Y., Fei X.},
publisher={Institute of Electrical and Electronics Engineers Inc.},
isbn={9781467380027},
language={English},
abbrev_source_title={Proc. - IEEE Int. Conf. E-Bus. Eng., ICEBE},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Saenz2015,
author={Saenz, M. and Strunk, J. and Jinsil, K.M. and Seo, H. and Malone, E.},
title={Flex AR: Anatomy education through kinetic tangible augmented reality},
journal={ACM SIGGRAPH 2015 Posters, SIGGRAPH 2015},
year={2015},
doi={10.1145/2787626.2792629},
art_number={a21},
note={cited By 3},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84959440280&doi=10.1145%2f2787626.2792629&partnerID=40&md5=eaaae0a2df8dad98f219ef3ad235604f},
affiliation={Texas A and M University, United States},
abstract={We present Flex AR, a kinetic tangible augmented reality [Billinghurst,2008] application for anatomy education. Anatomy has been taught traditionally in two dimensions, particularly for those in non-medical fields such as artists. Medical students gain hands-on experience through cadaver dissection [[Winkelmann, 2007]. However, with dissection becoming less practical, researchers have begun evaluating techniques for teaching anatomy through technology.},
keywords={Augmented reality;  Computer graphics;  Dissection, Anatomy educations;  Medical fields;  Medical students;  Two-dimension, Interactive computer graphics},
publisher={Association for Computing Machinery, Inc},
isbn={9781450336321},
language={English},
abbrev_source_title={ACM SIGGRAPH Posters, SIGGRAPH},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Pádua201533,
author={Pádua, L. and Adão, T. and Narciso, D. and Cunha, A. and Magalhães, L. and Peres, E.},
title={Towards modern costeffective and lightweight augmented reality setups},
journal={International Journal of Web Portals},
year={2015},
volume={7},
number={2},
pages={33-59},
doi={10.4018/IJWP.2015040103},
note={cited By 3},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84984670510&doi=10.4018%2fIJWP.2015040103&partnerID=40&md5=1d7cbdabd1a054a130ae43963b3d28bb},
affiliation={Engineering Department, University of Trás-os-Montes e Alto Douro, Vila Real, Portugal; INESC TEC, Porto, Portugal; University of Trás-os-Montes e Alto Douro, Vila Real, Portugal; ALGORITMI Center, University of Minho, Braga, Portugal},
abstract={Augmented Reality (AR) has been widely used in areas such as medicine, education, entertainment and cultural heritage to enhance activities that include (but are not limited to) teaching, training and amusement, through the completion of the real world with viewable and usually interactive virtual data (e.g. 3D models, geo-markers and labels). Despite the already confrmed AR benefts in the referred areas, many of the existing AR systems rely on heavy and obsolete hardware bundles composed of several devices and numerous cables that usually culminate in considerably expensive solutions. This issue is about to be tackled through the recent technological developments which currently enable the production of small-sized boards with remarkable capabilities - such as processing, visualization and storage - at relatively low prices. Following this line of reasoning, this paper proposes and compares fve different multi-purpose AR mobile units, running Windows or Android operating systems, having in mind low-cost and lightweight requirements and different levels of immersion: a laptop computer, two tablets, a smartphone and smartglasses. A set of tests was carried out to evaluate the proposed unit performance. Moreover, a set of users' assessments was also conducted, highlighting an overall acceptance regarding the use of the proposed units in AR applications. This paper is an extension of a previous work (Pádua et al., 2015) in which a conceptual architecture for mobile units - complying with AR requirements (including visualization, processing, location and communication) for indoor or outdoor utilization - was presented, along with a shorter set of lightweight and cost-effective AR mobile units and respective performance tests. Copyright © 2015,.},
author_keywords={Archeological visitations;  Augmented Reality;  Augmented reality mobile units;  MARS;  MixAR;  Mixed reality;  Mobile augmented reality systems/units;  Mobile devices},
keywords={Augmented reality;  Cost effectiveness;  Costs;  Digital storage;  Laptop computers;  Medical education;  Mobile devices;  Virtual reality;  Visualization, Archeological visitations;  MARS;  MixAR;  Mixed reality;  Mobile augmented reality;  Mobile units, Computer operating systems},
publisher={IGI Global},
issn={19380194},
language={English},
abbrev_source_title={Int. J. Web Portals},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Lohr2015226,
author={Lohr, M.},
title={Apps versus demonstration experiments: Improvement of quality of physics teaching in secondary education by the use of tablets},
journal={Proceedings of 2014 International Conference on Interactive Mobile Communication Technologies and Learning, IMCL 2014},
year={2015},
pages={226-231},
doi={10.1109/IMCTL.2014.7011137},
art_number={7011137},
note={cited By 3},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84922817697&doi=10.1109%2fIMCTL.2014.7011137&partnerID=40&md5=645f095f6a7f0e5633163493dab8aa40},
affiliation={BG/BRG Schwechat, Schwechat, Austria},
abstract={This paper outlines the possibilities for improving the quality in physics teaching by the use of apps on iPads. In order to find out whether apps with interactive simulations, feature for displaying readouts and with augmented reality content support pupils in achieving their learning goals, the author carried out surveys among students of two classes at the BG/BRG Schwechat. iPads show their advantages in the context of blended learning sequences: the devices are instantly ready to use and allow pure haptic interaction with the content. Moreover, iPads are devices which interact with the environment: Their internal sensors and cameras allow them to see, hear and respond to physical movement and acceleration. The instant read out and visual presentation of collected data makes the iPad extremely useful for Physics teaching. Augmented reality inside and outside the classroom is not science-fiction any more. © 2014 IEEE.},
author_keywords={apps;  augmented reality;  electronic learning;  mobile computing;  sensors;  tablet computers},
keywords={Application programs;  Augmented reality;  Mobile computing;  Mobile telecommunication systems;  Sensors;  Teaching, Augmented reality content;  Blended learning;  Electronic learning;  Haptic interactions;  Interactive simulations;  Physical movements;  Tablet computer;  Visual presentation, E-learning},
correspondence_address1={Lohr, M.; BG/BRG SchwechatAustria; email: manfred.lohr@gmail.com},
publisher={Institute of Electrical and Electronics Engineers Inc.},
isbn={9781479947423},
language={English},
abbrev_source_title={Proc. Int. Conf. Interact. Mob. Commun. Technol. Learn., IMCL},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Persefoni201545,
author={Persefoni, K. and Tsinakos, A.},
title={Use of augmented reality in terms of creativity in school learning},
journal={CEUR Workshop Proceedings},
year={2015},
volume={1450},
pages={45-53},
note={cited By 3},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84954536405&partnerID=40&md5=c20edefc04ec8aa50730b3e9f4eac00e},
affiliation={Eastern Macedonia and Thrace Institute of Technology, EMATTECH, Agios Loukas, Kavala, Greece},
abstract={Education provides a plethora of tools that can be used (alone or combined) for achieving better results. One of the most recent technological advances that can be used as an educational tool is Augmented Reality, a technology that can combine virtual and physical objects in order to enhance the real world. However, little is known about this technology and its possible applications in primary and secondary education. This paper consists a literature review focused on AR and its current and future incorporation in modern education via various context aware technologies (e.g. tablets, smartphones) which can provide opportunities for more interactive and joyful educational experiences. Also, it is described the possibility of implementing AR in Open Course Project situations, such as the one which is available at the Eastern Macedonia and Thrace Institute of Technology. Its purpose is to inform "creators" and stimulate "users" so that the benefits of this promising technology may be diffused throughout the educational process. Copyright © 2015 for the individual papers by the papers' authors.},
keywords={Augmented reality;  Education, Educational experiences;  Educational process;  Educational tools;  Literature reviews;  Modern educations;  Physical objects;  Primary and secondary education;  Technological advances, Engineering education},
publisher={CEUR-WS},
issn={16130073},
language={English},
abbrev_source_title={CEUR Workshop Proc.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Mast2015551,
author={Mast, D. and De Krom, J. and De Vries, S.},
title={Exploring the application of interactive video projection in physical education},
journal={TEI 2015 - Proceedings of the 9th International Conference on Tangible, Embedded, and Embodied Interaction},
year={2015},
pages={551-555},
doi={10.1145/2677199.2687901},
note={cited By 3},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84924065957&doi=10.1145%2f2677199.2687901&partnerID=40&md5=18a1ed76c9f47dc957dc54bbb328796a},
affiliation={Research Group Healthy Lifestyle in a Supporting Environment, Faculty IT and Design, Hague University of Applied Sciences, Haguee, Netherlands; Research Group Healthy Lifestyle in a Supporting Environment, Faculty Health, Nutrition and Sport, Hague University of Applied Sciences, Haguee, Netherlands; Research Group Healthy Lifestyle in a Supporting Environment, Hague University of Applied Sciences, Haguee, Netherlands},
abstract={This paper describes explorations into related technology and research regarding the application of interactive video projection within physical education and the gym of the future. We discuss the application of exergaming in physical education, spatial augmented reality as a technology and participatory design with teachers and children as a design method to develop new concepts. Based on our initial findings we propose directions for further research. Further work includes developing new applications based on the wishes, needs and ideas of physical education teachers and children, incorporating opportunities provided by recent technological developments.},
author_keywords={Exergames;  Interactive video projection;  Participatory design;  Physical education;  Spatial augmented reality},
keywords={Augmented reality;  Design;  Engineering education;  Teaching, Exergames;  Interactive video;  Participatory design;  Physical education;  Spatial augmented realities, Education},
publisher={Association for Computing Machinery, Inc},
isbn={9781450333054},
language={English},
abbrev_source_title={TEI - Proc. Int. Conf. Tangible, Embed., Embodied Interact.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Dragoni2019659,
author={Dragoni, A.F. and Quattrini, R. and Sernani, P. and Ruggeri, L.},
title={Real scale augmented reality. a novel paradigm for archaeological heritage fruition},
journal={Advances in Intelligent Systems and Computing},
year={2019},
volume={919},
pages={659-670},
doi={10.1007/978-3-030-12240-9_68},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064709157&doi=10.1007%2f978-3-030-12240-9_68&partnerID=40&md5=21343424fb1145c9ba2b6407d44a89aa},
affiliation={Department of Information Engineering (DII), Università Politecnica delle Marche, Via Brecce Bianche, Ancona, 60131, Italy; Department of Construction, Civil Engineering and Architecture (DICEA), Università Politecnica delle Marche, Via Brecce Bianche, Ancona, 60131, Italy},
abstract={3D contents have great potential in improving the communication and fruition of Cultural Heritage (CH). The visiting experience on an archaeological site or historical building can be improved by digital contents that help visitors to discover and learn how they once appeared. Augmented Reality (AR) is one of the technologies nowadays used for CH exploitation and it has the great quality of superimposing digital contents on elements of the reality. This paper shows a new interactive application on the archaeological site of Forum Sempronii: thanks to SLAM technology it allows the visitors to see several virtual reconstructions superimposed on the ruins walking around the site, so that they can see how anciently the roman city was. Great attention has been given to the creation of 3D contents: after the creation of high poly models they have been decimated and optimized in terms of number of polygons and textures in order to be fluently managed on mobile devices. The fruition of real scale contents on the real context increases immersive users’ experiences. © Springer Nature Switzerland AG 2019.},
author_keywords={AR;  Cyberarchaeology;  Immersive augmented reality;  SLAM;  Virtual anastylosis},
keywords={Architecture;  Argon;  Augmented reality;  Textures, Archaeological site;  Cyberarchaeology;  Historical buildings;  Immersive augmented realities;  Interactive applications;  SLAM;  Virtual anastylosis;  Virtual reconstruction, E-learning},
correspondence_address1={Quattrini, R.; Department of Construction, Civil Engineering and Architecture (DICEA), Università Politecnica delle Marche, Via Brecce Bianche, Italy; email: r.quattrini@univpm.it},
editor={Luigini A.},
publisher={Springer Verlag},
issn={21945357},
isbn={9783030122393},
language={English},
abbrev_source_title={Adv. Intell. Sys. Comput.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{López-garcía201839,
author={López-garcía, A. and Miralles Martínez, P.},
title={The augmented reality in teacher training. An experience in the practices of the Master's degree in Teaching Secondary Education [La realidad aumentada en la formación del profesorado. Una experiencia en las prácticas del Máster de Profesorado de Enseñanza Secundaria]},
journal={Campus Virtuales},
year={2018},
volume={7},
number={2},
pages={39-46},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058444702&partnerID=40&md5=21719187b338ec877fed86532057b1f4},
affiliation={Universidad de Murcia, Spain},
abstract={This paper presents an innovative experience of teaching practices of the Master's degree in Teacher Training in Secondary Education. Its approach has an impact on the evaluation of the practice's process, facilitating greater knowledge for all parties and a synthesis of the lessons learned. The contribution is destined for university students who are taking the Practicum as a compulsory subject. Its methodology is based on an augmented reality application that allows, by scanning an interactive image, to offer a variety of resources that facilitate the teacher the evolution of the practice's period, so that a closer monitoring of the student body can be carried out. A markup-based program is also used to write the document. The expected results point to the fact that these interactive resources make possible a greater technological and cultural richness, with elements that the teacher will be able to know and value about the student's practices period. © 2018 Red Universitaria de Campus Virtuales.},
author_keywords={Augmented reality;  ICT;  Practical tasks;  Teacher training},
publisher={Red Universitaria de Campus Virtuales},
issn={22551514},
language={Spanish},
abbrev_source_title={Campus Virtuales},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Lin20181075,
author={Lin, C.-H. and Chung, Y. and Chou, B.-Y. and Chen, H.-Y. and Tsai, C.-Y.},
title={A novel campus navigation APP with augmented reality and deep learning},
journal={Proceedings of 4th IEEE International Conference on Applied System Innovation 2018, ICASI 2018},
year={2018},
pages={1075-1077},
doi={10.1109/ICASI.2018.8394464},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050299187&doi=10.1109%2fICASI.2018.8394464&partnerID=40&md5=70ff8a3a98077cc4022058ac16b6f318},
affiliation={Department of Electrical Engineering, National Taiwan Normal University, Taipei, Taiwan},
abstract={Augmented reality has been widely used in many applications because of its ability to offer an amazing way to overlay computer-generated images over the user's real-world view, creating a composite view rooted in real and virtual worlds. Augmented Reality is a realistic, direct or indirect view of the physical reality environment whose elements are 'enhanced' through computer-generated or sensory input such as sound, video, graphics, tactile, or GPS data. In this paper, we present a novel campus navigation APP that uses augmented reality to provide users with a new and interesting way to meet our campus. With advanced augmented reality technologies such as computer vision and object recognition, the information about the campus environment and its objects is overlaid on the real world and becomes interactive. In order to improve the APP efficiency, this paper presents a virtual terrain modeling interface with deep learning to improve the object recognition ability. © 2018 IEEE.},
author_keywords={augmented reality;  computer vision;  computer vision;  deep learning},
keywords={Augmented reality;  Computer vision;  E-learning;  Global positioning system;  Object recognition;  Virtual reality, Augmented reality technology;  Computer generated;  Computer-generated images;  Physical reality;  Recognition abilities;  Sensory input;  Virtual terrain;  Virtual worlds, Deep learning},
editor={Lam A.D.K.-T., Prior S.D., Meen T.-H.},
publisher={Institute of Electrical and Electronics Engineers Inc.},
isbn={9781538643426},
language={English},
abbrev_source_title={Proc. IEEE Int. Conf. Appl. Syst. Innov., ICASI},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Khan2018,
author={Khan, M. and Trujano, F. and Choudhury, A. and Maes, P.},
title={Mathland: Playful mathematical learning in mixed reality},
journal={Conference on Human Factors in Computing Systems - Proceedings},
year={2018},
volume={2018-April},
doi={10.1145/3170427.3186499},
art_number={D108},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052013887&doi=10.1145%2f3170427.3186499&partnerID=40&md5=b83c30d31d3c20059ac4baca68b6a5dd},
affiliation={MIT Media Lab, Cambridge, MA  02139, United States},
abstract={Mathematical experiences are intrinsic to our everyday lives, yet mathematics education is mostly confined to textbooks. Seymour Papert used the term ‘Mathland’ to propose a world where one would learn mathematics as naturally as one learns French while growing up in France. We demonstrate a Mixed Reality application that augments the physical world with interactive mathematical concepts to enable constructionist mathematical learning in the real world. Using Mathland, people can collaboratively explore, experience and experiment with mathematical phenomena in playful, applied and exploratory ways. We implemented Mathland using the Microsoft Hololens and two custom controllers to afford complete immersion through tangible interactions, embodiment and situated learning. © 2018 Copyright is held by the owner/author(s).},
author_keywords={Education/Learning;  Embodied Interaction;  Play;  Situated Learning;  Tangible;  Virtual/Augmented Reality;  Wearable Computers},
keywords={Human computer interaction;  Human engineering;  Wearable computers, Embodied interaction;  Play;  Situated learning;  Tangible;  Virtual/Augmented Reality, Mixed reality},
publisher={Association for Computing Machinery},
isbn={9781450356206; 9781450356213},
language={English},
abbrev_source_title={Conf Hum Fact Comput Syst Proc},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Hensen201867,
author={Hensen, B. and Koren, I. and Klamma, R. and Herrler, A.},
title={An Augmented Reality Framework for Gamified Learning},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2018},
volume={11007 LNCS},
pages={67-76},
doi={10.1007/978-3-319-96565-9_7},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052708051&doi=10.1007%2f978-3-319-96565-9_7&partnerID=40&md5=fe83db890f3deec169cc6f8649affd38},
affiliation={Advanced Community Information Systems Group (ACIS), RWTH Aachen University, Lehrstuhl Informatik 5, Ahornstr. 55, Aachen, 52074, Germany; Faculty of Health, Medicine & Life Science, Maastricht University, Universiteitssingel 60, Maastricht, 6229 ER, Netherlands},
abstract={Formal education with physical objects is resource-intensive and does not scale well. In self-regulated settings, the long-term motivation of learners is an additional issue. Interactive 3D models provide a solution, as they can be replicated as needed. The user experience and immersiveness suffers in conventional Web-based viewers. The concept of mixed reality which encompasses both virtual and augmented reality creates new opportunities. In this article, we present a framework for mixed reality training that allows students to experience 3D models in an augmented reality environment. The resulting app runs on the Microsoft HoloLens and is suited for several settings like bedside teaching and workplace learning. User motivation and learning success are supported by a gamification strategy that rewards the successful completion of quizzes. We evaluated our framework with students of a medical university. Our open source software can be readily employed in various academic and industrial application areas. © 2018, Springer International Publishing AG, part of Springer Nature.},
author_keywords={Augmented reality;  Gamification;  Learning;  Microsoft HoloLens;  Mixed reality},
keywords={Application programs;  Augmented reality;  Computer aided instruction;  Education computing;  Mixed reality;  Motivation;  Open source software;  Open systems;  User interfaces;  Websites, Formal education;  Gamification;  Interactive 3-D models;  Learning;  MicroSoft;  Physical objects;  Virtual and augmented reality;  Workplace learning, E-learning},
correspondence_address1={Hensen, B.; Advanced Community Information Systems Group (ACIS), RWTH Aachen University, Lehrstuhl Informatik 5, Ahornstr. 55, Germany; email: hensen@dbis.rwth-aachen.de},
editor={Klamma R., Spaniol M., Hancke G., Osathanunkul K., Unankard S.},
publisher={Springer Verlag},
issn={03029743},
isbn={9783319965642},
language={English},
abbrev_source_title={Lect. Notes Comput. Sci.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Kose2018569,
author={Kose, A. and Tepljakov, A. and Petlenkov, E.},
title={Towards Assisting Interactive Reality: Interactive Reality for Education, Data Analysis and Industry},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2018},
volume={10851 LNCS},
pages={569-588},
doi={10.1007/978-3-319-95282-6_41},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050270608&doi=10.1007%2f978-3-319-95282-6_41&partnerID=40&md5=697beefe1397ddeea0e8ea32c7a5d84d},
affiliation={Department of Computer Systems, Tallinn University of Technology, Ehitajate tee 5, Tallinn, 19086, Estonia},
abstract={This paper addresses an interactive virtual reality based application of a physical environment. The application presents notable aspects for education, data analysis and industry since the physical building serves as a research and development center. As the project based on physical environment, one of the main target for the work is also concentrated to give high presence feeling for end-users. The developed application is verified in real time. We also introduced our findings in real-time data communication, detection and analysis of human behavior in immersive environment, control systems integration to VR. Data analysis part of the research is linked to human behaviors based on the perception of computational intelligence methods. The activities in immersive environment are engaged to entertaining and joyful learning approaches. Some ideas for further development are also described. © 2018, Springer International Publishing AG, part of Springer Nature.},
author_keywords={Architecture modelling;  Data analysis;  Human behavior;  Intelligent systems;  Real-time communication;  Virtual Reality},
keywords={Augmented reality;  Behavioral research;  Control system analysis;  Data communication systems;  Data handling;  Data reduction;  Information analysis;  Intelligent systems;  Real time systems;  Virtual addresses, Computational intelligence methods;  Developed applications;  Human behaviors;  Immersive environment;  Interactive virtual reality;  Real-time communication;  Real-time data communication;  Research and development, Virtual reality},
correspondence_address1={Kose, A.; Department of Computer Systems, Tallinn University of Technology, Ehitajate tee 5, Estonia; email: ahmet.kose@ttu.ee},
editor={De Paolis L.T., Bourdot P.},
publisher={Springer Verlag},
issn={03029743},
isbn={9783319952819},
language={English},
abbrev_source_title={Lect. Notes Comput. Sci.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Ortega2017,
author={Ortega, M. and Redondo, M.A. and Molina, A.I. and Bravo, C. and Lacave, C. and Arroyo, Y. and Sánchez, S. and García, M.A. and Collazos, C.A. and Toledo, J.J. and Luna-García, H. and Velázquez-Iturbide, J.A. and Gómez-Pastrana, R.A.},
title={IProg: Development of immersive systems for the learning of programming},
journal={ACM International Conference Proceeding Series},
year={2017},
volume={Part F131194},
doi={10.1145/3123818.3123874},
art_number={41},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85033482280&doi=10.1145%2f3123818.3123874&partnerID=40&md5=58bf1fb39d6ed0c8c63e40ca8ed79982},
affiliation={Escuela Superior de Informática, Universidad de Castilla, La Mancha, Spain; Grupo IDIS, Universidad Del Cauca, Colombia; Facultad de Ingeniería, Institución Universitaria, CESMAG, Colombia; Unidad Académica de Ingeniería Eléctrica, Universidad Autónoma de, Zacatecas, Mexico; Dpto. de Informática y Estadística, Universidad Rey Juan Carlos, Spain},
abstract={Basic "computing literacy" is said to be deemed necessary for all citizens, and provides an opportunity to prepare, over longer periods of time, future computing engineers. The iProg Project intends to achieve computing literacy research objectives by means of a number of applications for Programming Education, based on different techniques for advanced Computer- Human Interaction and visualization, including augmented reality and gesture-based interaction. The evaluation of Usability and User Experience of these new forms of interaction will require the use of advanced interaction techniques, including eye tracking and the gathering of biometric information. © 2017 Association for Computing Machinery.},
author_keywords={Evaluation;  Human-computer interaction;  Interactive systems;  Learning;  Research in learning programming},
keywords={Augmented reality;  Computer programming;  Computer systems programming;  Education, Biometric informations;  Computer Human Interaction;  Evaluation;  Gesture-based interaction;  Interactive system;  Learning;  Learning programming;  Learning-of-programming, Human computer interaction},
editor={Gonzalez-Calleros J.M., Guerrero-Garcia J., Ordonez C.A.C.},
publisher={Association for Computing Machinery},
isbn={9781450352291},
language={English},
abbrev_source_title={ACM Int. Conf. Proc. Ser.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Schröder2017,
author={Schröder, M. and Ritter, H.},
title={Deep learning for action recognition in augmented reality assistance systems},
journal={ACM SIGGRAPH 2017 Posters, SIGGRAPH 2017},
year={2017},
doi={10.1145/3102163.3102191},
art_number={a75},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028599204&doi=10.1145%2f3102163.3102191&partnerID=40&md5=0e6ba751c6bc4379e0f2b0935b32e03c},
affiliation={Neuroinformatics Group, Bielefeld University, Germany},
abstract={Recent advances in the development of optical head-mounted displays (HMDs), such as the Microsoft HoloLens, Google Glass, or Epson Moverio, which overlay visual information directly in the user's field of vision, have opened up new possibilities for augmented reality (AR) applications. We propose a system that uses such an optical HMD to assist the user during goal-oriented activities (e.g. manufacturing work) in an intuitive and unobtrusive way (Essig et al. 2016). To this end, our system observes and recognizes the user's actions and generates context-sensitive feedback. Figure 1 shows an overview of our approach, exemplified with the task of assembling a bird house. © 2017 Copyright held by the owner/author(s).},
author_keywords={Action recognition;  Augmented reality;  Deep learning},
keywords={Augmented reality;  Computer graphics;  Deep learning;  Interactive computer graphics, Action recognition;  Assistance system;  Context sensitive;  Goal-oriented;  Manufacturing work;  MicroSoft;  Optical heads;  Visual information, Helmet mounted displays},
publisher={Association for Computing Machinery, Inc},
isbn={9781450350150},
language={English},
abbrev_source_title={ACM SIGGRAPH Post., SIGGRAPH},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Patti2017,
author={Patti, E. and Mollame, A. and Erba, D. and Dalmasso, D. and Osello, A. and Macii, E. and Acquaviva, A.},
title={Combining Building Information Modelling and Ambient Data in Interactive Virtual and Augmented Reality Environments},
journal={IT Professional},
year={2017},
doi={10.1109/MITP.2017.265104553},
note={cited By 2; Article in Press},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85023613323&doi=10.1109%2fMITP.2017.265104553&partnerID=40&md5=af3625656a8130ebc35b3325712dd4c6},
abstract={Smart Building is recent interdisciplinary research field that aims to improve the monitoring, management and maintenance of buildings. In this scenario, we present an innovative solution for combining BIM (Building Information Modelling) data with ambient information collected by heterogeneous devices deployed in the building. In order to collect environmental information, we exploit in this work a distributed software architecture. It enables the interoperability between heterogeneous data-sources, either physical devices like sensor nodes or third party software like Archibus, where building information resides. On top of this infrastructure, we developed an Android-based application that presents environmental building information integrated with BIM data in an Augmented and Virtual Reality environment. The proposed solution provides users awareness about building conditions and energy consumptions. IEEE},
author_keywords={Architecture;  Augmented Reality;  BIM;  Building Management;  Buildings;  C Computer Systems Organization;  C.2 Communication/Networking and Information Technology;  C.2.4 Distributed Systems;  Computer architecture;  Internet-of-Things;  Interoperability;  J Computer Applications;  J.8 Internet Applications;  J.8.l Middleware/business logic;  Middleware;  N. Learning Technologies;  N.1 Learning environments;  N.1.g Virtual and augmented reality;  Object recognition;  Smart Building;  Virtual Reality},
publisher={IEEE Computer Society},
issn={15209202},
coden={IPMAF},
language={English},
abbrev_source_title={IT Prof},
document_type={Article in Press},
source={Scopus},
}

@ARTICLE{Lai201758,
author={Lai, C. and Chu, Y.},
title={Increasing the learning performance via augmented reality technology: A case study of digital image processing course},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2017},
volume={10108 LNCS},
pages={58-64},
doi={10.1007/978-3-319-52836-6_8},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85014273380&doi=10.1007%2f978-3-319-52836-6_8&partnerID=40&md5=0f6f0133af610d157c5fb7f05717271f},
affiliation={Department of Communication Engineering, Oriental Institute of Technology, Taipei, Taiwan; Education Resources and Publishing Center, National Academy for Educational Research, Taipei, Taiwan},
abstract={In this paper, an innovative teaching model to reinforce the teaching performance of teachers and the learning performance is proposed. Based on the digital image processing courses, an interactive teaching method containing immediate image retrieval, visual analysis and processing, imaging control, theoretical narration, and the extensive applications using AR technology and wearable devices is designed. This method converts the mode from teacher’s traditional theoretical lectures and the student’s passive learning behaviors into immediate and dynamic operations, immersive observations; changing combinations; and bi-directional interactions, exchanges, and discussions. It is expected that this method can improve student’s interest and motivation in learning and help them comprehensively understand the abstract concepts of course content and technology theories, as well as the skill in practical application, through real-time and immersive surrounding observations and interactive interface operations, thereby can enhance the learning performance. © Springer International Publishing AG 2017.},
author_keywords={Augmented reality;  Digital image processing;  Engineering education;  Video analysis;  Wearable device},
keywords={Augmented reality;  Curricula;  Digital devices;  Education;  Education computing;  Engineering education;  Image analysis;  Image processing;  Image retrieval;  Students;  Teaching;  Video signal processing;  Wearable computers;  Wearable technology, Augmented reality technology;  Bi-directional interaction;  Dynamic operations;  Innovative teaching;  Interactive interfaces;  Learning performance;  Video analysis;  Wearable devices, E-learning},
correspondence_address1={Lai, C.; Department of Communication Engineering, Oriental Institute of TechnologyTaiwan; email: fo001@mail.oit.edu.tw},
editor={Gennari R., Cao Y., Huang Y.-M., Wu T.-T., Xie H.},
publisher={Springer Verlag},
issn={03029743},
isbn={9783319528359},
language={English},
abbrev_source_title={Lect. Notes Comput. Sci.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{See2016,
author={See, Z.S. and Rengganaten, V. and Billinghurst, M. and Soo, S.},
title={Medical learning murmurs simulation with mobile audible augmented reality},
journal={SA 2016 - SIGGRAPH ASIA 2016 Mobile Graphics and Interactive Applications},
year={2016},
doi={10.1145/2999508.2999527},
art_number={a4},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85006913786&doi=10.1145%2f2999508.2999527&partnerID=40&md5=81c9f189be2b742b13b2773347de8a48},
affiliation={Sunway University, Malaysia; University Tunku Abdul Rahman, Malaysia; University of South Australia, Australia},
abstract={This paper presents the development of a mobile Augmented Reality (AR) heart rate murmur simulator that can be used for clinical teaching for medical trainees. Traditional medical training often requires the trainees to have hands on experience with real patients. However, it is not often possible to find certain types of heart murmurs with patients available for training. To overcome this limitation, we have developed a wearable clothing system using mobile audible AR that provides heart murmur simulation for facilitating medical learning experience. In this paper we describe the proposed system, a user evaluation study and directions for future work. © 2016 ACM.},
author_keywords={Augmented Reality;  Human computer interaction},
keywords={Augmented reality;  Blood vessels;  Cardiology;  Interactive computer graphics;  Interactive devices, Clothing systems;  Heart Murmur;  Heart rates;  Learning experiences;  Medical training;  Mobile augmented reality;  User evaluations, Human computer interaction},
publisher={Association for Computing Machinery, Inc},
isbn={9781450345514},
language={English},
abbrev_source_title={SA - SIGGRAPH ASIA Mob. Graph. Interact. Appl.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Zhu2016,
author={Zhu, K.},
title={Panel: Virtual reality and augmented reality for education},
journal={SA 2016 - SIGGRAPH ASIA 2016 Symposium on Education: Talks},
year={2016},
doi={10.1145/2993363.3006041},
art_number={3006041},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85006826926&doi=10.1145%2f2993363.3006041&partnerID=40&md5=004cc13e391d936ab8ce3e7ad2db8a84},
affiliation={School of Creative Media, City University of Hong Kong, Hong Kong},
abstract={Since the last few decades, virtual reality (VR) and augmented-reality (AR) interfaces have shown the potential to enhance teaching and learning, by combining physical and virtual worlds and leveraging the advantages of both [Yannier et al. 2015]. Educators from different countries have been experimenting this technology in their education systems. In 2007, Hougang Elementary school in Singapore applied an AR prototype in a typical primary (11 years-old) class to facilitate the learning of seed germination and plant growth , and indicated significant engagement and motivation encouraged by the use of the technology [Pang et al. 2007]. More recently, the advanced development of the VR devices has make VR an affordable and suitable interface for educations in different levels, including primary schools, secondary schools, colleges, and universities. In particular, virtual sandbox environment [min 2015], as defined as the VR environments that allow users to freely move through a virtual world, choose how/when to approach objectives, and create domain-specific mods, serve as a good candidate for teachers to design VR-based teaching and learning environment, and for students to explore the new knowledge freely. Motivated by the rapid development of AR and VR, this panel invites representatives from Hong Kong, Australia, and UK. The discussion will focus on the application of AR and VR technologies in different levels of education.},
author_keywords={Augmented reality;  Education;  Virtual reality},
keywords={Augmented reality;  Computer aided instruction;  E-learning;  Education;  Interactive computer graphics;  Seed;  Societies and institutions;  Teaching;  Virtual reality, Domain specific;  Education systems;  Elementary schools;  Primary schools;  Secondary schools;  Seed germination;  Teaching and learning;  Teaching and learning environments, Engineering education},
correspondence_address1={Zhu, K.; School of Creative Media, City University of Hong KongHong Kong; email: keninzhu@cityu.edu.hk},
publisher={Association for Computing Machinery, Inc},
isbn={9781450345453},
language={English},
abbrev_source_title={SA - SIGGRAPH ASIA Symp. Educ.: Talks},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Kommera2016279,
author={Kommera, N. and Kaleem, F. and Harooni, S.M.S.},
title={Smart augmented reality glasses in cybersecurity and forensic education},
journal={IEEE International Conference on Intelligence and Security Informatics: Cybersecurity and Big Data, ISI 2016},
year={2016},
pages={279-281},
doi={10.1109/ISI.2016.7745489},
art_number={7745489},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85004045232&doi=10.1109%2fISI.2016.7745489&partnerID=40&md5=b14f69ab0c43543557f3948e6b50b0c2},
affiliation={Information and Computer Sciences, Metropolitan State UniversityMN, United States},
abstract={Augmented reality is changing the way its users see the world. Smart augmented-reality glasses, with high resolution Optical Head Mounted display, supplements views of the real-world using video, audio, or graphics projected in front of user's eye. The area of Smart Glasses and heads-up display devices is not a new one, however in the last few years, it has seen an extensive growth in various fields including education. Our work takes advantage of a student's ability to adapt to new enabling technologies to investigate improvements teaching techniques in STEM areas and enhance the effectiveness and efficiency in teaching the new course content. In this paper, we propose to focus on the application of Smart Augmented-Reality Glasses in cybersecurity education to attract and retain students in STEM. In addition, creative ways to learn cybersecurity education via Smart Glasses will be explored using a Discovery Learning approach. This mode of delivery will allow students to interact with cybersecurity theories in an innovative, interactive and effective way, enhancing their overall live experience and experimental learning. With the help of collected data and in-depth analysis of existing smart glasses, the ongoing work will lay the groundwork for developing augmented reality applications that will enhance the learning experiences of students. Ultimately, research conducted with the glasses and applications may help to identify the unique skillsets of cybersecurity analysts, learning gaps and learning solutions. © 2016 IEEE.},
author_keywords={characteristics of cybersecurity analysts;  cybersecurity education;  Smart Augmented-Reality Glasses},
keywords={Augmented reality;  Big data;  Curricula;  Display devices;  Education;  Glass;  Helmet mounted displays;  Information science;  Students;  Teaching, Augmented reality applications;  Cyber security;  Cyber-security educations;  Effectiveness and efficiencies;  Enabling technologies;  Experimental learning;  Learning experiences;  Teaching techniques, STEM (science, technology, engineering and mathematics)},
editor={Mao W., Wang G.A., Zhou L., Kaati L.},
publisher={Institute of Electrical and Electronics Engineers Inc.},
isbn={9781509038657},
language={English},
abbrev_source_title={IEEE Int. Conf. Intell. Secur. Inf.: Cybersecur. Big Data, ISI},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Hrishikesh20161079,
author={Hrishikesh, N. and Nair, J.J.},
title={Interactive learning system for the hearing impaired and the vocally challenged},
journal={2016 International Conference on Advances in Computing, Communications and Informatics, ICACCI 2016},
year={2016},
pages={1079-1083},
doi={10.1109/ICACCI.2016.7732188},
art_number={7732188},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85007370525&doi=10.1109%2fICACCI.2016.7732188&partnerID=40&md5=a77f83e08673107475689d0747ebd7fe},
affiliation={Department of Computer Science and Engineering, Amrita School of Engineering, Amrita University, Kerala, 690525, India},
abstract={In our existing education system, teachers primarily engage students verbally in what we call 'chalk and talk' approach. Occasionally, certain learning models are also made use of for the purpose of teaching specific concepts. Smart classroom systems employ PowerPoint presentations, videos and the like. However, lack of sufficient self-interactive models and/or inadequate interaction with them, cause students lose focus. Young children, particularly with disabilities such as those with hearing impairment and vocal dysfunction are prone to it. Our studies showed that students experienced enhanced attentiveness in an environment conducive to self-interactive learning. The word interaction here does not refer to just teacher-student communication rather; it places greater emphasis on interactive self-learning. The student is utmost comfortable when he/she feels to be the center of attention or the teaching is exclusive to him/her. We propose a novel learning system in order to kindle the innate curiosity of students. This article presents an application of the ongoing research on interactive learning. Our system employs both Virtual Reality (VR) and Augmented Reality (AR) to bring about a deeper immersive and effective interactive learning experience to the students. This Interactive VR-AR Learning System (IVRARLS) provides a learning environment with each student being able to independently interact to learn with his or her own virtual learning models in real time. In our scheme, Microsoft Kinect is used for the extraction of interactive gestures of the participant(s). This approach is better suited particularly for the hearing impaired and/or vocally challenged children nevertheless it does not exclusively target them. © 2016 IEEE.},
author_keywords={Augmented reality;  Fiducial marker;  hearing impaired;  immersion;  interactive learning classrooms;  Kinect;  virtual reality;  vocally challenged},
keywords={Augmented reality;  Computer aided instruction;  Education;  Education computing;  Educational technology;  Information science;  Learning systems;  Students;  Teaching;  Virtual reality, Fiducial marker;  Hearing impaired;  immersion;  Interactive learning;  Kinect;  vocally challenged, Audition},
editor={Rodrigues J.J.P.C., Siarry P., Perez G.M., Tomar R., Pathan A.-S.K., Mehta S., Thampi S.M., Berretti S., Gorthi R.P., Pathan A.-S.K., Wu J., Li J., Jain V., Rodrigues J.J.P.C., Atiquzzaman M., Rodrigues J.J.P.C., Bedi P., Kammoun M.H.},
publisher={Institute of Electrical and Electronics Engineers Inc.},
isbn={9781509020287},
language={English},
abbrev_source_title={Int. Conf. Adv. Comput., Commun. Inf., ICACCI},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Srivastava2016421,
author={Srivastava, A. and Yammiyavar, P.},
title={Design of multimodal instructional tutoring agents using augmented reality and smart learning objects},
journal={ICMI 2016 - Proceedings of the 18th ACM International Conference on Multimodal Interaction},
year={2016},
pages={421-422},
doi={10.1145/2993148.2998531},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016553547&doi=10.1145%2f2993148.2998531&partnerID=40&md5=0235ed5d580d16e2ab5574e253142664},
affiliation={Department of Design, Indian Institute of Technology, Guwahati Assam, India},
abstract={This demo presents a novel technique of enriching students' learning experience in electronic engineering laboratories and the basis for its design. The system employs mobile augmented reality (AR) and physical smart objects that can be used in conjunction to assist students in laboratories. Such systems are capable of providing just-in-Time information and sensing errors made while prototyping of specific electronic circuits. These systems can help reduce cognitive load of students in laboratories and bridge gaps between theory and practical applications that students face in laboratories. Two prototypes have been developed - (i) an intelligent breadboard prototype that can sense errors like loose wiring, wrong connections, etc. for a specific experiment, and, (ii) an AR application that provides visualization and instruction for circuit assembly and operating test equipment. The intelligent breadboard acts as a smart learning object. Design methods were used to conceptualize and build such systems. The idea is to merge practices of Human Computer Interaction with those of machine learning to design highly situated physically located tutoring systems for students. Such systems can help innovatively in teaching and learning in engineering laboratories. © 2016 ACM.},
author_keywords={Augmented reality;  Education;  Embedded intelligence;  Smart learning objects;  Ubiquitous computing},
keywords={Augmented reality;  Cognitive systems;  Computation theory;  Design;  Education;  Equipment testing;  Interactive computer systems;  Laboratories;  Learning systems;  Research laboratories;  Software prototyping;  Students;  Teaching;  Ubiquitous computing, Circuit assembly;  Embedded intelligence;  Engineering laboratories;  Learning objects;  Mobile augmented reality;  Novel techniques;  Students' learning experiences;  Teaching and learning, Human computer interaction},
editor={Pelachaud C., Nakano Y.I., Nishida T., Busso C., Morency L.-P., Andre E.},
publisher={Association for Computing Machinery, Inc},
isbn={9781450345569},
language={English},
abbrev_source_title={ICMI - Proc. ACM Int. Conf. Multimodal Interact.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Lohr2016151,
author={Lohr, M.},
title={Scientific teaching with tablet PCs: Incorporating Tablet PCs into scientific workflows at schools},
journal={exp.at 2015 - 3rd Experiment International Conference: Online Experimentation},
year={2016},
pages={151-152},
doi={10.1109/EXPAT.2015.7463249},
art_number={7463249},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84973636656&doi=10.1109%2fEXPAT.2015.7463249&partnerID=40&md5=d173e8197f1a4e25bf504de6fc50456d},
affiliation={BG/BRG Schwechat, Schwechat, Austria},
abstract={The interactive demonstration «Scientific Teaching with Tablet PCs» deals with the capabilities of tablets for measurements of physical values and video analysis of motions. The author designed learning scenarios for science teaching in secondary education using sensors and mobile devices in order to enhance the motivation of pupils to deal with scientific issues. These learning scenarios were implemented and evaluated at the BG/BRG Schwechat, a public school in Austria using the concept of shared iPads with 30 iPads. The learning scenarios are available at the community «iPads@BG/BRG Schwechat» launched at the Open Discovery Space Portal. Open Discovery Space is funded by the European Commission, the aim is to provide a socially-powered, multilingual, open learning infrastructure to boost the adaptation of e-learning resources in Europe. The teaching methodology of the e-learning sequences in physics with the use of sensors meets the requests of the competency model for physics and follows the concept of «inquiry basesd learning». Measurements are carried out with the app «SparkVue» which enables real-time data collection with a mobile device. Data are displayed in real-time in a graph, bar graph, analog meter, digits or table. An analysis of data can be done with built-in statistical tools, furthermore data can be exported in order to analyze with spreadsheet like Excel or Numbers. As cooperative workflow the app allows to live data sharing across devices in the same network. Video analysis of moving objects is carried out by the app «Video Physics». The use of modern tablets and smartphones as measuring devices brings significant benefits for achieving learning goals and supports pupils in understanding complicated scientific concepts. © 2015 IEEE.},
author_keywords={apps;  augmented reality;  electronic learning;  mobile computing;  sensors;  tablet computers},
keywords={Application programs;  Augmented reality;  Data handling;  E-learning;  Mobile computing;  Mobile devices;  Personal computers;  Sensors;  Statistical mechanics, Cooperative workflow;  E-learning resources;  Electronic learning;  European Commission;  Real time data collections;  Scientific workflows;  Tablet computer;  Teaching methodologies, Teaching},
correspondence_address1={Lohr, M.; BG/BRG SchwechatAustria; email: manfred.lohr@gmail.com},
publisher={Institute of Electrical and Electronics Engineers Inc.},
isbn={9781467377171},
language={English},
abbrev_source_title={exp.at - Exp. Int. Conf.: Online Exp.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Frank2016385,
author={Frank, J.A. and Kapila, V.},
title={Towards teleoperation-based interactive learning of robot kinematics using a mobile augmented reality interface on a tablet},
journal={2016 Indian Control Conference, ICC 2016 - Proceedings},
year={2016},
pages={385-392},
doi={10.1109/INDIANCC.2016.7441163},
art_number={7441163},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84965167200&doi=10.1109%2fINDIANCC.2016.7441163&partnerID=40&md5=45206a6308d3a8dbe5888f98bdf0b251},
affiliation={Mechatronics and Controls Lab, Mechanical and Aerospace Engineering, NYU Tandon School of Engineering, Brooklyn, NY  11201, United States},
abstract={The integration of augmented reality (AR) techniques in user interface design has enhanced interactive experiences in teleoperation of robots, hands-on learning in classrooms, laboratory, and special education, and user training in an array of fields, e.g., aerospace, automotive, construction, manufacturing, medical, etc. However, AR-based user interfaces that command machines and tools have not been fully explored for their potential to enhance interactive learning of engineering concepts in the laboratory. This paper outlines the development of a mobile application executing on a tablet device, which renders an immersive AR-based graphical user interface to enable users to monitor, interact with, and control a four-link underactuated planar robot. Computer vision routines are used to extract real-time, vision-based measurements of the robot's joint angles and end effector location from the live video captured by the rear-facing camera on the tablet. The obtained measurements are used to render AR content to offer users with additional visual feedback. Touch gesture recognition is implemented to allow users to naturally and intuitively command the robot by tapping and dragging their fingers at desired locations on the tablet screen. Experimental results show the performance and efficacy of the proposed system as it is operated in two different modes: one in which the user has direct control over the angles of the actuated links of the robot and one in which the user has direct control over the end effector location. © 2016 IEEE.},
keywords={Augmented reality;  Educational technology;  End effectors;  Gesture recognition;  Graphical user interfaces;  Learning systems;  Location;  Machine design;  Remote control;  Rendering (computer graphics);  Robots;  Touch screens;  User interfaces;  Visual communication, Engineering concepts;  Hands-on learning;  Interactive learning;  Mobile applications;  Mobile augmented reality;  Special education;  User interface designs;  Vision-based measurements, Computer vision},
publisher={Institute of Electrical and Electronics Engineers Inc.},
isbn={9781467379939},
language={English},
abbrev_source_title={Indian Control Conf., ICC - Proc.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Liu2016205,
author={Liu, C.Z. and Kavakli, M.},
title={Mixed reality with a collaborative information system},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2016},
volume={10065 LNCS},
pages={205-219},
doi={10.1007/978-3-319-49178-3_16},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84996598692&doi=10.1007%2f978-3-319-49178-3_16&partnerID=40&md5=a9f760f446eefeb9a8429c349b95de25},
affiliation={Department of Computing, Faculty of Science and Engineering, Macquarie University, Sydney, NSW  2109, Australia},
abstract={In this paper, we present a mixed reality environment (MIXER) for immersive interactions. MIXER is an agent based collaborative information system displaying hybrid reality merging interactive computer graphics and real objects. MIXER is an agent based collaborative information system displaying hybrid reality merging interactive computer graphics and real objects. The system comprises a sensor subsystem, a network subsystem and an interaction subsystem. Related issues to the concept of mixed interaction, including human aware computing, mixed reality fusion, agent based systems, collaborative scalable learning in distributed systems, QoE-QoS balanced management and information security, are discussed. We propose a system architecture to perform networked mixed reality fusion for Ambient Interaction. The components of the mixed reality suit to perform human aware interaction are Interaction Space, Motion Monitoring, Action and Scenario Synthesisers, Script Generator, Knowledge Assistant Systems, Scenario Display, and a Mixed Reality Module. Thus, MIXER as an integrated system can provide a comprehensive human-centered mixed reality suite for advanced Virtual Reality and Augmented Reality applications such as therapy, training, and driving simulations. © Springer International Publishing AG 2016.},
author_keywords={Ambient interaction;  Collaborative scalable learning;  Human aware computing;  Mixed reality;  Mixed reality fusion;  QoE-QoS management},
keywords={Augmented reality;  Computer graphics;  Information management;  Information systems;  Interactive computer graphics;  Merging;  Mixers (machinery);  Network security;  Quality of service;  Security of data;  Virtual reality, Ambient interaction;  Collaborative scalable learning;  Human-aware;  Mixed reality;  QOS management, Distributed computer systems},
correspondence_address1={Liu, C.Z.; Department of Computing, Faculty of Science and Engineering, Macquarie UniversityAustralia; email: charles.liu@mq.edu.au},
editor={Perez G.M., Wang G., Han Y.},
publisher={Springer Verlag},
issn={03029743},
isbn={9783319491776},
language={English},
abbrev_source_title={Lect. Notes Comput. Sci.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{He201637,
author={He, G. and Sun, F. and Hu, D. and Lu, X. and Guo, Y. and Lai, S. and Pan, Z.},
title={ARDock: A web-ar based real-time tangible edugame for molecular docking},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2016},
volume={9654},
pages={37-49},
doi={10.1007/978-3-319-40259-8_4},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976634187&doi=10.1007%2f978-3-319-40259-8_4&partnerID=40&md5=19bc364e458a30768585a881b28f14a9},
affiliation={Department of Computer Science and Engineering, East China University of Science and Technology, Shanghai, 200237, China; State Key Laboratory of Virtual Reality Technology and Systems, Beihang University, Beijing, 100191, China; School of Science and Technology, Georgia Gwinnett College, Lawrenceville, GA  30043, United States; Digital Media and Interaction Research Center, Hangzhou Normal University, Hangzhou, 310036, China},
abstract={Molecular docking is increasingly considered as a key tool for lead discovery of structure-based drug design. While huge ligand-receptor combinations, intangible microcosmic molecular world and complex docking scoring are the major challenges for modern molecular docking. In this paper, we present an edugame called ARDock, which is a web-based and interactive molecular docking game. The web-based feature allows multiple participants to engage in the game and provides solutions to complex scientific problems. Augmented reality is imported and consequently molecular docking process becomes tangible. The relative positions of two molecules are instantly updated with the users’ operation, enabling the spatial locating capabilities of humans. The optimized scoring function is proposed to reduce the computation complexity, and the message-oriented middleware facilitates real-time communication between the browsers and the server. The overall framework and detailed designs are illustrated. Some combination strategies make this edugame more interesting, which in return can attract more users and enhance their continuous participation. Sufficient user evaluations validate the usability of this game. This work is a step to promote the popularization of molecular docking knowledge. © Springer International Publishing Switzerland 2016.},
author_keywords={Augmented reality;  Edugame;  Interactivity;  Molecular docking;  Real-time communication},
keywords={Augmented reality;  E-learning;  Middleware;  Websites, Computation complexity;  Continuous participations;  Edu-game;  Interactivity;  Message oriented middleware;  Molecular docking;  Real-time communication;  Structure based drug designs, Molecular modeling},
correspondence_address1={He, G.; Department of Computer Science and Engineering, East China University of Science and TechnologyChina; email: hegaoqi@ecust.edu.cn},
editor={Tian F., El Rhalibi A., Pan Z., Liu B.},
publisher={Springer Verlag},
issn={03029743},
isbn={9783319402581},
language={English},
abbrev_source_title={Lect. Notes Comput. Sci.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Jawad2015272,
author={Jawad, S. and Habib, A. and Ali, B.},
title={Enhanced interactive learning using augmented reality},
journal={17th IEEE International Multi Topic Conference: Collaborative and Sustainable Development of Technologies, IEEE INMIC 2014 - Proceedings},
year={2015},
pages={272-276},
doi={10.1109/INMIC.2014.7097350},
art_number={7097350},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84937239241&doi=10.1109%2fINMIC.2014.7097350&partnerID=40&md5=f7c3d7bd215017cfb11b9dae1ae86421},
affiliation={Department of Computer Science, Bahria University, Islamabad, Pakistan},
abstract={In the field of education, the need of combining learning with enjoyment can never be underestimated. In order to accomplish these goals, educational applications are widely being developedespecially for smart phones. Most of these applications, however provide a total virtual environment. Such an environmentlacks interactivity and providesa rigid learning experience. Augmented Reality (AR) can bridge the gap between virtual and real world thus providing a more natural and interactive learning experience. The main objective of this research work is to investigate the potential of AR to enhance the effectiveness of early learning experiences of children. Using AR technology, an interactive mobile application is developed to provide children aninnovative learning environmentfor basic concepts and skills development. The application engages children to complete simple tasks and interconnects a story with the tasks to gain and retain their interest. Currently, the tasks include English and Urdu alphabets and numeric digitsrecognition. The application, called Interactive Characters, is intended to be a platform for the further development of interactive and effective educational mobile applications with visually attractive augmented interface elements. © 2014 IEEE.},
keywords={Augmented reality;  Educational technology;  Learning systems;  Mobile computing;  Mobile telecommunication systems;  Smartphones;  Virtual reality, Basic concepts;  Educational Applications;  Interactive learning;  Interactive mobile applications;  Interface elements;  Learning experiences;  Mobile applications;  Skills development, Education},
editor={Rasheed H., Lakhani F., Maheshwari M.K.},
publisher={Institute of Electrical and Electronics Engineers Inc.},
isbn={9781479957545},
language={English},
abbrev_source_title={IEEE Int. Multi Topic Conf.: Collab. Sustain. Dev. Technol., IEEE INMIC - Proc.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Wongwatkit2015230,
author={Wongwatkit, C. and Meekaew, N. and Lati, W. and Tungpantong, C. and Saitum, W. and Atanan, Y.},
title={Inquiry-based learning with augmented reality mobile application to enhance scientific conceptual understanding: TheFruitAR},
journal={Workshop Proceedings of the 23rd International Conference on Computers in Education, ICCE 2015},
year={2015},
pages={230-235},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030118706&partnerID=40&md5=6531565c80335fab51748ae64818c12b},
affiliation={Department of Computer and Information Technology, Faculty of Industrial Education and Technology, King Mongkut's University of Technology Thonburi, Bangkok, Thailand; Department of Science, Nonsa-At Pitthayasan School, Udon Thani, Thailand; Department of Science, Ramwittaya Ruchamungklapisek School, Surin, Thailand},
abstract={Scientific inquiry has been considered to be a process to constructing scientific knowledge. With students' misconception of Types of Fruits and Their Flowers, we developed an augmented reality mobile application and its accompanying booklet, TheFruitAR. The purpose of this development was to enhance scientific conceptual understanding on such topic guided by inquiry learning approach. This could help facilitate their learning in a more meaningful way by interacting with interactive multimedia materials and learning activities on mobile. In order to evaluate the effectiveness of TheFruitAR, a comparative experiment was conducted with upper elementary school graders in Thailand. The findings showed that students who learned with our proposed development could outperform than those who learned with the conventional approach, indicating that TheFruitAR could enhance students' conceptual understanding. Moreover, students also revealed positive attitudes towards learning on TheFruitAR, indicating that it motivates students to inquire knowledge.},
author_keywords={Augmented reality;  Mobile learning;  Scientific inquiry},
keywords={Augmented reality;  Interactive computer systems;  Mobile computing;  Mobile telecommunication systems;  Multimedia systems;  Students, Comparative experiments;  Conceptual understanding;  Conventional approach;  Inquiry-based learning;  Interactive multimedia;  Mobile Learning;  Scientific inquiry;  Scientific knowledge, Education},
editor={Wu Y-T., Kojiri T., Kong S.C., Qiu F., Ogata H., Supnithi T., Wang Y., Chen W.},
publisher={Asia-Pacific Society for Computers in Education},
isbn={9784990801472},
language={English},
abbrev_source_title={Workshop Proc. Int. Conf. Comput. Educ., ICCE},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Ocampo2015169,
author={Ocampo, H. and Silva, G. and Salinas, P.},
title={Kinect TEAM: Kinesthetic Learning Applied to Mathematics Using Kinect},
journal={Procedia Computer Science},
year={2015},
volume={75},
pages={169-172},
doi={10.1016/j.procs.2015.12.234},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84985026371&doi=10.1016%2fj.procs.2015.12.234&partnerID=40&md5=b1a23f1bc736a2c75d349202d117daf1},
affiliation={Tecnológico de Monterrey, Av. Eugenio Garza Sada 2501, Monterrey, Nuevo León, Mexico},
abstract={The human interaction with computer can be used to create a wide range of learning technics that can be visual, animated, or interactive. Kinect can support kinesthetic pedagogical practices that can benefit students of mathematics, having also the potential of increase classroom participation, and improve the motivation of learning math. Kinect is a device development by Microsoft, originally designed for the Xbox 360 but later making a new version for pc and xbox one. Kinect is able to provide skeletal tracking, audio recognition and provide the developer with a depth camera and a normal camera and is able to capture movement up to 2 people simultaneously. With this capacity the Kinect makes a perfect hardware piece for Kinesthetic learning. Our main objective is to develop a set of tools involving augmented reality and virtual reality for the understanding and learning of Calculus for students in High School and College. The purpose this work is to show the progress made at the time in the application we have called "Playing with DOT". In it, students can interact visually and using gestures with the graphs of functions of a real variable. A character (DOT) is the way that represents the interaction with Kinect through the fist of the student. The gesture that occurs with the fist will result in a graphic representation of motion in a straight line it has been simulated with the fist. The student will identify different characteristics of movement performed by the graphics functions and their derivatives in a coordinate system. With the challenge that the game presents, it is expected that the student arrives to swiftly identify different behaviors of graphs. Features of growth or decrease and concave up or down will be associated with increasingly fast or slow movements, left or right. © 2015 The Authors.},
author_keywords={human interaction;  Kinesthetic;  math education;  motion sensor},
keywords={Augmented reality;  Calculations;  Cameras;  Education;  Human computer interaction;  Target tracking;  Teaching;  Virtual reality, Audio-recognition;  Co-ordinate system;  Device development;  Graphic representation;  Human interactions;  Kinesthetic;  Motion sensors;  Pedagogical practices, Students},
correspondence_address1={Ocampo, H.; Tecnológico de Monterrey, Av. Eugenio Garza Sada 2501, Mexico; email: ocampohector24@gmail.com},
editor={Ramirez Flores P.G., Martin Gutierrez J., Mendivil E.G., Ginters E.},
publisher={Elsevier B.V.},
issn={18770509},
language={English},
abbrev_source_title={Procedia Comput. Sci.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Frikha2015457,
author={Frikha, R. and Ejbali, R. and Zaied, M. and Amar, C.B.},
title={Natural gesture based interaction with virtual heart in augmented reality},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2015},
volume={9375 LNCS},
pages={457-465},
doi={10.1007/978-3-319-24834-9_53},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84983479277&doi=10.1007%2f978-3-319-24834-9_53&partnerID=40&md5=66c24b0de172d6297280dfac630240bd},
affiliation={REGIM-Lab: REsearch Groups in Intelligent Machines, University of Sfax, ENIS, BP 1173, Sfax, 3038, Tunisia},
abstract={Augmented reality AR is a relatively new technology that blends digital content such as information, sound, video, graphics, or GPS data into our real world. The natural interaction of users with virtual content is one of the big challenges of the AR application. In this paper, we present a new approach to natural interaction with virtual objects employing users’ hands and fingers. We use a real-time image processing system to track gestures from users as a first step and to convert the gestures’ shapes on object commands as a second step. The paper describes how these techniques were applied in an interactive AR heart visualization interface. Our aim is to provide an interactive learning tool that will help students to learn about the components of the heart. Experimental results showed the effectiveness of the proposed method. © Springer International Publishing Switzerland 2015.},
author_keywords={Augmented reality;  Hand gestures recognition;  Hand tracking;  Human computer interaction;  Virtual objects},
keywords={Augmented reality;  Engineering education;  Gesture recognition;  Global positioning system;  Image processing;  Virtual reality, Digital contents;  Gesture-based interaction;  Hand gesture;  Hand tracking;  Interactive learning tools;  Natural interactions;  Real-time image processing;  Virtual objects, Human computer interaction},
correspondence_address1={Frikha, R.; REGIM-Lab: REsearch Groups in Intelligent Machines, University of Sfax, ENIS, BP 1173, Tunisia; email: frikha.rawia.tn@ieee.org},
publisher={Springer Verlag},
issn={03029743},
language={English},
abbrev_source_title={Lect. Notes Comput. Sci.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Shih2015387,
author={Shih, D.-T. and Lin, C.L. and Tseng, C.-Y.},
title={Combining digital archives content with serious game approach to create a Gamified learning experience},
journal={International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives},
year={2015},
volume={40},
number={5W7},
pages={387-394},
doi={10.5194/isprsarchives-XL-5-W7-387-2015},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84974625450&doi=10.5194%2fisprsarchives-XL-5-W7-387-2015&partnerID=40&md5=850ddf51cb07f018446e62ed14fd5446},
affiliation={Dept. of Digital Multimedia Design, China University of Technology, Taipei, Taiwan; Dept. of Cultural and Creative Industries Management, National Taipei University of Education, Taipei, Taiwan},
abstract={This paper presents an interdisciplinary to develop content-Aware application that combines game with learning on specific categories of digital archives. The employment of content-oriented game enhances the gamification and efficacy of learning in culture education on architectures and history of Hsinchu County, Taiwan. The gamified form of the application is used as a backbone to support and provide a strong stimulation to engage users in learning art and culture, therefore this research is implementing under the goal of "The Digital ARt / ARchitecture Project". The purpose of the abovementioned project is to develop interactive serious game approaches and applications for Hsinchu County historical archives and architectures. Therefore, we present two applications, "3D AR for Hukou Old " and "Hsinchu County History Museum AR Tour" which are in form of augmented reality (AR). By using AR imaging techniques to blend real object and virtual content, the users can immerse in virtual exhibitions of Hukou Old Street and Hsinchu County History Museum, and to learn in ubiquitous computing environment. This paper proposes a content system that includes tools and materials used to create representations of digitized cultural archives including historical artifacts, documents, customs, religion, and architectures. The Digital ARt / ARchitecture Project is based on the concept of serious game and consists of three aspects: content creation, target management, and AR presentation. The project focuses on developing a proper approach to serve as an interactive game, and to offer a learning opportunity for appreciating historic architectures by playing AR cards. Furthermore, the card game aims to provide multi-faceted understanding and learning experience to help user learning through 3D objects, hyperlinked web data, and the manipulation of learning mode, and then effectively developing their learning levels on cultural and historical archives in Hsinchu County.},
author_keywords={Digital Archives;  Gamification;  Hukou Old Street;  Serious Game},
keywords={Architecture;  Augmented reality;  Exhibitions;  Imaging techniques;  Ubiquitous computing;  Virtual reality, Digital archives;  Gamification;  Historical archive;  Learning experiences;  Learning opportunity;  Serious games;  Ubiquitous computing environment;  Virtual exhibitions, History},
correspondence_address1={Tseng, C.-Y.; Dept. of Digital Multimedia Design, China University of TechnologyTaiwan; email: jingyueh@cute.edu.tw},
editor={Weng K.-H., Cheng H.-M., Yen Y.-N.},
publisher={International Society for Photogrammetry and Remote Sensing},
issn={16821750},
language={English},
abbrev_source_title={Int. Arch. Photogramm., Remote Sens. Spat. Inf. Sci. - ISPRS Arch.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Ridene2015797,
author={Ridene, T. and Leroy, L. and Chendeb, S.},
title={Innovative virtual reality application for road safety education of children in urban areas},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2015},
volume={9475},
pages={797-808},
doi={10.1007/978-3-319-27863-6_75},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84952815199&doi=10.1007%2f978-3-319-27863-6_75&partnerID=40&md5=55e319375b9919c6df6113cf1426c3ac},
affiliation={U2IS, Ensta ParisTech, Palaiseau, France; Paris 8 University, Saint-Denis, France},
abstract={In order to make children develop good safety habits on the streets, it is very important to educate them on this subject at an early age. The technological advancements allow the creation of applications for training assistance and support. Virtual Reality and Augmented Reality are some of the best suitable scientific domains for successful training applications. In this paper, we present an innovative application for child risk prevention and education in urban are as; this one is based on a collaborative Research & Technologies platform which refers to the dynamic simulation of a city containing artificial intelligence and behavior modeling for pedestrians, crowds, vehicles and traffic in 3D visual and audio environment. We propose an interactive scenario for child risk education and prevention. We experiment it in an autonomous city (Paris) represented in a virtual environment and including artificial intelligence. This scenario takes into account the social implication and the relation between real and virtual actors. © Springer International Publishing Switzerland 2015.},
keywords={Artificial intelligence;  Augmented reality;  Motor transportation;  Risk perception;  Safety engineering;  Three dimensional computer graphics;  Virtual reality, Behavior model;  Collaborative research;  Risk educations;  Risk prevention;  Social implication;  Technological advancement;  Training applications;  Virtual actors, Education},
correspondence_address1={Ridene, T.; U2IS, Ensta ParisTechFrance; email: taha.ridene@ensta-paristech.fr},
editor={Parvin B., Koracin D., Feris R., Weber G., Pavlidis I., McGraw T., Kopper R., Ye Z., Ragan E., Bebis G., Elendt M., Boyle R.},
publisher={Springer Verlag},
issn={03029743},
isbn={9783319278629},
language={English},
abbrev_source_title={Lect. Notes Comput. Sci.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Arenas2015537,
author={Arenas, L. and Zarraonandia, T. and Díaz, P. and Aedo, I.},
title={A platform for supporting the development of mixed reality environments for educational games},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2015},
volume={9192},
pages={537-548},
doi={10.1007/978-3-319-20609-7_51},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84947092903&doi=10.1007%2f978-3-319-20609-7_51&partnerID=40&md5=07db181cb3a7a4b963d8cc90370699fe},
affiliation={Computer Science Department, Universidad Carlos IIIMadrid, Spain},
abstract={In this work we present MR-GREP, a platform that supports educators in the design and implementation of mixed reality educational games. More specifically the system allows the instructional designers to create game experiences that can be played simultaneously in an augmented reality environment as well as in a virtual space that replicates the physical space. This seeks to support the implementation of collaborative learning experiences that combine the flexibility provided by the virtual worlds with the realism and physical component that training in real scenarios allows. The development of this type of environments usually demand advanced technical knowledge that educators normally lack. The platform aims to overcome this problem by providing a set of authoring tools and applications, which does not require programming skills from the user. © Springer International Publishing Switzerland 2015.},
author_keywords={Augmented reality;  Digital educational games;  Mixed reality;  Virtual reality},
keywords={Augmented reality;  Education;  Education computing;  Human computer interaction;  Interactive computer graphics;  Personnel training;  Virtual reality, Collaborative learning;  Design and implementations;  Educational game;  Instructional designer;  Mixed reality;  Mixed-reality environment;  Physical components;  Programming skills, Engineering education},
correspondence_address1={Zarraonandia, T.; Computer Science Department, Universidad Carlos IIISpain},
editor={Zaphiris P., Ioannou A.},
publisher={Springer Verlag},
issn={03029743},
isbn={9783319206080},
language={English},
abbrev_source_title={Lect. Notes Comput. Sci.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Walczak2015595,
author={Walczak, K. and Wiza, W. and Wojciechowski, R. and Wójtowicz, A. and Rumiński, D. and Cellary, W.},
title={Building augmented reality presentations with web 2.0 tools},
journal={Advances in Intelligent Systems and Computing},
year={2015},
volume={369},
pages={595-605},
doi={10.1007/978-3-319-19713-5_52},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84946719998&doi=10.1007%2f978-3-319-19713-5_52&partnerID=40&md5=4e66b8cac0444f2347f460ad27de51f7},
affiliation={Department of Information Technology, Poznań University of Economics, Poznań, Poland},
abstract={Augmented reality enables superimposing various kinds of computer generated content, such as interactive 2D and 3D multimedia objects, in real time, directly on a view of real objects. One of the application domains, which can particularly benefit from the use of AR techniques, is education. However, to enable widespread use of AR in education, simple and intuitive methods of preparation of learning content are required. In this paper, we propose an easy-to-use method of augmenting printed books with arbitrary multimedia content. A popular Moodle-based educational platform has been extended with a plugin enabling creation of AR presentations. In addition, an associated mobile application is provided, which helps teachers assign the presentations to book pages and enables students to access the content. © Springer International Publishing Switzerland 2015.},
author_keywords={AR learning;  Augmented reality;  E-Learning;  Moodle;  Web 2.0},
keywords={Artificial intelligence;  Augmented reality;  E-learning;  Teaching;  World Wide Web, 3D multimedia;  Computer generated;  Educational platforms;  Learning contents;  Mobile applications;  Moodle;  Multimedia contents;  Web 2.0, Education},
correspondence_address1={Walczak, K.; Department of Information Technology, Poznań University of EconomicsPoland; email: walczak@kti.ue.poznan.pl},
editor={Herrero A., Baruque B., Sedano J., Quintian H., Corchado E.},
publisher={Springer Verlag},
issn={21945357},
isbn={9783319197128},
language={English},
abbrev_source_title={Adv. Intell. Sys. Comput.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Arici2019,
author={Arici, F. and Yildirim, P. and Caliklar, Ş. and Yilmaz, R.M.},
title={Research trends in the use of augmented reality in science education: Content and bibliometric mapping analysis},
journal={Computers and Education},
year={2019},
volume={142},
doi={10.1016/j.compedu.2019.103647},
art_number={103647},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070561591&doi=10.1016%2fj.compedu.2019.103647&partnerID=40&md5=fa13dda45a81e1461410f59bb2a31d95},
affiliation={Department of Science Teaching, Kazim Karabekir Faculty of Education, Ataturk University, Erzurum, 25240, Turkey; Department of Computer Education & Instructional Technology, Kazim Karabekir Faculty of Education, Ataturk University, Erzurum, 25240, Turkey},
abstract={The aim of this study was to reveal research trends over the last six years by content analysis and to examine bibliometric results of articles related to the use of augmented reality (AR) in science education. For bibliometric mapping analysis, a total of 147 articles were accessed and for content analysis, a total of 79 articles published between 2013 and 2018 years were included from the Web of Science. From this, a total of 62 articles were selected for analysis. Our results revealed that mobile learning, science education, science learning and e-learning were the most used keywords in articles, while the focus of more recent articles tended to be on mobile learning. The results showed that recent articles have mostly focused on mobile learning and e-learning environments. The most-used words in the abstracts were education, knowledge, science education, experiment and effectiveness. It is evident that recent articles have focused mostly on students' knowledge and achievement. Azuma, Dunleavy and Klopfer are the most cited authors in this field. This is not surprising as they are probably the leading authors on AR in the literature. The most cited journals are Computers & Education, Journal of Science Education & Technology, Educational Technology and Society, Computers in Human Behavior, and British Journal of Educational Technology. These are the most prominent journals on the use of technology in education. Content analysis results showed that “Learning/Academic Achievement”, “Motivation” and “Attitude” have been the most examined variables in the articles. Since academic achievement is highly influenced by motivation and attitude, it is understandable that these variables are considered together in reviewed studies. It was found that mobile applications and marker-based materials on paper have been the most-favored types of materials for AR because these types of materials are easy to use and they can be developed easily and practically. Quantitative studies were the most used research design type but there have been only a limited number of qualitative studies in the last six years. This may be due to the increased tendency to use quantitative and mixed studies in recent years. © 2019 Elsevier Ltd},
author_keywords={Applications in subject areas;  Interactive learning environments;  Media in education;  Multimedia/hypermedia systems;  Virtual reality},
keywords={Augmented reality;  Behavioral research;  Computer aided instruction;  E-learning;  Educational technology;  Learning systems;  Mapping;  Motivation;  Virtual reality, Academic achievements;  Applications in subject areas;  E-learning environment;  Interactive learning environment;  Media in education;  Mobile applications;  Multimedia/hypermedia systems;  Technology in educations, Engineering education},
correspondence_address1={Yilmaz, R.M.; Ataturk University, Kazim Karabekir Faculty of Education, Department of Computer Education and Instructional TechnologyTurkey; email: rkufrevi@atauni.edu.tr},
publisher={Elsevier Ltd},
issn={03601315},
coden={COMED},
language={English},
abbrev_source_title={Comput Educ},
document_type={Article},
source={Scopus},
}

@ARTICLE{Ibarra-Herrera20191271,
author={Ibarra-Herrera, C.C. and Carrizosa, A. and Yunes-Rojas, J.A. and Mata-Gómez, M.A.},
title={Design of an app based on gamification and storytelling as a tool for biology courses},
journal={International Journal on Interactive Design and Manufacturing},
year={2019},
volume={13},
number={4},
pages={1271-1282},
doi={10.1007/s12008-019-00600-8},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068065897&doi=10.1007%2fs12008-019-00600-8&partnerID=40&md5=939aa3f5b49fa4d0c56a2f15a83ffcc9},
affiliation={School of Engineering and Science, Tecnologico de Monterrey, Ave. Atlixcayotl 5718, Puebla, PUE  72453, Mexico; School of Humanities and Education, Tecnologico de Monterrey, Ave. Atlixcayotl 5718, Puebla, PUE  72453, Mexico},
abstract={Engineering students often have little motivation for biology topics, thus tools that promote their interest and motivation are needed to improve the teaching–learning process in this area. The tools also should aid in the development of student competencies, a key objective of the new educational model of Tecnologico de Monterrey, the Tec21 model. In this context, an interactive approach involving app with elements of gamification and storytelling has been designed and tested in our project. Results showed that the students felt motivated after using the app (p value < 0.05). The element of gamification showed to be attractive to the students, but the tool of storytelling did not result that attractive (p value < 0.05 and p value > 0.05, respectively). Interestingly, students would recommend the use of this app to other students and professors (p value < 0.05). Additionally, most of the students approved the test involving the fundamentals of the central dogma of biology—a series of processes that cells use when replicating and when fabricating proteins, and a substantial majority of students felt that videos related to this topic are helpful. Thus, this app, Bio3D, can be considered in its first-version level as satisfactory in its measures of increasing student motivation and improving the teaching–learning process regarding the central dogma of biology. Further work will entail the upgrade of this app to include augmented reality in order to generate a full technological platform supporting efforts to increase the interaction and participation of the students and the professor in the course, thus enhancing the teaching–learning process. © 2019, Springer-Verlag France SAS, part of Springer Nature.},
author_keywords={App;  Biology;  Educational innovation;  Engineers;  Gamification;  Storytelling;  Tec21},
keywords={Application programs;  Augmented reality;  Biology;  Curricula;  E-learning;  Engineering;  Felt;  Learning systems;  Motivation;  Teaching, Educational innovations;  Educational models;  Gamification;  Interactive approach;  Storytelling;  Student competencies;  Tec21;  Technological platform, Students},
correspondence_address1={Ibarra-Herrera, C.C.; School of Engineering and Science, Tecnologico de Monterrey, Ave. Atlixcayotl 5718, Mexico; email: c.ibarra@tec.mx},
publisher={Springer-Verlag France},
issn={19552513},
language={English},
abbrev_source_title={Int. J. Interact. Des. Manuf.},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Pietroszek2019,
author={Pietroszek, K.},
title={IRIS: Inter-reality intera},
journal={Proceedings of the ACM Symposium on Virtual Reality Software and Technology, VRST},
year={2019},
doi={10.1145/3359996.3364731},
art_number={3364731},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076146923&doi=10.1145%2f3359996.3364731&partnerID=40&md5=80b95c0fc86c12ee4478f0edc589963f},
affiliation={IDEAS Lab, American University, Washington, DC, United States},
abstract={While many metaphors were developed for interactions from a specific point at the reality-virtuality continuum, much less attention has been paid to designing metaphors that allow the users to cross the boundaries between the virtual, the augmented, and the real. We propose a use of an Inter-Reality Interactive Surface (IRIS) that enables users to collaborate across the reality-virtuality continuum within the same application. While we examine IRIS in the context of an immersive educational platform, UniVResity, the metaphor can be generalized to many other application domains. © 2019 Copyright held by the owner/author(s).},
author_keywords={Augmented reality;  Collaboration;  Immersive learning;  Interaction metaphor;  Reality-virtuality continuum;  Virtual reality},
keywords={Augmented reality, Collaboration;  Educational platforms;  Immersive;  Immersive learning;  Interaction metaphors;  Interactive surfaces;  Virtuality continuum, Virtual reality},
correspondence_address1={Pietroszek, K.; IDEAS Lab, American UniversityUnited States; email: pietrosz@american.edu},
editor={Spencer S.N.},
publisher={Association for Computing Machinery},
isbn={9781450370011},
language={English},
abbrev_source_title={Proc. ACM Symp. Virtual Reality Softw. Technol. VRST},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Phade20191886,
author={Phade, G. and Goverdhane, K. and Vaidya, O.S. and Gandhe, S.},
title={A novel ICT tool for interactive learning for electronics engineering based on augmented reality},
journal={International Journal of Scientific and Technology Research},
year={2019},
volume={8},
number={8},
pages={1886-1893},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073350154&partnerID=40&md5=79167c818f2c799cf9102251843de517},
abstract={According to survey of India today, the present engineering education system, is now concluded to be insufficient to fulfil the current industrial market requirements. It is due to lack of required skill sets in the students. Talking about some engineering students, initially they anticipates some courses are difficult courses as an example, Electronics Engineering. Thus teaching such subjects becomes quite a challenging task for the teacher. Effective teaching learning of an engineering education mainly depends on theoretical and practical knowledge. As an example, Electronics Engineering includes logical and conceptual subjects in which things are to be imagined and visualized. Classroom teaching is provided through real papers, or books with additional web links, videos, or presentations, or static 3D model, simulations software helps up to some extent. Still there is need to develop some ICT based tools for conceptual understanding of the subject. Augmented Reality (AR) is one of the platforms to develop an ICT based tools. AR provides integration of both real and virtual world. Proposed system is developed using AR with which it is possible to find solutions to both the theoretical as well as practical approach by embossing the 4D images in the real world that include sound. Since high-end AR applications could be used on smart phones, Tablet PC’s etc., updated knowledge regarding the subjects can be easily made available for the students to understand the concept. This paper explores design and development of a novel and interactive ICT tool using AR. It include concept of AR Labs and AR classroom for engineering students. With this, AR Classroom which are virtual class room, will be available in student’s smart phone in the form of Mobile Application and AR Labs for lab experimentation will also be there whose output can be seen on Desktop or projector too. © 2019, International Journal of Scientific and Technology Research. All rights reserved.},
author_keywords={3D models;  AR classrooms AR Labs;  Augmented Reality (AR);  CT tool;  Homography;  Pose estimation},
publisher={International Journal of Scientific and Technology Research},
issn={22778616},
language={English},
abbrev_source_title={Int. J. Sci. Technol. Res.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Harishankar20191534,
author={Harishankar, M. and Pilaka, S. and Sharma, P. and Srinivasan, N. and Joe-Wong, C. and Tague, P.},
title={Procuring spontaneous session-level resource guarantees for real-time applications: An auction approach},
journal={IEEE Journal on Selected Areas in Communications},
year={2019},
volume={37},
number={7},
pages={1534-1548},
doi={10.1109/JSAC.2019.2916487},
art_number={8732668},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067593737&doi=10.1109%2fJSAC.2019.2916487&partnerID=40&md5=e465704ce07a42c10ef33874b7e206fc},
affiliation={Department of Electrical and Computer Engineering, Carnegie Mellon University, Moffett Field, CA  94035, United States; Information Networking Institute, Carnegie Mellon University, Moffett Field, CA  94089, United States},
abstract={Real-time multimedia applications, such as interactive gaming, live video streaming, and augmented reality, have strict latency and bitrate requirements. However, unpredictable network conditions, such as congestion and link quality, can severely degrade the quality of experience (QoE). While buffer-based mitigations cannot be applied to real-time applications due to their immediate resource needs, recent innovations in network slicing have demonstrated the feasibility of dedicating specified amounts of network resources to individual sessions in the radio access network. Encouraged by this, we propose to reserve network resources for multimedia sessions in real time according to their declared needs, thereby providing ad hoc session-level performance guarantees. Through Wi-Fi experiments and trace-driven LTE simulations, we show that such session-level resource provisioning is robust to real-time channel fluctuations and congestion externalities over the lifetime of a session. This approach, however, raises challenges: how can the network ensure that users are honest about their resource needs and optimally allocate its limited resources to users under uncertainty in future sessions' resource needs? We derive a novel multi-unit combinatorial auction (MUCA) model with a unique structure that can be exploited for fast winner determination, and yet incentivize truthful bidding, properties not simultaneously achieved in a generic MUCA but essential to making real-time session guarantees. Furthermore, since dynamic bidding in real time is challenging for end-users who are budget-constrained, we develop a reinforcement learning-based utility-maximizing strategy to distribute their budget across sessions and show that it yields high user utility. © 1983-2012 IEEE.},
author_keywords={5G mobile communication;  auction theory;  economics;  machine learning;  network slicing;  performance guarantees;  Quality of service;  reinforcement learning;  resource management},
keywords={Augmented reality;  Budget control;  Economics;  Learning systems;  Machine learning;  Quality of service;  Radio access networks;  Reinforcement learning, Auction theory;  Mobile communications;  Network slicing;  Performance guarantees;  Resource management, Multimedia systems},
correspondence_address1={Harishankar, M.; Department of Electrical and Computer Engineering, Carnegie Mellon UniversityUnited States; email: mharisha@andrew.cmu.edu},
publisher={Institute of Electrical and Electronics Engineers Inc.},
issn={07338716},
coden={ISACE},
language={English},
abbrev_source_title={IEEE J Sel Areas Commun},
document_type={Article},
source={Scopus},
}

@ARTICLE{Sprute2019373,
author={Sprute, D. and Tönnies, K. and König, M.},
title={A Study on Different User Interfaces for Teaching Virtual Borders to Mobile Robots},
journal={International Journal of Social Robotics},
year={2019},
volume={11},
number={3},
pages={373-388},
doi={10.1007/s12369-018-0506-3},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068803877&doi=10.1007%2fs12369-018-0506-3&partnerID=40&md5=b8c603fdaf5e4a3b0f3364d524d32fad},
affiliation={Bielefeld University of Applied Sciences, Campus Minden, Minden, 32427, Germany; Faculty of Computer Science, Otto-von-Guericke University Magdeburg, Magdeburg, 39106, Germany},
abstract={Human-aware robot navigation is an essential aspect to increase the acceptance of mobile service robots in human-centered environments, e.g. home environments. Robots need to navigate in a human-acceptable way according to the users’ conventions, presence and needs. In order to address the users’ needs, we employ virtual borders, which are non-physical borders and respected by the robots while working, to effectively restrict the workspace of a mobile robot and change its navigational behavior. To this end, we consider different user interfaces, i.e. visual markers, a laser pointer, a graphical user interface and a RGB-D Google Tango tablet with augmented reality application, to allow non-expert users the flexible and interactive definition of virtual borders. These user interfaces were evaluated with respect to their correctness, flexibility, accuracy, teaching effort and user experience. Experimental results show that the RGB-D Google Tango tablet as user interface yields the best overall results compared to the other user interfaces. Apart from a low teaching effort and high flexibility and accuracy, it features the highest user ratings acquired from a comprehensive user study with 25 participants for intuitiveness, comfort, learnability and its feedback system. © 2018, Springer Nature B.V.},
author_keywords={Human-aware navigation;  Human-centered environments;  Social human–robot interaction;  Socially-aware navigation;  User interfaces;  Virtual borders},
keywords={Augmented reality;  E-learning;  Human robot interaction;  Mobile robots;  Navigation;  User interfaces;  Virtual addresses;  Virtual reality, Augmented reality applications;  Feedback systems;  High flexibility;  Human-aware;  Human-centered environments;  Mobile service robots;  Robot interactions;  Virtual borders, Graphical user interfaces},
correspondence_address1={Sprute, D.; Bielefeld University of Applied Sciences, Campus Minden, Germany; email: dennis.sprute@fh-bielefeld.de},
publisher={Springer Netherlands},
issn={18754791},
language={English},
abbrev_source_title={Int. J. Soc. Rob.},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Koutitas2019299,
author={Koutitas, G. and Smith, K.S. and Lawrence, G. and Metsis, V. and Stamper, C. and Trahan, M. and Lehr, T.},
title={A virtual and augmented reality platform for the training of first responders of the ambulance bus},
journal={ACM International Conference Proceeding Series},
year={2019},
pages={299-302},
doi={10.1145/3316782.3321542},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069203441&doi=10.1145%2f3316782.3321542&partnerID=40&md5=64f5da0593cc330fb0df173601aadc72},
affiliation={Electrical and Computer Engineering, Texas State University, San Marcos, TX, United States; School of Social Work, Texas State University, San Marcos, TX, United States; School of Art and Design, Texas State University, San Marcos, TX, United States; Computer Science Texas State University, San Marcos, TX, United States; Austin Smart City City of Austin, Austin, TX, United States},
abstract={AmBus is a bus-sized ambulance that EMS personnel utilize during large-scale emergencies. Although EMS personnel receive annual training, evidence shows current training efforts leave some personnel unfamiliar with the AmBus system and unprepared to respond to an emergency. This work presents a novel interactive training application, utilizing emerging technologies in virtual and augmented reality, that can be delivered remotely to the distributed EMS personnel before they assemble, or as they are assembling. Our initial findings show that such an application can better prepare first responders to be as effective as possible in using the life-saving features of the AmBus. The methodology described in this work can be expanded to include other first responders, and, ultimately, lives may be saved because personnel are better prepared. © 2019 Copyright held by the owner/author(s). Publication rights licensed to ACM.},
author_keywords={Augmented reality;  First responders;  Training;  Virtual reality},
keywords={Ambulances;  Augmented reality;  E-learning;  Virtual reality, Annual training;  Emerging technologies;  First responders;  Interactive training;  Large-scale emergency;  Virtual and augmented reality, Personnel training},
publisher={Association for Computing Machinery},
isbn={9781450362320},
language={English},
abbrev_source_title={ACM Int. Conf. Proc. Ser.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Chiou2019719,
author={Chiou, Y.-M.},
title={Multi-party mixed reality interaction for earth sciences education},
journal={TEI 2019 - Proceedings of the 13th International Conference on Tangible, Embedded, and Embodied Interaction},
year={2019},
pages={719-722},
doi={10.1145/3294109.3302933},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063859591&doi=10.1145%2f3294109.3302933&partnerID=40&md5=edc7d310fc675f188ddd09e960c41f95},
affiliation={Computer and Information Sciences, University of Delaware, Newark, DE, United States},
abstract={Collaborative learning has been shown to be beneficial for children's learning performance, increasing the curiosity and intensity of the ability of cooperation. Mixed-Reality with collaborative learning is the trending research topic in the Human-Computer Interaction (HCI) area. Additionally, with the rise of attention to global warming which brings in more extreme weather and climate conditions, the earth science education would be one of the crucial topics for the next generation. Moreover, there are few augmented reality and mixed reality applications on earth science subject. In this paper, we propose a Mixed Reality Tornado Simulator which offers an earth science education in a collaborative setting. Students and the instructor can cooperate on learning the knowledge of the formation and its damage cause on human-built structures, farming, and vegetation by using our mixed reality application with the Microsoft HoloLens. Also, for evaluating the learning performance in this mixed reality setting, we propose to study the cognitive load while the student is learning the abstract knowledge in Earth Science. We will separate the student into a control group and experimental groups and use different teaching instruments to test the difference of cognitive load. © 2019 ACM.},
author_keywords={Collaborative Learning;  Interactive Earth Sciences Education;  Microsoft HoloLens;  Mixed Reality},
keywords={Augmented reality;  Earth (planet);  Global warming;  Human computer interaction;  Structures (built objects);  Students, Climate condition;  Collaborative learning;  Collaborative settings;  Experimental groups;  Human computer interaction (HCI);  Learning performance;  MicroSoft;  Science education, Mixed reality},
correspondence_address1={Chiou, Y.-M.; Computer and Information Sciences, University of DelawareUnited States; email: steveice@udel.edu},
publisher={Association for Computing Machinery, Inc},
isbn={9781450361965},
language={English},
abbrev_source_title={TEI - Proc. Int. Conf. Tangible, Embed., Embodied Interact.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Barrientos-Avendaño2019267,
author={Barrientos-Avendaño, E. and Rico-Bautista, D. and Coronel-Rojas, L.A. and Cuesta-Quintero, F.R.},
title={Botanical garden: Software-prototype for management and divulgation of native plants based on QR code and augmented reality [Jardín botánico: Prototipo desoftware para la gestión y divulgación de plantas nativas basado en código QR y realidad aumentada]},
journal={RISTI - Revista Iberica de Sistemas e Tecnologias de Informacao},
year={2019},
number={E17},
pages={267-282},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061194996&partnerID=40&md5=5bd7403a94cf04440c6dd85f36eabfbd},
affiliation={Departamento Sistemas e Informática, Grupo de ingeniería en innovación, tecnología y emprendimiento (GRIITEM), Universidad Francisco de Paula Santander Ocaña, Sede Algodonal Vía Acolsure, Ocaña, 546551, Colombia},
abstract={At the Francisco de Paula Santander Ocaña University (UFPS Ocaña) there is a botanical garden. The “Jorge Enrique Quintero Arenas” University Botanical Garden was created with the mission of conserving the dry forest ecosystem and the types of vegetation and flora present in the northeast of Colombia, providing adequate spaces for research and environmental education. This article presents the results of a software prototype. In the first phase.In the first phase, the state of the art of the models, technologies, analysis of terms and concepts is presented. In the second phase, it visualizes the definition of the functional and non-functional requirements that allow the virtualization of the botanical garden. The third phase is the design of the interactive scheme (digital album) based on technological tools such as augmented reality and virtual reality of the different plants and animals. In the final phase, the prototype of the mobile application is shown to have a control and monitoring of the plants. © 2019, Associacao Iberica de Sistemas e Tecnologias de Informacao. All rights reserved.},
author_keywords={Augmented reality;  Digital album;  Internet of things;  QR Code;  Smart university},
publisher={Associacao Iberica de Sistemas e Tecnologias de Informacao},
issn={16469895},
language={Spanish},
abbrev_source_title={Rev. Iberica Sist. Tecnol. Inf.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Tsai2019,
author={Tsai, Y.-T. and Jhu, W.-Y. and Chen, C.-C. and Kao, C.-H. and Chen, C.-Y.},
title={Unity game engine: interactive software design using digital glove for virtual reality baseball pitch training},
journal={Microsystem Technologies},
year={2019},
doi={10.1007/s00542-019-04302-9},
note={cited By 1; Article in Press},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059885787&doi=10.1007%2fs00542-019-04302-9&partnerID=40&md5=678b89ad7c2c6c63583f012a08b0708d},
affiliation={Department of Electrical Engineering, National Kaohsiung University of Science and Technology, No. 415, Chien Kung Rd, Sanmin Dist, Kaohsiung City, 80778, Taiwan; Department of Electrical Engineering/Super Micro Mass Research and Technology Center, Cheng Shiu University, No. 840, Chengcing Rd, Niaosong Dist, Kaohsiung City, 83347, Taiwan},
abstract={This paper proposes a novel baseball pitch training software design to interact with a virtual object in a virtual reality or augmented reality environment by combining a Unity game engine and a digital glove. An embedded microcontroller unit with a communication interface in the digital glove collects sensory data, including mechanical physical limit feedback, electric shock tactile feedback, finger-bending sensations, and three-dimensional spatial positioning, then interacts with the Unity game engine and HTC Vive through a personal computer. The user thereby experiences the sensation of holding an object in virtual reality. Autodesk Maya software is used to design a baseball pitch training mainframe with modeling and animation. The Unity game engine can load baseball pitching scenarios and create a three-dimensional virtual reality stream that is sent to an HTC Vive headset. To seamlessly complete the data exchange between the digital glove and the Unity engine, we use a shared memory mechanism designed with the C# Windows program. The embedded C# script design within the Unity game engine plays an important interactive role between virtual reality scenes and the digital glove. Our experimental results showed that players received physical feedback when touching virtual objects. The proposed design has potential for application in medical rehabilitation and physical training. © 2019, Springer-Verlag GmbH Germany, part of Springer Nature.},
keywords={Animation;  Augmented reality;  Computer games;  E-learning;  Electronic data interchange;  Personal computers;  Sports;  Virtual reality, Communication interface;  Embedded microcontroller;  Interactive software;  Modeling and animation;  Physical training;  Spatial positioning;  Tactile feedback;  Training softwares, Software design},
correspondence_address1={Chen, C.-Y.; Department of Electrical Engineering/Super Micro Mass Research and Technology Center, Cheng Shiu University, No. 840, Chengcing Rd, Niaosong Dist, Taiwan; email: k0464@gcloud.csu.edu.tw},
publisher={Springer Verlag},
issn={09467076},
language={English},
abbrev_source_title={Microsyst Technol},
document_type={Article in Press},
source={Scopus},
}

@CONFERENCE{Sarkar20188,
author={Sarkar, P. and Pillai, J.S. and Gupta, A.},
title={ScholAR: A collaborative learning experience for rural schools using augmented reality application},
journal={Proceedings - IEEE 9th International Conference on Technology for Education, T4E 2018},
year={2018},
pages={8-15},
doi={10.1109/T4E.2018.00010},
art_number={8590098},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061333975&doi=10.1109%2fT4E.2018.00010&partnerID=40&md5=f46616ba63cdf90d579f0fd2e1a8a092},
affiliation={IDC School of Design, Indian Institute of Technology Bombay, Mumbai, India; Electronics and Communication, Jaypee Institute of Information Technology, Noida, India},
abstract={Collaborative learning involves working in groups to solve a problem or perform a task. Collaborative learning is often encouraged in rural schools as due to lack of space and infrastructure, students are made to sit on floors and taught together within and between groups. Evidently, in rural schools, technologies have been introduced to support the existing teaching methods. Augmented Reality is one such technology that can provide a collaborative interactive experience. In our study, we provided an AR based application named 'ScholAR' to experimental group of 16 students of 7th grade as at that age they cultivate the ability to reason logically and develop conceptualizing skills. The application involved six tasks on the Mathematics topic of Introduction to 3D Solids targeted to enhance the spatial visualization skills of the students. We did a comparative study with the control group of 16 students who were taught the same topic using physical 3D models and the usual teaching method followed in their school. We report the results of this study, observations and analysis of the use of this AR application in a collaborative environment and the effect of collaboratively using the AR application on the students' performance. © 2018 IEEE.},
author_keywords={ARCore;  Augmented Reality;  Collaborative Learning;  Rural Education},
keywords={Augmented reality;  Education computing;  Teaching;  Three dimensional computer graphics, ARCore;  Augmented reality applications;  Collaborative environments;  Collaborative learning;  Comparative studies;  Experimental groups;  Rural educations;  Spatial visualization skills, Students},
editor={Kumar V., Murthy S., Kinshuk, Iyer S.},
publisher={Institute of Electrical and Electronics Engineers Inc.},
isbn={9781728111438},
language={English},
abbrev_source_title={Proc. - IEEE Int. Conf. Technol. Educ., T4E},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Nguyen2018,
author={Nguyen, N. and Muilu, T. and Dirin, A. and Alamäki, A.},
title={An interactive and augmented learning concept for orientation week in higher education},
journal={International Journal of Educational Technology in Higher Education},
year={2018},
volume={15},
number={1},
doi={10.1186/s41239-018-0118-x},
art_number={35},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054503413&doi=10.1186%2fs41239-018-0118-x&partnerID=40&md5=cb6d80cc00fb683ef0a5edd3de995a3e},
affiliation={Business Information Technology Department, Haaga-Helia UAS, Helsinki, Finland},
abstract={This paper details the concept development process for an interactive and augmented reality based application that compensates for attending Orientation Week at a higher education institution. The application will help freshmen learn about the institution’s environment and campus, degree program, and course curriculum before school starts. For efficiency and to elicit high emotional engagement, various pedagogical and technological approaches are used for presenting the content, such as gamification and augmented reality. Awareness of their future learning environment, study path, and course details helps students reduce their fear of failure, and this, in turn, prevents educational withdrawal. In addition to raising awareness, the interactive augmented learning for orientation application saves educational institutions significant time and resources by preparing new students for their educational journey on their personal mobile devices. The contribution of this paper is both for academicians and practitioners regarding the process for developing an innovative concept. © 2018, The Author(s).},
author_keywords={Augmented reality;  Concept design;  Emotional design;  Orientation week;  User-centered design},
correspondence_address1={Dirin, A.; Business Information Technology Department, Haaga-Helia UASFinland; email: amir.dirin@yahoo.com},
publisher={Springer Netherlands},
issn={23659440},
language={English},
abbrev_source_title={Int. j. educ. technol. high. educ.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Marques201896,
author={Marques, B.A.D. and Clua, E.W.G. and Vasconcelos, C.N.},
title={Deep spherical harmonics light probe estimator for mixed reality games},
journal={Computers and Graphics (Pergamon)},
year={2018},
volume={76},
pages={96-106},
doi={10.1016/j.cag.2018.09.003},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053797786&doi=10.1016%2fj.cag.2018.09.003&partnerID=40&md5=63369de52106b2f0c379d2c5016871a3},
affiliation={Instituto de Computação - UFF, Av. Gal. Milton Tavares de Souza, Niterói, RJ, Brazil},
abstract={The recent developments in virtual and mixed reality by the video game and entertainment industries are responsible for increasing user's visual immersion and provide a better user experience in games and other interactive simulations. However, the interaction between the user and simulated environment still relies on game controllers or other unnatural handheld devices. In the mixed reality context, the usage of more natural and immersive alternative to the game controllers, such as the user's hands, may drastically increase the game interface experience, allowing a personalized visual feedback of the user's interactions in the real-time simulation. There are basically two approaches for including the user's hand: a 3D reconstruction based method, typically based on depth cameras, or an image-based approach, composing the virtual scene with the real images of the user's hands. In the composition of the user's hands and virtual elements, perceptual discrepancies in the illumination of objects may occur, generating an inconsistency in the illumination of the mixed reality environment. A consistent illumination of the environment greatly improves the user's immersion in the mixed reality application. One way to ensure consistent illumination is by estimating the real-world illumination and use this information to adapt the virtual world lighting setting. We present the Spherical Harmonics Light Probe Estimator, a deep learning based technique that estimates the lighting setting of the real-world environment. The method uses a single RGB image and does not requires prior knowledge of the scene. The estimator outputs a light probe of the real-world lighting, represented by 9 spherical harmonics coefficients. The estimated light probe is used to create a composite image containing both real and virtual elements in an environment with a consistent illumination. We validate the technique through synthetic tests achieving an RMS error of 0.0573. We show the usage of the method in an augmented virtuality application. © 2018 Elsevier Ltd},
author_keywords={Augmented reality;  Deep learning;  Games;  Lighting estimation;  Mixed reality;  Virtual reality},
keywords={Augmented reality;  Deep learning;  Estimation;  Harmonic analysis;  Human computer interaction;  Interactive computer graphics;  Lighting;  Probes;  Spheres;  Virtual reality;  Visual communication, Augmented virtualities;  Entertainment industry;  Games;  Interactive simulations;  Lighting estimation;  Mixed-reality environment;  Real world environments;  Simulated environment, Mixed reality},
correspondence_address1={Marques, B.A.D.; Instituto de Computação - UFF, Av. Gal. Milton Tavares de Souza, Brazil; email: brunodorta@id.uff.br},
publisher={Elsevier Ltd},
issn={00978493},
coden={COGRD},
language={English},
abbrev_source_title={Comput Graphics (Pergamon)},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Dijaya2018,
author={Dijaya, R. and Maulidah, N.M. and Abdullah, D.},
title={Flashcard computer generated imagery medicinal plant for orthopedagogic education},
journal={MATEC Web of Conferences},
year={2018},
volume={197},
doi={10.1051/matecconf/201819715005},
art_number={15005},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053753527&doi=10.1051%2fmatecconf%2f201819715005&partnerID=40&md5=e8c3cf1237041126e7c4ae45885c2a0b},
affiliation={Universitas Muhammadiyah Sidoarjo, Department of Informatics, Sidoarjo, Indonesia; Universitas Malikussaleh, Department of Informatics, Aceh, Indonesia},
abstract={The Indonesia natural wealth of tropical forest store various plants such as ornamental plants, fruits, vegetables, spices and medicinal plants. Medicinal plants are a variety of plants that are recognized as plants for medicines. However, due to the lack of community knowledge about medicinal plants. So it takes the application of learning about the benefits of medicinal plants to the community, especially to children. Orthopedagogic Orthodontic Objects are exceptional children, who have abnormalities that require special educator services. Learning media associated with motor censorship can overcome the limitations of deaf and tuneless children who can improve the motor skills of the child. Because children with hearing impairment and speech have a lack of understanding of spoken and written language. Development of Computer Science technology today, thus encouraging the educational process to be more interesting and applicable in order to improve the quality of education media and learning interests of learners. Augmented Reality (AR) learning media is a technique of displaying objects directly by directing the camera to a real (marker) object. The aim of current developd application are to show 3 Dimensional interactive learning media using a marker of flashcards about medicinal plants as many as 20 types of medicinal plants. This is intended to facilitate the user especially on orthopedagogic education in recognizing the types of plants that are efficacious for treatment. © The Authors, published by EDP Sciences, 2018.},
keywords={Audition;  Augmented reality;  Education computing;  Learning systems;  Plants (botany), Computer generated imagery;  Educational process;  Hearing impairments;  Interactive learning;  Medicinal plants;  Ornamental plants;  Quality of education;  Science technologies, Engineering education},
correspondence_address1={Dijaya, R.; Universitas Muhammadiyah Sidoarjo, Department of InformaticsIndonesia; email: rohman.dijaya@umsida.ac.id},
editor={Nandiyanto A.B.D., Abdullah A.G.},
publisher={EDP Sciences},
issn={2261236X},
language={English},
abbrev_source_title={MATEC Web Conf.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Wang20181552,
author={Wang, Y. and Ong, S.K. and Nee, A.Y.C.},
title={Enhancing mechanisms education through interaction with augmented reality simulation},
journal={Computer Applications in Engineering Education},
year={2018},
volume={26},
number={5},
pages={1552-1564},
doi={10.1002/cae.21951},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053820303&doi=10.1002%2fcae.21951&partnerID=40&md5=9b6eee1ebf25aceedfdbd20ba4a08b35},
affiliation={Faculty of Mechanical Engineering and Mechanics, Ningbo University, Ningbo, China; Mechanical Engineering Department, National University of Singapore, Singapore},
abstract={Computer simulation has been used pervasively to help students understand deeply and visually the theoretical bases of mechanisms. This paper proposes an AR mechanism education system (ARMES) to provide a tool that can conduct mechanism simulations with high level of interaction, easy modeling, and simulation environment and working on real mechanisms. The system consists of theoretical lecture mode and practical exercise mode. Theoretical lecture mode adopts the basic theories of mechanisms from the book Mechanisms and Machine Theory (MMT) and provides an interactive learning style for users via an interactive tool. Practical exercise mode allows modeling, simulation, kinematical characteristics analysis, dynamic analysis, and synthesis based on the interaction with the information that has been rendered on a real mechanism via the interaction tool. In addition, the modeling is based on markers, making the system easy for novice learners to use. The simulation is based on geometrical concepts, making the geometrical bases of mechanism theories clear for users to understand. The evaluation of the system is conducted with 20 participants and a survey. The results reveal that by exploiting the characteristics of AR, the system is helpful in improving the interaction, visualization, and practicality of the mechanism problems. These features will make the system a powerful tool for the teaching of mechanisms. © 2018 Wiley Periodicals, Inc.},
author_keywords={augmented reality;  interaction;  mechanism;  modeling;  simulation},
keywords={Augmented reality;  Mechanisms;  Models;  Surveys, Characteristics analysis;  Education systems;  interaction;  Interaction tools;  Interactive learning;  Mechanism simulation;  simulation;  Simulation environment, Learning systems},
correspondence_address1={Ong, S.K.; Mechanical Engineering Department, National University of SingaporeSingapore; email: mpeongsk@nus.edu.sg},
publisher={John Wiley and Sons Inc.},
issn={10613773},
coden={CAPEE},
language={English},
abbrev_source_title={Comput Appl Eng Educ},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Siang201873,
author={Siang, C.V. and Isham, M.I.M. and Mohamed, F. and Yusoff, Y.A. and Mokhtar, M.K. and Tomi, B. and Selamat, A.},
title={Interactive holographic application using augmented reality EduCard and 3D holographic pyramid for interactive and immersive learning},
journal={2017 IEEE Conference on e-Learning, e-Management and e-Services, IC3e 2017},
year={2018},
pages={73-78},
doi={10.1109/IC3e.2017.8409241},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050737331&doi=10.1109%2fIC3e.2017.8409241&partnerID=40&md5=b13ed87c4661556823ec466e54e2af53},
affiliation={Faculty of Computing, Universiti Teknologi Malaysia, Skudai, Malaysia},
abstract={The advancement of augmented reality (AR) and holographic display technologies have a great potential to support and improve teaching and learning process, because the 3D images give new perspectives to the students to understand certain topic easily and intuitively. In this paper, an Interactive Holographic Display is introduced, which is aimed to ease the teachers to deliver the knowledge to the students as well as to provide self-learning for the students. This proposed solution is implemented using the AR tracking technique and fused with 3D holographic pyramid display. This makes the virtual objects can display in thin air like a real object and makes the holographic effect more realistic and interactive, as the user can interact with the virtual objects using an image target. This paper explains how the system is physically realized in term of hardware configuration and software design. © 2017 IEEE.},
author_keywords={3D holographic pyramid;  Feature-based augmented reality (AR);  holographic projection;  human-computer interaction},
keywords={Augmented reality;  E-learning;  Human computer interaction;  Image enhancement;  Software design;  Students;  Teaching;  Three dimensional displays, 3D holographic pyramid;  Display technologies;  Feature-based;  Hardware configurations;  Holographic applications;  Holographic projection;  Teaching and learning;  Tracking techniques, Holographic displays},
publisher={Institute of Electrical and Electronics Engineers Inc.},
isbn={9781538631454},
language={English},
abbrev_source_title={IEEE Conf. e-Learning, e-Management e-Services, IC3e},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Ati2018129,
author={Ati, M. and Kabir, K. and Abdullahi, H. and Ahmed, M.},
title={Augmented reality enhanced computer aided learning for young children},
journal={ISCAIE 2018 - 2018 IEEE Symposium on Computer Applications and Industrial Electronics},
year={2018},
pages={129-133},
doi={10.1109/ISCAIE.2018.8405457},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050669971&doi=10.1109%2fISCAIE.2018.8405457&partnerID=40&md5=93730451e643288a96aea02535decf85},
affiliation={College of Engineering, Abu Dhabi University, Abu Dhabi, United Arab Emirates},
abstract={Learning to write can be exhausting for young children. In Traditional teaching, children with a different learning abilities are taught with the same rubric. This, in turn, impacts children that need extra attention to catch up with their pairs, which leads children to suffer right from the early learning stages. Traditional teaching methods also are so rigid that makes them unable to automatically identify those children with less abilities and in need of extra work. Hence, with the rapid development of ICT, an innovative learning methods are sought to be important to allow children to be taught with different rubrics. The aim of this research is to improve learning process for pre-school children via introducing Augmented Reality (AR) in the process which, in turn, simplify the learning process as well as identifying children abilities. The research introduces gamification to the process in order to ease the burden on children. Furthermore, we are trying to involve both school as well home to be part of the educational cycle that makes parents to be part of the learning/educational process of their young children. Augmented reality combined with pleasing sound make the learning more interactive and enjoyable. The outcome of this research also helps parents to keep track of their children's learning. The paper also describes the deployment of the application in a local schools as a pilot study so teachers can get feedback on student's learning curve and to fine tune the work further. © 2018 IEEE.},
author_keywords={Augmented Reality;  Cloud Computing;  Education;  Mobile Application},
keywords={Augmented reality;  Cloud computing;  Education;  Industrial electronics;  Learning systems;  Teaching, Computer aided learning;  Innovative learning;  Learning abilities;  Learning curves;  Learning process;  Mobile applications;  Pre-school children;  Traditional teachings, Computer aided instruction},
publisher={Institute of Electrical and Electronics Engineers Inc.},
isbn={9781538635278},
language={English},
abbrev_source_title={ISCAIE - IEEE Symp. Comput. Appl. Ind. Electron.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Li2018881,
author={Li, S. and Dou, Y. and Xu, J. and Wang, Q. and Niu, X.},
title={MmCNN: A Novel Method for Large Convolutional Neural Network on Memory-Limited Devices},
journal={Proceedings - International Computer Software and Applications Conference},
year={2018},
volume={1},
pages={881-886},
doi={10.1109/COMPSAC.2018.00152},
art_number={8377777},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055456923&doi=10.1109%2fCOMPSAC.2018.00152&partnerID=40&md5=18ec4126d8a397ed608675abd0b17417},
affiliation={National Laboratory for Parallel and Distributed Processing, National University of Defense Technology, Changsha, China},
abstract={Deep learning recently has been widely used in many interactive application fields including but not limited to object recognition, speech recognition, natural language processing and so on. At the same time more and more attractive interactive applications (face recognition and augmented reality) are available on wearable and mobile devices. However, traditional deep learning methods such as CNN cost a lot of memory resources. This challenge makes it difficult to apply the powerful deep learning method on mobile memory limited platforms. In this paper we present a novel memory management strategy called mmCNN to solve this problem. This method helps us deploy a trained large size CNN on an any memory size platform including GPU, FPGA and memory-limited mobile devices. In our experiments, we run a feed-forward CNN process in an extremely small memory size (as low as 5MB) on a GPU platform. The result shows that our method saves more than 98% memory compared to a traditional CNN algorithm and further saves more than 90% compared to the sate-of-the-art related work 'vDNN'. Our work improve the computing scalability of interaction applications and break the memory bottleneck of using deep learning method on a memory-limited devices. © 2018 IEEE.},
author_keywords={Cnn;  GPU;  Memory capacity limited;  Memory management strategy},
keywords={Application programs;  Augmented reality;  Face recognition;  Graphics processing unit;  Interactive devices;  Natural language processing systems;  Neural networks;  Object recognition;  Speech recognition, Convolutional neural network;  Interactive applications;  Learning methods;  Limited devices;  Memory bottleneck;  Memory capacity;  Memory management;  Memory resources, Deep learning},
editor={Lung C.-H., Conte T., Liu L., Akiyama T., Hasan K., Tovar E., Takakura H., Claycomb W., Cimato S., Yang J.-J., Zhang Z., Ahamed S.I., Reisman S., Demartini C., Nakamura M.},
publisher={IEEE Computer Society},
issn={07303157},
isbn={9781538626665},
coden={PSICD},
language={English},
abbrev_source_title={Proc Int Comput Software Appl Conf},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Abdi201814673,
author={Abdi, L. and Meddeb, A.},
title={Driver information system: a combination of augmented reality, deep learning and vehicular Ad-hoc networks},
journal={Multimedia Tools and Applications},
year={2018},
volume={77},
number={12},
pages={14673-14703},
doi={10.1007/s11042-017-5054-6},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026802937&doi=10.1007%2fs11042-017-5054-6&partnerID=40&md5=64e75abf2d9156aac6e9a4e44465d4fb},
affiliation={Networked Objects Control and Communication Systems Laboratory, National Engineering School of Tunis, University of Tunis El Manar, Tunis, Tunisia; Networked Objects Control and Communication Systems Laboratory, National Engineering School of Sousse, University of Sousse, Sousse, Tunisia},
abstract={Improving traffic safety is one of the important goals of Intelligent Transportation Systems (ITS). In vehicle-based safety systems, it is more desirable to prevent an accident than to reduce severity of injuries. Critical traffic problems such as accidents and traffic congestion require the development of new transportation systems. Research in perceptual and human factors assessment is needed for relevant and correct display of this information for maximal road traffic safety as well as optimal driver comfort. One of the solutions to prevent accidents is to provide information on the surrounding environment of the driver. Augmented Reality Head-Up Display (AR-HUD) can facilitate a new form of dialogue between the vehicle and the driver; and enhance ITS by superimposing surrounding traffic information on the users view and keep drivers view on roads. In this paper, we propose a fast deep-learning-based object detection approaches for identifying and recognizing road obstacles types, as well as interpreting and predicting complex traffic situations. A single convolutional neural network predicts region of interest and class probabilities directly from full images in one evaluation. We also investigated potential costs and benefits of using dynamic conformal AR cues in improving driving safety. A new AR-HUD approach to create real-time interactive traffic animations was introduced in terms of types of obstacle, rules for placement and visibility, and projection of these on an in-vehicle display. The novelty of our approach is that both global and local context information are integrated into a unified framework to distinguish the ambiguous detection outcomes, enhance ITS by superimposing surrounding traffic information on the users view and keep drivers view on roads. © 2017, Springer Science+Business Media, LLC.},
author_keywords={Augmented reality;  Cooperative safety systems;  Deep learning;  Head-up display;  Intelligent transportation systems},
keywords={Accident prevention;  Accidents;  Advanced driver assistance systems;  Augmented reality;  Deep learning;  Image segmentation;  Intelligent systems;  Neural networks;  Object detection;  Roads and streets;  Security systems;  Vehicles;  Vehicular ad hoc networks, Convolutional neural network;  Driver information systems;  Head up displays;  Intelligent transportation systems;  Interactive traffics;  Severity of injuries;  Surrounding environment;  Transportation system, Traffic congestion},
correspondence_address1={Abdi, L.; Networked Objects Control and Communication Systems Laboratory, National Engineering School of Tunis, University of Tunis El ManarTunisia; email: lotfiabdi@hotmail.com},
publisher={Springer New York LLC},
issn={13807501},
coden={MTAPF},
language={English},
abbrev_source_title={Multimedia Tools Appl},
document_type={Article},
source={Scopus},
}

@ARTICLE{Jurdi2018187,
author={Jurdi, S. and Garcia-Sanjuan, F. and Nacher, V. and Jaen, J.},
title={Children's Acceptance of a Collaborative Problem Solving Game Based on Physical Versus Digital Learning Spaces},
journal={Interacting with Computers},
year={2018},
volume={30},
number={3},
pages={187-206},
doi={10.1093/iwc/iwy006},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046171461&doi=10.1093%2fiwc%2fiwy006&partnerID=40&md5=45ee2d6a9dbf4842b98d4051023afa89},
affiliation={ISSI Group, Departamento de Sistemas Informáticos y Computación (DSIC), Universitat Politècnica de València, Camino de Vera, s/n., Valencia, 46022, Spain},
abstract={Collaborative problem solving (CPS) is an essential soft skill that should be fostered from a young age. Research shows that a good way of teaching such skills is through video games; however, the success and viability of this method may be affected by the technological platform used. In this work we propose a gameful approach to train CPS skills in the form of the CPSbot framework and describe a study involving 80 primary school children on user experience and acceptance of a game, Quizbot, using three different technological platforms: two purely digital (tabletop and handheld tablets) and another based on tangible interfaces and physical spaces. The results show that physical spaces proved to be more effective than the screen-based platforms in several ways, as well as being considered more fun and easier to use by the children. Finally, we propose a set of design considerations for future gameful CPS systems based on the observations made during this study. © The Author(s) 2018. Published by Oxford University Press on behalf of The British Computer Society. All rights reserved.},
author_keywords={collaborative learning;  mixed/augmented reality;  tables and interactive surfaces;  tablet computers;  tangible interaction;  ubiquitous and mobile computing design and evaluation},
keywords={E-learning;  Human computer interaction;  Interactive computer systems;  Ubiquitous computing, Collaborative learning;  Design and evaluations;  Interactive surfaces;  mixed/augmented reality;  Tablet computer;  Tangible interaction, Problem solving},
correspondence_address1={Garcia-Sanjuan, F.; ISSI Group, Departamento de Sistemas Informáticos y Computación (DSIC), Universitat Politècnica de València, Camino de Vera, s/n., Spain; email: fegarcia@dsic.upv.es},
publisher={Oxford University Press},
issn={09535438},
coden={INTCE},
language={English},
abbrev_source_title={Interact Comput.},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Laviole2018,
author={Laviole, J. and Albouys-Perrois, J. and Thevin, L. and Brock, A.},
title={Nectar: Multi-user spatial augmented reality for everyone},
journal={ACM International Conference Proceeding Series},
year={2018},
doi={10.1145/3234253.3234317},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058641348&doi=10.1145%2f3234253.3234317&partnerID=40&md5=6a9b0adf7cb44e7d80944bf1ee91fed9},
affiliation={RealityTech, Bordeaux, France; Inria, Talence, France; ENAC, Toulouse, France},
abstract={In this demonstration we showcase a new spatial augmented reality device (interactive projection) with three applications: education and experimentation of color models, map exploration for visually impaired people and scientific vulgarization of machine learning. The first exhibition is an interactive exploration about the nature of light. Visitors can experiment with additive subtractive color models. We engage them with questions, and they have to reply using cards to find out answers. This exhibit is suitable for children. The second exhibition is about map exploration and creation for Visually Impaired Persons (VIP). VIP generally use tactile maps with braille to learn about an unknown environment. However, these maps are not accessible to the 80% of VIP who don’t read braille. Our prototype augments raised-line maps with audio output. The third exhibition is destined to be used for scientific outreach. It enables the creation of artificial neural networks (ANN) using tangible interfaces. Neurons are represented by laser-cut diamond shaped tokens, and the data to learn is printed on cards. The ANN learns to differentiate shapes, and the whole learning process is made visible and interactive. These three applications demonstrate the capabilities of our hardware and software development kit in different scenarios. At ReVo, each demonstration will have its own setup and interactive space. © 2018 Copyright held by the owner/author(s). Publication rights licensed to Association for Computing Machinery.},
author_keywords={Child-computer interaction;  Education;  Machine learning;  Mapping;  Multi-user;  Object tracking;  Open-source;  Scientific visualization;  Spatial augmented reality;  Tabletop;  Tangible interaction;  Visual impairment},
keywords={Application programs;  Augmented reality;  Color codes;  Data visualization;  Education;  Exhibitions;  Interactive computer systems;  Mapping;  Maps;  Neural networks;  Open source software;  Software design;  Virtual reality, Child-computer interactions;  Multi-user;  Object Tracking;  Open sources;  Spatial augmented realities;  Tabletop;  Tangible interaction;  Visual impairment, Learning systems},
publisher={Association for Computing Machinery},
isbn={9781450353816},
language={English},
abbrev_source_title={ACM Int. Conf. Proc. Ser.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Moedjiono20181,
author={Moedjiono, S. and Nurcahyadi and Kusdaryono, A.},
title={Media Interactive Learning and biology subjects implementation with augmented reality application},
journal={Proceedings of the 2nd International Conference on Informatics and Computing, ICIC 2017},
year={2018},
volume={2018-January},
pages={1-6},
doi={10.1109/IAC.2017.8280626},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047335007&doi=10.1109%2fIAC.2017.8280626&partnerID=40&md5=a1e3d121d06862686aee30679143761f},
affiliation={Budi Luhur University, Jakarta, Indonesia; SMK Fadilah, Tangerang Selatan, Indonesia},
abstract={Media Interactive Learning will be very beautiful if applied in the world of education, especially high school students that on average have Smartphones. Therefore, can be designed a media learning application that will use the biology subjects with the material in human organs, which will use the materials of the high school grade XI. Android is a container that can be used to apply media applications learning, using Augmented Reality (AR) technology which is often called AR Media learning would be more interesting to use. The result is media learning and biology subjects with AR technology using a marker Natural Feature Tracking reading techniques. © 2017 IEEE.},
author_keywords={Android;  Augmented Reality (AR);  marker;  Natural Feature Tracking;  smartphone},
keywords={Android (operating system);  Augmented reality;  Biology;  Educational technology;  Learning systems;  Smartphones, Android;  Augmented reality applications;  High school students;  Interactive learning;  marker;  Media application;  Natural feature tracking;  Reading techniques, Computer aided instruction},
publisher={Institute of Electrical and Electronics Engineers Inc.},
isbn={9781538629840},
language={English},
abbrev_source_title={Proc. Int. Conf. Inf. Comput., ICIC},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Muñoz-Sajama201865,
author={Muñoz-Sajama, M. and Cornejo-Mejías, R. and Aracena-Pizarro, D. and Navarrete-álvarez, M.},
title={An application of augmented reality to explore the heritage site “aldea de san lorenzo” [Una aplicación de realidad aumentada para recorrer el sitio patrimonial “aldea de san lorenzo”]},
journal={Ingeniare},
year={2018},
volume={26},
pages={65-76},
doi={10.4067/S0718-33052018000500065},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064766500&doi=10.4067%2fS0718-33052018000500065&partnerID=40&md5=588ae5c38ae73f338712f5d8caeea29a},
affiliation={Escuela Universitaria de Ingeniería Industrial, Informática y Sistemas, Área de Ingeniería de Computación e Informática, Universidad de Tarapacá, Arica, Chile; CONICYT de la Región de Arica y Parinacota, Universidad de Tarapacá, Arica, Chile},
abstract={This paper shows the development of an Augmented Reality application that brings the Archaeological Museum of San Miguel de Azapa, a cultural heritage of difficult access through 2D and 3D representations according to the available historical research. The application for mobile devices with Android operating system allows knowing the history of an ancestral community that lived a thousand years ago in the “Aldea de San Lorenzo” located in the north of Chile. Through the user interfaces proposed in the content about which they are described, the housing aspect of the enclosures found in the heritage site, the activities that were carried out inside the housing and the food storage process. The development shows the use of the tools ARToolKit and Vuforia for Unity that allow working with Augmented Reality through a file structure, which is used to create scenes with interactive interfaces and 3D modeling directly. The final application results from the feedback of school users and the general public, from its use in interactive samples and technology fairs. It is hoped that the development of this application can contribute to bring the cultural places of difficult access to anyone and contribute thereby to the valuation of the local heritage. © 2018, Universidad de Tarapaca. All rights reserved.},
author_keywords={Aldea de San Lorenzo;  Archaeology;  Augmented reality;  Education active;  Unity;  Vuforia},
correspondence_address1={Aracena-Pizarro, D.; Escuela Universitaria de Ingeniería Industrial, Informática y Sistemas, Área de Ingeniería de Computación e Informática, Universidad de TarapacáChile; email: daracena@academicos.uta.cl},
publisher={Universidad de Tarapaca},
issn={07183291},
language={Spanish},
abbrev_source_title={Ingeniare},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Pappa2018456,
author={Pappa, D. and Papadopoulos, H.},
title={Designing a prototype training environment for physiotherapists building on advanced gaming technologies},
journal={Proceedings of the European Conference on e-Learning, ECEL},
year={2018},
volume={2018-November},
pages={456-463},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057949430&partnerID=40&md5=cff9e62480556c7c19257705dee5389d},
affiliation={Division of Applied Technologies, National Center for Scientific Research, Demokritos, Attiki, Greece; Institute of Informatics and Telecommunications, National Center for Scientific Research, Demokritos, Attiki, Greece},
abstract={Recent years have seen the proliferation of digital games in areas beyond entertainment. Serious games have quickly gained momentum in professional training, as they allow for authentic learning experiences that are closely aligned to real-world issues, problems, and applications, provide immersion, and incorporate the essential ingredients of training: critical thinking, awareness of emotions, (collaborative) knowledge construction, creative problem solving and innovation. Incorporating advanced AR/VR technologies, serious games are revolutionising fields like medical training, which traditionally relies on textbook-based theoretical education and clinical placements. The paper first discusses the important role that gaming technologies increasingly play in training healthcare professionals and reviews state-of-the-art applications and best practice in the field, to then investigate the requirements and present the design of a prototype training environment for physiotherapists that builds on advanced gaming technologies. This professional group is purposely selected due to the inherent complexity of physical therapy, a type of treatment that encompasses a wide variety of aspects (kinesiology, physiology, pathophysiology, etc) and takes place in various healthcare settings. Physiotherapy refers to the recovery, improvement, and maintenance of a person’s movement abilities. Physiotherapists should be able to analyse and assess the functional and physical state of a person, treat by movement, compensate disability, guarantee health care and prevention, and stimulate and educate healthy living. They are also called to manage psychological issues that impact rehabilitation. Physiotherapist training is a continuous process aimed at keeping professionals constantly up to date with new scientific insights, methods, technologies and tools. Advanced gaming technologies can allow physiotherapists to gain a greater understanding of possible therapeutic interventions and develop their clinical reasoning and decision making in the selection and justification of their chosen therapeutic approach. The paper applies the Design Science Research Methodology (DSRM) to design a suitable training solution for the promotion of authentic, comprehensive learning. Within the proposed system design, augmented reality modules are embedded alongside the game simulation and virtual world environment to provide participants with an authentic simulated game scenario in which to immerse themselves. © The Authors, 2018. All Rights Reserved.},
author_keywords={E-learning;  Professional training;  Serious games},
keywords={Augmented reality;  Decision making;  Design;  E-learning;  Engineering education;  Health care;  Human computer interaction;  Interactive computer graphics;  Personnel training;  Physical therapy;  Problem solving;  Professional aspects;  Virtual reality, Comprehensive learning;  Creative problem-solving;  Design-science researches;  Health care professionals;  Knowledge construction;  Professional groups;  Professional training;  Therapeutic intervention, Serious games},
editor={Andreatos A., Sgouropoulou C., Ntalianis K.},
publisher={Academic Conferences Limited},
issn={20488637},
isbn={9781912764075},
language={English},
abbrev_source_title={Proc. Eur. Conf. e-Learn., ECEL},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Antoshchuk2018143,
author={Antoshchuk, S. and Kovalenko, M. and Sieck, J.},
title={Creating an interactive musical experience for a concert hall},
journal={International Journal of Computing},
year={2018},
volume={17},
number={3},
pages={143-152},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056416233&partnerID=40&md5=46c7f01dbc8f8bb54f4b59dd5b026e77},
affiliation={Odessa National Polytechnic University, Ave. Schevchenko 1F, Odessa, 65044, Ukraine; University of Applied Science Berlin, Wilhelminenhofstr. 75A, Berlin, 12459, Germany; Namibia University of Science and Technology, Storch Street 5, Windhoek, Namibia},
abstract={In this paper we introduce a Kinect based posture recognition approach that can classify the user's pose and gesture and match them to a set of predefined musical instruments. The efficiency of the approach is then demonstrated using two applications. The Virtual Orchestra system uses poseand gesture-recognition along with Augmented Reality technology to add a virtual musical instrument into the scene, both visually and audibly: the visual representation of the instrument is placed into the user's hands and the sound of the corresponding instrument is played. An additional functionality is that the user can control the intensity and the pitch of the sound by changing the speed of his hand or finger movements. The Magic Mirror game is the second application developed for the Berlin Concert Hall that uses the posture recognition approach to introduce the visitors to some classical music pieces and familiarize them with various classical musical instruments. © Research Institute for Intelligent Computer Systems, 2018.},
author_keywords={Augmented reality;  Computer vision;  Gesture recognition;  Machine learning;  Pose estimation;  Virtual instrument},
publisher={Research Institute of Intelligent Computer Systems},
issn={17276209},
language={English},
abbrev_source_title={Int. J. Comput.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Dombrowski2018393,
author={Dombrowski, M. and Buyssens, R. and Smith, P.A.},
title={Virtual reality training to enhance motor skills},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2018},
volume={10909 LNCS},
pages={393-402},
doi={10.1007/978-3-319-91581-4_29},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050609873&doi=10.1007%2f978-3-319-91581-4_29&partnerID=40&md5=e460de416ad5799e98bdbcb3c70e0108},
affiliation={University of Central Florida, Orlando, United States},
abstract={The use of Virtual Reality (VR) and Augmented Reality (AR) as a healing aid is a relatively newer concept in the field of rehabilitation and training. Clinicians now have access to virtual worlds and games in which they can immerse their patients into interactive scenarios that would not have been possible in previous years. Studies have shown effective results when VR/AR is incorporated into rehabilitation and training therapy practice. Mobility limited individuals can move freely within an open world virtual environment using the enhancements of virtual reality platforms like the HTC VIVE and Oculus Rift. The recent widespread consumer availability of VR/AR platforms has made it possible for clinicians to have the ability to incorporate fully immersive tech into their treatment regimens. Their research methods range from the implementation of consumer video game systems to custom developed hardware and software to enhance training. Clinicians are utilizing VR/AR platforms to better engage their patients. In doing so they are improving the effectiveness of training. Researchers have seen the implementation of these new tools improve the psychological effects of phantom limb syndrome, and improve motor skills for those with multiple sclerosis, cerebral palsy and other mobility debilitating conditions. This research will survey the past, present and future of applications and research in VR/AR Game experiences to aid in training and rehabilitation, exploring current state of research and the documented effectiveness of using games to heal. The benefits and potential further uses for emerging technologies within the healthcare field will guide the implementation of VR/AR applications to aid in the training of children to best learn to implement 3D printed prosthetic limbs in their everyday lives. In collaboration with Limbitless Solutions at the University of Central Florida, researchers have been engaged in discussions with young recipients of 3D prosthetic limbs. The researchers will discuss their findings and plans for how VR/AR Game experiences can provide solutions for the enhancement of the day to day routines of young prosthetic users. © Springer International Publishing AG, part of Springer Nature 2018.},
author_keywords={Augmented Reality;  Game design;  Games;  Motor skills;  Virtual Reality},
keywords={Artificial limbs;  Augmented reality;  Computer games;  E-learning;  Human computer interaction;  Interactive computer graphics;  Virtual reality, Emerging technologies;  Game design;  Games;  Hardware and software;  Motor skills;  Psychological effects;  University of Central Florida;  Virtual reality training, Mixed reality},
correspondence_address1={Dombrowski, M.; University of Central FloridaUnited States; email: MattD@ucf.edu},
editor={Fragomeni G., Chen J.Y.},
publisher={Springer Verlag},
issn={03029743},
isbn={9783319915807},
language={English},
abbrev_source_title={Lect. Notes Comput. Sci.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Zhao201857,
author={Zhao, Q.},
title={The application of augmented reality visual communication in network teaching},
journal={International Journal of Emerging Technologies in Learning},
year={2018},
volume={13},
number={7},
pages={57-70},
doi={10.3991/ijet.v13i07.8780},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049159740&doi=10.3991%2fijet.v13i07.8780&partnerID=40&md5=ed19d038762278a989acbb56890ae4f6},
affiliation={Jiujiang University art institute, Jiangxi, 332000, China},
abstract={In order to improve the effectiveness of online teaching, visual communication of augmented reality technology was applied. Network teaching was an auxiliary teaching form that used the network as a medium to carry out teaching information transmission. It was an extension of classroom teaching and an organic integration of information and technology and art. The visual effect of the online teaching interface directly affected the quality of teaching information delivery. Based on augmented reality technology, the research, analysis and analysis of interactive interface design content, processes and principles were carried out in terms of human-computer interaction, user experience, and visual communication. Augmented reality based visual interaction interface design methods were summarized. The results showed that visual communication based on augmented reality could provide a new form of teaching demonstration and enrich the content of classroom teaching. To sum up, this method improves the students' participation and enthusiasm, and enhances the teaching effect. © 2018 Qian Zhao.},
author_keywords={Augmented reality;  Interactive design;  User experience;  Visual communication},
keywords={Augmented reality;  Human computer interaction;  Teaching;  Visual communication, Augmented reality technology;  Information and technologies;  Information delivery;  Information transmission;  Interactive design;  Interactive interfaces;  Teaching demonstrations;  User experience, E-learning},
correspondence_address1={Zhao, Q.; Jiujiang University art instituteChina; email: qianzhao28437@163.com},
publisher={Kassel University Press GmbH},
issn={18688799},
language={English},
abbrev_source_title={Int. J. Emerg. Technol. Learn.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Khan2018133,
author={Khan, M. and Trujano, F. and Maes, P.},
title={Mathland: Constructionist mathematical learning in the real world using immersive mixed reality},
journal={Communications in Computer and Information Science},
year={2018},
volume={840},
pages={133-147},
doi={10.1007/978-3-319-93596-6_9},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049091338&doi=10.1007%2f978-3-319-93596-6_9&partnerID=40&md5=9ee05e616cc44ede0f8e9d85c9c09711},
affiliation={MIT Media Lab, Cambridge, United States},
abstract={Mathematical experiences are intrinsic to our everyday lives, yet mathematics education is mostly confined to textbooks. Seymour Papert used the term ‘Mathland’ to propose a world where one would learn mathematics as naturally as one learns French while growing up in France. We built a Mixed Reality application that augments the physical world with interactive mathematical concepts to enable constructionist mathematical learning in the real world. Using Mathland, people can collaboratively explore, experience and experiment with mathematical phenomena in playful, applied and exploratory ways. We implemented Mathland using the Microsoft Hololens and two custom controllers to afford complete immersion through tangible interactions, embodiment and situated learning. Our preliminary study with 30 participants shows that a considerable percentage of participants found Mathland to not only be engaging (83%), but also efficacious in the areas of collaborative learning (92.8%), problem solving (96.6%) and mathematics education (90%). © Springer International Publishing AG, part of Springer Nature 2018.},
author_keywords={Education/learning;  Embodied interaction;  Play;  Situated learning;  Tangible;  Virtual/augmented reality;  Wearable computers},
keywords={Problem solving;  Wearable computers, Embodied interaction;  Play;  Situated learning;  Tangible;  Virtual/augmented reality, Mixed reality},
correspondence_address1={Khan, M.; MIT Media LabUnited States; email: minakhan01@gmail.com},
editor={Beck D., Allison C., Ogle T., Pirker J., Gutl C., Richter J., Morgado L., Pena-Rios A.},
publisher={Springer Verlag},
issn={18650929},
isbn={9783319935959},
language={English},
abbrev_source_title={Commun. Comput. Info. Sci.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Sen2018843,
author={Sen, A. and Chuen, C.L.K. and Zay Hta, A.C.},
title={Toward smart learning environments: Affordances and design architecture of augmented reality (AR) applications in medical education},
journal={Smart Innovation, Systems and Technologies},
year={2018},
volume={79},
pages={843-861},
doi={10.1007/978-981-10-5828-8_80},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041507578&doi=10.1007%2f978-981-10-5828-8_80&partnerID=40&md5=8e9aada1940352b1148af26e3fad5dc7},
affiliation={Jeffrey Cheah School of Medicine and Health Sciences, Monash University Malaysia, Bandar Sunway, Subang Jaya, Selangor  47500, Malaysia; Faculty of Science & Technology, Department of Computing & Information Systems, Sunway University, Bandar Sunway, Subang Jaya, Selangor  47500, Malaysia},
abstract={Medical education places emphasis on situational learning of real-life clinical contexts, while simultaneously focusing on human body three-dimensional (3D) visualization. However, classrooms and laboratories being the main learning environment in early years of medical education, there is limited exposure to real clinical environments to adequately meet such objectives. This study proposes that augmented reality (AR) applications can provide both affordances. Such applications fulfill many of the criteria for smart learning environments (SLE). A systematic review aiming to identify the affordances of AR applications, their design architectures, and impact evaluations was conducted. This review evaluated 25 studies and, with model case studies, analyzed how the different AR applications provided situational learning and visualization in medical education and how their design architecture provided such affordances toward contextualized, interactive, and personalized SLEs. It was found that AR affords facilitation of situational learning and visualization individually. Their integrated educational impact, however, needs to be evaluated further. © 2018, Springer Nature Singapore Pte Ltd.},
author_keywords={Augmented reality;  Basic medical sciences education;  Design architecture;  Medical education;  Situational learning;  Visualization},
keywords={Architecture;  Augmented reality;  Computer aided instruction;  Flow visualization;  Medical education;  Three dimensional computer graphics;  Visualization, Clinical environments;  Design architecture;  Impact evaluation;  Learning environments;  Medical science;  Situational learning;  Systematic Review;  Three dimensional (3D) visualization, Education},
correspondence_address1={Sen, A.; Jeffrey Cheah School of Medicine and Health Sciences, Monash University Malaysia, Bandar Sunway, Malaysia; email: arkendu.sen@monash.edu},
editor={Srivastava S., Mundra A., Somani A.K., Rawat S.},
publisher={Springer Science and Business Media Deutschland GmbH},
issn={21903018},
isbn={9789811058271},
language={English},
abbrev_source_title={Smart Innov. Syst. Technol.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Lin2018725,
author={Lin, E.C.-H. and Shih, Y.-C. and Chang, R.-C.},
title={A research on integrating AR and multimedia technology for teaching and learning system design},
journal={Lecture Notes in Electrical Engineering},
year={2018},
volume={422},
pages={725-731},
doi={10.1007/978-981-10-3187-8_68},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031420065&doi=10.1007%2f978-981-10-3187-8_68&partnerID=40&md5=ab80cb0adf7d31e6e437295a92045c72},
affiliation={Department of Information Communication, Asia University, Taichung, Taiwan; Department of Biotechnology, Asia University, Taichung, Taiwan; Department of Digital Media Design, Asia University, Taichung, Taiwan},
abstract={Due to the great progress of information technology and the mature development of the multimedia technology, the computer and multimedia elements is involved in the learning materials. Recently, the due to the popularity of mobile devices, augmented reality development has become more sophisticated, more and more applications using augmented reality technology to attract the attention of the user or consumer. In this Paper, an interactive multimedia learning system with augmented reality technology is proposed to improve the effectiveness and efficiency of teaching and learning behavior. © Springer Nature Singapore Pte Ltd. 2018.},
author_keywords={Augmented reality;  Interactivity multimedia},
keywords={Augmented reality;  Computation theory;  Interactive computer systems;  Learning systems;  Multimedia systems;  Teaching, Augmented reality technology;  Effectiveness and efficiencies;  Interactive multimedia;  Interactivity;  Learning materials;  Multimedia elements;  Multimedia technologies;  Teaching and learning, Engineering education},
correspondence_address1={Lin, E.C.-H.; Department of Information Communication, Asia UniversityTaiwan; email: edgarlin@asia.edu.tw},
editor={Yen N.Y., Hung J.C.},
publisher={Springer Verlag},
issn={18761100},
isbn={9789811031861},
language={English},
abbrev_source_title={Lect. Notes Electr. Eng.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Chiu2018319,
author={Chiu, C.-C. and Lee, L.-C.},
title={System satisfaction survey for the App to integrate search and augmented reality with geographical information technology},
journal={Microsystem Technologies},
year={2018},
volume={24},
number={1},
pages={319-341},
doi={10.1007/s00542-017-3333-9},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85015152235&doi=10.1007%2fs00542-017-3333-9&partnerID=40&md5=ff931c732aa01a197036895987067a85},
affiliation={National Taipei University of Technology, No 1, Sec. 3, Zhongxiao E. Rd., Taipei, 10608, Taiwan},
abstract={Digital humanities are unfamiliar words in Taiwan. With the popularity of digital technology and mobile computing, Digital Human Geography in both theory and practice have emerged many new potentials and development opportunities. However, the research field regarding digital human geography can cover many areas, such as: mobile augmented reality, local media and service design, urban space interaction, virtual mixed space, space humanistic experience, historical materials reproduction, creativity of digital local sense, cultural narrative and art experience, local action games, mobile learning, and location-related business applications etc. This study aims to transfer information to specific groups through a simple and straightforward manner. With digital technology in combination with humane digital contents, people under the scenario of interactive interface are allowed to apply geographic information system (GIS) and geo-fencing program to convert data into visual images and through today’s Infographics to clearly use visual design characteristics in content presentation. Therefore, our study was to develop a new App, called “Ai Guang Zhan”. People can use “Ai Guang Zhan” App to integrate all exhibition related services. The App can be downloaded from smartphone or tablet PC for users to search in any time the arts and cultural activities and public facilities in the nearest place and receive instant mobile navigation services among various cultural and creative parks. To understand the preference and satisfaction by the people who use the UI interface for the APP designed from the study, a random questionnaire survey will be conducted in Huashan Cultural and Creative Industry Park and Songshan Cultural and Creative Park. The survey results will be used as reference for function improvement of next APP version. The primary purpose of this research is to propose a model for the development of applications, as well as methods for a clearer and easier visual presentation of information to be used as a reference for practitioners or application designers. The application, developed by the study through the proposed processes, was found to be effective; the developed application could be utilized as a new and useful tool to facilitate the utilization of academic and cultural resources. Additionally, users’ specific comments and suggestions collected by the study could be adopted as a reference for future application development. The application developed by this study was found to serve effectively as a method to promote the development of art and cultural activities of all sizes in various regions, and stimulate the exchange of arts and humanities between urban and rural areas. Furthermore, the application has the ability to attract younger people to participate in art and cultural activities, find their own interests, and explore more corresponding activities with its assistance. Future applications associated to art and cultural activities are suggested to effectively integrate AR, GIS, and visual design (such as Infographics) technologies, and thereby offer users more diversified, convenient, and useful functions. Restricted by the resources of labor and limited time, the functional design and development of the application still requires improvement. Specifically, the combination of AR technology and information presentation of art and cultural activities, as well as the calculation of relative distance and travel time were not presented effectively. The next step of the project would involve revising the content and functionalities of the application based on users’ feedback collected by this study, reviewing the acceptance of market responses of the application, and seeking a development company or foundation for technology transfer. Moreover, we intend to combine more technologies such as diversified cross-platform functions, visualized design of information, and interactive devices to further improve the application, and thereby stimulate social, human, and geographical interactions. © 2017, Springer-Verlag Berlin Heidelberg.},
keywords={Augmented reality;  Computation theory;  Data handling;  Exhibitions;  Geographic information systems;  Personal computers;  Surveys;  Technology transfer;  Travel time;  Virtual reality, Business applications;  Cultural and creative industries;  Developed applications;  Geographical information;  Information presentation;  Interactive interfaces;  Mobile augmented reality;  Questionnaire surveys, Search engines},
correspondence_address1={Lee, L.-C.; National Taipei University of Technology, No 1, Sec. 3, Zhongxiao E. Rd., Taiwan; email: f10666@ntut.edu.tw},
publisher={Springer Verlag},
issn={09467076},
language={English},
abbrev_source_title={Microsyst Technol},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Touel20171,
author={Touel, S. and Mekkadem, M. and Kenoui, M. and Benbelkacem, S.},
title={Collocated learning experience within collaborative augmented environment (anatomy course)},
journal={2017 5th International Conference on Electrical Engineering - Boumerdes, ICEE-B 2017},
year={2017},
volume={2017-January},
pages={1-5},
doi={10.1109/ICEE-B.2017.8192219},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046655738&doi=10.1109%2fICEE-B.2017.8192219&partnerID=40&md5=ea324e0b6726bb5cf40b86d70cf94998},
affiliation={University of Boumerdes, Boumerdes, Algeria; Centre de Développement des Technologies Avancées, CDTA, Algiers, Algeria},
abstract={Nowadays, collaborative systems and applications are widely used to allow multiple users to work together in order to achieve one same goal. In the field of virtual and augmented realities, such collaboration is often sought to effectuate complex activities in some relevant experiences. Users can share virtual objects, but most importantly, they use collaborative 3D interaction, visualize their objects manipulation in real time and communicate with each other to coordinate their actions efficiently. These users will, therefore, be able to work together in a shared virtual environment to carry out different tasks. In this paper, we present our work related to the design and implementation of a collaborative augmented system, our application introduces a multi-users experience in a face-to-face configuration and can be used by the students in anatomy course. © 2017 IEEE.},
author_keywords={Anatomy course;  Augmented reality;  Collaborative environment;  Learning application},
keywords={Augmented reality;  Computer aided instruction;  Virtual reality, Anatomy course;  Collaborative 3D Interactions;  Collaborative augmented environment;  Collaborative environments;  Collaborative systems;  Design and implementations;  Shared virtual environments;  Virtual and augmented reality, Curricula},
publisher={Institute of Electrical and Electronics Engineers Inc.},
isbn={9781538606865},
language={English},
abbrev_source_title={Int. Conf. Electr. Eng. - Boumerdes, ICEE-B},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Chen2017135,
author={Chen, L. and Francis, K. and Tang, W.},
title={Semantic Augmented Reality Environment with Material-Aware Physical Interactions},
journal={Adjunct Proceedings of the 2017 IEEE International Symposium on Mixed and Augmented Reality, ISMAR-Adjunct 2017},
year={2017},
pages={135-136},
doi={10.1109/ISMAR-Adjunct.2017.49},
art_number={8088466},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040257288&doi=10.1109%2fISMAR-Adjunct.2017.49&partnerID=40&md5=eb6b4a75ae75077dadf68a95764468d9},
affiliation={Bournemouth University, United Kingdom},
abstract={In Augmented Reality (AR) environment, realistic interactions between the virtual and real objects play a crucial role in user experience. Much of recent advances in AR has been largely focused on developing geometry-aware environment, but little has been done in dealing with interactions at the semantic level. High-level scene understanding and semantic descriptions in AR would allow effective design of complex applications and enhanced user experience. In this paper, we present a novel approach and a prototype system that enables the deeper understanding of semantic properties of the real world environment, so that realistic physical interactions between the real and the virtual objects can be generated. A material-aware AR environment has been created based on the deep material learning using a fully convolutional network (FCN). The state-of-the-art dense Simultaneous Localisation and Mapping (SLAM) has been used for the semantic mapping. Together with efficient accelerated 3D ray casting, natural and realistic physical interactions are generated for interactive AR games. Our approach has significant impact on the future development of advanced AR systems and applications. © 2017 IEEE.},
keywords={Augmented reality;  Mapping;  Rendering (computer graphics);  User interfaces, Complex applications;  Convolutional networks;  Physical interactions;  Real world environments;  Scene understanding;  Semantic descriptions;  Semantic properties;  Simultaneous localisation and mappings, Semantics},
correspondence_address1={Tang, W.; Bournemouth UniversityUnited Kingdom; email: wtang@bournemouth.ac.uk},
editor={Broll W., Regenbrecht H., Bruder G., Servieres M., Sugimoto M., Swan J.E.},
publisher={Institute of Electrical and Electronics Engineers Inc.},
isbn={9780769563275},
language={English},
abbrev_source_title={Adjun. Proc. IEEE Int. Symp. Mixed Augment. Real., ISMAR-Adjunct},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Okada201775,
author={Okada, Y. and Kaneko, K. and Tanizawa, A.},
title={Interactive educational contents development framework and its extension for web based VR/AR applications},
journal={18th International Conference on Intelligent Games and Simulation, GAME-ON 2017},
year={2017},
pages={75-79},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049931531&partnerID=40&md5=55e021acf01a129b19e367ee33603bf5},
affiliation={Innovation Center for Educational Resources, Kyushu University Library, Kyushu University, Fukuoka, Japan; CyberSecurity Center, Kyushu University, Fukuoka, Japan},
abstract={This paper treats one of the activities of ICER (Innovation Center for Educational Resources) in Kyushu University Library of Kyushu University, Japan. It is the development of educational contents using recent ICT for enhancing the educational efficiency in the university. Especially, this activity focuses on the development of attractive and interactive educational contents using 3D CG. So, the authors have already proposed a framework dedicated for the development of Web-based interactive 3D educational contents and introduced a couple of practical educational contents actually developed using the proposed framework. For developing more attractive educational contents using Virtual Reality(VR)/Augmented Reality(AR), the authors added new functionalities to make the framework possible to develop Web-based VR/AR applications. This paper introduced this new web-based VR/AR application development framework. © 2017 EUROSIS. All rights reserved.},
author_keywords={3D Graphics;  Augmented Reality;  Development Framework;  Virtual Reality;  Web Technology},
keywords={Augmented reality;  E-learning;  Virtual reality, 3D graphics;  Application development frameworks;  Development frameworks;  Educational contents;  Educational resource;  Innovation centers;  University libraries;  Web technologies, Websites},
editor={Kehoe J.},
publisher={EUROSIS},
language={English},
abbrev_source_title={Int. Conf. Intell. Games Simul., GAME-ON},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Han2016,
author={Han, R. and Auer, D. and Edenhofer, S. and Von Mammen, S.},
title={Skynetz: A playful experiential robotics simulator},
journal={2016 8th International Conference on Games and Virtual Worlds for Serious Applications, VS-Games 2016},
year={2016},
doi={10.1109/VS-GAMES.2016.7590365},
art_number={7590365},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85013149267&doi=10.1109%2fVS-GAMES.2016.7590365&partnerID=40&md5=585e5fef956610296f3a1daee31d388f},
affiliation={Organic Computing Group, University of Augsburg, Germany},
abstract={We introduce SkyNetz, a playful interactive robotics simulator for computer science students. Its focus lies on the visualization of a probabilistic robot localization algorithm considering noise in the sensors and actuators of the robot on the one hand, as well as an environment filled with obstacles which damage the robot on contact on the other hand. The goal of the simulation is training students on the intricacies of the algorithm and to develop a notion on the impact of the considered factors such as the degree of sustained sensory noise. In order to facilitate learning and promote exploration, we embed a game mode that conveys the basic interactions with the simulator and the factors shaping the robot's behavior. In the game, the player helps the simulated robot to reach its destination with as little damage as possible. This is done by setting waypoints for the robot by adjusting the parameters of the deployed localization algorithm as well as the quality of sensors and the accuracy of the robots movements. By playing with these parameters, the user playfully learns their effects, which are visualized in 3D-contrary to the hard mathematical approach presented in books. SkyNetz also has the capacity to communicate with a real robot, to show its current position and position estimates. In the long run, this will provide the foundation for novel augmented reality games. The paper includes a general introduction to the topic of interactive robot simulation, background on the specific problem of localization estimation, the presentation of our approach and the results from a small user study. © 2016 IEEE.},
keywords={Augmented reality;  Estimation;  Robot applications;  Robotics;  Serious games;  Simulators;  Virtual reality, Computer science students;  Interactive robotics;  Localization algorithm;  Mathematical approach;  Position estimates;  Robot localization;  Sensors and actuators;  Specific problems, Robots},
publisher={Institute of Electrical and Electronics Engineers Inc.},
isbn={9781509027224},
language={English},
abbrev_source_title={Int. Conf. Games Virtual Worlds Serious Appl., VS-Games},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Arcos2016,
author={Arcos, C. and Fuertes, W. and Villacis, C. and Zambrano, M. and Noboa, T. and Tacuri, A. and Aules, H. and Toulkeridis, T.},
title={Playful and interactive environment-based augmented reality to stimulate learning of children},
journal={Proceedings of the 18th Mediterranean Electrotechnical Conference: Intelligent and Efficient Technologies and Services for the Citizen, MELECON 2016},
year={2016},
doi={10.1109/MELCON.2016.7495421},
art_number={7495421},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84979223166&doi=10.1109%2fMELCON.2016.7495421&partnerID=40&md5=9137381bc557235625700f6eccb0eb44},
affiliation={Computer Sciences Department, Universidad de Las Fuerzas Armadas- ESPE, Sangolquí, Ecuador},
abstract={Our study is about how to create educational software using Augmented Reality combined with Bloom's Taxonomy, whose main purpose is to stimulate spatial reasoning improving the learning process of children. To reach this main objective, we have applied an incremental Object-Oriented Hypermedia Design Method, with the purpose to produce a mobile application for a learning basis on Smart-Client architecture. Furthermore, we incorporated operations necessary for cognitive development and effective learning in the logic of the application. Therefore, we applied modern 3D technology approaches such as Unity 3D Game Engine and Vuforia. Additionally, we designed and implemented a Computerized Classification Test based on the Bloom's taxonomy in order to determine the learning results. The validation of our proposed solution has been engaged by testing them in two representative public schools. The results demonstrate that this educational software for learning stimulates the cognitive development and improves the comprehension of children, with an effective quantitative assessment based on a constructivist paradigm. © 2016 IEEE.},
author_keywords={Augmented Reality;  Bloom Taxonomy;  educational software;  Vuforia},
keywords={Augmented reality;  Blooms (metal);  Taxonomies, Bloom taxonomies;  Classification tests;  Cognitive development;  Educational software;  Interactive Environments;  Mobile applications;  Quantitative assessments;  Vuforia, Object oriented programming},
editor={Mavromoustakis C., Louca S., Pattichis C.S., Georgiou J., Michael D., Paschalidou A., Kyriacou E., Vassiliou V., Panayiotou C., Kyriakides E., Ellinas G., Hadjichristofi G., Loizou C.},
publisher={Institute of Electrical and Electronics Engineers Inc.},
isbn={9781509000579},
language={English},
abbrev_source_title={Proc. Mediterr. Electrotech. Conf.: Intell. Effic. Technol. Serv. Citiz., MELECON},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Bazzaza2016443,
author={Bazzaza, M.W. and Alzubaidi, M. and Zemerly, M.J. and Weruga, L. and Ng, J.},
title={Impact of smart immersive mobile learning in language literacy education},
journal={IEEE Global Engineering Education Conference, EDUCON},
year={2016},
volume={10-13-April-2016},
pages={443-447},
doi={10.1109/EDUCON.2016.7474591},
art_number={7474591},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84994643753&doi=10.1109%2fEDUCON.2016.7474591&partnerID=40&md5=b667e5786e75e995a5519265ff633da1},
affiliation={Khalifa University, ECE Department, Abu Dhabi, United Arab Emirates; Etisalat BT Innovation Center (EBTIC), Abu Dhabi, United Arab Emirates},
abstract={With the fast paced improvements in smart devices such as tablets and smartphones, many schools in the developed countries are trying to improve the traditional pedagogical methods by harnessing smart learning technology for different purposes. In this paper, we proposed the use of a smart novel educational technology to immerse the students in the learning process by engaging as many of the students' senses as possible through the creation of interactive elements and entertaining features. This process is also called edutainment, combining both education and entertainment, and it works by making students learn subconsciously in an immersive manner. The aim of this paper is to demonstrate how an immersive augmented reality application can work in conjunction with Arabic schoolbooks in an attempt to improve Arabic literacy for children in the UAE. The reason for this is that children in the UAE are being exposed to English most of the time and, as a consequence, gradually losing their mother tongue. A focus field-study was then conducted on two groups of Grade 1 students to get a pre-understanding in the impact of such educational technology, targeted for younger learners, in language literacy education. © 2016 IEEE.},
author_keywords={Augmented Reality;  Edutainment;  Game-Based Learning;  Immersive Augmented Reality;  Smart Education},
keywords={Augmented reality;  Educational technology;  Engineering education;  Students;  Teaching, Developed countries;  Edutainment;  Game-based Learning;  Immersive augmented realities;  Interactive elements;  Learning process;  Learning technology;  Pedagogical method, Education},
publisher={IEEE Computer Society},
issn={21659559},
isbn={9781467386333},
language={English},
abbrev_source_title={IEEE Global Eng. Edu. Conf., EDUCON},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Sugimoto2016189,
author={Sugimoto, M.},
title={Augmented Tangibility Surgical Navigation Using Spatial Interactive 3-D Hologram zSpace with OsiriX and Bio-Texture 3-D Organ Modeling},
journal={Proceedings - 2015 International Conference on Computer Application Technologies, CCATS 2015},
year={2016},
pages={189-194},
doi={10.1109/CCATS.2015.53},
art_number={7372343},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964713772&doi=10.1109%2fCCATS.2015.53&partnerID=40&md5=087e1c46148e1e4ef3f25e0be2a72480},
affiliation={Gastroenterology, Kobe University Graduate School of Medicine, Kobe, Japan},
abstract={We developed a new spatial navigation system for medical informatics by interactive superimposing 3-D hologram and 3D printing technology. Interactive stereo display was used for the existence of an interaction between the users and stereo images of the patient's anatomy depicted on the display in the form of tracking the user's head and hand/arm position. Sensing the user's head position created motion parallax information, an immersive depth cue that can be added to the binocular parallax already present in the display. We also developed new technology of bio-texture modeling by multi-material 3D printing to form 3D organ textures and structures. Based on patient-specific MDCT data sets, regions of interest were segmented using DICOM viewer OsiriX application. After generating 3D surface models of the organ and STL file out of the patient's 3D data, the inkjet 3D printer created a 3D multi-material organ replica. Sensing the user's hand or arm position using motion sensor attached the patient's life size 3-D printed organ model, allowed the user to manipulate the spatial attributes of the virtual and real printed organs, which can enhance spatial reasoning and augmented tangibility. These tangible organ replication provide better anatomical reference tool as a tailormade simulation and navigation, and contribute to medical safety and accuracy, less-invasiveness and improvement of the medical education for students and trainees. © 2015 IEEE.},
author_keywords={3-D printer;  Augmented reality;  Mixed reality;  OsiriX;  Virtual reality},
keywords={Augmented reality;  Education computing;  Face recognition;  Geometrical optics;  Holograms;  Information science;  Medical education;  Multidetector computed tomography;  Navigation systems;  Printers (computer);  Printing;  Printing machinery;  Printing presses;  Stereo image processing;  Virtual reality, Binocular parallax;  Medical informatics;  Mixed reality;  OsiriX;  Regions of interest;  Spatial navigation;  Spatial reasoning;  Surgical navigation, 3D printers},
correspondence_address1={Sugimoto, M.; Gastroenterology, Kobe University Graduate School of MedicineJapan; email: sgmt@med.kobe-u.ac.jp},
editor={Bossard A., Takahashi S., Shiraki Y., Tanaka T.},
publisher={Institute of Electrical and Electronics Engineers Inc.},
isbn={9781467382113},
language={English},
abbrev_source_title={Proc. - Int. Conf. Comput. Appl. Technol., CCATS},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Sandanayake201611454,
author={Sandanayake, T.C.},
title={Upcoming trends in virtual learning to enhance technology based learning},
journal={International Journal of Applied Engineering Research},
year={2016},
volume={11},
number={23},
pages={11454-11460},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031302894&partnerID=40&md5=ba701b0dbfe110a287078d6b5c98f7b1},
affiliation={Faculty of Information Technology, University of Moratuwa, Bandaranayake Mawatha, Moratuwa, Katubedda, 10400, Sri Lanka},
abstract={The development of the information &communication technology provides increase to new opportunities for learning. Online learning has been identified as the enabler for learners to keep up with changes in the global economy that now occur in Internet era and it is one of the most significant recent developments in the higher education. When consider about the last decades the e-learning concept has changed in rapidly along with new technologies and e-learning concept has become the most ubiquitous method to use in teaching and learning. Number of collages, schools universities and organizations use online-leaning concept in all over the world to enhance the knowledge, abilities and skills of learners in more effective and interactive manner. One of the biggest challenges of higher education reformation in developing solutions is facilitation and delivery of the right information and skills to the right learners at the right time. Virtual learning becomes a sub section of e-learning which describe internet based learning systems in a economical model rather than other conventional educational models. Virtual learning provides number of advantages to users though innovative systems such as; providing more interactive and collaborative environment for users. Different types of virtual learning environments available in the existing teaching and learning methods which has developed along with various web technologies and some simple multimedia technologies such as enabling audio and video files embed to the system. Technologist today are experimenting to enhance and develop modern and complex multimedia technologies to virtual learning systems such as virtual reality and augmented reality to improve the interactivityand effectiveness of the virtual learning systems. This paper provides a comprehensive review based on evaluation of the virtual learning systems and how will virtual learning systems change according to change of the technologies to enhance the effectiveness of those systems in the future. © Research India Publications.},
author_keywords={Learning Environments;  Online Learning;  Virtual Learning},
correspondence_address1={Sandanayake, T.C.; Faculty of Information Technology, University of Moratuwa, Bandaranayake Mawatha, Moratuwa, Sri Lanka; email: thanujas@uom.lk},
publisher={Research India Publications},
issn={09734562},
language={English},
abbrev_source_title={Int. J. Appl. Eng. Res.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Hou2016371,
author={Hou, L. and Chi, H.-L. and Utiome, E. and Wang, X.},
title={Cooperative and immersive coaching to facilitate skill development in construction tasks},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2016},
volume={9929 LNCS},
pages={371-377},
doi={10.1007/978-3-319-46771-9_48},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84994166864&doi=10.1007%2f978-3-319-46771-9_48&partnerID=40&md5=23ce43842c960c8dfa502252d78ec3cb},
affiliation={Griffith University, Gold Coast, Australia; Curtin University, Perth, Australia},
abstract={At present, construction operations training offered by qualified organisations and associations for the Australian oil and gas, mineral and chemical industries have been provided at only limited levels. Moreover, the relevant training facilities and centres being established or considered in the construction agenda are insufficient to meet the growing standard of operators and industry expansion. These facts illustrate the need for developing effective cooperative coaching and learning systems for expediting the acquisition of fundamental construction skills. Accordingly, the aim of this ongoing study is to establish scientific principles for developing appropriate Virtual Reality (VR) and Augmented Reality (AR) supported cooperative and immersive training prototypes and curriculum to meet the above mentioned purposes. Through the application of pertinent learning theories, system prototyping and experimentation techniques, this study is envisioned to significantly supplement interactive and immersive site experiences from immersive training environment, and produce cost-effective and efficient ways to manage the skill shortage challenges in mega construction projects. © Springer International Publishing AG 2016.},
author_keywords={Cognitive theories;  Concurrent Engineering (CE);  Immersive training;  Skills acquisition;  Virtual Reality (VR) and Augmented Reality (AR)},
keywords={Augmented reality;  Chemical industry;  Chemical operations;  Concurrent engineering;  Cost effectiveness;  Curricula;  Virtual reality;  Visualization, Cognitive theory;  Construction agendas;  Construction operations;  Construction projects;  Fundamental construction;  Immersive;  Scientific principles;  Skills acquisition, Personnel training},
correspondence_address1={Hou, L.; Griffith UniversityAustralia; email: lei.hou@griffith.edu.au},
editor={Luo Y.},
publisher={Springer Verlag},
issn={03029743},
isbn={9783319467702},
language={English},
abbrev_source_title={Lect. Notes Comput. Sci.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Boonbrahm2016115,
author={Boonbrahm, P. and Kaewrat, C. and Boonbrahm, S.},
title={Interactive augmented reality: A new approach for collaborative learning},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2016},
volume={9753},
pages={115-124},
doi={10.1007/978-3-319-39483-1_11},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84978915399&doi=10.1007%2f978-3-319-39483-1_11&partnerID=40&md5=57064d2f6665cbbc0531e14128f0e452},
affiliation={School of Informatics, Walailak University, Tha Sala, Nakhon Si Thammarat, 80160, Thailand},
abstract={This study aims at using new technology, interactive augmented reality (AR), to establish collaborative learning. Interactive augmented reality means that virtual objects can be interacted and displayed in real world which made them easy to understand or easy to work with. In this paper, we have developed a system to support collaborative work in which users can be in different locations and use interactive augmented reality technology to help them doing collaborative work which in this case is completing a 3D jigsaw puzzle. For the interactive AR system, Unity 3D game engine was used on a Vuforia platform. Apples’ iPads were chosen as the device to perform the task due to ease of use, good camera quality and good display for AR applications. The results show that the two users can collaborate by helping each other to get the job done in AR environment. © Springer International Publishing Switzerland 2016.},
author_keywords={Augmented reality;  Collaboration learning;  Interactive},
keywords={Augmented reality;  Display devices;  Human computer interaction, 3D game engines;  Augmented reality technology;  Collaboration learning;  Collaborative learning;  Collaborative Work;  Interactive;  Interactive ar;  Virtual objects, Engineering education},
correspondence_address1={Boonbrahm, P.; School of Informatics, Walailak University, Tha Sala, Thailand; email: poonpong@gmail.com},
editor={Zaphiris P., Ioannou A.},
publisher={Springer Verlag},
issn={03029743},
isbn={9783319394824},
language={English},
abbrev_source_title={Lect. Notes Comput. Sci.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Fernando2016693,
author={Fernando, R. and Dupre, K. and Skates, H.},
title={Tangible user interfaces for teaching building physics: Towards continuous designing in education},
journal={CAADRIA 2016, 21st International Conference on Computer-Aided Architectural Design Research in Asia - Living Systems and Micro-Utopias: Towards Continuous Designing},
year={2016},
pages={693-702},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84973547669&partnerID=40&md5=53d5e89d40e9d65f206c2962f0c8a1d1},
affiliation={Griffith University, Gold Coast, Australia},
abstract={This paper follows our evaluation and research into designing tangible physical media for the purposes of teaching building physics to undergraduate architecture students. These media interfaces make use of a virtual environment to promote an understanding of the cycles, which govern architectural and urban projects (for example solar studies, the flow of heat, air and water). This project aims to create an ecology of devices which can be used by students to self-direct themselves and harbour critical making in their research methods (with the explicit intent of dissolving the barrier between design and research). The basic premise of this research, is that in light of growing student numbers, more students lacking confidence in numeracy skills as well as the desire to have self-directed or group-directed learning, tangible media has a promising role to play. There are several reasons for this optimism. The first is that a better sense of intuition is gained from an interactive model over reading notes from a lecture or textbook. The second is that tangible media engages in other modes of learning, being valuable to students who have an aptitude for kinesthetic and spatial learning over text-dominant learning. © 2016, The Association for Computer-Aided Architectural Design Research in Asia (CAADRIA), Hong Kong.},
author_keywords={Augmented reality;  Designing for teaching;  Internet of things;  Pedagogy;  Tangible user interfaces},
keywords={Architectural design;  Augmented reality;  Biological systems;  Education;  Education computing;  Internet of things;  Phase interfaces;  Structural design;  Students;  Teaching;  Virtual reality, Building physics;  Interactive modeling;  Media interface;  Pedagogy;  Spatial learning;  Student numbers;  Tangible media;  Tangible user interfaces, User interfaces},
editor={Schnabel M.A., Nakapan W., Roudavski S., Chien S.-F., Kim M.J., Choo S.},
publisher={The Association for Computer-Aided Architectural Design Research in Asia (CAADRIA)},
isbn={9789881902672},
language={English},
abbrev_source_title={CAADRIA, Int. Conf. Comput.-Aided Archit. Des. Res. Asia - Living Syst. Micro-Utop.: Towar. Contin. Des.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Jia201627,
author={Jia, X. and Huang, J.},
title={Development of network interactive teaching materials and empirical in "Management" courses},
journal={International Journal of Emerging Technologies in Learning},
year={2016},
volume={11},
number={5},
pages={27-32},
doi={10.3991/ijet.v11i05.5690},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84971554633&doi=10.3991%2fijet.v11i05.5690&partnerID=40&md5=c878606c62def67d8306f2f2d252471f},
affiliation={Depart of Chongqing, Youth Vocational and Technical College, Chongqing, 400712, China; Institution of Technology of Chongqing, City Management Vocational College, Chongqing, 401331, China},
abstract={Network interactive teaching material utilizes multimedia technology for digital processing of traditional paper content and makes the teaching material suitable for various electronic terminals. Network interactive teaching material making is closely related to the development of distance teaching. This paper mainly takes Human Resource Management as the experimental course, utilizes teaching resource cloud platform of augmented reality interactive teaching materials for empirical study on the application of network interactive teaching material in Human Resource Management course, discusses the application effect of new distance education and teaching resources, offers theoretical and data support for development of network interactive teaching material and distance education and exploits potential development direction of future course construction.},
author_keywords={Cloud platform;  Distance education;  Human Resource Management;  Network interactive teaching material},
keywords={Augmented reality;  Curricula;  Distance education;  Education;  Educational technology;  Human resource management;  Information management;  Multimedia systems;  Natural resources management;  Resource allocation, Application effect;  Cloud platforms;  Course constructions;  Development directions;  Experimental course;  Multimedia technologies;  Resource management;  Teaching materials, Teaching},
publisher={Kassel University Press GmbH},
issn={18688799},
language={English},
abbrev_source_title={Int. J. Emerg. Technol. Learn.},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Li2015,
author={Li, Y. and Guo, A. and Chin, C.L.},
title={A platform for mobile augmented reality app creation without programming},
journal={SIGGRAPH Asia 2015 Mobile Graphics and Interactive Applications, SA 2015},
year={2015},
doi={10.1145/2818427.2818452},
art_number={2818452},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84960885490&doi=10.1145%2f2818427.2818452&partnerID=40&md5=268507c33b00b7f752c43247cb62925b},
affiliation={Institute for Infocomm Research (I2R), A STAR, Singapore},
abstract={There are many application areas on using smartphone to access relevant information. By taking a picture from a physical object using a smartphone app, we use image recognition technology to provide a quick link between the physical object and its relevant information. However, developing smartphone apps is expensive and time consuming. We developed a platform called MIMAS AR Creator, which is a web based software platform for automatic creation of smartphone apps for multimedia access using pictures captured from the smartphone camera and its GPS location. This platform allows people without programming skill to create a smartphone app in a few minutes with existing multimedia contents, shorten more than 90% of the app development time. The digital contents can be web pages, videos, audios, images, or 3D graphics with or without animation etc. The platform can be used for mobile advertising and retail marketing, mobile learning and tour guide etc. For example, with the created app running, people can point their phone camera to a picture on newspaper, product brochure, or physical product to obtain more relevant information provided by the advertisers or vendors. They can also point the phone camera to a building or monument to retrieve relevant historical information.},
keywords={Augmented reality;  Cameras;  Image recognition;  Interactive computer graphics;  Marketing;  Multimedia systems;  Smartphones;  Telephone sets;  Websites;  World Wide Web, Automatic creations;  Historical information;  Image recognition technology;  Mobile advertising;  Mobile augmented reality;  Multimedia contents;  Smart-phone cameras;  Web-based softwares, Signal encoding},
publisher={Association for Computing Machinery, Inc},
isbn={9781450339285},
language={English},
abbrev_source_title={SIGGRAPH Asia Mobile Graph. Interact. Appl., SA},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Rodríguez-Vizzuett2015,
author={Rodríguez-Vizzuett, L. and Pérez-Medina, J.L. and Muñoz-Arteaga, J. and Guerrero-García, J. and Álvarez-Rodríguez, F.J.},
title={Towards the definition of a framework for the management of interactive collaborative learning applications for preschoolers},
journal={ACM International Conference Proceeding Series},
year={2015},
volume={07-09-September-2015},
doi={10.1145/2829875.2829878},
art_number={a11},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84960128201&doi=10.1145%2f2829875.2829878&partnerID=40&md5=d7949fb962591adcf507b8024c5aa43e},
affiliation={Universidad Autónoma de Aguascalientes, Av. Universidad 940, Ags., Mexico; Université Catholique de Louvain, Place des Doyens 1, Louvain-la-Neuve, Belgium; Benemérita Universidad Autónoma de Puebla, Av. 14 Sur y San Claudio, Puebla, Mexico},
abstract={The adoption of technologies in education has been changing the traditional teaching system considerably. New educational paradigms make use of technological tools to enhance the knowledge given in a classroom. In the literature review there aren't reports of Frameworks that are based on models and methods for developing Interactive Collaborative Learning Applications for Preschoolers (ICLAP). This paper proposes a meta-model for a Framework supporting the development of ICLAP taking into account the technology, the educational aspect and collaborative techniques that were observed during the attendance to sessions in schools. The ICLAP meta-model includes useful concepts for the use of Augmented Reality since we found that it emerges as a technology of interest in diverse areas and especially in education. Our contribution could be used for teachers, designers and developers as a conceptual guide. In addition, a study case is presented to illustrate the main concepts included in the meta-model. © 2015 ACM.},
author_keywords={Augmented Reality;  Col-laborative Application;  Collaborative Learning;  Framework},
keywords={Augmented reality;  Education;  Educational technology;  Engineering education;  Teaching, Collaborative learning;  Collaborative technique;  Educational aspects;  Framework;  Literature reviews;  Study case;  Teaching systems;  Technological tools, Human computer interaction},
publisher={Association for Computing Machinery},
isbn={9781450334631},
language={English},
abbrev_source_title={ACM Int. Conf. Proc. Ser.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Bhowmik201583,
author={Bhowmik, A.K. and BenHimane, S. and Kutliroff, G. and Molyneaux, D. and Lucas, B.C. and Rand, C. and Ho, H.P.},
title={Immersive applications based on depth-imaging and 3D-sensing technology},
journal={Digest of Technical Papers - SID International Symposium},
year={2015},
volume={46},
number={Book 1},
pages={83-86},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84963686066&partnerID=40&md5=cccf1c9b0d5606a0dffacb8ecbc70240},
affiliation={Intel Corporation, Santa Clara, CA, United States; Intel Development Center, Israel},
abstract={The recent developments in depth-imaging and 3D computer vision techniques allow efficient and real-time acquisition, reconstruction, and understanding of the 3D environment, which enable an array of life-like and immersive applications. We show here an excerpt of some of the key technologies spanning sensors, algorithms, and system integration based on depth imaging and 3D sensing technology. The small form factor, the low power and the real-time depth image capture are the key enablers. We talk here about emerging trends in this burgeoning field and new enabled applications that include immersive and interactive gaming, virtual home and office decoration, virtual cloth fitting, video conferencing with custom background and synthetic environment, education and training, and numerous other new entertainment and productivity usages with natural and intuitive interactions. © 2015 SID.},
author_keywords={3D reconstruction;  3D sensing;  Augmented reality;  Background segmentation;  Collaborative augmented reality;  Dense scene reconstruction;  Depth imaging;  Enhanced photography;  Enhanced videography;  Hand skeleton tracking;  Head-mounted display;  Real-time tracking;  RGB-D camera},
keywords={Augmented reality;  Computer vision;  Helmet mounted displays;  Image processing;  Video conferencing;  Video recording, 3-D sensing;  3D reconstruction;  Background segmentation;  Collaborative augmented realities;  Depth imaging;  Enhanced videography;  Head mounted displays;  Real time tracking;  Rgb-d cameras;  Scene reconstruction, Image reconstruction},
editor={Morreale J.},
publisher={Blackwell Publishing Ltd},
issn={0097966X},
language={English},
abbrev_source_title={Dig. Tech. Pap. SID Int. Symp.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Fonseca2015,
author={Fonseca, D. and Villagrasa, S. and Valls, F. and Redondo, E. and Climent, A. and Vicent, L.},
title={Engineering teaching methods using hybrid technologies based on the motivation and assessment of student's profiles},
journal={Proceedings - Frontiers in Education Conference, FIE},
year={2015},
volume={2015-February},
number={February},
doi={10.1109/FIE.2014.7044209},
art_number={7044209},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84938099554&doi=10.1109%2fFIE.2014.7044209&partnerID=40&md5=9ebd655442cc6d6769139663d4d35694},
affiliation={La Salle Barcelona Campus, Ramon Llull University, Barcelona, Spain; Expressió Gràfica Arquitectónica i, Universitat Politècnica de Catalunya, Barcelona, Spain; La Salle Open University, UOLS, La Massana, Andorra},
abstract={This paper describes the evolution and integration of hybrid interfaces in the visualization of three-dimensional models, and presents the results of a preliminary study based on the profile and the student motivation. The study is conducted with first and second year Building Engineering degree students in order to incorporate the augmented reality technology in different subjects and case studies. The resources developed combine traditional methods with interactive visualization of complex virtual models and mobile systems to present this type of content with the purpose of enhancing the student's visualization and spatial analysis skills and their motivation. We have used a mixed method research with quantitative evaluations (using a pre and post-test), and personal qualitative assessment (using the Bipolar Laddering technic) to further strengthen the results. In general, the student motivation to use this technology at classroom is positive and the preliminary results show us an improvement of their academic results, a confirmation of the adequacy of the method. © 2014 IEEE.},
author_keywords={augmented reality;  hybrid visualization;  mixed methods;  mobile learning;  spatial skills;  student motivation},
keywords={Augmented reality;  Education;  Education computing;  Motivation;  Teaching;  Three dimensional computer graphics;  Visualization, Augmented reality technology;  Interactive visualizations;  Mixed method;  Mobile Learning;  Qualitative assessments;  Spatial skills;  Student motivation;  Three-dimensional model, Students},
publisher={Institute of Electrical and Electronics Engineers Inc.},
issn={15394565},
coden={PFECD},
language={English},
abbrev_source_title={Proc. Front. Educ. Conf. FIE},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Uribe2015,
author={Uribe, F.C.},
title={Increased reality applied to the teaching of the descriptive geometry [Realidad aumentada aplicada a la enseñanza de la geometría descriptiva]},
journal={AUS},
year={2015},
volume={18},
art_number={004},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84978436644&partnerID=40&md5=167b7cec353fe040bad501ad06506b83},
affiliation={Universidad Nacional de Colombia, Colombia; Magíster en Comunicación Visual en Arquitectura y Diseño, Universidad Politécnica de Cataluña, Spain; Académico Universitaria Agustiniana - Uniagustiniana, Bogotá, Colombia},
abstract={Augmented reality allows students to visualize tridimensional shapes by turning and handing them in the palm of their hand. Taking objects "away" from the computer improves the students' perception of the three projection planes. A pedagogical application was designed with this new representation tool. Tridimensional models were made using the Google Sketchup open license software to view these 3D models using augmented reality. Handling the 3D models by students improves the clarity of tridimensional perception. The project also allowed for the assessment of pedagogical aspects, including the ways through which students improve their learning experience and how teachers can use these tools to build a more interactive setting where students can play an active role in the construction of their own learning environment. © 2016 Instituto de Arquitectura y Urbanismo, Facultad de Ciencias de la Ingeniería, Universidad Austral de Chile.},
author_keywords={Architecture;  Augmented reality;  Descriptive geometry;  ITCs},
correspondence_address1={Uribe, F.C.; Universidad Nacional de ColombiaColombia; email: franz.calderon@uniagustiniana.edu.co},
publisher={Universidad Austral de Chile},
issn={0718204X},
language={Spanish},
abbrev_source_title={Aus},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Arámburo-Lizárraga201534,
author={Arámburo-Lizárraga, J. and Sanabria, J.C.},
title={An Application for the Study of Art Movements},
journal={Procedia Computer Science},
year={2015},
volume={75},
pages={34-42},
doi={10.1016/j.procs.2015.12.196},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964078881&doi=10.1016%2fj.procs.2015.12.196&partnerID=40&md5=f3ce60dc86ba55d1bd40e53dc9f06451},
affiliation={Centro Universitario de Ciencias Económico Administrativas, CUCEA-Universidad de Guadalajara, Núcleo Universitario Los Belenes, Periférico Norte No 799, Zapopan, Jalisco, C.P. 45100, Mexico},
abstract={This work presents a general architecture for creating an application called the Art Movement Learning App (AMLA), whereby students can familiarize themselves with key characteristics of a given art movement (such as Surrealism), using technology, and appropriate the experience through their own artistic creation in a mixed reality environment. The architecture consists of two modules. The first is an apprentice art-and-technology familiarization module, wherein a specific art movement is introduced through a cumulative sequence of six phases, using a digital surface: (1) observation, where students analyze images portraying key characteristics of the chosen movement; (2) combination, including a set of tools that enables the combination of 2D images and 3D models, in light of these characteristics; (3) association, where key elements abstracted from a given artwork are matched with their location in the original artwork; (4) grouping, where students determine the characteristics shared by a given set of artworks; (5) discernment, where students choose from a pair of images, one of which belongs to the art movement that the AMLA was configured to introduce; and finally (6) evaluation by peers, where the artworks created in Phase 2 are evaluated by other students, using a preset scale. The major features of the art movement to be used as stimuli are selected in advance, after which the AMLA configures the respective phases. The second AMLA module is an Augmented Reality module, enabling students to create artworks displayed in mixed reality scenarios. This module consists of two phases: one wherein a student creates an artwork in a specific real-world environment, which is associated, by GPS coordinates or location-based services (LBS), with a physical object; and a second phase, wherein artworks are displayed as part of the app, so that anyone downloading the application can view the students' work, and evaluate it using an affective-response scale. User registration is necessary in order to access the first module; thus, if the application is downloaded without registration, only the final phase, of the second module, will be shown (i.e.; artworks are displayed with augmented reality using GPS coordinates or LBS). The objective of the AMLA is to present an interactive process, through various stages, involving a set of actions enabling students to learn more about the characteristics of art movements, while enhancing both their creative skills and their art-perception experience. © 2015 The Authors.},
author_keywords={application development;  Art Movement Learning App (AMLA);  augmented reality (AR);  Gradual Immersion Method (GIM)},
keywords={Augmented reality;  Education;  Education computing;  Global positioning system;  Human computer interaction;  Location based services;  Mobile telecommunication systems;  Telecommunication services;  Virtual reality, Application development;  Art Movement Learning App (AMLA);  General architectures;  Immersion method;  Interactive process;  Key characteristics;  Mixed-reality environment;  Real world environments, Students},
correspondence_address1={Arámburo-Lizárraga, J.; Centro Universitario de Ciencias Económico Administrativas, CUCEA-Universidad de Guadalajara, Núcleo Universitario Los Belenes, Periférico Norte No 799, Mexico; email: jaramburo@cucea.udg.mx},
editor={Ramirez Flores P.G., Martin Gutierrez J., Mendivil E.G., Ginters E.},
publisher={Elsevier B.V.},
issn={18770509},
language={English},
abbrev_source_title={Procedia Comput. Sci.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Bates201550,
author={Bates, M. and Saridaki, M. and Kolovou, E. and Mourlas, C. and Brown, D. and Burton, A. and Battersby, S. and Parsonage, S. and Yarnall, T.},
title={Designing location-based gaming applications with teenagers to address early school leaving},
journal={Proceedings of the European Conference on Games-based Learning},
year={2015},
volume={2015-January},
pages={50-57},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84955162412&partnerID=40&md5=8b5af1036e754d1607f5d10232f8ac3e},
affiliation={Interactive Systems Research Group, Nottingham Trent University, United Kingdom; Department of Communication and Media, School of Economic and Political Sciences, University of Athens, Ariu, Gaetana, Greece; Greenhat Interactive Ltd, Birmingham, United Kingdom},
abstract={Early school leaving (ESL) is an urgent and serious problem, both for individuals and society as a whole. Factors such as learning difficulties, social problems or a lack of motivation, guidance or support all contribute to ESL, although the situation varies across EU countries. High rates of ESL are detrimental to making lifelong learning a reality and increase the risk of unemployment, poverty and social exclusion. Since normally there is not a unique reason for leaving education or vocational training, answers are no easy. In response to these concerns, the Code RED project (http://www.coderedproject. eu) has been created to address the high proportion of drop out from Initial Vocational Education and Training (IVET) and ESL in the UK, Greece, Italy and Cyprus via the development of new games-based learning applications (both desktop and mobile) to inform young adults (aged 16+) of the issues surrounding ESL. Location-based gaming (LBG) applications represent a form of play that is designed to be undertaken on a device in motion which changes the game experience based on the location. The design of these products presents many challenges to developers surrounding user interfaces, processing power and the availability of space. The ARIS platform (Augmented Reality and Interactive Storytelling) covers a broad field of LBG design components such as geo-location data, location-sensitive informational objects, interactive dialogues and QR code input. As such, ARIS has been selected by Code RED researchers to teach LBG and mobile augmented reality design concepts and prototype new design ideas with young adults. This paper will discuss the issues which are contributing to ESL within the EU and report upon the results of a short term participatory design initiative within Code RED to co-design new location-based gaming applications with participating IVET students (aged 14+) to address these issues. In the UK, participating students were successful in formulating a game concept suitable for transfer into LBG surrounding lifestyle choices such as alcohol and drug abuse which may contribute to ESL. In Greece, participating students with learning disabilities were successful in creating a fictional 'solve the mystery' LBG using the ARIS platform. Students decided to focus the game's narrative on the issue of exclusion from school and jumping into fast conclusions during schooling years. In Italy, participating children were successful in designing an orienteering-based LBG to promote cultural heritage via exploration of an ancient castle. This process also enabled participants to research and learn more about this local landmark. The paper will discuss the application of the participatory design methodology between project partners and will document the LBG output from this process. Finally, the paper will identify how these products will be positioned as part of future work to address ESL.},
author_keywords={ARIS;  Early school leaving;  Employability;  Location-based games;  Participatory design},
keywords={Augmented reality;  Availability;  Codes (symbols);  Design;  Education;  Location;  Students;  User interfaces, ARIS;  Early school leaving;  Employability;  Location based games;  Participatory design, Product design},
editor={Kolas L., Munkvold R.},
publisher={Dechema e.V.},
issn={20490992},
isbn={9781910810583},
language={English},
abbrev_source_title={Proc. European Conf. Games-based Learn.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{CheDalim202044,
author={Che Dalim, C.S. and Sunar, M.S. and Dey, A. and Billinghurst, M.},
title={Using augmented reality with speech input for non-native children's language learning},
journal={International Journal of Human Computer Studies},
year={2020},
volume={134},
pages={44-64},
doi={10.1016/j.ijhcs.2019.10.002},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074369569&doi=10.1016%2fj.ijhcs.2019.10.002&partnerID=40&md5=7c91f641b7113338dde92f687dfa9f37},
affiliation={Faculty of Computer Science and Information Technology, Universiti Tun Hussein Onn Malaysia, Batu Pahat, 86400, Malaysia; Media and Game Innovation Centre of Excellence, Institute of Human Centred Engineering, Universiti Teknologi Malaysia, Johor Bahru, 81310, Malaysia; Faculty of Engineering, School of Computing, Universiti Teknologi Malaysia, Johor Bahru, 81310, Malaysia; Empathic Computing Lab, University of South Australia, Australia; Empathic XR and Pervasive Computing Lab, University of Queensland, Australia},
abstract={Augmented Reality (AR) offers an enhanced learning environment which could potentially influence children's experience and knowledge gain during the language learning process. Teaching English or other foreign languages to children with different native language can be difficult and requires an effective strategy to avoid boredom and detachment from the learning activities. With the growing numbers of AR education applications and the increasing pervasiveness of speech recognition, we are keen to understand how these technologies benefit non-native young children in learning English. In this paper, we explore children's experience in terms of knowledge gain and enjoyment when learning through a combination of AR and speech recognition technologies. We developed a prototype AR interface called TeachAR, and ran two experiments to investigate how effective the combination of AR and speech recognition was towards the learning of 1) English terms for color and shapes, and 2) English words for spatial relationships. We found encouraging results by creating a novel teaching strategy using these two technologies, not only in terms of increase in knowledge gain and enjoyment when compared with traditional strategy but also enables young children to finish the certain task faster and easier. © 2019 Elsevier Ltd},
author_keywords={Human-computer interface;  Improving classroom teaching;  Interactive learning environments;  Teaching/learning strategies},
keywords={Augmented reality;  Computer aided instruction;  Learning systems, Enhanced learning;  Human computer interfaces;  Improving classroom teaching;  Interactive learning environment;  Learning Activity;  Spatial relationships;  Speech recognition technology;  Teaching/learning strategy, Speech recognition},
correspondence_address1={Che Dalim, C.S.; Faculty of Engineering, School of Computing, Universiti Teknologi MalaysiaMalaysia; email: csamihah@gmail.com},
publisher={Academic Press},
issn={10715819},
coden={IHSTE},
language={English},
abbrev_source_title={Int J Hum Comput Stud},
document_type={Article},
source={Scopus},
}

@ARTICLE{Ibáñez2020,
author={Ibáñez, M.B. and Uriarte Portillo, A. and Zatarain Cabada, R. and Barrón, M.L.},
title={Impact of augmented reality technology on academic achievement and motivation of students from public and private Mexican schools. A case study in a middle-school geometry course},
journal={Computers and Education},
year={2020},
volume={145},
doi={10.1016/j.compedu.2019.103734},
art_number={103734},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073815705&doi=10.1016%2fj.compedu.2019.103734&partnerID=40&md5=7a6603962debb3c9ba0162ffad1b0996},
affiliation={Departamento de Ingeniería Telemática, Universidad Carlos III de Madrid, Madrid, Spain; Tecnológico Nacional de México, Instituto Tecnológico de Culiacán, Culiacán, Mexico},
abstract={In this paper, the authors show that augmented reality technology has a positive impact on learning-related outcomes of middle-school Mexican students. However, the impact varies depending on whether students were enrolled in public or private schools. The authors designed an augmented reality application for students to practice the basic principles of geometry, and a similar application which encompasses identical learning objectives and content deployed in a Web-based learning environment. A 2 × 2 × 2 factorial design was employed with 93 participants to investigate the effect of type of technology (web, augmented reality), type of school (private, public), and time of assessment (pre, post) on motivation, and declarative learning. The results show that: (1) there is an interactive effect of type of technology, type of school, and time of assessment when students' achievement scores are measured; (2) students using the augmented reality-based learning environments scored higher in post-test than those using the web-based application; (3) the augmented reality learning environment was more learning effective compared with the web-based learning environment in public schools, but not in private schools; (4) there is not an interactive effect of type of technology, type of school and time of assessment when students' motivation is measured; (5) students from private schools reported higher levels of motivation compared with those from public schools when using the augmented reality learning environment. The research findings imply that in Mexico, augmented reality technology can be exploited as an effective learning environment for helping middle-school students from public and private schools to practice the basic principles of Geometry. © 2019 Elsevier Ltd},
author_keywords={Applications in subject areas;  Augmented reality;  Interactive learning environments;  Motivation},
keywords={Augmented reality;  E-learning;  Engineering education;  Geometry;  Motivation;  School buildings;  Students;  Websites, Applications in subject areas;  Augmented reality applications;  Augmented reality technology;  Effective Learning Environment;  Interactive learning environment;  Middle school students;  Web-based applications;  Web-based learning environment, Computer aided instruction},
correspondence_address1={Ibáñez, M.B.; Departamento de Ingeniería Telemática, Universidad Carlos III de Madrid, Leganés, Spain; email: mbibanez@it.uc3m.es},
publisher={Elsevier Ltd},
issn={03601315},
coden={COMED},
language={English},
abbrev_source_title={Comput Educ},
document_type={Article},
source={Scopus},
}

@ARTICLE{Huerta2020836,
author={Huerta, O. and Unver, E. and Arslan, R. and Kus, A. and Allen, J.},
title={An approach to improve technical drawing using VR and AR tools},
journal={Computer-Aided Design and Applications},
year={2020},
volume={17},
number={4},
pages={836-849},
doi={10.14733/cadaps.2020.836-849},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075360494&doi=10.14733%2fcadaps.2020.836-849&partnerID=40&md5=56b5c247d78ba1293b7697130f761412},
affiliation={University of Huddersfield, United Kingdom; Uludag University, Turkey},
abstract={In this paper, the authors present the development of 3D interactive AR/VR teaching system from a design-based method to help engineering and product design students improve on critical and complex topics related to TD skills according to an international survey and as part of a broader European funded research project. This work shows that human-centred approaches can improve the understanding of students needs and facilitate the development of AR/VR technology applications for T&L within an international and multidisciplinary team. © 2020 CAD Solutions, LLC.},
author_keywords={Augmented Reality;  Teaching and Learning;  Technical Drawings;  Virtual Reality},
keywords={Augmented reality;  Students;  Virtual reality, Interactive ar;  International survey;  Multi-disciplinary teams;  Teaching and learning;  Teaching systems;  Technical drawing;  Technology application, Product design},
correspondence_address1={Huerta, O.; University of HuddersfieldUnited Kingdom; email: o.huertacardoso@hud.ac.uk},
publisher={CAD Solutions, LLC},
issn={16864360},
language={English},
abbrev_source_title={Comput.-Aided Des. Appl.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Alzahrani2020282,
author={Alzahrani, N.M. and Lajmi, S.},
title={AugmentedBook: A collaborative e-learning augmented reality platform},
journal={Advances in Intelligent Systems and Computing},
year={2020},
volume={1018},
pages={282-288},
doi={10.1007/978-3-030-25629-6_44},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070019823&doi=10.1007%2f978-3-030-25629-6_44&partnerID=40&md5=8b0cbba42c4eccb44b7f6c4de5805834},
affiliation={Information Technology Department, Faculty of Computer Science and Information Technology, Albaha University, Albaha, Saudi Arabia; MIRACL: Multimedia InfoRmation Systems and Advanced Computing Laboratory, University of Sfax, Technological Pole of Sfax, Sakiet Ezzit, Sfax, 3021, Tunisia},
abstract={This paper introduces an augmented reality-based framework (called AugmentedBook) for e-learning that allows the creation of collaborative notes, illustrative media (i.e. video, 2D or 3D image, audio) for mobile devices or Google glass. The augmented content can be added to real-world educational support to make it more comprehensive, interactive and collaborative. In this platform, students and teachers can add collaborative notes to any part of the educational support system. They can also find illustrative media and indicate the pertinence of the result. Using our AugmentedBook platform, students can also download the enriched support using a mobile device. Our framework solves the problem of standard integration of augmented reality applications in education, offering a distributed framework which is e-learning compliant. © 2020, Springer Nature Switzerland AG.},
author_keywords={Augmented reality;  Collaborative annotation;  E-learning;  Mobile device},
keywords={Augmented reality;  E-learning;  Mobile computing, 3-D image;  Augmented reality applications;  Collaborative annotation;  Collaborative e-Learning;  Distributed framework;  Educational support systems;  Real-world, Students},
correspondence_address1={Alzahrani, N.M.; Information Technology Department, Faculty of Computer Science and Information Technology, Albaha UniversitySaudi Arabia; email: noufalzahrani@bu.edu.sa},
editor={Ahram T., Taiar R., Colson S., Choplin A.},
publisher={Springer Verlag},
issn={21945357},
isbn={9783030256289},
language={English},
abbrev_source_title={Adv. Intell. Sys. Comput.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Mao2020303,
author={Mao, C.-C. and Chen, F.-Y.},
title={Augmented reality and 3-D visualization effects to enhance battlefield situational awareness},
journal={Advances in Intelligent Systems and Computing},
year={2020},
volume={1018},
pages={303-309},
doi={10.1007/978-3-030-25629-6_47},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069981091&doi=10.1007%2f978-3-030-25629-6_47&partnerID=40&md5=be70431fcb1eab38f793370c27d41cf7},
affiliation={Department of Applied Arts, Fu Hsing Kang College, National Defense University, No.70, Sec. 2 Zhongyang N. Rd. Beitou Dist., Taipei, Taiwan},
abstract={This study presents the augmented reality technology and 3D information visualization for Army’s military education to realize the interactive tactical course teaching and consider the user center research and human-computer interaction architecture as a solution to improve the common operational picture. The purpose is to improve the Army’s command and general staff officers in tactical operations to learn battlefield situational awareness to enhance interest in learning and effective decision support. We constructed a prototype augmented reality program, the traditional tactical image and symbols of war games into 3-D virtual images, Which includes military equipment, urban architecture and geography scenes and other models, teaching applications to import tactical operations, not only to break through the limitations of a traditional 2-D image, enhanced visual effects and digital technology information, revealing a more complete battlefield scene. At the same time, through virtual operation, students are more interactive. In order to verify and collect the utility and data of learning, quasi-experimental research has been used. Experiments have shown that using 3-D information Visualization for better understanding of military tasks and space environments can enhance learning interest and perception of situation awareness. © 2020, Springer Nature Switzerland AG.},
author_keywords={3-D animation;  Augmented Reality;  Human-computer interaction;  Information visualization;  Situation awareness},
keywords={Animation;  Application programs;  Augmented reality;  Decision support systems;  Education computing;  Engineering education;  Human computer interaction;  Image enhancement;  Information analysis;  Information systems;  Military applications;  Military photography;  Visualization, 3-D information visualization;  3D animation;  Augmented reality technology;  Common operational picture;  Information visualization;  Situation awareness;  Situational awareness;  Teaching applications, Three dimensional computer graphics},
correspondence_address1={Mao, C.-C.; Department of Applied Arts, Fu Hsing Kang College, National Defense University, No.70, Sec. 2 Zhongyang N. Rd. Beitou Dist., Taiwan; email: Chia-ChiMao@gmail.com},
editor={Ahram T., Taiar R., Colson S., Choplin A.},
publisher={Springer Verlag},
issn={21945357},
isbn={9783030256289},
language={English},
abbrev_source_title={Adv. Intell. Sys. Comput.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Lou201919,
author={Lou, D.},
title={Two fast prototypes of web-based augmented reality enhancement for books},
journal={Library Hi Tech News},
year={2019},
volume={36},
number={10},
pages={19-24},
doi={10.1108/LHTN-08-2019-0057},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074443507&doi=10.1108%2fLHTN-08-2019-0057&partnerID=40&md5=fe71221dd0b71c1fd803b600fae711a4},
affiliation={Department of Information, Technology and Collection, Palo Alto City Library, Palo Alto, CA, United States},
abstract={Purpose: The purpose of this paper is to identify a light and scalable augmented reality (AR) solution to enhance library collections. Design/methodology/approach: The author first did research to identify the major obstacle in creating a scalable AR solution. Next, she explored possible workaround methods and successfully developed two prototypes that make the current Web-based AR work with ISBN barcode. Findings: Libraries have adopted AR technology in recent years mainly by developing mobile applications for specific education or navigation programs. Yet a straight-forward AR solution to enhance a library's collection has not been seen. One of the obstacles lies in finding a scalable and painless solution to associate special AR objects with physical books. At title level, books already have their unique identifier – the ISBN number. Unfortunately, marker-based AR technology only accept two-dimensional (2-D) objects, not the one-dimensional (1-D) EAN barcode (or ISBN barcode) used by books, as markers for technical reasons. In this paper, the author shares her development of two prototypes to make the Web-based AR work with the ISBN barcode. With the prototypes, a user can simply scan the ISBN barcode on a book to retrieve related AR content. Research limitations/implications: This paper mainly researched and experimented with Web-based AR technologies in the attempt to identify a solution that is as platform-neutral as possible, and as user-friendly as possible. Practical implications: The light and platform-neutral AR prototypes discussed in this paper have the benefits of minimum cost on both the development side and the experience side. A library does not need to put any additional marker on any book to implement the AR. A user does not need to install any additional applications in his/her smartphone to experience the AR. The prototypes show a promising future where physical collections inside libraries can become more interactive and attractive by blurring the line of reality and virtuality. Social implications: The paper can help initiate the discussion on applying Web-based AR technologies to library collections. © 2019, Emerald Publishing Limited.},
author_keywords={API;  Augmented reality;  Books;  Collections;  ISBN barcode;  JQuery;  Libraries;  Makerless AR;  Marker-based AR;  Technology;  Web-based AR;  Web-based barcode reader;  Web-based barcode scanner},
correspondence_address1={Lou, D.; Department of Information, Technology and Collection, Palo Alto City LibraryUnited States; email: loudan1980@gmail.com},
publisher={Emerald Group Publishing Ltd.},
issn={07419058},
language={English},
abbrev_source_title={Libr. Hi Tech News},
document_type={Article},
source={Scopus},
}

@ARTICLE{Murwonugroho20192789,
author={Murwonugroho, W. and Ardianto, D.T.},
title={Visual fantasy in children‘s learning through virtual & augmented reality},
journal={International Journal of Scientific and Technology Research},
year={2019},
volume={8},
number={12},
pages={2789-2794},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076748073&partnerID=40&md5=9c559708f829d08984e14c2a6028bfb7},
affiliation={Faculty of Art & Design at Universitas Trisakti, Jakarta, Indonesia; Art and Design Faculty, Universitas Sebelas Maret, Surakarta, Indonesia},
abstract={The aim of this study is to analyze the impact of using virtual reality technology and augmented reality as a medium of learning for children. Virtual technology and augmented reality are often used as interactive learning media to illustrate how living things interac t, with the application of animations as a simulation of aesthetic elements that appear real, though false. Moreover, the realness is due to the power in the presentation of gestures, expressions, and movements of visible things, hence, the visual pseudo-appearance seems impossible in real life. This media has kindled the emotional intelligence of children, enabling an increase in the freedom of expression. Furthermore, research using this phenomenology methodology established the scientific contribution of technology learning essence, leading to the emergence of visual fantasy in children. This encompasses the imagination that appears within the mind as though they were real. In addition, this creates a space, which seems to be unlimited, as t he visual elements are colorful and rhythmic, while the wildness of creativity enhances the effectivity of learning systems, through this technology, as well as attaining the position of being children‘s‘ preferred choice. © 2019, IJSTR.},
author_keywords={Augmented Reality;  Learning;  Virtual Reality;  Visual Fantasy},
publisher={International Journal of Scientific and Technology Research},
issn={22778616},
language={English},
abbrev_source_title={Int. J. Sci. Technol. Res.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Bozzelli2019,
author={Bozzelli, G. and Raia, A. and Ricciardi, S. and De Nino, M. and Barile, N. and Perrella, M. and Tramontano, M. and Pagano, A. and Palombini, A.},
title={An integrated VR/AR framework for user-centric interactive experience of cultural heritage: The ArkaeVision project},
journal={Digital Applications in Archaeology and Cultural Heritage},
year={2019},
volume={15},
doi={10.1016/j.daach.2019.e00124},
art_number={e00124},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073688888&doi=10.1016%2fj.daach.2019.e00124&partnerID=40&md5=2d25bfe8c53a320588b58857c7b316dd},
affiliation={Digitalcomoedia, Naples, IT, Italy; CNR, Institute of Technologies applied to Cultural Heritage, Rome, IT, Italy; Department of Biosciences and Territory (DiBT) - University of Molise, Italy},
abstract={The ArkaeVision project is aimed at enabling a new way of enjoying Cultural Heritage through a more engaging and culturally-qualified user experience. The main goal is the creation of a technological infrastructure for the permanent enhancement of cultural resources. Hence, ArkaeVision represents a user-centric integrated system able to offer different modalities of exploitation of Cultural Heritage assets, including virtual representations of monuments, works of art and objects, as well as the stories associated to them. ArkaeVision therefore introduces a new communication paradigm, made of game-alike exploration of a 3D environment, virtually reconstructed, with elements of digital fiction and an engaging stortytelling, applied to two case studies: the exploration of the Hera II Temple of Paestum with Virtual Reality (VR) technology, and the exploration of the slab of the Swimmer Tomb with Augmented Reality (AR). The emotional component is fundamental in ArkaeVision, because it generates the motivation and leads people to use immersive viewers, as the HTC Vive, which allow the learning process to be activated more quickly, as many cognitivists and psychologists reported in the latest researches. Also the involvement of users through gamification is well expressed in ArkaeVision. This model of action (and interaction) designed for the public allows to emphasize the role of users through a system that is “guided” by their choices and times, in order to increase users’ engagement within the virtual exploration, and favour the content understanding by direct experience. Evaluations conducted on a preliminary prototype suggested that the communicative approach is very promising for education and engagement into cultural heritage experiences. © 2019},
author_keywords={Augmented reality;  Digital storytelling;  Gamification;  User experience design;  Virtual reality},
correspondence_address1={Bozzelli, G.; DigitalcomoediaItaly; email: guido.bozzelli@digitalcomedia.com},
publisher={Elsevier Ltd},
issn={22120548},
language={English},
abbrev_source_title={Digit. Appl. Archaeol. Cult. Herit.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Fidan2019,
author={Fidan, M. and Tuncel, M.},
title={Integrating augmented reality into problem based learning: The effects on learning achievement and attitude in physics education},
journal={Computers and Education},
year={2019},
volume={142},
doi={10.1016/j.compedu.2019.103635},
art_number={103635},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069602317&doi=10.1016%2fj.compedu.2019.103635&partnerID=40&md5=68a295dd7ec367e1696dccaf721da956},
affiliation={Distance Education Research and Application Center, Bartin University, Bartin, 74100, Turkey; Faculty of Education, Department of Educational Sciences, Bolu Abant Izzet Baysal University, Bolu, 14280, Turkey},
abstract={This study investigates the effects of Problem Based Learning (PBL) assisted with Augmented Reality (AR) on learning achievement and attitude towards physics subjects as a part of science education. The sample of the study included 91 seventh graders from a province in the north of Turkey. A quasi-experimental design with two experimental groups and a control group was utilized. Based upon marker-based AR technologies, FenAR software was developed to support with PBL activities in the classroom. The experimental results indicated that integrating AR into PBL activities both increased students' learning achievement and promoted their positive attitudes towards physics subjects. This technology contributed to students' long-term retention of the concepts in the field of physics. In semi-structured interviews, the students emphasized that AR applications were more useful, realistic, and interesting for their learning; helped them to understand and analyse the problem scenarios. Apart from educational advantages, AR applications may lead to physical disorders among some of the students. It has been suggested that AR technology can be a potential and effective tool for activating students' positive emotions in PBL process. Moreover, implications on use of AR for physics education and recommendations for further studies are also discussed in the study. © 2019},
author_keywords={Architectures for educational technology system;  Improving classroom teaching;  Interactive learning environments;  Multimedia/hypermedia systems;  Teaching/learning strategies},
keywords={Augmented reality;  Computer aided instruction;  Educational technology;  Learning systems, Architectures for educational technology system;  Improving classroom teaching;  Interactive learning environment;  Multimedia/hypermedia systems;  Teaching/learning strategy, Students},
correspondence_address1={Fidan, M.; Distance Education Research and Application Center, Bartin UniversityTurkey; email: mfidan@bartin.edu.tr},
publisher={Elsevier Ltd},
issn={03601315},
coden={COMED},
language={English},
abbrev_source_title={Comput Educ},
document_type={Article},
source={Scopus},
}

@ARTICLE{JosephDube201912,
author={Joseph Dube, T. and İnce, G.},
title={A novel interface for generating choreography based on augmented reality},
journal={International Journal of Human Computer Studies},
year={2019},
volume={132},
pages={12-24},
doi={10.1016/j.ijhcs.2019.07.005},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069600368&doi=10.1016%2fj.ijhcs.2019.07.005&partnerID=40&md5=12e58887395593f330f7d4646b5a24c9},
affiliation={Computer Engineering Department, Istanbul Technical University, Istanbul, Turkey},
abstract={Choreography is a creative art of defining sequences of movement. The choreographing process benefits a lot from the use of digital applications. In this study, we investigate the effects of different interactive techniques on user experience for a choreography generator interface. We develop a virtual reality-based and an augmented reality-based interface and compare them with 1) a personal computer-based choreography generator interface and 2) a touch-based mobile application for choreography generation. We evaluate user performance and user experience on the interfaces in terms of task completion time, as well as subjective criteria, like mental stress, physical stress, and pleasure. Our research contributes to the study of how different interaction methods of the same application affect user experience. This research also contributes to the study of virtual and augmented reality in education and training applications. The results verify the effectiveness of augmented reality in developing training and design applications, particularly choreography. The augmented reality interface emerged as the preferred choice for users. Furthermore, the results demonstrate the effectiveness of natural user interaction approaches in interface design. © 2019},
author_keywords={Augmented reality;  Choreography;  Natural user interfaces;  User experience;  Virtual reality},
keywords={Augmented reality;  Personal computers;  Virtual reality, Choreography;  Education and training;  Generator interfaces;  Interactive techniques;  Natural user interactions;  Natural user interfaces;  User experience;  Virtual and augmented reality, User interfaces},
correspondence_address1={İnce, G.; Computer Engineering Department, Istanbul Technical UniversityTurkey; email: gokhan.ince@itu.edu.tr},
publisher={Academic Press},
issn={10715819},
coden={IHSTE},
language={English},
abbrev_source_title={Int J Hum Comput Stud},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Li2019,
author={Li, Z. and Chen, L. and Liu, C. and Gao, Y. and Ha, Y. and Xu, C. and Quan, S. and Xu, Y.},
title={3D human avatar digitization from a single image},
journal={Proceedings - VRCAI 2019: 17th ACM SIGGRAPH International Conference on Virtual-Reality Continuum and its Applications in Industry},
year={2019},
doi={10.1145/3359997.3365707},
art_number={a12},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077124492&doi=10.1145%2f3359997.3365707&partnerID=40&md5=53328fa49f893f61f8bd7425e628d93c},
affiliation={OPPO US Research Center, Palo Alto, CA, United States; University of Rochester, Rochester, NY, United States},
abstract={With the development of AR/VR technologies, a reliable and straightforward way to digitize three-dimensional human body is in high demand. Most existing methods use complex equipment and sophisticated algorithms. This is impractical for everyday users. In this paper, we propose a pipeline that reconstructs 3D human shape avatar at a glance. Our approach simultaneously reconstructs the three-dimensional human geometry and whole body texture map with only a single RGB image as input.We first segment the human body part from the image and then obtain an initial body geometry by fitting the segment to a parametric model. Next, we warp the initial geometry to the final shape by applying a silhouette-based dense correspondence. Finally, to infer invisible backside texture from a frontal image, we propose a network we call InferGAN. Comprehensive experiments demonstrate that our solution is robust and effective on both public and our own captured data. Our human avatars can be easily rigged and animated using MoCap data. We developed a mobile application that demonstrates this capability in AR/VR settings. © 2019 Association for Computing Machinery.},
author_keywords={3D reconstruction;  Augmented Reality;  Deep Learning;  Human body modeling},
keywords={Augmented reality;  Deep learning;  Geometry;  Image reconstruction;  Image segmentation;  Image texture;  Interactive computer graphics;  Virtual reality, 3D reconstruction;  Complex equipment;  Dense correspondences;  Frontal images;  Human body modeling;  Mobile applications;  Parametric modeling;  Single images, Three dimensional computer graphics},
editor={Spencer S.N.},
publisher={Association for Computing Machinery, Inc},
isbn={9781450370028},
language={English},
abbrev_source_title={Proc. - VRCAI: ACM SIGGRAPH Int. Conf. Virtual-Real. Continuum its Appl. Ind.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Singh2019,
author={Singh, K. and Srivastava, A. and Achary, K. and Dey, A. and Sharma, O.},
title={Augmented reality-based procedural task training application for less privileged children and autistic individuals},
journal={Proceedings - VRCAI 2019: 17th ACM SIGGRAPH International Conference on Virtual-Reality Continuum and its Applications in Industry},
year={2019},
doi={10.1145/3359997.3365703},
art_number={a31},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077115533&doi=10.1145%2f3359997.3365703&partnerID=40&md5=4d975d17910f10d479dcec43c5622c22},
affiliation={IIIT Delhi, India; Tamana NGO, India; University of Queensland, Australia},
abstract={In this work, we evaluate the applicability of using Augmented Reality applications in for enhanced learning experiences for children from less privileged backgrounds, with a focus on autistic population. Such an intervention can prove to be very useful to children with reduced cognitive development. In our evaluation, we compare the AR mode of instruction for a procedural task training, using tangram puzzles, with live demonstration and a desktopbased application. First, we performed a within-subjects user study on neurotypical children in the age group of 9-12 years. We asked the children to independently solve a tangram puzzle after being trained through different modes of instruction. Second, we used the same instruction modes to train autistic participants. Our findings indicate that during training, children took the longest time to interact with Desktop-based instruction, and took the shortest time to interact with the live demonstration mode. Children also took the longest time to independently solve the tangram puzzle in the Desktop mode. We also found that autistic participants could use AR-based instructions but required more time to go through the training. © 2019 Association for Computing Machinery.},
author_keywords={Augmented reality;  Autism;  Children;  Instruction;  Less privileged;  Training},
keywords={Interactive computer graphics;  Personnel training;  Virtual reality, Augmented reality applications;  Autism;  Children;  Cognitive development;  Enhanced learning;  Instruction;  Less privileged;  Task trainings, Augmented reality},
editor={Spencer S.N.},
publisher={Association for Computing Machinery, Inc},
isbn={9781450370028},
language={English},
abbrev_source_title={Proc. - VRCAI: ACM SIGGRAPH Int. Conf. Virtual-Real. Continuum its Appl. Ind.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Jorge2019,
author={Jorge, J. and Dos Anjos, R.K. and Silva, R.},
title={Dynamic occlusion handling for real-time AR applications},
journal={Proceedings - VRCAI 2019: 17th ACM SIGGRAPH International Conference on Virtual-Reality Continuum and its Applications in Industry},
year={2019},
doi={10.1145/3359997.3365700},
art_number={a15},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077114679&doi=10.1145%2f3359997.3365700&partnerID=40&md5=625d86e75eca6750edaac6569067e634},
affiliation={INESC-ID, Técnico, U. Lisboa, Lisboa, Portugal; Instituto Superior Técnico, U. Lisboa, Lisboa, Portugal},
abstract={Augmented reality (AR) allows computer generated graphics to be overlaid in images or video captured by a camera in real time. This technology is often used to enhance perception by providing extra information or simply by enriching the experience of the user. AR offers a significant potential in many applications such as industrial, medical, education and entertainment. However, for AR to achieve the maximum potential and become fully accepted, the real and virtual objects within the user's environment must become seamlessly integrated. Three main types of problems arise when we try to achieve this effect: Illumination issues, tracking difficulties and occlusion troubles. In this work we present an algorithm to handle AR occlusions in real time. Our approach uses raw depth information of the scene to realize a rough foreground/background segmentation.We use this information, as well as details from color data to estimate a blending coefficient and combine the virtual objects with the real objects into a single image. After experimenting with different scenes we show that our approach is able to produce consistent and aesthetically pleasing occlusions between virtual and real objects, with a low computational cost. Furthermore, we explore different alternatives to improving the quality of the final results while overcoming limitations of previous methods. © 2019 Association for Computing Machinery.},
author_keywords={Alpha Matting;  Augmented Reality;  Dynamic Occlusion Handling;  Real-time Realistic Occlusion},
keywords={Augmented reality;  Interactive computer graphics, Alpha matting;  Computational costs;  Computer generated graphics;  Depth information;  Foreground/background;  Occlusion handling;  Real time;  Virtual objects, Virtual reality},
editor={Spencer S.N.},
publisher={Association for Computing Machinery, Inc},
isbn={9781450370028},
language={English},
abbrev_source_title={Proc. - VRCAI: ACM SIGGRAPH Int. Conf. Virtual-Real. Continuum its Appl. Ind.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Jayaprakash2019226,
author={Jayaprakash, K.P. and Stephens, C. and Lesnick, B. and Arriaga, R.I.},
title={Asthma-nauts: Apps using gameplay to collect health metrics and educate kids about asthma},
journal={Proceedings of the ACM Conference on Computer Supported Cooperative Work, CSCW},
year={2019},
pages={226-230},
doi={10.1145/3311957.3359483},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076086476&doi=10.1145%2f3311957.3359483&partnerID=40&md5=8c41be68d05d6f759683b32dff413328},
affiliation={Interactive Computing, Georgia Institute of TechnologyGA, United States; College of Computer Science, Georgia Institute of TechnologyGA, United States; Children's Healthcare of Atlanta, Atlanta, GA, United States},
abstract={In this paper, we propose the designs for two apps that benefit pediatric patients with asthma. We discuss the current state of the field through results from a survey of published apps related to asthma. We observed several key gaps that were unfilled and use these results to derive a set of requirements for a new app design. We describe two different designs that meet these requirements. The apps are designed to collect health metrics and educate kids aged 7-12 years through gameplay in two different contexts, at home and in hospital Emergency Departments (ED). © 2019 Copyright is held by the owner/author(s).},
author_keywords={Apps;  Asthma;  Augmented reality;  Design;  Education;  Lung function data;  MHealth;  Mobile application;  Pediatric asthma;  Ubiquitous computing},
keywords={Application programs;  Augmented reality;  Design;  Education;  Groupware;  Hospitals;  Interactive computer systems;  mHealth;  Pediatrics;  Ubiquitous computing, Asthma;  Gameplay;  Hospital emergency departments;  Lung function;  Mobile applications;  Pediatric patients, Diseases},
publisher={Association for Computing Machinery},
isbn={9781450366922},
language={English},
abbrev_source_title={Proc. ACM Conf. Comput. Support. Coop. Work CSCW},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Koo2019,
author={Koo, S. and Kim, J. and Kim, C. and Kim, J. and Cha, H.S.},
title={Development of an augmented reality tour guide for a cultural heritage site},
journal={Journal on Computing and Cultural Heritage},
year={2019},
volume={12},
number={4},
doi={10.1145/3317552},
art_number={24},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075639514&doi=10.1145%2f3317552&partnerID=40&md5=7f369fa00430c90020e421b8f66285f9},
affiliation={Engineering Research Institute, Ajou University, Sanhakwon 810, 206 Worldcup-ro, Yeongtong-gu, Suwon-si, Gyeonggi-do, 16499, South Korea; Department of Architectural Engineering, Ajou University, Sanhakwon 712, 206Worldcup-ro, Yeongtong-gu, Suwon-si, Gyeonggi-do, 16499, South Korea; Korea Institute of Civil Engineering and Building Technology, 283 Goyang-daero, Ilsanseo-gu, Goyang-si, Gyeonggi-do, 10223, South Korea; Department of Architecture, Sungkyunkwan University, Seobu-ro,Jangan-gu, Suwon-si, Gyeonggi-do, 16419, South Korea},
abstract={In this article, the design, development, and evaluation of augmented reality (AR)-based mobile application for a tour guide are discussed. The objectives of this article are twofold. First, the research focuses on the development of a complete working set of a mobile tour application furnished with AR. For such an application to be successfully adopted by the general public, user requirements and application usability are investigated, and the application is designed and implemented to fulfill those findings. Second, the developed application is demonstrated by applying it to a UNESCO designated World Heritage site, Hwaseong Fortress in Suwon, South Korea, and evaluated via a survey instrument developed explicitly for mobile application evaluation. A systematically developed survey instrument from the fields of tourism, information systems, and human-computer interaction is tailored to fit into this research and employed for the application evaluation. The application's operation flow consists of three main functions: navigation to the points of interest, visualization of information with AR technology, and interactive learning activities with AR-based serious games. Efforts are made to provide a more immersive and interactive experience of the historical, cultural, and architectural details of the heritage site utilizing novel AR visualization methods. The evaluation returned positive results with suggestions of possible refinements for future works. The proposed device-aided tour mechanism is anticipated to enhance tourists' experiences as well as being important guidance in future mobile tourism application development as to how the application should be designed and implemented to be accepted by the general public. © 2019 Association for Computing Machinery. All rights reserved.},
author_keywords={Augmented reality;  Device-aided tourism;  Hwaseong Fortress;  Mobile tour guide application},
keywords={Human computer interaction;  Mobile computing;  Serious games;  Surveys;  Visualization, Developed applications;  Device-aided tourism;  Hwaseong Fortress;  Interactive learning;  Mobile tourism applications;  Tour guide;  Visualization method;  Visualization of information, Augmented reality},
publisher={Association for Computing Machinery},
issn={15564673},
language={English},
abbrev_source_title={J. Comput. Cult. Heritage},
document_type={Article},
source={Scopus},
}

@ARTICLE{Dhamdhere2019882,
author={Dhamdhere, P. and Singh, N.K. and Biswas, H. and Gupta, A. and Vairamuthu, S.},
title={Augmented reality for abnormal kids},
journal={International Journal of Scientific and Technology Research},
year={2019},
volume={8},
number={11},
pages={882-886},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075081143&partnerID=40&md5=b5346d6c7c7758d8fad94a8d05a18968},
affiliation={VIT, Vellore, India},
abstract={Augmented Reality is a general term for a gathering of advances used to mix PC produced data with a normal viewer natural sense. Since smartphones have become ubiquitous, "Augmented Reality' has been developed to run on them. AR tools utilize the devices sensors (camera input, compass, etc) and put helpful data (in a particular order) in a layer over the picture from the phone camera or webcam which, thus, is seen on the device screen. Augmented Reality has massive potential in the field of education and training. This paper shows an instructive application for some, individuals pass by abnormal kids with learning handicap without notice. Dissimilar to different incapacities like viral fever, physical problem and visual disability a learning failure is a disguised hindrance. Students with learning handicaps get down to business, go to school and college and move forward on a gainful life. It is even more so beneficial for children with learning disabilities. It makes them excited about education as the AR Scrapbook uses fun, interactive and compelling experiences. This paper is designed as a social collaborative experience. It helps in development of cognitive skills and fine motor skills. It sparks the imagination and creativity and enhances their general knowledge and vocabulary. It also intends to help children learn faster and better. This is education of the future. © IJSTR 2019.},
author_keywords={Claustrophobia;  Dementia;  Dyslexia;  Index Terms: Augmented Reality;  Schizophrenia;  Unity 3D;  Virtual Reality},
publisher={International Journal of Scientific and Technology Research},
issn={22778616},
language={English},
abbrev_source_title={Int. J. Sci. Technol. Res.},
document_type={Article},
source={Scopus},
}

@CONFERENCE{NoAuthor2019,
title={Proceedings - SUI 2019: ACM Conference on Spatial User Interaction},
journal={Proceedings - SUI 2019: ACM Conference on Spatial User Interaction},
year={2019},
page_count={175},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077094880&partnerID=40&md5=de2f36b71e341dbf19052543c1df3cf7},
abstract={The proceedings contain 35 papers. The topics discussed include: pursuit sensing: extending hand tracking space in mobile VR applications; minuet: multimodal interaction with an Internet of things; analysis of peripheral vision and vibrotactile feedback during proximal search tasks with dynamic virtual entities in augmented reality; investigating the effect of distractor interactivity for redirected walking in virtual reality; LIVE: the human role in learning in immersive virtual environments; blended agents: manipulation of physical objects within mixed reality environments and beyond; extending virtual reality DisplayWall environments using augmented reality; extramission: a large scale interactive virtual environment using head mounted projectors and retro-reflectors; and effects of dark mode on visual fatigue and acuity in optical see-through head-mounted displays.},
editor={Spencer S.N.},
publisher={Association for Computing Machinery, Inc},
isbn={9781450369756},
language={English},
abbrev_source_title={Proc. - SUI: ACM Conf. Spat. User Interact.},
document_type={Conference Review},
source={Scopus},
}

@CONFERENCE{Andayani2019,
author={Andayani, U. and Syahputra, M.F. and Muchtar, M.A. and Sattar, M. and Prayudani, S. and Fahmi, F.},
title={3D Modelling Intestine Anatomy with Augmented Reality for Interactive Medical Learning},
journal={IOP Conference Series: Materials Science and Engineering},
year={2019},
volume={648},
number={1},
doi={10.1088/1757-899X/648/1/012035},
art_number={012035},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075260077&doi=10.1088%2f1757-899X%2f648%2f1%2f012035&partnerID=40&md5=dfe1a7f04893280a4cdb7f31fa0e4bd1},
affiliation={Department of Information Technology, Universitas Sumatera Utara, Indonesia; Department of Computer and Informatics, Politeknik Negeri Medan, Indonesia; Department of Electrical Engineering, Universitas Sumatera Utara, Indonesia},
abstract={Humans, one of the heterotrophic living things must meet energy needs by consuming food. The food is then described in the digestive system to become an energy source. The digestive system is composed of the digestive tract and digestive gland glands. In the excerpt of the book "Prometheus" human anatomy, the digestive tract acts as a tool for receiving, chewing, delivering, storing, digesting, absorbing (absorbing) and eliminating food. The small intestine, large intestine, and rectum are organs included in the digestive process. This organ is one of the materials taught to science students to the level of students, especially in medicine. Submission of material about the digestive system in humans themselves is still through conventional media such as blackboards, and images contained in books. Several innovations have been carried out, but still, the development of learning innovations must continue to be developed, so that less interesting subject matter makes it easier for students to know a subject matter with the help of technology and multimedia. The conventional method can only be told without being visualized. If using Augmented Reality (AR) has advantages, namely virtual storage (memory), can be learned at any time, can only be installed on a smartphone, each of them can be studied without thematic tools, and can be visualized by scenarios or stories about problems. The marker was used from the Prometheus book [10] then the AR as the visualization of the organs. The results by developing a 3D model using blender and unity showed that the optimal models could be created by combining both their applications and the testing result of marker detection stable from 15-45 cm and tilt marker detection between 45° - 150°. © 2019 IOP Publishing Ltd. All rights reserved.},
keywords={3D modeling;  Augmented reality;  Engineering education;  mHealth;  Students;  Three dimensional computer graphics;  Virtual storage, Conventional methods;  Digestive glands;  Digestive tract;  Large intestine;  Living things;  Marker detections;  Small intestine;  Subject matters, Digestive system},
correspondence_address1={Andayani, U.; Department of Information Technology, Universitas Sumatera UtaraIndonesia; email: ulfi.andayani@usu.ac.id},
publisher={Institute of Physics Publishing},
issn={17578981},
language={English},
abbrev_source_title={IOP Conf. Ser. Mater. Sci. Eng.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Vortmann2019482,
author={Vortmann, L.-M.},
title={Attention-driven interaction systems for augmented reality},
journal={ICMI 2019 - Proceedings of the 2019 International Conference on Multimodal Interaction},
year={2019},
pages={482-486},
doi={10.1145/3340555.3356088},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074931843&doi=10.1145%2f3340555.3356088&partnerID=40&md5=6922153ab4f913d939d52da10232ed29},
affiliation={Cognitive Systems Lab, Department of Mathematics and Computer Science, University of Bremen, Bremen, Germany},
abstract={Augmented reality (AR) glasses enable the embedding of visual content in a real-world surroundings. In this PhD project, I will implement user interfaces which adapt to the cognitive state of the user, for example by avoiding distractions or re-directing the user's attention towards missed information. For this purpose, sensory data from the user is captured (Brain activity via EEG of fNIRS, eye tracking, physiological measurements) and modeled with machine learning techniques. The focus of the cognitive state estimation is centered around attention related aspects. The main task is to build models for an estimation of a person's attentional state from the combination and classification of multimodal data streams and context information, as well as their evaluation. Furthermore, the goal is to develop prototypical user interfaces for AR glasses and to test their usability in different scenarios. © 2019 Copyright held by the owner/author(s).},
author_keywords={Adaptive systems;  Attention;  Augmented reality;  Classification;  Interaction;  Machine learning;  User interface},
keywords={Adaptive systems;  Augmented reality;  Brain;  Classification (of information);  Eye tracking;  Glass;  Interactive computer systems;  Interface states;  Learning systems;  Machine learning;  Petroleum reservoir evaluation, Attention;  Cognitive state;  Context information;  Interaction;  Interaction systems;  Machine learning techniques;  Multimodal data streams;  Physiological measurement, User interfaces},
correspondence_address1={Vortmann, L.-M.; Cognitive Systems Lab, Department of Mathematics and Computer Science, University of BremenGermany; email: vortmann@uni-bremen.de},
editor={Gao W., Ling Meng H.M., Turk M., Fussell S.R., Schuller B., Schuller B., Song Y., Yu K.},
publisher={Association for Computing Machinery, Inc},
isbn={9781450368605},
language={English},
abbrev_source_title={ICMI - Proc. Int. Conf. Multimodal Interact.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Barros2019206,
author={Barros, H.O. and Campos, F. and Correia, W. and Teixeira, J.M.},
title={A study applied to the validation of the box and blocks manual dexterity virtual test with non-disabled users [Um Estudo Aplicado a Validaç ao do Teste Virtual de Destreza Manual Box and Blocks com Usuarios sem Deficiencia]},
journal={Proceedings - 2019 21st Symposium on Virtual and Augmented Reality, SVR 2019},
year={2019},
pages={206-215},
doi={10.1109/SVR.2019.00045},
art_number={8921130},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077236870&doi=10.1109%2fSVR.2019.00045&partnerID=40&md5=8b3616a28295bb1bb7666e0c7d52d53e},
affiliation={CESAR, Recife, Brazil; Universidade Federal de Pernambuco, Departamento de Design, Recife, Brazil; Departamento de Eletronica e Sistemas, Universidade Federal de Pernambuco, Recife, Brazil},
abstract={The present research had as objective to perform a concordance study of the interaction with physical and virtual artifacts. For this, the Box and Blocks test, which is considered the most simple and popular manual function test used in the world, was used as model task. There were 1.620 tests, 720 physical tests and 900 virtual immersive and non-immersive forms; collected with the 30 volunteers without altering the manual dexterity that concluded all the research. We analyzed the quantitative results of physical and virtual Box and Blocks tests and the usability requirements used to create the interactive applications. The virtual tests were created based on virtual reality heuristics and the approach to building serious games based on virtual reality for health. The immersive virtual tests were fully compatible with the physical results found in this research and with the literature reference results. The non-immersive virtual tests of previous vision showed compatibility after previous training, which enabled the learning of the virtual task. © 2019 IEEE.},
author_keywords={Virtual Reality;  Virtual Rehabilitation;  Virtual Systems Usability},
keywords={Augmented reality;  Serious games;  Virtual reality, Fully compatible;  Interactive applications;  Manual dexterity;  Quantitative result;  Usability requirements;  Virtual artifacts;  Virtual rehabilitation;  Virtual systems, Testing},
publisher={Institute of Electrical and Electronics Engineers Inc.},
isbn={9781728154343},
language={Portuguese},
abbrev_source_title={Proc. - Symp. Virtual Augment. Real., SVR},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Hsu20191400,
author={Hsu, H.-P. and Wenting, Z. and Hughes, J.E.},
title={Developing Elementary Students’ Digital Literacy Through Augmented Reality Creation: Insights From a Longitudinal Analysis of Questionnaires, Interviews, and Projects},
journal={Journal of Educational Computing Research},
year={2019},
volume={57},
number={6},
pages={1400-1435},
doi={10.1177/0735633118794515},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053399669&doi=10.1177%2f0735633118794515&partnerID=40&md5=09b07829e1191906f5b11f9288138a3c},
affiliation={Learning Technologies Program, Department of Curriculum & Instruction, The University of Texas at AustinTX, United States},
abstract={This mixed-method case study investigated digital literacy (DL) development among 32 elementary-level students who created multimodal, contextual, and interactive augmented reality (AR) artifacts in a 20-week after-school program in Northern Taiwan. The instructional design combined situated and spiral learning experiences with AR, implemented through a blended learning environment. Data sources included pre- and post-program digital learning student surveys, student and teacher interviews, classroom observations, and AR artifact assessments. Results indicated statistically significant increases with moderate effect sizes in five areas of students’ DL practices: information management; collaboration; communication and sharing; creation; and evaluation and problem-solving. Students did not increase DL in one area: ethics and responsibility. The situated and spiral learning-by-design approach offered increasingly complex AR creation projects in which students developed and transferred their DL. The face-to-face and online learning settings offered multiple ways to collaborate and facilitated the development of students’ DL. The AR technology enabled students to develop DL through designing AR using three types of representation features: multimodal, interactive, and contextual. Practical and theoretical implications for adapting or enhancing this instructional design in future DL programs and for future research are discussed. © The Author(s) 2018.},
author_keywords={augmented reality;  digital literacy;  elementary school students;  learning by design;  project-based learning},
correspondence_address1={Hughes, J.E.; Learning Technologies Program, Department of Curriculum & Instruction, The University of Texas at AustinUnited States; email: joanh@austin.utexas.edu},
publisher={SAGE Publications Inc.},
issn={07356331},
language={English},
abbrev_source_title={J. Educ. Comput. Res.},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Wahyudi2019151,
author={Wahyudi, A.K. and Yuan Mambu, J. and Lengkong, A.V. and Nurhadi and Ardian, Z.},
title={Implementing Augmented Reality as a Digital Props of Brain Anatomy using 3D Cuboid Tracker},
journal={2019 1st International Conference on Cybernetics and Intelligent System, ICORIS 2019},
year={2019},
pages={151-155},
doi={10.1109/ICORIS.2019.8874917},
art_number={8874917},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074425053&doi=10.1109%2fICORIS.2019.8874917&partnerID=40&md5=e9214787b830ddd2fb0d4ad352f533f0},
affiliation={Department of Computer Science, Klabat University, Airmadidi, Indonesia; Department of Computer Science, Prisma University, Manado, Indonesia; Department of Computer Engineering, Sriwijaya University, Palembang, Indonesia; Department of Computer Science, Universitas Ubudiyah Indonesia, Banda Aceh, Indonesia},
abstract={Augmented Reality may propose several advantages over the conventional method as a teaching aid, including in learning brain anatomy in health education. To gives an alternative to the typical props, and we proposed a learning aid in the form of AR mobile application where a student can hold and observe the human brain in the form of a 3D digital props. By utilizing the 3D cuboid tracker, the proposed system offers an affordable digital prop and yet allow natural handling of the object, which gives a new learning experience. Through performance testing, we found how the device specifications' may slightly affect the proposed system performance. However, through a usability testing, the proposed system and method is preferred over other methods such as a book, information on the screen, and 2D AR object. This research shows the proposed system and method have a lot of potential in aiding much more interactive and stimulating learning activities. © 2019 IEEE.},
author_keywords={augmented reality;  brain anatomy;  cuboid tracker;  health education;  mobile application},
keywords={Augmented reality;  Intelligent systems;  Mobile computing, Brain anatomy;  Conventional methods;  cuboid tracker;  Device specification;  Health education;  Learning experiences;  Mobile applications;  Performance testing, Learning systems},
publisher={Institute of Electrical and Electronics Engineers Inc.},
isbn={9781728114729},
language={English},
abbrev_source_title={Int. Conf. Cybern. Intell. Syst., ICORIS},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Jacoby2019,
author={Jacoby, D. and Coady, Y. and Dahl, E. and Wynden, A. and Richardson, M.},
title={VR Tsunami!},
journal={ACM SIGGRAPH 2019 Appy Hour, SIGGRAPH 2019},
year={2019},
doi={10.1145/3305365.3329728},
art_number={a9},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071494649&doi=10.1145%2f3305365.3329728&partnerID=40&md5=e61f2cfb6f35715cdbc8057814518b32},
affiliation={QVirt Labs, Inc, Victoria, BC, Canada; University of Victoria, Victoria, BC, Canada},
abstract={The Mod Squad lab at the University of Victoria is focused on research that combines geospatial analytics, cloud computing, and Virtual/Augmented Reality. VR Tsunami is an example of Serious Gaming that uses the interaction styles of video games to engage students in learning outcomes. The experience is based on real data from a real tsunami event, provided on a range of devices to teach middle school students about emergency preparedness in areas of British Columbia that are prone to tsunami activity. © 2019 Copyright Held by the Owner/Author(s).},
author_keywords={Geospatial applications;  Serious Gaming;  VR in education},
keywords={Interactive computer graphics;  Tsunamis, British Columbia;  Emergency preparedness;  Geo-spatial;  Geospatial applications;  Interaction styles;  Learning outcome;  Middle school students;  Serious gaming, Serious games},
publisher={Association for Computing Machinery, Inc},
isbn={9781450363068},
language={English},
abbrev_source_title={ACM SIGGRAPH Appy Hour, SIGGRAPH},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Cook2019,
author={Cook, M. and Payne, A. and Ackley, A. and Seo, J.H. and Gonzalez, K.C. and Kicklighter, C. and Pine, M. and McLaughlin, T.},
title={Innervate immersion: Case study of dynamic simulations in AR/VR environments for learning muscular innervation},
journal={ACM SIGGRAPH 2019 Posters, SIGGRAPH 2019},
year={2019},
doi={10.1145/3306214.3338580},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071275091&doi=10.1145%2f3306214.3338580&partnerID=40&md5=285af73a6cea292cd5aa214dba85c3c5},
affiliation={Texas A and M University College StationTX, United States},
abstract={We present a collaborative immersive technology effort, InNervate AR and InNervate VR. These applications meet the need to expand on existing anatomy education platforms by implementing a more dynamic and interactive user interface. This user interface allows for exploration of the complex relationship between motor nerve deficits and their effects upon the canine anatomy's ability to produce movement. Preliminary AR user studies provided us with positive feedback in the quality of learning. The studies show that the dynamic touch interactions in AR definitely benefit students' critical reasoning and spatial visualization in learning motor nerve and muscle relationships. However, users seek a more immersive VR-based learning environment, without the distractions that an AR experience may offer. Based on this feedback, a VR version of this learning experience was created. Preliminary responses show that users are satisfied with this VR environment which allows them to manipulate and control the anatomical content with full-body interactions. © 2019 Copyright held by the owner/author(s).},
author_keywords={Anatomy Education;  Augmented Reality;  Immersive Technology;  Virtual Reality},
keywords={Augmented reality;  Computer aided instruction;  Feedback;  Interactive computer graphics;  Virtual reality, Anatomy educations;  Complex relationships;  Full-body interaction;  Immersive technologies;  Interactive user interfaces;  Learning environments;  Learning experiences;  Spatial visualization, User interfaces},
publisher={Association for Computing Machinery, Inc},
isbn={9781450363143},
language={English},
abbrev_source_title={ACM SIGGRAPH Posters, SIGGRAPH},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Sisto2019,
author={Sisto, A. and Detweiler, J. and Luo, V. and Mani, V. and Agarawala, A. and Mine, M. and Grossman, B.},
title={The future of shared experiences - XR is a lonely world},
journal={ACM SIGGRAPH 2019 Panels, SIGGRAPH 2019},
year={2019},
doi={10.1145/3306212.3328125},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071269483&doi=10.1145%2f3306212.3328125&partnerID=40&md5=744998a5071dda87bbbe72fa32bcc7ca},
affiliation={VentureX, Washington, D.C., United States; Fantasmo, Venice, CA, United States; NASA Jet Propulsion Laboratory, Los Angeles, CA, United States; PTC, Somerville, MA, United States; Spatial, New York, NY, United States; Disney Imagineering, Los Angeles, CA, United States; Magnopus, Los Angeles, CA, United States},
abstract={XR has never been more immersive, entertaining and dynamic than it is now. So why is the virtual world still such a lonely place? Shared virtual experiences are slowing becoming a reality, with the potential to transform the way XR is used in education, entertainment, telepresence and the enterprise. But will technology and content finally coevolve to support realistic, real-time, multi-person interactions? This panel explores the expanding dimensions of shared experiences in XR, offering views on emerging trends, applications and breakthrough technologies. © Copyright is held by the owner/author(s).},
author_keywords={Augmented reality;  Extended reality;  Virtual reality},
keywords={Augmented reality;  Virtual reality;  Visual communication, Breakthrough technology;  Emerging trends;  Extended reality;  Immersive;  Real time;  Shared experiences;  Telepresence;  Virtual worlds, Interactive computer graphics},
correspondence_address1={Sisto, A.; VentureXUnited States; email: aaron@venturex.ai},
publisher={Association for Computing Machinery, Inc},
isbn={9781450363129},
language={English},
abbrev_source_title={ACM SIGGRAPH Panels, SIGGRAPH},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Matuszka2019,
author={Matuszka, T. and Czuczor, F. and Sóstai, Z.},
title={Heromirror interactive: A gesture controlled augmented reality gaming experience},
journal={ACM SIGGRAPH 2019 Posters, SIGGRAPH 2019},
year={2019},
doi={10.1145/3306214.3338554},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071252426&doi=10.1145%2f3306214.3338554&partnerID=40&md5=be54ad8f0c63bf755a0d0619f36cb2bb},
affiliation={Department of Research and Development INDE R and D; Department of Software Development, INDE R and D; Department of Content Development, INDE R and D},
abstract={Appropriately chosen user interfaces are essential parts of immersive augmented reality experiences. Regular user interfaces cannot be efficiently used for interactive, real-time augmented reality applications. In this study, a gesture controlled educational gaming experience is described where gesture recognition relies on deep learning methods. Our implementation is able to replace a depth-camera based gesture recognition system using conventional camera while ensuring the same level of recognition accuracy. © 2019 Copyright held by the owner/author(s).},
author_keywords={Augmented reality;  Computer vision;  Deep learning;  Human experience},
keywords={Augmented reality;  Cameras;  Computer vision;  Deep learning;  Interactive computer graphics;  User interfaces, Augmented reality applications;  Augmented reality gaming;  Conventional camera;  Educational gaming;  Gesture recognition system;  Human experience;  Immersive augmented realities;  Recognition accuracy, Gesture recognition},
publisher={Association for Computing Machinery, Inc},
isbn={9781450363143},
language={English},
abbrev_source_title={ACM SIGGRAPH Posters, SIGGRAPH},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Ro2019,
author={Ro, H. and Byun, J.-H. and Park, Y.J. and Han, T.-D.},
title={Display methods of projection augmented reality based on deep learning pose estimation},
journal={ACM SIGGRAPH 2019 Posters, SIGGRAPH 2019},
year={2019},
doi={10.1145/3306214.3338608},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071240403&doi=10.1145%2f3306214.3338608&partnerID=40&md5=599163bd21f6eda55fd9ad5482a25ef0},
affiliation={Media System Lab, Yonsei University, Seoul, South Korea},
abstract={In this paper, we propose three display methods for projection-based augmented reality. In spatial augmented reality (SAR), determining where information, objects, or contents are to be displayed is a difficult and important issue. We use deep learning models to estimate user pose and suggest ways to solve the issue based on this data. Finally, each method can be appropriately applied according to various the applications and scenarios. © 2019 Copyright held by the owner/author(s).},
author_keywords={Deep Learning;  Mixed Reality;  Pose Estimation;  Projection Augmented Reality;  Spatial Augmented Reality},
keywords={Augmented reality;  Interactive computer graphics;  Mixed reality, Learning models;  Pose estimation;  Spatial augmented realities, Deep learning},
publisher={Association for Computing Machinery, Inc},
isbn={9781450363143},
language={English},
abbrev_source_title={ACM SIGGRAPH Posters, SIGGRAPH},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Qin20191367,
author={Qin, S. and Li, Z. and Li, J. and Chen, Z. and Ding, J. and Liu, W.},
title={Design and Implementation of Interactive AR System for Campus Roaming [校园漫游互动AR系统设计与实现]},
journal={Xitong Fangzhen Xuebao / Journal of System Simulation},
year={2019},
volume={31},
number={7},
pages={1367-1376},
doi={10.16182/j.issn1004731x.joss.18-VR0739},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071397677&doi=10.16182%2fj.issn1004731x.joss.18-VR0739&partnerID=40&md5=362afeb21a0746435bf8a3f57f5138ee},
affiliation={South china Institute of Software Engineering, Guangzhou University, Guangzhou, 510990, China; School of Science, Zhejiang Sci-Tech University, Hangzhou, 310018, China},
abstract={There are many kinds of navigation applications in universities recently. These applications have obvious shortcomings, which only indicate the outdoor locations without detail information; even some places cannot be found in the map; and it takes a lot of time to design a system. Meanwhile the system cannot achieve real-time interaction effect in virtual ramble. An interactive campus roaming augmented reality (AR) system is designed combining with GPS module for locating outside the campus and utilizing deep learning technology to achieve locating the inside buildings of campus. Simultaneously AR technology will improve interactivity of the system. The experiment results show that the interactive campus roaming AR system proposed in the paper is effective for locating in campus. The navigation service can provide the information of university in real time for the visitors and further provides a platform for culture communication. © 2019, The Editorial Board of Journal of System Simulation. All right reserved.},
author_keywords={Augmented reality;  Campus roaming;  Deep learning technology;  Global Positioning System},
publisher={Acta Simulata Systematica Sinica},
issn={1004731X},
coden={XFXUF},
language={Chinese},
abbrev_source_title={Xitong Fangzhen Xuebao},
document_type={Article},
source={Scopus},
}

@CONFERENCE{NoAuthor2019,
title={Proceedings - 2019 International Symposium on Educational Technology, ISET 2019},
journal={Proceedings - 2019 International Symposium on Educational Technology, ISET 2019},
year={2019},
page_count={288},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071034174&partnerID=40&md5=d74cc4d8382c5c0a10d144f6df90157e},
abstract={The proceedings contain 59 papers. The topics discussed include: An interactive virtual reality application in education for soil and water conservation; personalized training in fast-food restaurants using augmented reality glasses; a talent assessment model based on learning behaviors and patterns; an investigation of academic self-efficacy, intrinsic motivation and connected classroom climate on college students' engagement in blended learning; determinants of acceptance of on-line courses for continuous studies; smart learning environment: A case on the construction of smart classrooms in colleges and universities in Guangzhou; using open educational resources for teaching in higher education: A review of case studies; the Google search engine: A blended-learning tool for student empowerment; and the actual condition of teachers and the teacher training about ICT utilization in Leyte, the Philippines.},
editor={Hynek P., Klimova B., Au O., Hynek J., Wang F.L.},
publisher={Institute of Electrical and Electronics Engineers Inc.},
isbn={9781728133874},
language={English},
abbrev_source_title={Proc. - Int. Symp. Educ. Technol., ISET},
document_type={Conference Review},
source={Scopus},
}

@CONFERENCE{Abid2019544,
author={Abid, M. and Bhimra, M.A. and Mubeen, M. and Zahid, A.B. and Shahid, S.},
title={Peppy: A paper-based augmented reality application to help children against dysgraphia},
journal={Proceedings of the 18th ACM International Conference on Interaction Design and Children, IDC 2019},
year={2019},
pages={544-549},
doi={10.1145/3311927.3325311},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068806353&doi=10.1145%2f3311927.3325311&partnerID=40&md5=9c6140a3f67947bed4a551e1f5f64ff9},
affiliation={Lahore University of Management Science, Lahore, Pakistan},
abstract={Over the years, researchers have found an increase in learning problem among young children especially related to writing. Among these is a drop in dexterity or developmental dysgraphia due to a lack of fine motor skills. Also discovered is that handwritten activities on paper help work out these problems and with the advancement in technology in today's day and age, better combative measures can be taken against these problems. With Peppy, a mobile application using augmented reality (AR), our aim is to fight these problems using technology as well as paper by augmenting it into something that is both interactive and useful for child development. Although educational AR applications already exist, they don't focus on improving children's fine motor skills using paper-based exercises. Peppy brings enjoyable, thought-provoking and intriguing paper prototypes consisting of colouring, games, and puzzles to life through AR. © 2019 Association for Computing Machinery.},
author_keywords={Augmented Reality;  Children;  Dysgraphia;  Fine motor skills;  Paper-based;  Smartphones},
keywords={Augmented reality;  Smartphones, Augmented reality applications;  Child development;  Children;  Dysgraphia;  Fine motors;  Learning problem;  Mobile applications;  Paper prototypes, Paper},
publisher={Association for Computing Machinery, Inc},
isbn={9781450366908},
language={English},
abbrev_source_title={Proc. ACM Int. Conf. Interact. Des. Child., IDC},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Ang2019,
author={Ang, I.J.X. and Lim, K.H.},
title={Enhancing STEM Education using Augmented Reality and Machine Learning},
journal={2019 7th International Conference on Smart Computing and Communications, ICSCC 2019},
year={2019},
doi={10.1109/ICSCC.2019.8843619},
art_number={8843619},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073216090&doi=10.1109%2fICSCC.2019.8843619&partnerID=40&md5=f33fab6b080da6e0b425d09d38edb0a7},
affiliation={Department of Electrical and Computer Engineering, Curtin University, Malaysia, CDT 250, Miri, Sarawak, 98009, Malaysia},
abstract={Learning Science, Technology, Engineering and Mathematics (STEM) in the 21st century has been evolved from the conventional textbook to the interactive platform using electronic devices. This paper presents the implementation of a mobile application system, named AUREL (Augmented Reality Learning) in enhancing the learning experience by projecting Augmented Reality (AR) objects onto 2D images. This AR visualization is used to improve the understanding of STEM subjects and increases the enthusiasm of students towards STEM subjects. In this implementation, Google's Cloud Tensor Processing Units (TPUs) are used to train specific datasets alongside Cloud Vision API to detect a wide range of objects. ML Kit for Firebase is used to host the custom TensorFlow Lite models for specific use cases for better accuracy. On the other hand, Google Cloud Platform (GCP) is used to harvest STEM data, manage STEM 3D information and data processing. Subsequently, the processed information will be displayed in AR in the mobile application using ARCore's Sceneform SDK. The application of AUREL could be extended to all science subjects so that students can learn using an interactive platform. © 2019 IEEE.},
author_keywords={Augmented Reality;  Machine Learning;  STEM Education},
keywords={Augmented reality;  Data handling;  Education computing;  Engineering education;  Image enhancement;  Learning systems;  Machine learning;  Mobile computing;  Students, Electronic device;  Interactive platform;  Learning experiences;  Learning science;  Mobile applications;  Processed information;  Processing units;  STEM education, STEM (science, technology, engineering and mathematics)},
publisher={Institute of Electrical and Electronics Engineers Inc.},
isbn={9781728115573},
language={English},
abbrev_source_title={Int. Conf. Smart Comput. Commun., ICSCC},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Ramos2019135,
author={Ramos, M.J.H. and Comendador, B.E.V.},
title={Artitser: A mobile augmented reality in classroom interactive learning tool on biological science for junior high school students},
journal={ACM International Conference Proceeding Series},
year={2019},
pages={135-139},
doi={10.1145/3337682.3337700},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072231165&doi=10.1145%2f3337682.3337700&partnerID=40&md5=c95e8b88275fca03c4c875b4efbb7ad6},
affiliation={Polytechnic University of the Philippines, Graduate Program Office, Sta. Mesa, Manila, Philippines},
abstract={The authors implemented an Augment Reality (AR) to develop a mobile application called ARTitser that was utilized for Junior High School students as a supportive tool to learn Biological Science. The said application runs in iOS that integrates AR technology education which may help the teachers in facilitating delivery of the daily lessons using a realistic representation of objects for a better learning experience. It may also assist the teachers to monitor the performance of the students when using AR lesson. Moreover, the students may enjoy ARTitser application because they will see 3D objects associated to biology lesson. Based on the result of the survey, the respondents highly recommended the ARTitser with a grand mean of 4.52 which is highly acceptable. Thus, the said tool can be implemented in the Junior High School students which may motivate as well as improve the performance of the students. © 2019 Association for Computing Machinery.},
author_keywords={Biology;  Interactive Learning Tool;  Mobile Augmented Reality;  Mobile Learning},
keywords={Augmented reality;  Biology;  Educational technology;  Learning systems;  Surveys, Biological science;  Interactive learning tools;  Junior high schools;  Learning experiences;  Mobile applications;  Mobile augmented reality;  Mobile Learning;  Technology education, Students},
publisher={Association for Computing Machinery},
isbn={9781450372008},
language={English},
abbrev_source_title={ACM Int. Conf. Proc. Ser.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Khalid2019,
author={Khalid, F. and Ali, A.I. and Ali, R.R. and Bhatti, M.S.},
title={AREd: Anatomy learning using augmented reality application},
journal={2019 International Conference on Engineering and Emerging Technologies, ICEET 2019},
year={2019},
doi={10.1109/CEET1.2019.8711843},
art_number={8711843},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066492934&doi=10.1109%2fCEET1.2019.8711843&partnerID=40&md5=d203168910e64faa4724d10f476821ff},
affiliation={Department of Computer Science, COMSATS University Islamabad, Lahore Campus, Lahore, Pakistan},
abstract={With the advancements in technology, innovative teaching methodologies are being utilized in the educational environment. Among these, the most promising methodology is Augmented Reality which makes it possible for students to fully understand an abstract concept by representing a visualized and interactive 3D model. This paper gives review of recent studies on AR in different fields of education as well as an overview of some applications that use AR in the field of education to highlight the benefits of utilization of augmented reality. This paper presents an augmented reality application which generates 3D models of anatomy which aims to help students and instructors alike. A survey was conducted with the purpose of exploring acceptance and benefits of this application. The outcomes of survey suggested that students retain what they learned from this application longer compared to traditional teaching methods, students retain concentration from proposed method. © 2019 IEEE.},
author_keywords={3D models (three dimensional);  4D models (four dimensional);  AR;  AR Applications;  AR education;  Augmented Reality;  E-learning;  Innovative teaching methodology;  Interactive Education;  Marker Based Augmented Reality},
keywords={3D modeling;  Argon;  Augmented reality;  E-learning;  Education computing;  Students;  Surveys, 4D models (four dimensional);  AR application;  Augmented reality applications;  Educational environment;  Innovative teaching;  Interactive 3-D models;  Interactive education;  Teaching methods, Three dimensional computer graphics},
publisher={Institute of Electrical and Electronics Engineers Inc.},
isbn={9781538621707},
language={English},
abbrev_source_title={Int. Conf. Eng. Emerg. Technol., ICEET},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{VazquezBriseno2019751,
author={Vazquez Briseno, M. and Gomez Soto, O.N. and Marquez Tellez, A. and Nieto Hipolito, J.I. and Infante Prieto, S. and Sanchez Lopez, J.D.D.},
title={Enhancing Nutrition Learning Using Interactive Tools},
journal={IEEE Latin America Transactions},
year={2019},
volume={17},
number={5},
pages={751-758},
doi={10.1109/TLA.2019.8891943},
art_number={8891943},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075009162&doi=10.1109%2fTLA.2019.8891943&partnerID=40&md5=806b12615a6a037854c646f3cc840792},
affiliation={Universidad Autonoma de Baja California, Mexico},
abstract={Nowadays, obesity is a serious health problem worldwide. Its occurrence has exponentially increased in both children and adults, especially in developing countries. Since overweight and obese children are more likely to be overweight or obese adults, it is important to control and prevent childhood obesity. Moreover, overweight and obesity can put children at higher risk for various health problems. Recently, several information and communication technology tools have been designed to promote good health habits, physical activity, nutrition education, and weight loss. Most of these tools, however, target at an adult audience and fail to capture the attention of children. To address this gap, we present two child-friendly prototypes as nutrition education tools for preventing obesity. The prototypes rely on computational techniques such as augmented reality and serious games to provide children a more user-friendly experience. We also present the designs and evaluation of the prototypes and provide key guidelines for developers. © 2003-2012 IEEE.},
author_keywords={Augmented reality;  Mobile Health;  Mobile software;  Sensors;  Serious games},
keywords={Augmented reality;  Developing countries;  Health risks;  mHealth;  Sensors;  Serious games, Childhood obesity;  Computational technique;  Education tool;  Information and Communication Technologies;  Interactive tool;  Mobile softwares;  Physical activity;  User friendly, Nutrition},
publisher={IEEE Computer Society},
issn={15480992},
language={Spanish},
abbrev_source_title={IEEE. Lat. Am. Trans.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Tong201974,
author={Tong, Q. and Li, X. and Lin, K. and Li, C. and Si, W. and Yuan, Z.},
title={Cascade-LSTM-Based Visual-Inertial Navigation for Magnetic Levitation Haptic Interaction},
journal={IEEE Network},
year={2019},
volume={33},
number={3},
pages={74-80},
doi={10.1109/MNET.2019.1800371},
art_number={8726075},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068869817&doi=10.1109%2fMNET.2019.1800371&partnerID=40&md5=f2e05fbd467ef10b1c56fed79c7f8028},
affiliation={Wuhan University, China; Dalian University of Technology, China; Chinese Academy of Sciences, China},
abstract={Haptic feedback is crucial to immersive experience in virtual and augmented reality applications. The existing promising maglev haptic devices have advantages of no mechanical friction and low inertia. However, their performance is limited by the navigation approach, which mainly results from the challenge that it is difficult to obtain high precision, high frequency, and good stability with lightweight design at the same time. In this study, we reformulate visual-inertial navigation as a regression problem, and adopt deep learning to perform fusion navigation for maglev haptic interaction. A cascade-LSTM-based q-increment learning method is first proposed to progressively learn the increments of target variables. Two cascade LSTM networks are then constructed to estimate the increments of position and orientation, which are pipelined to accomplish visual-inertial fusion navigation. Additionally, we set up a maglev haptic platform as the system testbed. Experimental results show that our cascade-LSTMbased visual-inertial fusion navigation approach can reach 200 Hz while maintaining high-precision navigation (the mean absolute error of the position and orientation is less than 1 mm and 0.02°, respectively) for a maglev haptic interactive deformation application. © 1986-2012 IEEE.},
keywords={Augmented reality;  Deep learning;  Inertial confinement fusion;  Inertial navigation systems;  Laser fusion;  Long short-term memory;  Magnetic levitation;  Navigation, Haptic interactions;  Increment learning;  Inertial navigations;  Mean absolute error;  Mechanical friction;  Position and orientations;  Regression problem;  Virtual and augmented reality, Air navigation},
correspondence_address1={Yuan, Z.; Wuhan UniversityChina},
publisher={Institute of Electrical and Electronics Engineers Inc.},
issn={08908044},
coden={IENEE},
language={English},
abbrev_source_title={IEEE Network},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Nainggolan2019,
author={Nainggolan, E.R. and Asymar, H.H. and Nalendra, A.R.A. and Anton and Sulaeman, F. and Sidik and Radiyah, U. and Susafarati},
title={The Implementation of Augmented Reality as Learning Media in Introducing Animals for Early Childhood Education},
journal={2018 6th International Conference on Cyber and IT Service Management, CITSM 2018},
year={2019},
doi={10.1109/CITSM.2018.8674350},
art_number={8674350},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064350028&doi=10.1109%2fCITSM.2018.8674350&partnerID=40&md5=ce3851fd43f3801a32d6e257831653ff},
affiliation={Information Technology, STMIK Nusa Mandiri Jakarta, Jakarta, Indonesia; Computer Engineering, AMIK BSI Jakarta, Jakarta, Indonesia; Information Management, AMIK BSI Tangerang, Tangerang, Indonesia},
abstract={The early childhood education is the process of learning where the children are on the step to know and to be curious of their surroundings. It is also a time for children to grow and to explore the knowledge. Nowadays some schools of early childhood still use the old method such as of face-to-face or read book. Consequently, it makes the students of early childhood easily bored with this method and need the new method to make they are interested in. Hence, it needs an interactive learning media to make the children interest in. The selection of making media of introduction animal based on recognition of Augmented reality using Unity 3D because it supports Animated Augmented reality itself which contained by animations, the text, images, 3D, audio, and video as well as Vuforia mobile device SDK that enables the creation of Augmented reality. The FAST Corner Detection algorithm is used in this system for the purpose of speeding up computing time in real-time with the consequences of lowering the level of accuracy of detection angle. The Aim of this research is to give the detail information about the using of visual information about the animals interactively through the three-dimensional animation using the technology of Augmented Reality. The result of this research is the application of interactively learning media based on the augmented reality. It can help the teacher of the early childhood education (PAUD) to introduce the name, shape even sound of the animal to the pupils. © 2018 IEEE.},
author_keywords={Algorithm Fast Corner Detection;  Augmented reality;  Early Childhood Education Program;  The introduction of animals},
keywords={Animals;  Character recognition;  Edge detection;  Information use, Corner detection;  Detection angle;  Early childhood educations;  Early childhoods;  Interactive learning;  Process of learning;  Three-dimensional animations;  Visual information, Augmented reality},
publisher={Institute of Electrical and Electronics Engineers Inc.},
isbn={9781538654330},
language={English},
abbrev_source_title={Int. Conf. Cyber IT Serv. Manag., CITSM},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Zhao20191108,
author={Zhao, G. and Zhang, Q. and Chu, J. and Li, Y. and Liu, S. and Lin, L.},
title={Augmented Reality Application for Plant Learning},
journal={Proceedings of the IEEE International Conference on Software Engineering and Service Sciences, ICSESS},
year={2019},
volume={2018-November},
pages={1108-1111},
doi={10.1109/ICSESS.2018.8663953},
art_number={8663953},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063610972&doi=10.1109%2fICSESS.2018.8663953&partnerID=40&md5=f89dd04c789e263633fae2b4cfd4830e},
affiliation={School of Educational Information Technology Central China Normal, University Wuhan, China; National Engineering Research, Center for E-Learning Central China Normal, University Wuhan, China},
abstract={Augmented reality learning resources meet the requirements of contextual and adaptive ubiquitous learning and are gradually favored in the field of education. In our previous work, we proposed a plant knowledge expansion learning system. This system used mobile intelligent terminal to take pictures of plants to get the text, pictures, audio, video and other information related to plants. On the basis of the existing system, this paper further explored the application of augmented reality technology for plant learning, and developed plants augmented reality information display module. This module can be used to scan a specific plant and obtain its 3D model and text information in realtime. Learners can interact with the model by rotating and scaling, which effectively enhances learners' interest in learning. © 2018 IEEE.},
author_keywords={augmented reality technology (AR);  interactive learning;  plant learning},
keywords={3D modeling;  Augmented reality;  Knowledge acquisition;  Plant expansion;  Software engineering, Augmented reality applications;  Augmented reality technology;  Information display;  Interactive learning;  Knowledge expansion;  Mobile intelligent terminals;  plant learning;  Ubiquitous learning, Learning systems},
editor={Babu M.S.P., Wenzheng L.},
publisher={IEEE Computer Society},
issn={23270586},
isbn={9781538665640},
language={English},
abbrev_source_title={Proc.IEEE Int. Conf. Software Eng. Serv. Sci., ICSESS},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Kouzi20191594,
author={Kouzi, M.E. and Mao, A. and Zambrano, D.},
title={An educational augmented reality application for elementary school students focusing on the human skeletal system},
journal={26th IEEE Conference on Virtual Reality and 3D User Interfaces, VR 2019 - Proceedings},
year={2019},
pages={1594-1599},
doi={10.1109/VR.2019.8798058},
art_number={8798058},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071886458&doi=10.1109%2fVR.2019.8798058&partnerID=40&md5=c8abd5497db7a4e11019663693f79e5c},
affiliation={Carleton University, Canada},
abstract={Augmented Reality (AR) as a new field regarding Human Computing Interaction (HCI) has been gaining momentum in the last few years. Being able to project interactive graphics into real-life environments can be applied in various fields, research and commercial goals. In the field of education, textbooks are still considered to be the primary tool used by students to learn about new topics. Since AR requires interaction and exploration, it brings a ludic component that is hard to replicate using regular textbooks. The application we developed allows elementary school students to interact with a fully three-dimensional human skeleton model, using specialized virtual buttons. Students can understand this complex structure and learn the names of important bones just by using a tablet, a picture and their hands. Results show that the majority of students consider that our AR application helped them visualize and learn more about the human skeletal system. Additionally, the data we gathered shows that there was a 16% increase in correct responses regarding bone names after using our AR application. Our AR application successfully helped the students learn about the human skeletal system by introducing them to AR technologies. © 2019 IEEE.},
author_keywords={3d object;  Augmented reality;  Education;  Elementary school;  Human computer interaction (HCI);  Skeleton system},
keywords={Augmented reality;  Bone;  Education;  Education computing;  Human computer interaction;  Musculoskeletal system;  Textbooks;  Three dimensional computer graphics;  User interfaces;  Virtual reality, 3D object;  Augmented reality applications;  Complex structure;  Elementary schools;  Human computer interaction (HCI);  Human skeleton model;  Interactive graphics;  Skeleton system, Students},
publisher={Institute of Electrical and Electronics Engineers Inc.},
isbn={9781728113777},
language={English},
abbrev_source_title={IEEE Conf. Virtual Real. 3D User Interfaces, VR - Proc.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{NoAuthor2019,
title={26th IEEE Conference on Virtual Reality and 3D User Interfaces, VR 2019 - Proceedings},
journal={26th IEEE Conference on Virtual Reality and 3D User Interfaces, VR 2019 - Proceedings},
year={2019},
page_count={949},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071879995&partnerID=40&md5=48211aaa675e4059009d2c54891e9296},
abstract={The proceedings contain 460 papers. The topics discussed include: Shooter bias and socioeconomic status in virtual reality; Coretet: A dynamic virtual musical instrument for the twenty-first century; VR and volitional pain: Testing immersive interventions during a tattoo; interactive and multimodal-based augmented reality for remote assistance using a digital surgical microscope; the matter of attention and motivation - understanding unexpected results from auditory localization training using augmented reality; body-prop interaction: Evaluation of augmented open discs and egocentric body-based interaction; toward virtual stress inoculation training of prehospital healthcare personnel: A stress-inducing environment design and investigation of an emotional connection factor; virtual classmates: Embodying historical learners' messages as learning companions in a VR classroom through comment mapping; and short-term path prediction for virtual open spaces.},
publisher={Institute of Electrical and Electronics Engineers Inc.},
isbn={9781728113777},
language={English},
abbrev_source_title={IEEE Conf. Virtual Real. 3D User Interfaces, VR - Proc.},
document_type={Conference Review},
source={Scopus},
}

@CONFERENCE{Klippel20191022,
author={Klippel, A. and Wallgrun, J.O. and Masrur, A. and Zhao, J. and Lafemina, P.},
title={Warping space and time-reviving educational tools of the 19th century},
journal={26th IEEE Conference on Virtual Reality and 3D User Interfaces, VR 2019 - Proceedings},
year={2019},
pages={1022-1023},
doi={10.1109/VR.2019.8797897},
art_number={8797897},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071873936&doi=10.1109%2fVR.2019.8797897&partnerID=40&md5=c3388513362ec8eaacfa748378ff1815},
affiliation={Pennsylvania State University, United States},
abstract={xR has the potential to warp both space and time. We demonstrate this potential by designing a mixed reality application for mobile devices for the Penn State's Obelisk, a historic landmark on the main Penn State campus that artistically reveals the geological history of Pennsylvania. Our AR application allows for placing a model of the Obelisk on any surface, interacting with the individual stones to reveal their geological characteristics and location of excavation, and changing to an immersive VR experience of this location based on 360° imagery. Originally conceptualized as a teaching tool for the School of Mines, our xR application revives the Obelisk's long forgotten mission and allows educators to integrate it once more into the curriculum as well as creatively expand its potential. © 2019 IEEE.},
author_keywords={Augmented reality;  Interactive learning;  Mixed reality},
keywords={Augmented reality;  Curricula;  Geology;  Mixed reality, AR application;  Educational tools;  Geological characteristics;  Geological history;  Interactive learning;  Location based;  Space and time;  Teaching tools, User interfaces},
publisher={Institute of Electrical and Electronics Engineers Inc.},
isbn={9781728113777},
language={English},
abbrev_source_title={IEEE Conf. Virtual Real. 3D User Interfaces, VR - Proc.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Sun20191738,
author={Sun, Y. and Armengol-Urpi, A. and Reddy Kantareddy, S.N. and Siegel, J. and Sarma, S.},
title={MagicHand: Interact with iot devices in augmented reality environment},
journal={26th IEEE Conference on Virtual Reality and 3D User Interfaces, VR 2019 - Proceedings},
year={2019},
pages={1738-1743},
doi={10.1109/VR.2019.8798053},
art_number={8798053},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071866764&doi=10.1109%2fVR.2019.8798053&partnerID=40&md5=d42c0320596f87f0e17c93e0bfe41916},
affiliation={MIT, United States; Michigan State University, United States},
abstract={We present an Augmented Reality (AR) visualization and interaction tool for users to control Internet of Things (IoT) devices with hand gestures. Today, smart IoT devices are becoming increasingly ubiquitous with diverse forms and functions, yet most user controls over them are still limited to mobile devices and web interfaces. Recently, AR has been developed rapidly, and provided immersive solutions to enhance user experience of applications in many fields. Its capability to create immersive interactions allows AR to improve the way smart devices are controlled via more direct visual feedback. In this paper, we create a functional prototype of one such system, enabling seamless interactions with sound and lighting systems through the use of augmented hand-controlled interaction panels. To interpret users' intentions, we implement a standard 2D convolution neural network (CNN) for real-time hand gesture recognition and deploy it within our system. Our prototype is also equipped with a simple but effective object detector which can identify target devices within a proper range by analyzing geometric features. We evaluate the performance of our system qualitatively and quantitatively and demonstrate it on two smart devices. © 2019 IEEE.},
author_keywords={Augmented reality;  Deep learning;  Hand gesture recognition;  Head mounted display;  Image and 3d data processing;  Iot devices;  Object detection;  Visual and interactive control},
keywords={Augmented reality;  Data handling;  Deep learning;  Gesture recognition;  Helmet mounted displays;  Object detection;  Palmprint recognition;  User interfaces;  Virtual reality;  Visual communication, 3D data processing;  Hand-gesture recognition;  Head mounted displays;  Interactive control;  Iot devices, Internet of things},
publisher={Institute of Electrical and Electronics Engineers Inc.},
isbn={9781728113777},
language={English},
abbrev_source_title={IEEE Conf. Virtual Real. 3D User Interfaces, VR - Proc.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{NoAuthor2019,
title={Proceedings of the 2019 3rd International Conference on Virtual and Augmented Reality Simulations, ICVARS 2019},
journal={ACM International Conference Proceeding Series},
year={2019},
page_count={99},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070543798&partnerID=40&md5=c9d4a83bcb4afec75b3bcc86dd552729},
abstract={The proceedings contain 17 papers. The topics discussed include: influence of interactive questions on the sense of presence and anxiety in a virtual-reality job-interview; development of chemical incident response training program by applying virtual reality technology; therapeutic virtual reality for nyctophobic disorder; virtual reality for anatomical vocabulary learning; development of dual cognitive task virtual reality game addressing stroke rehabilitation; game cinematography - towards understanding relationship between spatial distortion and game-play; a new method to render virtual walls for haptic systems: ’tracking wall’. application to needle insertion simulation; collaborative hands-on training on haptic simulators; PD pattern recognition in transformers based on greyscale images and affinity propagation algorithm; development of automated platform for image capturing and counting algorithm for viral plaque; and design of an autonomous sentry gun system for the detection of people in restricted zones.},
publisher={Association for Computing Machinery},
isbn={9781450365925},
language={English},
abbrev_source_title={ACM Int. Conf. Proc. Ser.},
document_type={Conference Review},
source={Scopus},
}

@ARTICLE{Chang20194965,
author={Chang, Y.-S. and Chen, Y.-S. and Chiang, C.-W.},
title={The differences in pleasing value and learning performance among different groups using mobile augmented reality system for cultural environment learning},
journal={Multimedia Tools and Applications},
year={2019},
volume={78},
number={4},
pages={4965-4986},
doi={10.1007/s11042-018-6928-y},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057965100&doi=10.1007%2fs11042-018-6928-y&partnerID=40&md5=74bc9dcc29418d57c487449ab1127801},
affiliation={Department of Digital Media Design, Asia University, 500, Lioufeng Rd., Wufeng, Taichung, 41354, China; Department of Information Management, Hwa Hsia University of Technology, 111, Gongzhuan Rd., Zhonghe Dist, New Taipei City, 235, China; Department of Digital Content Design, Ling Tung University, 1, Ling tung Rd., Taichung, 408, China},
abstract={Mobile Augmented Reality (MAR) has becomes more widely used and provides the great context of an immersive virtual learning environment. However, sometimes the learning effect is influenced by the pleasing value, which is always subjective and learning driven. In order to ensure a successful launch of the MAR cultural interactive learning tool, it is extremely important to predict the pleasing value of design alternatives based on the common language understood by students. For learners, in the learning process, the value of pleasure comes from the improvement of external emotional interest as well as internal cognitive interest that learners already have. This research will examine if students have problems with operating the MAR, and to understand whether they have pleasing value and a learning performance. Thus, this research has proposed a difference of visual perception and a construction for the evaluation of pleasing value as well as the culture of learning performance between media students and students in other majors. The research team has chosen different cultural temples in Shi-lin and Tam-sui in Taiwan using the MAR systems to evaluate the correctness and speed of the reaction in between the two groups represented as: the experimental group and the control group. The research objects will be the second year/sophomore studentsat Taipei University of Marine Technology. There were two classes with different majors and there were 35 students in each class. This research took one of the classes as the experimental group with “MAR empirical teaching in cultural and environmental learning” and other class will be the control group using the traditional teaching method. The result from the experiment and the ANCOVA analysis indicates: (1) Based on the results of experiments, the participants appreciated the MAR approach. The learning performance of the students did improve significantly via ACNOVA. (2) The experimental group has a more significant effect compared to the control group in the aspect from the four learning performance constructions: stylistic, cultural value, cultural characterization and innovation services. (3) Through the bi-variance statistical analysis (One-Way, ANOVA), there was a significant positive correlation between pleasing value and the improvement of post-learning interest in the experimental group. This research found that based on the exploration factor from that the results the interfaces were built on a mobile phone with a touch-screen can be a model for the effectiveness examination, It can also expand the MAR application scope by incorporating it into teaching. © 2018, Springer Science+Business Media, LLC, part of Springer Nature.},
author_keywords={and Cultural learning;  Mobile augmented reality;  Mobile learning},
keywords={Augmented reality;  Computer aided instruction;  E-learning;  Human computer interaction;  Marine engineering;  Petroleum reservoir evaluation;  Students;  Touch screens, Cultural environment;  Cultural learning;  Interactive learning tools;  Mobile augmented reality;  Mobile Learning;  Positive correlations;  Traditional teachings;  Virtual learning environments, Learning systems},
correspondence_address1={Chen, Y.-S.; Department of Information Management, Hwa Hsia University of Technology, 111, Gongzhuan Rd., Zhonghe Dist, China; email: ys_chen@cc.hwh.edu.tw},
publisher={Springer New York LLC},
issn={13807501},
coden={MTAPF},
language={English},
abbrev_source_title={Multimedia Tools Appl},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Mokhtar201911,
author={Mokhtar, M.K. and Mohamed, F. and Sunar, M.S. and Arshad, M.A.M. and Mohd Sidik, M.K.},
title={Development of Mobile-Based Augmented Reality Colouring for Preschool Learning},
journal={2018 IEEE Conference on e-Learning, e-Management and e-Services, IC3e 2018},
year={2019},
pages={11-16},
doi={10.1109/IC3e.2018.8632639},
art_number={8632639},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062853321&doi=10.1109%2fIC3e.2018.8632639&partnerID=40&md5=748af2277067ba2a1fb0cb17b8cf9002},
affiliation={Media and Game Innovation Centre of Excellence, Institute of Human Centered Engineering, Universiti Teknologi Malaysia, Skudai, Malaysia; V3X Malaysia SDN. Bhd., Skudai, Malaysia},
abstract={Coloring activity with pens and paper is a natural activity and an important experience for children to practice and express their creative skills. To gain interest and attention of kids making these creative activities are the main challenge faced by teachers and parents. By developing augmented reality coloring to solve this problem require us to design a mobile application with suitable coloring book contents designed suit for kids. This work aims to provide guidelines developing interactive coloring book with augmented reality for kids that integrate with our previous technique. Wonderful Augmented Reality and Arts (wARna) is our previous fast texturing technique as the main core of the framework application that interactively play colored 2D coloring book page by visualizing it in 3D on a user's view of the real world. This work proposed a framework with suitable specification in creation of content so it reusable to create new coloring content that integrated with a mobile application and highlighting issues that need to be solved. © 2018 IEEE.},
author_keywords={Augmented Reality;  Colouring Activity;  Image-based Target;  Marked-less;  Preschool Education},
keywords={Augmented reality;  Computer software reusability;  E-learning;  Mobile computing, Coloring activity;  Creative activity;  Creative skills;  Image-based;  Marked-less;  Mobile applications;  Preschool education;  Texturing techniques, Coloring},
publisher={Institute of Electrical and Electronics Engineers Inc.},
isbn={9781538672631},
language={English},
abbrev_source_title={IEEE Conf. e-Learn., e-Manag. e-Serv., IC3e},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{NoAuthor2019,
title={2nd International Conference on Innovative Technologies and Learning, ICITL 2019},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2019},
volume={11937 LNCS},
page_count={864},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076792012&partnerID=40&md5=d6f36a05c6f85c81bf41d4d6af9aa6bf},
abstract={The proceedings contain 89 papers. The special focus in this conference is on Innovative Technologies and Learning. The topics include: Visual Attention Analysis During Program Debugging Using Virtual Reality Eye Tracker; the Effects of Collaborative Learning on Students’ English Learning Motivation and Style; the Designing of Constructivist Web-Based Learning Environment to Enhance Problem Solving Process and Transfer of Learning for Computer Education Student; Using Process Mining Techniques to Discover Student’s Activities, Navigation Paths, and Behavior in LMS Moodle; scaffolding Learning for the Novice Players of Go; an Image Recognition Practice for Using Mobile Phone During Class; building a Chinese Facial Expression Database for Automatically Detecting Academic Emotions to Support Instruction in Blended and Digital Learning Environments; obtaining Managerial Skills in Virtual Reality; Design and Development of Constructivist Augmented Reality (AR) Book Enhancing Analytical Thinking in Computer Classroom; the Influence of Interactive and Non-interactive E-Book on the Learning Effectiveness of High and Low Achievement Nursing Students; effect of Augmented Reality on Astronomical Observation Instruction; enhanced Learning of Jazz Chords with a Projector Based Piano Keyboard Augmentation; improving Programming Education Quality with Automatic Grading System; tasks for Assessing Computational Thinking Skills at Secondary School Level; the Effects of Interactive Learning Environment to Enhance the Algorithmic Thinking for Data Structure; design and Evaluation of an Interactive Teaching Platform for Guided Instruction in Programming with Real-Time Compilation; designing Framework of Constructivist Digital Learning Environment Model to Enhance Creative Thinking for Undergraduate Students; user-Centered Design of Mobile Application Model for Academic Library Services.},
editor={Ronningsbakk L., Wu T.-T., Sandnes F.E., Huang Y.-M.},
publisher={Springer},
issn={03029743},
isbn={9783030353421},
language={English},
abbrev_source_title={Lect. Notes Comput. Sci.},
document_type={Conference Review},
source={Scopus},
}

@ARTICLE{Kum-Biocca2019374,
author={Kum-Biocca, H.H. and Kim, H. and Biocca, F. and Cho, Y.},
title={AR-VIS: Augmented Reality Interactive Visualization Environment for Exploring Dynamic Scientific Data},
journal={Communications in Computer and Information Science},
year={2019},
volume={1088},
pages={374-380},
doi={10.1007/978-3-030-30712-7_47},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075835483&doi=10.1007%2f978-3-030-30712-7_47&partnerID=40&md5=f171de5bff2112808a8d2b9d50b16194},
affiliation={School of Art and Design, College of Architecture & Design, New Jersey Institute and Technology, Newark, NJ, United States; Physics Department, New Jersey Institute and Technology, Newark, NJ, United States; Department of Informatics, Ying Wu College of Computing, New Jersey Institute and Technology, Newark, NJ, United States; Teaching, Learning, and Leadership Division, The University of Pennsylvania, Philadelphia, PA, United States},
abstract={The AR Vis project is a general-purpose interactive data visualization platform for collaborative interaction with scientific data. The platform is designed for augmented reality displays of data supporting multi-user interaction and simulations. Methods developed include a procedural pipeline for data culling, modeling, visualization, and porting to multiuser augmented reality. A prototype interactive visualization application demonstrates the system via visualization and simulation of magnetic fields. The magnetic field visualizations are attached to physical objects or embedded in the environment. The invisible magnetic fields are transformed into tangible models of nano and geospatial scales magnetic phenomena accessible to a user’s full body (embodied) interaction. The project seeks to make a significant contribution to scientific visualization. Extending beyond the cognitive impact of traditional scientific visualization, the goal of the AR Vis platform is to additionally leverage human perception and spatial cognition and make data patterns tangible, manipulable and more accessible. In supporting augmented information cognition in scientists and learners, AR Vis design supports data discovery and learning. The prototype implementation uses physics data modeling of the invisible and largely intangible forces of magnetism across different scales. The project yields both a prototype platform and develops a data visualization pipeline. Both demonstrate a substantial and concrete implementation and demonstration of AR Vis techniques. © 2019, Springer Nature Switzerland AG.},
author_keywords={Augmented reality;  Interactive visualization;  Magnetic fields;  Scientific data},
keywords={Augmented reality;  Electromagnetic field effects;  Human computer interaction;  Magnetic fields;  Pipelines;  Simulation platform;  Visualization, Collaborative interaction;  Interactive visualizations;  Magnetic field visualization;  Multi-user interaction;  Prototype implementations;  Scientific data;  Visualization and simulation;  Visualization platforms, Data visualization},
correspondence_address1={Kum-Biocca, H.H.; School of Art and Design, College of Architecture & Design, New Jersey Institute and TechnologyUnited States; email: hyejin.kum-biocca@NJIT.edu},
editor={Stephanidis C., Antona M.},
publisher={Springer},
issn={18650929},
isbn={9783030307110},
language={English},
abbrev_source_title={Commun. Comput. Info. Sci.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Wallgrün2019126,
author={Wallgrün, J.O. and Chang, J.S.-K. and Zhao, J. and Sajjadi, P. and Oprean, D. and Murphy, T.B. and Baka, J. and Klippel, A.},
title={For the Many, Not the One: Designing Low-Cost Joint VR Experiences for Place-Based Learning},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2019},
volume={11883 LNCS},
pages={126-148},
doi={10.1007/978-3-030-31908-3_9},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075673696&doi=10.1007%2f978-3-030-31908-3_9&partnerID=40&md5=69692f7e617b78038e5d4c68be7606ce},
affiliation={ChoroPhronesis, Department of Geography, The Pennsylvania State University, University Park, United States; School of Information Science and Learning Technologies, University of Missouri, Columbia, United States; Penn State Marcellus Center for Outreach and Research, University Park, United States; Department of Geography, The Pennsylvania State University, University Park, United States},
abstract={The paper details the design and evaluation of a joint, multi-user immersive virtual field trip (iVFT). The setting for our work centers on academic disciplines that value place-based education. The reported user study is embedded into a developing research framework on place-based learning and the role immersive experiences play as supplement, proxy, or through providing experiences physically not possible. The results of this study are both practical as well as theoretical, demonstrating the feasibility of using entry level immersive technologies in regular classroom settings and showing that even low-cost VR experiences strongly relying on 360 ∘ imagery add value to place-based education. With quantitative analysis, we also identify potentially critical aspects in how individual differences shape the adoption of this technology. Finally, we report insights gained through two qualitative analyses on how to improve the design of future iVFTs for educational purposes. © Springer Nature Switzerland AG 2019.},
author_keywords={Place-based education;  Virtual field trip;  Virtual reality},
keywords={Augmented reality;  Virtual reality, Classroom settings;  Design and evaluations;  Immersive technologies;  Individual Differences;  Place-based;  Qualitative analysis;  Research frameworks;  Virtual field trips, Costs},
correspondence_address1={Wallgrün, J.O.; ChoroPhronesis, Department of Geography, The Pennsylvania State UniversityUnited States; email: wallgrun@psu.edu},
editor={Bourdot P., Interrante V., Nedel L., Magnenat-Thalmann N., Zachmann G.},
publisher={Springer},
issn={03029743},
isbn={9783030319076},
language={English},
abbrev_source_title={Lect. Notes Comput. Sci.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Chen2019,
author={Chen, L. and Tang, W. and John, N.W. and Wan, T.R. and Zhang, J.J.},
title={Context-Aware Mixed Reality: A Learning-Based Framework for Semantic-Level Interaction},
journal={Computer Graphics Forum},
year={2019},
doi={10.1111/cgf.13887},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075379063&doi=10.1111%2fcgf.13887&partnerID=40&md5=9f3bb2279aae31215252068a68607572},
affiliation={Creative Technology, Bournemouth University, Bournemouth, United Kingdom; Department of Computer Science, University of Chester, Chester, United Kingdom; School of Informatics, University of Bradford, Bradford, United Kingdom; National Centre for Computer Animation, Bournemouth University, Bournemouth, United Kingdom},
abstract={Mixed reality (MR) is a powerful interactive technology for new types of user experience. We present a semantic-based interactive MR framework that is beyond current geometry-based approaches, offering a step change in generating high-level context-aware interactions. Our key insight is that by building semantic understanding in MR, we can develop a system that not only greatly enhances user experience through object-specific behaviours, but also it paves the way for solving complex interaction design challenges. In this paper, our proposed framework generates semantic properties of the real-world environment through a dense scene reconstruction and deep image understanding scheme. We demonstrate our approach by developing a material-aware prototype system for context-aware physical interactions between the real and virtual objects. Quantitative and qualitative evaluation results show that the framework delivers accurate and consistent semantic information in an interactive MR environment, providing effective real-time semantic-level interactions. © 2019 The Authors. Computer Graphics Forum published by Eurographics - The European Association for Computer Graphics and John Wiley & Sons Ltd},
author_keywords={augmented reality;  interaction;  interaction techniques;  methods and applications;  methods and applications-computer games;  virtual environments},
keywords={Augmented reality;  Computer games;  Interactive computer graphics;  Semantics;  User interfaces;  Virtual reality, Context-aware interaction;  interaction;  Interaction techniques;  Interactive technology;  Physical interactions;  Qualitative evaluations;  Real world environments;  Semantic understanding, Mixed reality},
publisher={Blackwell Publishing Ltd},
issn={01677055},
coden={CGFOD},
language={English},
abbrev_source_title={Comput Graphics Forum},
document_type={Article},
source={Scopus},
}

@ARTICLE{Izquierdo2019120,
author={Izquierdo, J.L. and Alfonso, M.R. and Zambrano, M.A. and Segovia, J.G.},
title={Mobile application to encourage education in school chess students using augmented reality and m-learning. [Aplicación móvil para fortalecer el aprendizaje de ajedrez en estudiantes de escuela utilizando realidad aumentada y m-learning]},
journal={RISTI - Revista Iberica de Sistemas e Tecnologias de Informacao},
year={2019},
volume={2019},
number={E22},
pages={120-133},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075314406&partnerID=40&md5=f074d3efd1d1712f773afaf21dab7806},
affiliation={Universidad Politécnica Salesiana, Guayaquil, Ecuador},
abstract={The present study proposes an innovative educational methodology for elementary school kids that want to learn chess by using a mobile application which applies the augmented reality technique as a mechanism of reinforcement in Primary School. Interest in learning is encouraged when appropriate technological devices are involved. For this reason, digital education arouses motivation to learn, especially at an early age, when kids begin their academic training with creative initiatives using accessible applications for every subject. However, in Ecuador there are no applications created with augmented reality to strengthen and encourage the learning of chess. With this concept arrives “Jaque Maitte”, which is a mobile application, that uses a dynamic learning technique called Gamification. It achieves the learning of chess, with various methods of application for education, giving precise information about learning in an interactive way. © 2019, Associacao Iberica de Sistemas e Tecnologias de Informacao. All rights reserved.},
author_keywords={Augmented Reality;  Big Data;  Digital Education;  Interactive Systems;  M-Learning},
publisher={Associacao Iberica de Sistemas e Tecnologias de Informacao},
issn={16469895},
language={Spanish},
abbrev_source_title={Rev. Iberica Sist. Tecnol. Inf.},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Taran2019,
author={Taran, V.N.},
title={Use of elements of augmented reality in the educational process in higher educational institutions},
journal={CEUR Workshop Proceedings},
year={2019},
volume={2494},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075285278&partnerID=40&md5=da2050b1e6ba5ad40d8463800756bacb},
affiliation={V.I. Vernadsky Crimean Federal University, Simpferopol, 298600, Russian Federation},
abstract={The widespread use of various gadgets by students, schoolchildren and even children of preschool age expands the possibilities of educational technologies through the visualization and virtualization of information and processes that are explained by this information. The reality created by gadgets, sometimes absorbs the user so that they can not distinguish between the invented and realized by computer technology environment from the natural. This feature should be used in training to improve its quality and increase its effectiveness, as well as for educational purposes. Combination of real environment and digital information is possible due to technologies of augmented reality. The article provides definitions of augmented reality; its properties are considered. The following types of augmented reality used in education are highlighted: learning applications (addition of teaching visualized information); books with the use of augmented reality; object modeling (drawings in engineering, architecture, construction, etc.); process simulation; games; skills training applications, such as aircraft piloting. The problem of material memorization, which is presented in the form of a pyramid of learning (or material memorization), is considered. The possibilities of introducing augmented reality into the educational process are analyzed and its positive and negative sides are revealed during training. Mandatory and undesirable elements of learning through the use of augmented reality are identified. It is shown that the use of augmented reality in teaching allows to achieve high results when combining modern information technologies and technical innovations with classical teaching methods, while taking into account psychological and pedagogical methods and means. Copyright 2019 for this paper by its authors.},
author_keywords={Augmented reality;  Educational technologies;  Gadgets;  Information technology;  Interactive technologies;  Teaching},
keywords={Augmented reality;  Educational technology;  Engineering education;  Information technology;  Teaching;  Training aircraft, Computer technology;  Digital information;  Educational institutions;  Gadgets;  Interactive technology;  Modern information technologies;  Process simulations;  Technical innovation, E-learning},
correspondence_address1={Taran, V.N.; V.I. Vernadsky Crimean Federal UniversityRussian Federation; email: victoriya_yalta@ukr.net},
editor={Rugelj J., Lapina M.},
publisher={CEUR-WS},
issn={16130073},
language={English},
abbrev_source_title={CEUR Workshop Proc.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Huang2019,
author={Huang, W. and Xiang, H. and Li, S.},
title={The application of augmented reality and unity 3D in interaction with intangible cultural heritage},
journal={Evolutionary Intelligence},
year={2019},
doi={10.1007/s12065-019-00314-6},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074857455&doi=10.1007%2fs12065-019-00314-6&partnerID=40&md5=f60d32c48a2068bb9f35b626aa9e7211},
affiliation={Network and Information Center, Experimental Teaching Center, Guangdong University of Foreign Studies, Xiaoguwei, Panyu District, Guangzhou Higher Education Mega Center, Guangzhou, Guangdong Province  510006, China; School of Art, Guangdong University of Foreign Studies, Xiaoguwei, Panyu District, Guangzhou Higher Education Mega Center, Guangzhou, Guangdong Province  510006, China; School of English Education, Guangdong University of Foreign Studies, Xiaoguwei, Panyu District, Guangzhou Higher Education Mega Center, Guangzhou, Guangdong Province  510006, China},
abstract={The current predicament of intangible cultural heritage is its vulnerability and rarity, and an expression that is difficult to construct in the space-time dimension. It is difficult for visitors to really understand and touch these local intangible cultural heritages. For this reason, the need to develop new methodologies for cultural heritage learning and art appreciation is always present, and this is increasingly supported by digital technologies. The research in this paper is to apply the self-issuance method to the folk intangible cultural heritage center. It is different from the traditional AR method of presenting crafts directly through HMD. Instead, the use of low-cost technology, Augmented Reality technology and unity 3D technology provide a new way of interaction. By using HMD, smartphone, Leap motion and software created in UNITY 3D, the application of the augmented reality program is achieved. It allows users to interact with the intangible cultural heritage easily and fully it in a virtual physical environment. Based on the principle of human natural interaction, it can be achieved by structured light target image scanning and the design and experiment of photographic measurement. Then a local intangible cultural heritage model database can be established to provide virtual prototype files. The results of the experimental show that the data transmission is effective and the three-dimensional interaction between people and exhibits can be realized. The research results can be applied to the interactive mode practice of the intangible cultural heritage center, and provide an effective interactive mode for the intangible cultural heritage in the form of augmented reality interaction. In this way, visitors can have a deep impression on the intangible cultural heritage and the culture can be spreaded widely all over the world. © 2019, Springer-Verlag GmbH Germany, part of Springer Nature.},
author_keywords={Augmented reality;  Intangible cultural heritage;  Interaction;  Unity 3D;  Virtual reality},
keywords={Application programs;  Arts computing;  Engineering education;  Virtual reality, Augmented reality technology;  Digital technologies;  Intangible cultural heritages;  Interaction;  Natural interactions;  Photographic measurements;  Physical environments;  Three-dimensional interaction, Augmented reality},
correspondence_address1={Huang, W.; Network and Information Center, Experimental Teaching Center, Guangdong University of Foreign Studies, Xiaoguwei, Panyu District, Guangzhou Higher Education Mega Center, China; email: 172564946@qq.com},
publisher={Springer Verlag},
issn={18645909},
language={English},
abbrev_source_title={Evol. Intelligence},
document_type={Article},
source={Scopus},
}

@ARTICLE{Rusli201989,
author={Rusli, F.N. and Zulkifli, A.N. and bin Saad, M.N. and Yussop, Y.M.},
title={A study of students' motivation in using the mobile arc welding learning app},
journal={International Journal of Interactive Mobile Technologies},
year={2019},
volume={13},
number={10},
pages={89-105},
doi={10.3991/ijim.v13i10.11305},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073111841&doi=10.3991%2fijim.v13i10.11305&partnerID=40&md5=82e81f428d49c58e8620b959fa6b17e7},
affiliation={School of Multimedia Technology and Communication, Universiti Utara Malaysia, Malaysia; School of Creative Industry Management and Performing Arts, Universiti Utara Malaysia, Malaysia},
abstract={Welding is an introductory core subject that is taught in every mechanical engineering programs at all polytechnics in Malaysia. Normally students will learn the theoretical concepts of welding in the class followed by instruction-based training in the workshop. However, students have difficulty to follow everything that has been taught in the class in a limited time. Welding is dangerous for beginners and the welding environments are harmful and injurious to the health. In this paper, we introduce Mobile Arc Welding Learning (MAWL) app, a new approach for learning arc welding that incorporates mobile technology and enhanced with augmented reality (AR). The aim of this app is to enhance the contents used in arc welding learning materials used in the conventional learning by visualizing the information through the use of text, images, videos and 3D models. The MAWL app covers topics related to safety in welding, components of welding and steps in welding. The students can use the app to learn about welding on their own anytime and anywhere. The potential of using the MAWL app for welding learning among the polytechnic students has been investigated, specifically focusing on ease of use, learn ability, satisfaction, usefulness, motivation and engagement. The results of the evaluation indicate that the users strongly agreed on ease of use, learn ability, satisfaction, usefulness and motivation, while they agreed on engagement. These prove that the MAWL app has the potential to contribute to students' welding learning through interactive and accessible information that satisfies them. © 2019 International Association of Online Engineering.},
author_keywords={Arc Welding Learning;  Augmented Reality;  Mobile Learning;  TVET;  User Evaluation},
correspondence_address1={Rusli, F.N.; School of Multimedia Technology and Communication, Universiti Utara MalaysiaMalaysia; email: najwarusli.18@gmail.com},
publisher={International Association of Online Engineering},
issn={18657923},
language={English},
abbrev_source_title={Int. J. Interact. Mob. Technol.},
document_type={Article},
source={Scopus},
}

@ARTICLE{NoAuthor2019,
title={17th IFIP TC13 International Conference on Human-Computer Interaction, INTERACT 2019},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2019},
volume={11749 LNCS},
page_count={3130},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072987989&partnerID=40&md5=835c1c32c1724963ad810a01ab97c655},
abstract={The proceedings contain 213 papers. The special focus in this conference is on Human-Computer Interaction. The topics include: Experiencing Materialized Reading: Individuals’ Encounters with Books; “I Kept Browsing and Browsing, But Still Couldn’t Find the One”: Salient Factors and Challenges in Online Typeface Selection; integrating a Binaural Beat into the Soundscape for the Alleviation of Feelings; what Is Beautiful Continues to Be Good: People Images and Algorithmic Inferences on Physical Attractiveness; design and Evaluation of Three Interaction Models for Manipulating Internet of Things (IoT) Devices in Virtual Reality; head Mounted Display Interaction Evaluation: Manipulating Virtual Objects in Augmented Reality; on the Use of Persistent Spatial Points for Deploying Path Navigation in Augmented Reality: An Evaluation Study; User Experience Guidelines for Designing HMD Extended Reality Applications; am I Moving Along a Curve? A Study on Bicycle Traveling-In-Place Techniques in Virtual Environments; analysis of Utilization in the Message Card Production by Use of Fusion Character of Handwriting and Typeface; design and Evaluation of an Augmented Reality App for Learning Geometric Shapes in 3D; Enhance Engine Room Diagnostics Through Audio-Focused VR Simulation; Head-Controlled Menu in Mixed Reality with a HMD; VR Interaction Modalities for the Evaluation of Technical Device Prototypes; combining Tablets with Smartphones for Data Analytics; COMMONS: A Board Game for Enhancing Interdisciplinary Collaboration When Developing Health and Activity-Related Wearable Devices; on-Body Tangible Interaction: Using the Body to Support Tangible Manipulations for Immersive Environments; splitSlider: A Tangible Interface to Input Uncertainty; introduction to Automation and to Its Potential for Interactive Systems Design.},
editor={Lamas D., Loizides F., Nacke L., Petrie H., Winckler M., Zaphiris P.},
publisher={Springer Verlag},
issn={03029743},
isbn={9783030293895},
language={English},
abbrev_source_title={Lect. Notes Comput. Sci.},
document_type={Conference Review},
source={Scopus},
}

@ARTICLE{Kim2019243,
author={Kim, S.J.S. and Sanchez, A. and Hanifzai, J.F. and Palispis, F. and Nishimura, K.},
title={The OTC (Object to Camera) Approach to Visualize Behind Stories of Museum Exhibits},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2019},
volume={11786 LNCS},
pages={243-252},
doi={10.1007/978-3-030-30033-3_19},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072872845&doi=10.1007%2f978-3-030-30033-3_19&partnerID=40&md5=c9fbeee71b6c5ff7d932843ce976a5e2},
affiliation={University of Nevada Las Vegas (UNLV), Las Vegas, NV  89052, United States},
abstract={Augmented Reality (AR) is a growing field, with great potential purposes in many different environments including public museums and galleries. This paper introduces the use of AR in a public museum that is designed to bridge museum visitors, especially preschoolers to art pieces installed in a public museum. In collaboration with the UNLV Marjorie Barrick Museum, we created an Augmented Reality experience called the OTC (Object To Camera) to showcase one’s artwork through an augmented medium that shows the behind scenes of the art pieces. The experience was intended to have a more physical approach, to distinguish itself from other augmented reality experiences the user may have come into contact with. An observation was conducted as a field study with preschoolers at a community event held at the UNLV Marjorie Barrick Museum and showed that interactive AR has potential applications in the museum to enhance the learning process. © 2019, Springer Nature Switzerland AG.},
author_keywords={AR;  Art;  Augmented reality;  Cube;  Digital experience;  Museum;  STEAM;  STEM;  Vuforia},
keywords={Argon;  Arts computing;  Augmented reality;  Bridges;  Cameras;  Exhibitions;  Human computer interaction;  Steam;  STEM (science, technology, engineering and mathematics), Cube;  Digital experience;  Interactive ar;  Learning process;  Museum exhibits;  Museums and galleries;  Physical approaches;  Vuforia, Museums},
correspondence_address1={Kim, S.J.S.; University of Nevada Las Vegas (UNLV)United States; email: sj.kim@unlv.edu},
editor={Stephanidis C.},
publisher={Springer Verlag},
issn={03029743},
isbn={9783030300326},
language={English},
abbrev_source_title={Lect. Notes Comput. Sci.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{NoAuthor2019,
title={21st International Conference on Human-Computer Interaction, HCII 2019},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2019},
volume={11786 LNCS},
page_count={610},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072856201&partnerID=40&md5=228146b18bb62cb0834d87be112371ba},
abstract={The proceedings contain 46 papers. The special focus in this conference is on Human-Computer Interaction. The topics include: Evaluating System Sufficiency in a Multimodal, Multiuser Sensemaking Environment Designed for Intelligence Analysis; CiSA: An Inclusive Chatbot Service for International Students and Academics; some Mathematical and Practical Aspects of Decision-Making Based on Similarity; explorative Visualization of Food Data to Raise Awareness of Nutritional Value; a New Paradigm of Addressing the Complexity of Entrepreneurial Community Design Leveraging Augmented Reality; sentiment Analysis Through Machine Learning for the Support on Decision-Making in Job Interviews; stereohaptics Toolkit for Dynamic Tactile Experiences; a Review of Augmented Reality-Based Human-Computer Interaction Applications of Gesture-Based Interaction; The OTC (Object to Camera) Approach to Visualize Behind Stories of Museum Exhibits; accessibility Studies: Abuses, Misuses and the Method of Poietic Design; through the Realities of Augmented Reality; development of a Puzzle Game to Learn Coding for Elementary Students; which Virtual Piano Keyboard for Children with Autism? A Pilot Study; shadowHunter: Facilitating Children’s Outdoor Exploration with Shadows; an Innovative Employment of Virtual Humans to Explore the Chess Personalities of Garry Kasparov and Other Class-A Players; the Relationship Between Game Elements and Player Emotions by Comparing Game Frameworks; research on Multimedia Teaching in Universities Under Human-Computer Interaction Environment; employing a Voice-Based Emotion-Recognition Function in a Social Chatbot to Foster Social and Emotional Learning Among Preschoolers; recommender Systems for an Enhanced Mobile e-Learning; Using CFD Technology to Simulate a Model of Human Thermoregulation in the Stable Temperature Environment; modeling Drone Crossing Movement with Fitts’ Law.},
editor={Stephanidis C.},
publisher={Springer Verlag},
issn={03029743},
isbn={9783030300326},
language={English},
abbrev_source_title={Lect. Notes Comput. Sci.},
document_type={Conference Review},
source={Scopus},
}

@ARTICLE{Cen2019,
author={Cen, L. and Ruta, D. and Mahmoud Mohd Said Al Qassem, L. and Ng, J.},
title={Augmented Immersive Reality (AIR) for Improved Learning Performance: A Quantitative Evaluation},
journal={IEEE Transactions on Learning Technologies},
year={2019},
doi={10.1109/TLT.2019.2937525},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071536186&doi=10.1109%2fTLT.2019.2937525&partnerID=40&md5=3080c63161b59bbf3e10f094e40950bb},
affiliation={Etisalat British Telecom Innovation Centre, Khalifa University of Science, Technology And Research, Abu Dhabi, Abu Dhabi United Arab Emirates (e-mail: cen.ling@ku.ac.ae); Etisalat British Telecom Innovation Centre, Khalifa University of Science Technology, 105955 Abu Dhabi, Abu Dhabi United Arab Emirates (e-mail: dymitr.ruta@ku.ac.ae); Etisalat British Telecom Innovation Centre, Khalifa University of Science, Technology And Research, Abu Dhabi, Abu Dhabi United Arab Emirates (e-mail: 100037108@kustar.ac.ae); Etisalat British Telecom Innovation Centre, Khalifa University of Science, Technology And Research, Abu Dhabi, Abu Dhabi United Arab Emirates (e-mail: jason.ng@kustar.ac.ae)},
abstract={Technology-enhanced learning has attracted increasing attention of educational community focused on improvement of traditional classroom learning. Augmented immersive reality (AIR) technologies enhance users' perception of reality by augmenting it with computer-generated components such as audio, video, 2/3-D graphics, GPS data, etc. The AIR introduces new dimensions of learning experience that ensure better attention, focus and entertainment, thereby boosting students' motivation and attainment. This work presents an award winning AIR-based educational mobile system, code-named AIR-EDUTECH, that was developed to help high school students learn chemistry. The AIR-EDUTECH introduced new AIR features to help students better understand and learn basic concepts of molecular chemistry. It offers immersive 3D visualization and visual interaction with the examined structures that provides a broader and more retentive knowledge and improves intuition around forming basic chemical reactions. The system was introduced and tested in a field study with 45 students in the 11th grade chemistry class, and its impact was evaluated by the formal assessment quiz along with the feedback from survey conducted after the trial. Collected data have been subjected to an in-depth multi-modal quantitative analysis that revealed that AIR-EDUTECH stimulated significant improvements in understanding and retention of the taught content as well as turned learning chemistry into a fun, interesting and interactive experience. It also uncovered a hidden structure of taught knowledge dependencies and highlighted the role that AIR technology could play in reinforcing the retention of critical knowledge that may otherwise widen student knowledge gaps. IEEE},
author_keywords={AIR-EDUTECH;  Augmented Immersive Reality (AIR);  Augmented Reality (AR);  education data mining;  Mobile learning},
keywords={Augmented reality;  Chemical analysis;  Data mining;  Three dimensional computer graphics, Educational community;  High school students;  Immersive;  Learning experiences;  Learning performance;  Mobile Learning;  Quantitative evaluation;  Technology enhanced learning, Students},
publisher={Institute of Electrical and Electronics Engineers},
issn={19391382},
language={English},
abbrev_source_title={IEEE Trans. Learn. Technol.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Yugcha2019393,
author={Yugcha, E.P. and Ubilluz, J.I. and Andaluz, V.H.},
title={Virtual Training for Industrial Process: Pumping System},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2019},
volume={11614 LNCS},
pages={393-409},
doi={10.1007/978-3-030-25999-0_33},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070826232&doi=10.1007%2f978-3-030-25999-0_33&partnerID=40&md5=8c371c0105bda6dbe31787102eb9f772},
affiliation={Universidad de las Fuerzas Armadas ESPE, Sangolquí, Ecuador},
abstract={The article presents a virtual environment of a pumping system oriented to training of users that interact with industrial processes. The application of it was performed in a graphic engine Unity 3D, where shows two training environments: (i) Electro pumps laboratory, simulates control operations of control for manipulating many configurations from centrifugal pumps in individual, serie or parallel in order to visualize by an HMI the physical parameters such as: pressure, flow and temperature; (ii) Industrial environment the user prepares in a complementary way how to know industrial processes in a practical and realistic way. In order for making the virtual application immersive and interactive, the modeling of the electrical characteristics of the pumping system was carried out. © 2019, Springer Nature Switzerland AG.},
author_keywords={Immersive and interactive;  Pumped system;  Unity 3D;  Virtual environment},
keywords={E-learning;  Pumping plants;  Pumps;  Virtual reality, Control operations;  Electrical characteristic;  Immersive;  Industrial environments;  Industrial processs;  Physical parameters;  Pumped systems;  Virtual application, Augmented reality},
correspondence_address1={Yugcha, E.P.; Universidad de las Fuerzas Armadas ESPEEcuador; email: epyugcha@espe.edu.ec},
editor={De Paolis L.T., Bourdot P.},
publisher={Springer Verlag},
issn={03029743},
isbn={9783030259983},
language={English},
abbrev_source_title={Lect. Notes Comput. Sci.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Frontoni2019319,
author={Frontoni, E. and Paolanti, M. and Puggioni, M. and Pierdicca, R. and Sasso, M.},
title={Measuring and Assessing Augmented Reality Potential for Educational Purposes: SmartMarca Project},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2019},
volume={11614 LNCS},
pages={319-334},
doi={10.1007/978-3-030-25999-0_28},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070822865&doi=10.1007%2f978-3-030-25999-0_28&partnerID=40&md5=687bba3b17643480066731f6815d71c8},
affiliation={Department of Information Engineering, Universitá Politecnica delle Marche, Via Brecce Bianche 12, Ancona, 60131, Italy; Dipartimento di Ingegneria Civile, Edile e dell’Architettura, Universitá Politecnica delle Marche, Ancona, 60100, Italy; UBISIVE s.r.l., Via Dell’Universitá 13, Fermo, FM  63900, Italy},
abstract={Augmented and Virtual reality proved to be valuable solutions to convey contents in a more appealing and interactive way. Their use is nearly embracing several domains like medicine, geospatial applications, industry, tourism and so on. But among the others, the one that might benefit the most by their use is the Cultural Heritage. In fact, given the improvement of mobile and smart devices in terms of both usability and computational power, contents can be easily conveyed with a realism level never reached in the past. However, despite the tremendous number of researches related with the presentation of new fascinating applications of ancient goods and artifacts augmentation, few papers are focusing on the real effect that these tools have on learning. In fact, whether a disposable use of such tools seems to have a great benefit in terms of visual impact for the users, the same cannot be said about the long-term effect they have on the users, especially for education purposes. Within the framework of SmartMarca project, that will be briefly explained in these pages, this paper focuses on assessing the potential of AR applications specifically designed for Cultural Heritage. More specifically, tests have been conducted on an Augmented Reality experience upon different paintings. For evaluating the benefits of such technology in terms of learning, we have performed our experiment on classrooms of teenagers. By testing different learning approaches, we were able to evaluate and assess the effectiveness of using these technologies for the education process. The paper will even argue on the necessity of developing new tools to enable users to become producers of contents of AR/VR experiences, since up to now there no exists a platform specifically designed for an agile creation, even for not skilled programmers. © 2019, Springer Nature Switzerland AG.},
keywords={Virtual reality, Augmented and virtual realities;  Computational power;  Cultural heritages;  Education process;  Geospatial applications;  Interactive way;  Learning approach;  Long-term effects, Augmented reality},
correspondence_address1={Frontoni, E.; Department of Information Engineering, Universitá Politecnica delle Marche, Via Brecce Bianche 12, Italy; email: e.frontoni@staff.univpm.it},
editor={De Paolis L.T., Bourdot P.},
publisher={Springer Verlag},
issn={03029743},
isbn={9783030259983},
language={English},
abbrev_source_title={Lect. Notes Comput. Sci.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Pellas2019489,
author={Pellas, N. and Kazanidis, I.},
title={Developing and assessing augmented reality applications for mathematics with trainee instructional media designers: An exploratory study on user experience},
journal={Journal of Universal Computer Science},
year={2019},
volume={25},
number={5},
pages={489-514},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070675748&partnerID=40&md5=9012759d334a36c4971867424b8c3f61},
affiliation={University of the Aegean, Syros, Greece; Advanced Educational Technologies & Mobile Applications Lab, Eastern Macedonia and Thrace Institute of Technology, Kavala, Greece},
abstract={Various interactive and innovative applications generated by Augmented Reality (AR) technology have given great potentials in different learning subjects and specifically in STEM (science, technology, engineering, and mathematics) education. Nevertheless, previous studies regarding AR integration inside classrooms have shown that as a valuable technology for students’ motivation and participation alone cannot automatically lead to its successful use. This study focuses on teaching and learning mathematics by taking advantage of AR technology to visualize several problems and let users interact with its contents. In this perspective, the purpose of this study is to present an instructional approach by which competencies of seventy-eight (n=78) trainee instructional media designers with a successful and appropriate integration of AR technology inside classroom contexts using HP Reveal and Blippar. In favor of designing and assessing AR applications for mathematics, the instructional media designers have shown satisfactory performance and user experience. Specifically, all AR applications seemed that enable the representation of intuitive learning scenarios and increased greatly users’ interactive experience, thus encouraging their achievements and outcomes. This study contributes to the most relevant practices of teaching and learning for mathematics with the integration of AR applications which are developed by trainee instructional media designers to support successfully the educational process with several examples to be visualized by merging physical (“target tracking”) with digital features and objects. © J.UCS.},
author_keywords={Augmented reality;  Instructional design;  User expectations;  User experience;  User experience assessment},
publisher={IICM},
issn={0948695X},
language={English},
abbrev_source_title={J. Univers. Comput. Sci.},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Aggarwal2019510,
author={Aggarwal, R. and Singhal, A.},
title={Augmented Reality and its effect on our life},
journal={Proceedings of the 9th International Conference On Cloud Computing, Data Science and Engineering, Confluence 2019},
year={2019},
pages={510-515},
doi={10.1109/CONFLUENCE.2019.8776989},
art_number={8776989},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070643925&doi=10.1109%2fCONFLUENCE.2019.8776989&partnerID=40&md5=5e568d53f98f86abc9bbafa8383638e5},
affiliation={ASET, Amity University Uttar Pradesh, Noida, India},
abstract={Augmented Reality is a combination of a real and a computer-generated or virtual world. It is achieved by augmenting computer-generated images on real world. It is of four types namely marker based, marker less, projection based and superimposition based augmented reality. It has many applications in the real world. AR is used in various fields such as medical, education, manufacturing, robotics and entertainment. Augmented reality comes under the field of mixed reality. It can be considered as an inverse reflection of Virtual Reality. They both have certain similarities and differences. This paper gives information about Augmented Reality and how it started. It analyses various types of augmented reality, its applications and its advantages and disadvantages. This paper also gives us knowledge regarding those major threats that augmented reality will face in the near future and about its current and future applications. It gives us a comparison between the two related topics, Augmented reality and Virtual reality. The following paper also helps us know about the effect of Augmented Reality on the human life. © 2019 IEEE.},
author_keywords={Augmented Reality;  Mixed Reality;  Real World;  Virtual reality;  Virtual World},
keywords={Augmented reality;  Cloud computing;  Interactive computer graphics;  Virtual reality, Computer generated;  Computer-generated images;  Future applications;  Human lives;  ITS applications;  Real-world;  Virtual worlds, Mixed reality},
publisher={Institute of Electrical and Electronics Engineers Inc.},
isbn={9781538659335},
language={English},
abbrev_source_title={Proc. Int. Conf. Cloud Comput., Data Sci. Eng., Confluence},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Afrianto2019334,
author={Afrianto, I. and Faris, A.F. and Atin, S.},
title={Hijaiyah letter interactive learning for mild mental retardation children using Gillingham method and augmented reality},
journal={International Journal of Advanced Computer Science and Applications},
year={2019},
volume={10},
number={6},
pages={334-341},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070515925&partnerID=40&md5=994be70bffc675849a1eb86791e17e4e},
affiliation={Departement of Informatics Engineering, Universitas Komputer Indonesia, Bandung, Indonesia},
abstract={Assistive technology for children with special needs is a problem that is interesting to study. Collaboration between methods and latest technology can be used as a learning aid for them. Learning of Hijaiyah letters is the first step to being able to read the Holy Qur'an. Mentally retarded children have IQs below the average normal child, so their learning process is slower and requires special methods. This study aims to develop an application by using the Gillingham and augmented reality methods to help mentally retarded children recognize Hijaiyah letters. The Gillingham method uses a visual, auditory, kinestetic, and tactile (VAKT) approach, that can be used to facilitate mentally retarded children. While augmented reality is used to develop more interesting and interactive applications. Based on the results of research and testing, it can be concluded that the learning application that was built can improve children's memory and understanding of Hijaiyah letters, The results of the pretest and posttest testing, showed an increase of 12% for children who were difficult to receive learning material and 6% for children who are classified as easy to receive learning material. © 2019 International Journal of Advanced Computer Science and Applications.},
author_keywords={Augmented reality;  Gillingham;  Hijaiyah;  Intercative learning;  Mild retarded child;  VAKT},
publisher={Science and Information Organization},
issn={2158107X},
language={English},
abbrev_source_title={Intl. J. Adv. Comput. Sci. Appl.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Liu201991,
author={Liu, C. and Chen, X. and Liu, S. and Zhang, X. and Ding, S. and Long, Y. and Zhou, D.},
title={The exploration on interacting teaching mode of augmented reality based on hololens},
journal={Communications in Computer and Information Science},
year={2019},
volume={1048},
pages={91-102},
doi={10.1007/978-981-13-9895-7_9},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069840593&doi=10.1007%2f978-981-13-9895-7_9&partnerID=40&md5=241626994209c36d2ee2a44e06c52811},
affiliation={National Engineering Research Center for E-Learning, Central China Normal University, 152 Luoyu Road, Wuhan, 430079, China; National Engineering Laboratory for Educational Big Data, Central China Normal University, 152 Luoyu Road, Wuhan, 430079, China},
abstract={In recent years, the applications of augmented reality and the visualization of mixed reality for education are popular. However the lacking of multi-modal interaction for teaching and learning results in the teaching mode staying at the teacher-centered knowledge-feeding pattern, and the ability of the AR technology underutilized. This paper proposes an interactive teaching mode of augmented reality based on HoloLens, taking full advantage of the device which combines 3D scenes, audio, video and teaching content. Applying gesture, voice, holographic interaction and viewpoint tracking technology to practical teaching, this paper demonstrates a new student-centered teaching mode which includes the dynamic classroom teaching, multi-modal interactive practicing and the multi-form feedback learning. This paper carries out an empirical research in senior one students. The results indicate that the interest and initiative of students in learning are increased, the ability of understanding abstract knowledge is significantly improved, and the academic performance of students is promoted. This paper is devoted to promoting the deep integration of augmented reality and teaching, the innovation in teaching process and method has been explored positively. © Springer Nature Singapore Pte Ltd. 2019.},
author_keywords={Augmented reality HoloLens;  Interactive learning;  Learning environment;  Mobile learning;  Nonlinear interactive teaching mode},
keywords={Augmented reality;  Computer aided instruction;  Educational technology;  Mixed reality, Academic performance;  Interactive learning;  Learning environments;  Mobile Learning;  Multi-Modal Interactions;  Student-centered teaching;  Teaching and learning;  Teaching modes, Students},
correspondence_address1={Zhou, D.; National Engineering Research Center for E-Learning, Central China Normal University, 152 Luoyu Road, China; email: zhoudongbo@mail.ccnu.edu.cn},
editor={Cheung S.K.S., Li K.C., Lee L.-K., Jiao J., Zhang X., Zhan Z.},
publisher={Springer Verlag},
issn={18650929},
isbn={9789811398940},
language={English},
abbrev_source_title={Commun. Comput. Info. Sci.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{NoAuthor2019,
title={11th International Conference on Virtual, Augmented and Mixed Reality, VAMR 2019, held as part of the 21st International Conference on Human-Computer Interaction, HCI International 2019},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2019},
volume={11575 LNCS},
page_count={1081},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069751224&partnerID=40&md5=c502fed6a02b86d82dec05697184c9f8},
abstract={The proceedings contain 78 papers. The special focus in this conference is on Virtual, Augmented and Mixed Reality. The topics include: Investigating the Potential Effectiveness of Allocentric Mixed Reality Deictic Gesture; autonomous Agent Teammate-Likeness: Scale Development and Validation; augmented Reality in Education: A Study on Preschool Children, Parents, and Teachers in Bangladesh; Physically Extended Virtual Reality (PEVR) as a New Concept in Railway Driver Training; Developing a VR Training Program for Geriatric Patients with Chronic Back Pain: A Process Analysis; a Multi-procedural Virtual Reality Simulator for Orthopaedic Training; exploring Extended Reality as a Simulation Training Tool Through Naturalistic Interactions and Enhanced Immersion; a Study on the Development of a Mixed Reality System Applied to the Practice of Socially Interactive Behaviors of Children with Autism Spectrum Disorder; visualizations for Communicating Intelligent Agent Generated Courses of Action; Cicero VR - Public Speaking Training Tool and an Attempt to Create Positive Social VR Experience; Virtual Dome System Using HMDs: An Alternative to the Expensive and Less Accessible Physical Domes; GVRf and Blender: A Path for Android Apps and Games Development; designing Educational Virtual Environments for Construction Safety: A Case Study in Contextualizing Incident Reports and Engaging Learners; Augmented Reality (AR) Assisted Laryngoscopy for Endotracheal Intubation Training; TurtleGO: Application with Cubes for Children’s Spatial Ability Based on AR Technology; lumaPath: An Immersive Virtual Reality Game for Encouraging Physical Activity for Senior Arthritis Patients; A New Practice Method Based on KNN Model to Improve User Experience for an AR Piano Learning System; foreword.},
editor={Chen J.Y.C., Fragomeni G.},
publisher={Springer Verlag},
issn={03029743},
isbn={9783030215644},
language={English},
abbrev_source_title={Lect. Notes Comput. Sci.},
document_type={Conference Review},
source={Scopus},
}

@ARTICLE{Cook2019359,
author={Cook, M. and Payne, A. and Seo, J.H. and Pine, M. and McLaughlin, T.},
title={InNervate AR: Dynamic Interaction System for Motor Nerve Anatomy Education in Augmented Reality},
journal={Communications in Computer and Information Science},
year={2019},
volume={1033},
pages={359-365},
doi={10.1007/978-3-030-23528-4_49},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069730896&doi=10.1007%2f978-3-030-23528-4_49&partnerID=40&md5=3d37b2b14e2752c2d9261dc79701b18a},
affiliation={Texas A&M University, College Station, TX  77840, United States},
abstract={Augmented reality applications for anatomy education have seen a large growth in its literature presence for 3D model education technology. However, the majority of these new anatomy applications limit their educational scope to the labelling of anatomical structures and layers, and simple identification interactions. There is a strong need for expansion of augmented reality applications, in order to give the user more interactive control of the anatomy education material. To meet this need, the mobile augmented reality application, InNervate AR, was created. This application allows the user to scan a marker for two distinct learning modules; one for labelling and identification of anatomy structures, the other one for interacting with the radial nerve of the canine forelimb. The first module matches other existing anatomy augmented reality structures. The second module is unique, because it allows the user to play an animation of the anatomy models, to show what the normal range of motion for the muscles of the limb is, based on the motor innervation of radial nerve. Next, the user can select where to make a cut along the length of the radial nerve, to cause a nerve deficit to one or more of the muscles of the limb. Based on this user input, the application will then play a new animation of the changed range of motion of the canine thoracic limb. A formal user study was run with this new application, which including pre- and post- knowledge assessments. Our initial data analysis showed that qualitative students’ responses and quantitative data were significantly positive. This implies that the application may prove to be educationally effective. We are going to expand the scope of the application based on the analyses of user data and feedback, and develop educational modules for all of the motor nerves of the canine forelimb. © Springer Nature Switzerland AG 2019.},
author_keywords={Anatomy;  Augmented reality;  Educational technology},
keywords={3D modeling;  Animation;  Augmented reality;  Education computing;  Educational technology;  Human computer interaction;  Muscle, Anatomical structures;  Anatomy;  Augmented reality applications;  Dynamic interaction system;  Education technology;  Interactive control;  Knowledge assessment;  Mobile augmented reality, Three dimensional computer graphics},
correspondence_address1={Cook, M.; Texas A&M UniversityUnited States; email: atmgirl@tamu.edu},
editor={Stephanidis C.},
publisher={Springer Verlag},
issn={18650929},
isbn={9783030235277},
language={English},
abbrev_source_title={Commun. Comput. Info. Sci.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{NoAuthor2019,
title={21st International Conference on Human-Computer Interaction, HCI International 2019},
journal={Communications in Computer and Information Science},
year={2019},
volume={1033},
page_count={1560},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069729608&partnerID=40&md5=e1a9861928d9585877e250cea8db233b},
abstract={The proceedings contain 207 papers. The special focus in this conference is on Human-Computer Interaction. The topics include: Research on Evaluation Model of Social Game Advertising Effect Based on Eye Movement Experiment; towards a Narrative Driven Understanding of Games User Experience; Application of Archery to VR Interface; what Drives Female Players’ Continuance Intention to Play Mobile Games? The Role of Aesthetic and Narrative Design Factors; simultaneous Dialog Robot System; a Robot System Using Mixed Reality to Encourage Driving Review; self-learning Guide for Bioloid Humanoid Robot Assembly with Elements of Augmented Reality to Support Experiential Learning in Sauro Research Seeding; developing a Behavior Converter to Make a Robot Child-Like for Enhancing Human Utterances; can We Recognize Atmosphere as an Agent?: Pilot Study; design Strategies of Corporate Gamification Systems that Evokes Employee Motivation – Creative Process of Gathering Game Design Elements into Working System; GEC-HR: Gamification Exercise Companion for Home Robot with IoT; discussion on the Feasibility of Soft Actuator as an Assistive Tool for Seniors in Minimally Invasive Surgery; Recognition of Listener’s Nodding by LSTM Based on Movement of Facial Keypoints and Speech Intonation; AI-Based Technical Approach for Designing Mobile Decision Aids; human Learning in Data Science; How to Achieve Explainability and Transparency in Human AI Interaction; Data on RAILs: On Interactive Generation of Artificial Linear Correlated Data; adaptation of Machine Learning Frameworks for Use in a Management Environment: Development of a Generic Workflow; software to Support Layout and Data Collection for Machine-Learning-Based Real-World Sensors; phenomenology of Experience in Ambient Intelligence.},
editor={Stephanidis C.},
publisher={Springer Verlag},
issn={18650929},
isbn={9783030235277},
language={English},
abbrev_source_title={Commun. Comput. Info. Sci.},
document_type={Conference Review},
source={Scopus},
}

@ARTICLE{NoAuthor2019,
title={11th International Conference on Virtual, Augmented and Mixed Reality, VAMR 2019, held as part of the 21st International Conference on Human-Computer Interaction, HCI International 2019},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2019},
volume={11574 LNCS},
page_count={1081},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069702468&partnerID=40&md5=fd2f0d29a32e802f7968f21359433a4f},
abstract={The proceedings contain 78 papers. The special focus in this conference is on Virtual, Augmented and Mixed Reality. The topics include: Investigating the Potential Effectiveness of Allocentric Mixed Reality Deictic Gesture; autonomous Agent Teammate-Likeness: Scale Development and Validation; augmented Reality in Education: A Study on Preschool Children, Parents, and Teachers in Bangladesh; Physically Extended Virtual Reality (PEVR) as a New Concept in Railway Driver Training; Developing a VR Training Program for Geriatric Patients with Chronic Back Pain: A Process Analysis; a Multi-procedural Virtual Reality Simulator for Orthopaedic Training; exploring Extended Reality as a Simulation Training Tool Through Naturalistic Interactions and Enhanced Immersion; a Study on the Development of a Mixed Reality System Applied to the Practice of Socially Interactive Behaviors of Children with Autism Spectrum Disorder; visualizations for Communicating Intelligent Agent Generated Courses of Action; Cicero VR - Public Speaking Training Tool and an Attempt to Create Positive Social VR Experience; Virtual Dome System Using HMDs: An Alternative to the Expensive and Less Accessible Physical Domes; GVRf and Blender: A Path for Android Apps and Games Development; designing Educational Virtual Environments for Construction Safety: A Case Study in Contextualizing Incident Reports and Engaging Learners; Augmented Reality (AR) Assisted Laryngoscopy for Endotracheal Intubation Training; TurtleGO: Application with Cubes for Children’s Spatial Ability Based on AR Technology; lumaPath: An Immersive Virtual Reality Game for Encouraging Physical Activity for Senior Arthritis Patients; A New Practice Method Based on KNN Model to Improve User Experience for an AR Piano Learning System; foreword.},
editor={Fragomeni G., Chen J.Y.C.},
publisher={Springer Verlag},
issn={03029743},
isbn={9783030216061},
language={English},
abbrev_source_title={Lect. Notes Comput. Sci.},
document_type={Conference Review},
source={Scopus},
}

@ARTICLE{NoAuthor2019,
title={13th International Conference on Universal Access in Human-Computer Interaction, UAHCI 2019, held as part of the 21st International Conference on Human-Computer Interaction, HCI International 2019},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2019},
volume={11573 LNCS},
page_count={1285},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069689573&partnerID=40&md5=aafb62885b42bf8b3619673b58ff1c4a},
abstract={The proceedings contain 95 papers. The special focus in this conference is on Universal Access in Human-Computer Interaction. The topics include: Design of an Intelligent and Immersive System to Facilitate the Social Interaction Between Caregivers and Young Children with Autism; taking Neuropsychological Test to the Next Level: Commercial Virtual Reality Video Games for the Assessment of Executive Functions; evaluation of Handwriting Skills in Children with Learning Difficulties; “Express Your Feelings”: An Interactive Application for Autistic Patients; The Design of an Intelligent LEGO Tutoring System for Improving Social Communication Skills Among Children with Autism Spectrum Disorder; an Augmented Reality-Based Word-Learning Mobile Application for Children with Autism to Support Learning Anywhere and Anytime: Object Recognition Based on Deep Learning; design and Evaluation of Mobile Applications for Augmentative and Alternative Communication in Minimally-verbal Learners with Severe Autism; principles for Evaluating Usability in Multimodal Games for People Who Are Blind; a Low Resolution Haptic Interface forÂ Interactive Applications; usability Enhancement and Functional Extension of a Digital Tool for Rapid Assessment of Risk for Autism Spectrum Disorders in Toddlers Based on Pilot Test and Interview Data; a Fitts’ Law Evaluation of Hands-Free and Hands-On Input on a Laptop Computer; a Time-Discrete Haptic Feedback System for Use by Persons with Lower-Limb Prostheses During Gait; quali-Quantitative Review of the Use of Multimodal Interfaces for Cognitive Enhancement in People Who Are Blind; Statistical Analysis of Novel and Traditional Orientation Estimates from an IMU-Instrumented Glove; modeling Human Eye Movement Using Adaptive Neuro-Fuzzy Inference Systems; creating Weather Narratives.},
editor={Antona M., Stephanidis C.},
publisher={Springer Verlag},
issn={03029743},
isbn={9783030235628},
language={English},
abbrev_source_title={Lect. Notes Comput. Sci.},
document_type={Conference Review},
source={Scopus},
}

@ARTICLE{Song2019372,
author={Song, Y. and Kim, J. and Cho, H.},
title={TurtleGO: Application with Cubes for Children’s Spatial Ability Based on AR Technology},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2019},
volume={11575 LNCS},
pages={372-383},
doi={10.1007/978-3-030-21565-1_25},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069657909&doi=10.1007%2f978-3-030-21565-1_25&partnerID=40&md5=f3965b3106f1679bd4481517cc989957},
affiliation={Department of Mathematics Education, Seoul National University, Seoul, South Korea; Graduate School of Culture Technology, KAIST, Daejeon, South Korea},
abstract={In this paper, we introduce a new application called TurtleGO that uses augmented reality (AR) technology, with which K-2 children can experience a geometric sense of the egocentric perspective. This application was developed with the concept of Logo-MicroWorlds, which allows children to examine and simulate their geometric ideas in a virtual world with a turtle agent. TurtleGO provides children with real-time feedback in a monitor representing the augmented turtle image on blocks based on AR technology while children are playing with actual blocks. Our application is flexible and inexpensive as it makes possible the use of various sized cubes already in possession. All the children between grades 2 through 5 improved in their ability to distinguish pair of stimuli as identical or mirror images when they used TurtleGO. However, we found that our application provides an effective and intuitive AR learning environment to lower grade elementary students, improving their spatial transformation skills since upper graders could solve the tasks easily without it. © 2019, Springer Nature Switzerland AG.},
author_keywords={Augmented reality (AR);  Body syntonic;  Egocentric perspective;  Spatial ability;  Spatial transformation;  Tangible interaction},
keywords={Augmented reality;  Computer aided instruction;  Human computer interaction;  Image enhancement;  Interactive computer graphics;  Students, Body syntonic;  Egocentric perspective;  Spatial abilities;  Spatial transformation;  Tangible interaction, Mixed reality},
correspondence_address1={Cho, H.; Department of Mathematics Education, Seoul National UniversitySouth Korea; email: hancho@snu.ac.kr},
editor={Chen J.Y.C., Fragomeni G.},
publisher={Springer Verlag},
issn={03029743},
isbn={9783030215644},
language={English},
abbrev_source_title={Lect. Notes Comput. Sci.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Pullan2019,
author={Pullan, G. and Chuan, T. and Wong, D.K.T. and Jasik, F.},
title={Enhancing web-based CFD post-processing using machine learning and augmented reality},
journal={AIAA Scitech 2019 Forum},
year={2019},
doi={10.2514/6.2019-2223},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068933235&doi=10.2514%2f6.2019-2223&partnerID=40&md5=44fb21342b6e5fa236d1c501dab8abfe},
affiliation={Whittle Laboratory, Department of Engineering, University of Cambridge, Cambridge, United Kingdom},
abstract={Two approaches for improving web-based post-processing tools for databases of computational fluid dynamics solutions are presented. The first uses Machine Learning to automatically classify the computational results and detect features of interest in the solutions. The second uses Augmented Reality to display three-dimensional models, on a tablet or phone screen, so that they appear as real objects to the user. Two examples of the application of Machine Learning are given. In the first, a convo-lutional neural network (CNN) is used to detect three-dimensional separations (“corner separations”) in the exit flow field of axial compressor blades. The CNN is trained on an artificially generated training set of two-dimensional scalar fields and shown to be accurate when classifying either experimental or computational results. The second example is the use of a variant of the ‘YOLO’ (You Only Look Once) CNN that can detect objects in an image and report their position and size. The network is trained, again using artificially generated data, to detect vortices from two-component, two-dimensional velocity fields. The network is shown to be able to to detect the tip vortex shed by computations of the Onera M6 wing. A multi-user Augmented Reality ‘room’ is demonstrated that provides an interactive, collaborative environment for the analysis of computational results. Selected geometry or flow data can be extracted from the database and rendered in the web browser of a device (phone or tablet) on top of a live feed from the device’s camera. The view of the computation responds to the movement of the device, such that a team of engineers can interrogate the solution as if they were viewing the computed results superimposed on a real object. © 2019 by the American Institute of Aeronautics and Astronautics, Inc. All rights reserved.},
keywords={Augmented reality;  Aviation;  Axial-flow compressors;  Classification (of information);  Computational fluid dynamics;  E-learning;  Edge detection;  Machine learning;  Telephone sets;  Velocity;  Vortex flow;  Websites, Axial compressor blades;  CFD post-processing;  Collaborative environments;  Computational results;  Corner separation;  Post processing;  Three-dimensional model;  Velocity field, Object detection},
publisher={American Institute of Aeronautics and Astronautics Inc, AIAA},
isbn={9781624105784},
language={English},
abbrev_source_title={AIAA Scitech Forum},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Pinchuk2019437,
author={Pinchuk, O.P. and Tkachenko, V.A. and Burov, O.Yu.},
title={AV and VR as gamification of cognitive tasks},
journal={CEUR Workshop Proceedings},
year={2019},
volume={2387},
pages={437-442},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068801577&partnerID=40&md5=f6a90a631fac70790189ac593e2a3a4d},
affiliation={Institute of Information Technologies and Learning Tools, Ukraine},
abstract={The paper presents a comparative analysis of the functionality of mobile applications of the augmented reality Da Vinci Machines AR, Electricity AR, Bridges AR, Geometry, the collection of VR models VictoryVR Science Curriculum and the digital collection Mozaik. The possibility of using these tools for educational purposes is explored, in particular, to construct cognitive tasks for students during the study of subjects in the natural and mathematical cycle. The indicated shortcomings are stated, didactic requirements for such educational activities are formulated. Among others, attention is focused on the following indicators: hardware, usability, variability of model parameters, interactivity, interdisciplinary use, and the ability to activate certain cognitive actions of students, degree/form of gamification. The educational potential of using interactive models and video is analyzed for both group and individual work with students. Examples of methodical developments are given. © 2019 CEUR-WS. All rights reserved.},
author_keywords={Augmented reality;  Gamification;  Learning environment;  Synthetic learning environment;  Virtual reality},
keywords={Augmented reality;  Computer aided instruction;  Education computing;  Industrial research;  Knowledge management;  Virtual reality, Comparative analysis;  Digital collections;  Educational activities;  Educational potential;  Gamification;  Learning environments;  Methodical development;  Mobile applications, Students},
correspondence_address1={Pinchuk, O.P.; Institute of Information Technologies and Learning ToolsUkraine; email: opinchuk100@gmail.com},
editor={Ermolayev V., Mallet F., Yakovyna V., Yakovyna V., Mayr H.C., Spivakovsky A.},
publisher={CEUR-WS},
issn={16130073},
language={English},
abbrev_source_title={CEUR Workshop Proc.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Strada2019,
author={Strada, F. and Bottino, A. and Lamberti, F. and Mormando, G. and Ingrassia, P.L.},
title={Holo-BLSD - A Holographic Tool for Self-training and Self-evaluation of Emergency Response Skills},
journal={IEEE Transactions on Emerging Topics in Computing},
year={2019},
doi={10.1109/TETC.2019.2925777},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068452336&doi=10.1109%2fTETC.2019.2925777&partnerID=40&md5=6030084f5ff57c6f3cec4e48254755ac},
affiliation={Dipartimento di Automatica e Informatica, Politecnico di Torino, Torino, Piemonte Italy (e-mail: francesco.strada@polito.it); Dipartimento di Automatica e Informatica, Politecnico di Torino, Torino, Italy Italy 10129 (e-mail: andrea.bottino@polito.it); Dipartimento di Automatica ed Informatica, Politecnico di Torino, Torino, TO Italy I-10129 (e-mail: fabrizio.lamberti@polito.it); Scuola di Medicina e Chirurgia, Università degli Studi di Padova, Padova, Padova Italy (e-mail: giulia.mormando@gmail.com); Department of Translational Medicine, Università del Piemonte Orientale, Novara, Novara Italy (e-mail: pierluigi.ingrassia@med.uniupo.it)},
abstract={In case of cardiac arrest, prompt intervention of bystanders can be vital in saving lives. Basic Life Support and Defibrillation (BLSD) is a procedure designed to deliver a proficient emergency first response. Developing skills in BLSD in a large part of the population is a primary educational goal of resuscitation medicine. In this context, novel computer science technologies like Augmented Reality (AR) and Virtual Reality (VR) can alleviate some of the drawbacks of traditional instructor-led courses, especially concerning time and cost constraints. This paper presents Holo-BLSD, an AR system that allows users to learn and train the different operations involved in BLSD and receive an automatic assessment. The system uses a standard manikin which is \quotes{augmented} by an interactive virtual environment that reproduces realistic emergency scenarios. The proposed approach has been validated through a user study. Subjective results confirmed the usability of the devised tool and its capability to stimulate learners' attention. Objective results indicated no statistical significance in the differences between the examiners' evaluation of users who underwent traditional and AR training; they also showed a close agreement between expert and automatic assessments, suggesting that Holo-BLSD can be regarded as an effective self-learning method and a reliable self-evaluation tool. IEEE},
author_keywords={Augmented Reality;  Basic Life Support and Defibrillation (BLSD);  self-evaluation;  self-learning;  user study},
keywords={Augmented reality;  Emergency services;  Resuscitation;  Virtual reality, Automatic assessment;  Basic life supports;  Interactive virtual environments;  Science technologies;  Self evaluation;  Self-learning;  Statistical significance;  User study, Learning systems},
publisher={IEEE Computer Society},
issn={21686750},
language={English},
abbrev_source_title={IEEE Trans. Emerg. Top. Comput.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Lebedev2019287,
author={Lebedev, G. and Klimenko, H. and Fartushniy, E. and Shaderkin, I. and Kozhin, P. and Galitskaya, D.},
title={Building a telemedicine system for monitoring the health status and supporting the social adaptation of children with autism spectrum disorders},
journal={Smart Innovation, Systems and Technologies},
year={2019},
volume={143},
pages={287-294},
doi={10.1007/978-981-13-8303-8_26},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067257725&doi=10.1007%2f978-981-13-8303-8_26&partnerID=40&md5=dbf35391947dc02aa2643f87dba14ea2},
affiliation={I.M. Sechenov First Moscow State Medical University, 2-4 Bolshaya Pirogovskaya st, Moscow, 119991, Russian Federation; Federal Research Institute for Health Organization and Informatics, 11, Dobrolubova street, Moscow, 127254, Russian Federation},
abstract={In the Russian Federation, a large number of children are born with autism spectrum disorders, and the sooner parents notice such disorders in a child, and the earlier the rehabilitation and treatment program begins, the higher the likelihood of his social adaptation. The difficulties in raising such a child lie in the complexity of his learning outside of children’s groups and the complexity of his medical care. In this regard, the development of digital applications that facilitate medical care and education of such children at home is important and relevant. This paper formulates the requirements for building a telemedicine system that monitors the health status and supports the social adaptation of children with autism spectrum disorders. It is determined that the system will be an information resource on the Internet, including a hardware and software complex for remote monitoring of children’s health at home, the workplace of a doctor monitoring a child, dynamic video surveillance system of a child’s behavior using deep learning methods artificial neural networks with early diagnostics of reactive reactions, complex systems with elements of virtual reality and augmented reality for distance training and adaptation of the children, set of interactive tools and test definition of autism spectrum disorders in different age of the child. The methods for implementing such a telemedicine system are given. This work was supported by the RFBR grant 18-07-00987. © Springer Nature Singapore Pte Ltd. 2019.},
author_keywords={Artificial neural networks;  Autism spectrum disorders (ASD);  Clinical (medical) decision support system;  Digital health;  Telemedicine;  Virtual reality systems},
keywords={Augmented reality;  Complex networks;  Decision support systems;  Deep learning;  Diagnosis;  Diseases;  Network security;  Neural networks;  Remote patient monitoring;  Security systems;  Software testing;  Telemedicine;  Virtual reality, Autism spectrum disorders;  Children with autisms;  Digital applications;  Hardware and software;  Information resource;  Russian federation;  Telemedicine systems;  Virtual reality system, Patient rehabilitation},
correspondence_address1={Lebedev, G.; I.M. Sechenov First Moscow State Medical University, 2-4 Bolshaya Pirogovskaya st, Russian Federation; email: rektorat@sechenov.ru},
editor={Howlett R.J., Jain L.C., Jain L.C., Czarnowski I., Jain L.C., Jain L.C.},
publisher={Springer Science and Business Media Deutschland GmbH},
issn={21903018},
isbn={9789811383021},
language={English},
abbrev_source_title={Smart Innov. Syst. Technol.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Marcel2019,
author={Marcel, F.},
title={Mobile augmented reality learning objects in higher education},
journal={Research in Learning Technology},
year={2019},
volume={27},
doi={10.25304/rlt.v27.2133},
art_number={2133},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066993063&doi=10.25304%2frlt.v27.2133&partnerID=40&md5=564337fc81668e584d14e06ad14bec14},
affiliation={Niagara College, University of Toronto, Department of Curriculum, Teaching and Learning, Toronto, Canada},
abstract={Teachers and learners in all sectors of education continue to have access to a growing number of mobile augmented reality (AR) applications for the creation and implementation of mobile AR experiences and learning objects (LOs). In this study, affordances of mobile AR and LOs for higher education are investigated through the mobile AR platform HP Reveal. Digital trace data from publicly shared and published AR users’ LOs were examined to investigate affordances of AR technology in educational organisations and institutions and their potential implications in areas of higher education. For this purpose, a quantitative comparative analysis of system data and content from 632 AR LOs was conducted at two instances over a 2-year interval period. Each LO was thematically coded to determine multimodal functionalities and characteristics. Further thematic coding and categorisation revealed four emergent categories for affordances in higher education: learner interaction, collaboration, cultural exploration and digital storytelling. Results also revealed increases over time in the use of recorded and online video content and the use of three-dimensional (3D) characters for educational purposes. An examination of the affordances offered by the AR platform revealed opportunities for educators to explore further interactive and collaborative uses of AR with their learners for pedagogical purposes in higher education. © 2019 Faith Marcel.},
author_keywords={Augmented reality;  Digital trace data;  Learning objects;  Mixed reality;  Mobile augmented reality;  Technology in higher education},
correspondence_address1={Marcel, F.; Niagara College, University of Toronto, Department of Curriculum, Teaching and LearningCanada; email: fmarcel@niagaracollege.ca},
publisher={Association for Learning Technology},
issn={21567069},
language={English},
abbrev_source_title={Res. Learn. Technol.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Li2019232,
author={Li, W. and Wen, L. and Bian, X. and Lyu, S.},
title={Evolvement Constrained Adversarial Learning for Video Style Transfer},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2019},
volume={11361 LNCS},
pages={232-248},
doi={10.1007/978-3-030-20887-5_15},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066781711&doi=10.1007%2f978-3-030-20887-5_15&partnerID=40&md5=4e167b33a2f24babf97f3c16a0538cc6},
affiliation={University at Albany, SUNY, Albany, United States; JD Finance AI Lab, San Francisco, United States; GE Global Research, Niskayuna, United States},
abstract={Video style transfer is a useful component for applications such as augmented reality, non-photorealistic rendering, and interactive games. Many existing methods use optical flow to preserve the temporal smoothness of the synthesized video. However, the estimation of optical flow is sensitive to occlusions and rapid motions. Thus, in this work, we introduce a novel evolve-sync loss computed by evolvements to replace optical flow. Using this evolve-sync loss, we build an adversarial learning framework, termed as Video Style Transfer Generative Adversarial Network (VST-GAN), which improves upon the MGAN method for image style transfer for more efficient video style transfer. We perform extensive experimental evaluations of our method and show quantitative and qualitative improvements over the state-of-the-art methods. © 2019, Springer Nature Switzerland AG.},
keywords={Augmented reality;  Image enhancement;  Optical flows, Adversarial learning;  Adversarial networks;  Experimental evaluation;  Interactive games;  Non-Photorealistic Rendering;  Rapid motions;  State-of-the-art methods, Computer vision},
correspondence_address1={Li, W.; University at Albany, SUNYUnited States; email: wli20@albany.edu},
editor={Schindler K., Mori G., Li H., Jawahar C.V.},
publisher={Springer Verlag},
issn={03029743},
isbn={9783030208868},
language={English},
abbrev_source_title={Lect. Notes Comput. Sci.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Mokhsin2019425,
author={Mokhsin, M. and Zainol, A.S. and Ibrahim, E.N.M. and Som, M.H.M. and Basit, K.A.A. and Azman, A.A.},
title={ARMyPat: Mobile application in learning malay historical patriots using augmented reality},
journal={Lecture Notes in Networks and Systems},
year={2019},
volume={67},
pages={425-445},
doi={10.1007/978-981-13-6031-2_6},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066138419&doi=10.1007%2f978-981-13-6031-2_6&partnerID=40&md5=e048d7ef6aafd8a7c301b8a74a11841d},
affiliation={Faculty of Computer & Mathematical Sciences, Universiti Teknologi MARA, Shah Alam, Selangor  40450, Malaysia; Institute of Malay Thoughts and Leadership (IMPAK), Universiti Teknologi MARA, Shah Alam, Selangor  40450, Malaysia; Faculty of Art and Design, Universiti Teknologi MARA, Shah Alam, Selangor  40450, Malaysia},
abstract={In the era of evolving technology, the generation who was born in 1995 onwards or known as Gen Z in Malaysia is becoming less interested in knowing and learning about Malay Historical Figures. Currently, the medium or tool applied in learning about Malay Historical Figures is only by using textbook as reference in the classroom. Looking at this scenario, this project attempts to attract their interest in learning historical information, especially about Malay Figure by converting the text or image information into an interactive learning method. The approach for this project is by implementing an augmented reality technology where the interactive fighting game has been embedded. The objectives of this study are to identify the requirements, design and develop Augmented Reality mobile learning application about Malay Historical Figures with the commercial name of ARMyPat (Augmented Reality based in Learning about Malay Patriots). This application prototype will be compatible for the Android platform mobile devices and the target users for this application are students aged between 10 and 15 years old who learn the historical subject at school. The project methodology is ADDIE model that covered analyses, design, develop, implement and evaluation phase since this methodology is suitable for the interactive learning development process. The students can obtain the information such as the summary of character, biodata, heritage and contribution interactively. For 3D character model view, they can learn and know the attraction of the martial art which is Silat. Therefore, they can learn a few movements of the Silat martial art. The last part is an interactive fighting game whereby it can bring the students to the fighting action in real environment and encourage them to know about the heroism characters of that Malay Historical Figure. In the end, this application is to encourage young generation patriotism spirits towards Historical Figure in Malaysia by utilizing augmented reality technology. © Springer Nature Singapore Pte Ltd. 2019.},
author_keywords={ADDIE research methodology;  Augmented reality;  Malay figures;  Mobile game;  Mobile learning},
correspondence_address1={Mokhsin, M.; Faculty of Computer & Mathematical Sciences, Universiti Teknologi MARAMalaysia; email: mudiana@tmsk.uitm.edu.my},
publisher={Springer},
issn={23673370},
language={English},
abbrev_source_title={Lect. Notes Networks Syst.},
document_type={Book Chapter},
source={Scopus},
}

@CONFERENCE{Kaleem2019123,
author={Kaleem, F. and Kommera, N. and Pusey, P.},
title={Augmented reality mobile forensic laboratory (AMFL)},
journal={IMCIC 2019 - 10th International Multi-Conference on Complexity, Informatics and Cybernetics, Proceedings},
year={2019},
volume={1},
pages={123-127},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066046938&partnerID=40&md5=a306946ab8b908b5838bef69a76f6a63},
affiliation={Computer Science and Cybersecurity, Metropolitan State University, St. Paul, MN  55449, United States; Portia Pusey, LLC, Baldwin, MD  21013, United States},
abstract={In this paper, we discuss the potential of augmented reality technology-based teaching and learning approach to enhance cybersecurity and forensics education. Augmented Reality (AR) superimposes digital information directly in front of a user’s field of vision with enriching content to supplement real world experiences. We have developed an interactive Windows based Augmented Reality application for Microsoft HoloLens, which is aimed to enhance students’ learning and understanding of cybersecurity and forensics concepts. Our work focuses on the capacity of the unique features of AR via smart glasses to provide meaningful hands-on learning experiences. The application augments the step-by-step process of performing a forensics lab along with some 2D images and videos to assist students in successfully completing their labs with minimal or no help from the instructor. Augmented reality techniques allow students to experience sensations and explore learning experiences that, in some cases, may exceed those offered by traditional laboratory classes. Copyright 2019. © by the International Institute of Informatics and Systemics. All rights reserved.},
author_keywords={Augmented Reality;  Cybersecurity Education;  Microsoft HoloLens;  Mobile Forensic Laboratory},
keywords={Augmented reality;  Laboratories;  Students, Augmented reality applications;  Augmented reality technology;  Cyber-security educations;  Learning and understanding;  MicroSoft;  Mobile forensics;  Real-world experience;  Teaching and learning, Computer forensics},
publisher={International Institute of Informatics and Systemics, IIIS},
language={English},
abbrev_source_title={IMCIC - Int. Multi-Conf. Complex., Informatics Cybern., Proc.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Requejo201915,
author={Requejo, L.F.S. and Reyes, J.C.R. and Padilla, A.B. and Riega, R.V.},
title={Taxonomy of applications and video games and statistical model of mixed reality market sectors for the development of applications},
journal={ICSIT 2019 - 10th International Conference on Society and Information Technologies, Proceedings},
year={2019},
pages={15-20},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065972618&partnerID=40&md5=ce7e2f1e794731008e20120ebc822cdf},
affiliation={Department of Systems and Information Engineering, Peruvian University of Applied Sciences Lima, Lima, 27, Peru},
abstract={Emerging technologies are innovative ideas that provide solutions in order to help us to simplify everyday and organizational tasks. One of these technologies that have great potential is Mixed Reality, which has as a concept the fusion of virtual reality, an environment of digital objects and scenes; and augmented reality, virtual objects that integrate with the real world but do not interact with it. The potential of Mixed Reality has been used by highly recognized companies in order to solve problems in different sectors such as health, education, industry, etc. This project will present the research carried out on the existing technologies based on Mixed Reality and the technological contribution provided by these technologies according to their functionality, in order to propose a classification taxonomy of the found technologies (applications) and a statistical model of adoption by commercial value to provide guidance on existing technological solutions by sector and for the development of technology projects based on existing technologies. Copyright © 2019 by the International Institute ofInformatics and Systemics.},
author_keywords={Mixed reality;  Mixed reality devices;  Mixed reality market sectors;  Statistical model;  Taxonomy},
keywords={Augmented reality;  Commerce;  Engineering education;  Interactive computer graphics;  Taxonomies, Digital Objects;  Emerging technologies;  Innovative ideas;  Market sectors;  Provide guidances;  Statistical modeling;  Technological solution;  Technology projects, Mixed reality},
editor={Carrasquero J.V., Callaos N.C., Sanchez B., Welsch F., Tremante A.},
publisher={International Institute of Informatics and Systemics, IIIS},
isbn={9781950492053},
language={English},
abbrev_source_title={ICSIT - Int. Conf. Soc. Inf. Technol., Proc.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Ihamäki2019205,
author={Ihamäki, P. and Heljakka, K.},
title={The internet of art as a site for learning and fun – Playful experiences through augmented geocaching},
journal={CEUR Workshop Proceedings},
year={2019},
volume={2359},
pages={205-216},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065721452&partnerID=40&md5=43f55a00a0bedebcb2b89913f0e6d559},
affiliation={Prizztech Ltd., Pori, Finland; University of Turku, Pori, Finland},
abstract={The Internet of Art as in public and connected art installations gives birth to interactivity and participation, which in turn, introduce new challenges, not only to the production of artworks, but also in how to involve the participants and how to evaluate the results of target experiences, such as social connectedness, context, playfulness, and gamification. This case study presents an example of interactive and participatory forms of the Internet of Art. We have used a multimethod approach including qualitative research methods to understand preschool-aged children’s experiences who used the Sigrid-Secrets Augmented Reality application in playing the game of geocaching and finding physical artworks prior to the geocache. We have observed two groups of preschoolers play-testing, analysed the videotaped documentation of the testing, and followed the children drawing their memorable experiences of the geocaching trail. By using the Playful Experiences (PLEX) framework, we have evaluated the preschoolers’ memorable experiences of playing. Our findings demonstrate how augmented techniques can be used to transform the physical surroundings in order to create a hybrid game-world suited for learning and fun. In this game-world the player can become immersed in the flow of playful experiences, and engage with edutaining exercises while being simultaneously connected to both to the Internet of Art and to the physical dimensions of the real world environment. © 2018 CEUR-WS. All rights reserved.},
author_keywords={Augmented Reality (AR) Application;  Gamification;  Geocaching;  Internet of Art;  Internet of things;  Sigrid-Secrets Geocache},
keywords={Augmented reality;  Internet of things;  Video recording, Augmented reality applications;  Gamification;  Geocache;  Geocaching;  Multi-method approach;  Pre-school aged child;  Qualitative research methods;  Real world environments, Arts computing},
editor={Hamari J., Koivisto J., Hamari J.},
publisher={CEUR-WS},
issn={16130073},
language={English},
abbrev_source_title={CEUR Workshop Proc.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{NoAuthor2019,
title={12th International Conference on Interactive Mobile Communication, Technologies and Learning, IMCL 2018},
journal={Advances in Intelligent Systems and Computing},
year={2019},
volume={909},
page_count={406},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065306654&partnerID=40&md5=c3476f189f35476742c4bf7c05d64478},
abstract={The proceedings contain 36 papers. The special focus in this conference is on Interactive Mobile Communication, Technologies and Learning. The topics include: Using virtual experiments in teaching control theory; mobile e-training tools for augmented reality eye fundus examination; use of mobile apps for logging patient encounters and facilitating and tracking direct observation and feedback of medical student skills in the clinical setting; myvitalwallet—I bring my (own) health; PTGuide—a platform for personal trainers and customers; Development of a VR simulator prototype for myocardial infarction treatment training; Learning—an AR approach; gamifying history using beacons and mobile technologies; a framework for preadolescent programmers to create cooperative multiplayer reading games; using an augmented reality geolocalized quiz game as an incentive to overcome academic procrastination; Mastering the MOOC: Exploring a unique approach to online course development; using gamification technique to increase capacity in the resolution of problems during the process teaching and learning programming; encouraging student motivation through gamification in engineering education; a survey of mobile learning approaches for teaching internet of things; The design and implementation of a low-cost demo tool to teach dynamics in the IOT era; Interactive and adaptable mobile-friendly e-learning environments for k-12 and higher STEM education and skills training; a novel approach for secure in-class delivery of educational content via mobile routers with functionally enhanced firmware; leveraging low-power wide area networks for precision farming: Limabora—a smart farming case using lora modules, gateway, ttn and firebase in Kenya; poster: Carris application for public transportation; Hardware and software for learning IOT technologies.},
editor={Auer M.E., Tsiatsos T.},
publisher={Springer Verlag},
issn={21945357},
isbn={9783030114336},
language={English},
abbrev_source_title={Adv. Intell. Sys. Comput.},
document_type={Conference Review},
source={Scopus},
}

@ARTICLE{Nasongkhla201948,
author={Nasongkhla, J. and Supadaec, C. and Chiasiriphan, T.},
title={Implementing multiple AR markers in learning science content with Junior High School students in Thailand},
journal={International Journal of Emerging Technologies in Learning},
year={2019},
volume={14},
number={7},
pages={48-60},
doi={10.3991/ijet.v14i07.9855},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065084510&doi=10.3991%2fijet.v14i07.9855&partnerID=40&md5=665412d9a820df65c356b7e522ff7e5a},
affiliation={Director of Innovative Educational Technology (iNET), Chulalongkorn University, Thailand; Faculty of Education, Chulalongkorn University, Thailand; Innovative Educational Technology (iNET), Thailand},
abstract={This study demonstrates a supplementary classroom technology using an Augmented Reality (AR) application to enhance students in learning Genetics at Junior High School in Thailand. The tool provides visual cards of concepts about Genetics with multiple AR markers (cards). An interactive experience provides students a multiple-choice format to respond to different cases (questions). Using a purposive sampling technique, sixty students from the 9th grade compared and selected AR markers to generate an animated twodimensional graphic with sound feedback. In addition, the students' learning scores were compared among the groups of different analytical thinking abilities who used single and multiple AR markers. The results found the potential of using Augmented Reality (AR) in supporting students' learning especially in improving analytical thinking ability. © 2019 Kassel University Press GmbH.},
author_keywords={Augmented reality;  Genetics;  Multiple-choice format;  Thailand},
keywords={Augmented reality;  Chromosomes, Analytical thinking;  Classroom technology;  Genetics;  Junior high schools;  Learning science;  Multiple-choice formats;  Sampling technique;  Thailand, Students},
correspondence_address1={Nasongkhla, J.; Director of Innovative Educational Technology (iNET), Chulalongkorn UniversityThailand; email: jaitip.n@chula.ac.th},
publisher={Kassel University Press GmbH},
issn={18688799},
language={English},
abbrev_source_title={Int. J. Emerg. Technol. Learn.},
document_type={Article},
source={Scopus},
}

@ARTICLE{NoAuthor2019,
title={10th International Conference on Intelligent Technologies for Interactive Entertainment, INTETAIN 2018},
journal={Lecture Notes of the Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering, LNICST},
year={2019},
volume={273},
page_count={159},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065018717&partnerID=40&md5=864767a5ed1cf5918d216deeb49cec4f},
abstract={The proceedings contain 15 papers. The special focus in this conference is on Intelligent Technologies for Interactive Entertainment. The topics include: Exploring Novel Methodology for Classifying Cognitive Workload; Scene Reconstruction for Storytelling in 360 $$^\circ $$ Videos; User Behaviour Analysis and Personalized TV Content Recommendation; virtual and Augmented Reality Interfaces in Shared Game Environments: A Novel Approach; microbial Integration on Player Experience of Hybrid Bio-digital Games; a Brief Overview on the Evolution of Drawing Machines; Compression-Based Classification of ECG Using First-Order Derivatives; predicting Postoperative Complications for Gastric Cancer Patients Using Data Mining; a Many-Valued Empirical Machine for Thyroid Dysfunction Assessment; detecting Automatic Patterns of Stroke Through Text Mining; a Preliminary Evaluation of a Computer Vision-Based System to Detect Effects of Aromatherapy During High School Classes via Movement Analysis; virtual Agents for Professional Social Skills Training: An Overview of the State-of-the-Art; a Machine Learning Approach to Detect Violent Behaviour from Video.},
editor={Cortez P., Magalhaes L., Portela C.F., Adao T., Branco P.},
publisher={Springer Verlag},
issn={18678211},
isbn={9783030164461},
language={English},
abbrev_source_title={Lect. Notes Inst. Comput. Sci. Soc. Informatics Telecommun. Eng.},
document_type={Conference Review},
source={Scopus},
}

@ARTICLE{Garofalo2019671,
author={Garofalo, V.},
title={Digital technologies for the fruition of archaeological heritage. The visualisation of the temple C metopes polychrome in selinunte},
journal={Advances in Intelligent Systems and Computing},
year={2019},
volume={919},
pages={671-680},
doi={10.1007/978-3-030-12240-9_69},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064680677&doi=10.1007%2f978-3-030-12240-9_69&partnerID=40&md5=1ad745dc027ddfb489f8cb565d7b6449},
affiliation={Department of Architecture (DARCH), Università degli Studi di Palermo, Viale delle Scienze edificio 14, Palermo, 90138, Italy},
abstract={Through the tools of the representation this paper investigates a hypothetical virtual re-presentation of the metopes original polychromies. The reconstructive interpretative process was carried out through a critical reading of historical and iconographic sources. Starting from the reading of drawings made by Angell and Harris at the time of the archaeological finds, of Hittorff’s studies and watercolors, and of some coloured fragments still observable in the original metopes, the graphic elaborations that simulate the original polychromes have been prepared. The purpose of this study and of the analysis here described is the experimentation of an interactive visualisation application (augmented reality) designed for the “Antonino Salinas” Regional Archaeological Museum of Palermo. The study is part of the repertoire of virtual reconstructions, through the use of light, of lost colour configurations. The project aims to propose a new modality for the use of archaeological finds, thanks to an inedited teaching and immersive experience of the metopes and to the experimentation of a new visual environment that overlaps the real one leading to rethink the relationship between reality and its representation. © Springer Nature Switzerland AG 2019.},
author_keywords={3D model;  Augmented reality;  SfM survey;  Video mapping},
keywords={3D modeling;  Augmented reality;  Visualization, Digital technologies;  Immersive;  Interactive visualisation;  New modality;  Virtual reconstruction;  Visual environments, E-learning},
correspondence_address1={Garofalo, V.; Department of Architecture (DARCH), Università degli Studi di Palermo, Viale delle Scienze edificio 14, Italy; email: vincenza.garofalo@unipa.it},
editor={Luigini A.},
publisher={Springer Verlag},
issn={21945357},
isbn={9783030122393},
language={English},
abbrev_source_title={Adv. Intell. Sys. Comput.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Cao2019524,
author={Cao, R. and Hou, W.},
title={Research on the Interaction Design of AR Picture Books via Usability Test},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2019},
volume={11354 LNCS},
pages={524-534},
doi={10.1007/978-3-030-15127-0_53},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064677183&doi=10.1007%2f978-3-030-15127-0_53&partnerID=40&md5=33b40052c6b638b7875766eb40b37004},
affiliation={School of Digital Media and Design Arts, Beijing University of Posts and Telecommunications, No 10, Xitucheng Road, Haidian District, Beijing, 100876, China},
abstract={In children’s books, picture books account for seventy percent. With the development of information technology, picture book with Augmented Reality (AR) is an emerging application under the influences of digital technologies, which is a new kind of picture book with the auxiliary of games. The AR picture book bases on the children’s cognitive level and the operation of the mobile devices, satisfying their needs of exploring and learning new things. Under the literature review and competitive analysis, we exploratively put forward the prototypes of interactive AR picture books, especially for the kids aged from 5 to 8. Furthermore, we designed the usability test on one of our prototypes, Rocket Dream, to better understand the process of interaction design. According to the results, we testify the feasibility of AR picture books as well as figure out some issues in the interaction processes, such as the weak guidance in the interactive operation, incomplete essential information in the interface, as well as the fact that children’s preference of visible interaction and touch operations and they are more sensitive to large objects. Also, we propose potential solutions to these issues in the following parts, which could be useful for the future of AR picture books. © 2019, Springer Nature Switzerland AG.},
author_keywords={AR picture books;  Child education;  Human-computer interaction;  Interaction design;  Usability test},
keywords={Augmented reality;  Design;  Reviews;  Rockets, Child educations;  Competitive analysis;  Digital technologies;  Emerging applications;  Interaction design;  Interaction process;  Interactive operations;  Usability tests, Human computer interaction},
correspondence_address1={Cao, R.; School of Digital Media and Design Arts, Beijing University of Posts and Telecommunications, No 10, Xitucheng Road, Haidian District, China; email: 1170695087@qq.com},
editor={Zu Q., Rodriguez Garcia J.G., Tang Y.},
publisher={Springer Verlag},
issn={03029743},
isbn={9783030151263},
language={English},
abbrev_source_title={Lect. Notes Comput. Sci.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Meschini2019326,
author={Meschini, A. and Feriozzi, R.},
title={Representing and communicating the cultural heritage construction of virtual urban and architectural scale places for learning},
journal={Advances in Intelligent Systems and Computing},
year={2019},
volume={919},
pages={326-335},
doi={10.1007/978-3-030-12240-9_35},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064623175&doi=10.1007%2f978-3-030-12240-9_35&partnerID=40&md5=a83e497ea24749dde20b4daea4449afd},
affiliation={School of Architecture and Design “Eduardo Vittoria” (SAAD), University of Camerino, Viale della Rimembranza snc, Ascoli Piceno, 63100, Italy},
abstract={This contribution addresses the opportunities that technological innovations offer to expand accessibility to knowledge. The goal is to verify how the organization of specific content, together with the use of identified technologies, are factors that significantly influence the relationship between users, the curators of the transmitted information, and the institutions appointed to conserve and enhance various cultural heritage. In particular, two experimentations centred on using augmented reality/virtuality and interactive media were made to verify the potential of their use and application to two different types of cultural heritage. Both experimentations have the common goal of identifying and initiating new cognitive processes based mainly on inquiry in an active, exploratory way, that is, allowing users to interact with the information tied to the cultural heritage, offering broad, multi-sensory use. © Springer Nature Switzerland AG 2019.},
author_keywords={3D reconstruction;  Cultural heritage;  Immersive navigation;  Interactive interfaces;  Virtual environments},
keywords={Augmented reality;  Historic preservation;  Virtual reality, 3D reconstruction;  Architectural scale;  Cognitive process;  Cultural heritages;  Immersive;  Interactive interfaces;  Interactive media;  Technological innovation, E-learning},
correspondence_address1={Meschini, A.; School of Architecture and Design “Eduardo Vittoria” (SAAD), University of Camerino, Viale della Rimembranza snc, Italy; email: alessandra.meschini@unicam.it},
editor={Luigini A.},
publisher={Springer Verlag},
issn={21945357},
isbn={9783030122393},
language={English},
abbrev_source_title={Adv. Intell. Sys. Comput.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Huang201970,
author={Huang, T.-C. and Chen, M.-Y. and Hsu, W.-P.},
title={Do learning styles matter? Motivating learners in an augmented geopark},
journal={Educational Technology and Society},
year={2019},
volume={22},
number={1},
pages={70-81},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063800693&partnerID=40&md5=2013873a591a7ed778158f81288b7030},
affiliation={Department of Information Management, National Taichung University of Science and Technology, Taiwan},
abstract={Augmented reality (AR) technology has recently been applied to outdoor learning in an attempt to overcome the drawbacks associated with traditional teaching environments. This study conducted an experiment designed to examine how augmented reality (AR) technology in mobile devices can be used to generate virtual objects to create a context-aware, AR-enabled guided tour application for outdoor learning. The participants were 70 elementary school students (average age: 11 years), who were randomly divided into control and experiment groups. The results showed the proposed system provided learners with a friendly, interactive interface and rich, engaging media to improve learning performance and stimulate the students' internal motivation to learn. The system's quantification of the learning motivations noted in Keller's ARCS model and Kolb's learning style theory can be used to improve the design of the learning materials. In conclusion: (1) The proposed system and activity helps stimulate learning intention via the pursuit of outdoor learning objectives, (2) the AR technology provides learners with contextual information related to the outdoor learning environment, and (3) the benefits of the proposed model do not differ for students with different learning styles. © International Forum of Educational Technology & Society (IFETS).},
author_keywords={ARCS;  Augmented reality;  Learning styles;  Motivation;  Ubiquitous learning},
correspondence_address1={Chen, M.-Y.; Department of Information Management, National Taichung University of Science and TechnologyTaiwan; email: mychen.academy@gmail.com},
publisher={National Taiwan Normal University},
issn={11763647},
language={English},
abbrev_source_title={Educational Technology and Society},
document_type={Article},
source={Scopus},
}

@ARTICLE{Fernandes2019223,
author={Fernandes, W. and Gomes, T. and Fernandes, A. and Mascarnes, S. and Panchal, D.},
title={Interactive print media using augmented reality},
journal={Advances in Intelligent Systems and Computing},
year={2019},
volume={898},
pages={223-232},
doi={10.1007/978-981-13-3393-4_23},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062294957&doi=10.1007%2f978-981-13-3393-4_23&partnerID=40&md5=68c98974b5d267897bdb094841e37d30},
affiliation={Department of Computer Engineering, St. Francis Institute of Technology, Mumbai, India},
abstract={Augmented Reality is one of the revolutionary technologies gaining fast pace in enhancing user interaction. Education is evolving rapidly and needs to keep accomplishing its goal of providing knowledge seamlessly. The use of mere images in print media like textbooks limits learner’s understandability. A much more interactive approach is required to boost the overall learning experience. The existing systems are quite capable of delivering useful content such as 3D models, by using special markers for tracking done in images. This limits their potential as it is not feasible to create markers for every image and is time-consuming. This research work focusses on developing an Android application using Marker-less AR. The proposed system encompasses image recognition using a mobile camera, rendering relevant YouTube videos pertaining to the image, and their superimposition in AR. The aim of this system is to enhance the productivity of education to enliven images with interactive videos. © Springer Nature Singapore Pte Ltd. 2019.},
author_keywords={Augmented Reality (AR);  Marker-less;  Normalization;  YouTube videos;  YouTube videos ranking},
keywords={Augmented reality;  Image recognition;  Soft computing, Android applications;  Interactive approach;  Interactive video;  Learning experiences;  Marker-less;  Normalization;  Revolutionary technology;  YouTube, Image enhancement},
correspondence_address1={Gomes, T.; Department of Computer Engineering, St. Francis Institute of TechnologyIndia; email: thelmagomes.11@gmail.com},
editor={Mohana Reddy G.R., Reddy V.S., Prasad V.K., Wang J.},
publisher={Springer Verlag},
issn={21945357},
isbn={9789811333927},
language={English},
abbrev_source_title={Adv. Intell. Sys. Comput.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Tan2019340,
author={Tan, K. and Lim, C.},
title={Malaysian music augmented reality (MMAR): Development of traditional musical instruments using augmented reality},
journal={International Journal of Innovative Technology and Exploring Engineering},
year={2019},
volume={8},
number={4S},
pages={340-345},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061757609&partnerID=40&md5=596610c8f8c83e16d0d584d4328c8b5e},
affiliation={Faculty of Art, Computing and Creative Industry, Sultan Idris Education University, Malaysia},
abstract={The public music schooling course of study in Malaysia was brought in as a required subject into the primary schools since 1983 through the program of "Integrated Primary School Curriculum". The predominant intention of Malaysian music education is for pupils to improve an curiosity and an appreciation of music and songs of the Malaysian culture. In addition, the specific aim of music education in the Integrated Primary School Curriculum is to provide students who’ve a basic awareness then understanding of music, similarly as minimum skills in composing music. When comparing to traditional method (non-interactive), one of the drawbacks is the missing level of realism. Therefore, an Augmented Reality (AR) based approach may offer a way out to enhance the visual information. AR technology has been established and matured to the peak where the education sector can use it for effective teaching and learning especially to provide realistic learning experience to the students. In addition, the Ministry of Higher Education is strongly urging to get on board of the digital transformation since AR is one of the nine pillars that define Industry 4.0. The objectives of this research has two folds: (i) to promote Malaysian music education especially the traditional musical instrument to young generation by exploiting the technology from AR and (ii) to develop an AR application by enriching the digital content on top of the traditional musical instrument to help the students in the primary school to understand and learn the traditional musical instruments anywhere and at anytime. This research is found to be able to support interactions between students in the class, cultivating more interest in traditional music and instruments through the smooth transition between the reality and virtuality, as the interaction with a computer can improve the interest in learning and teaching. © BEIESP.},
author_keywords={Augmented reality;  Mobile learning;  Randomized psychoacoustic model},
publisher={Blue Eyes Intelligence Engineering and Sciences Publication},
issn={22783075},
language={English},
abbrev_source_title={Int. J. Innov. Technol. Explor. Eng.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Kundu2019641,
author={Kundu, S.N. and Nawaz, M.},
title={Geospatial risk communication and visualization of natural hazards using augmented reality constructs},
journal={Lecture Notes in Civil Engineering},
year={2019},
volume={9},
pages={641-651},
doi={10.1007/978-981-10-8016-6_49},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060331197&doi=10.1007%2f978-981-10-8016-6_49&partnerID=40&md5=d51426eb0ebeca19cde0466f0a3cb112},
affiliation={Department of Geography, National University of Singapore, Singapore, Singapore},
abstract={GIS-based maps are currently the norm for risk visualization and communication of natural hazards. With advances in geospatial visualization and spatial interface technologies, interactive and dynamic risk visualization is now possible. Augmented reality adds another dimension to realistic visualization of natural hazards like floods and volcanic flows which can be achieved through spatial risk visualization and communication simulations in virtual reality mode. Communicating the knowledge to the most vulnerable communities which are residing in the risk zones is very useful for local stakeholders as they are mostly needful of the adaptation strategies. The current article experiments the use of an Augmented Reality Construct for developing a risk visualization interface, which delivers spatially aware geovisualization simulations. We propose the Augmented Reality Sandbox for educating and engaging the local community through simulated visualization of hazard risk and vulnerability with an aim to achieve holistic learning. This construct has a great potential for developing interactive and location-aware three-dimensional real-world simulations and visualization. We suggest that such applications be more prevalently used as we found it to be more effective than static 3D visualization constructs like hazard maps in communicating the risk potential from natural hazards like floods and volcanic lava flows. © Springer Nature Singapore Pte Ltd. 2019.},
author_keywords={Augmented reality;  Geographical information systems;  Hazard maps;  Risk visualization},
correspondence_address1={Kundu, S.N.; Department of Geography, National University of SingaporeSingapore; email: snkundu@gmail.com},
publisher={Springer},
issn={23662557},
language={English},
abbrev_source_title={Lect. Notes Civ. Eng.},
document_type={Book Chapter},
source={Scopus},
}

@ARTICLE{Christaki2019566,
author={Christaki, K. and Apostolakis, K.C. and Doumanoglou, A. and Zioulis, N. and Zarpalas, D. and Daras, P.},
title={Space wars: An augmentedvr game},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2019},
volume={11296 LNCS},
pages={566-570},
doi={10.1007/978-3-030-05716-9_47},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059835296&doi=10.1007%2f978-3-030-05716-9_47&partnerID=40&md5=4423fa7ac7deb7bff171b5a8485002fa},
affiliation={Visual Computing Lab, Information Technologies Institute, Centre for Research and Technology Hellas, Thessaloniki, Greece},
abstract={Over the past couple of years, Virtual and Augmented Reality have been at the forefront of the Mixed Reality development scene, whereas Augmented Virtuality has significantly lacked behind. Widespread adoption however requires efficient low-cost platforms and minimalistic interference design. In this work we present Space Wars, an end-to-end proof of concept for an elegant and rapid-deployment Augmented VR platform. Through the engaging experience of Space Wars, we aim to demonstrate how digital games, as forerunners of innovative technology, are perfectly suited as an application area to embrace the underlying low-cost technology, and thus pave the way for other adopters (such as healthcare, education, tourism and e-commerce) to follow suit. © 2019, Springer Nature Switzerland AG.},
author_keywords={3D Capture;  Augmented Virtuality;  Mixed Reality (MR);  Virtual Reality (VR)},
keywords={Augmented reality;  Costs;  Education computing;  Engineering education;  Interactive computer graphics, 3D Capture;  Application area;  Augmented virtualities;  Innovative technology;  Low cost technology;  Proof of concept;  Rapid deployments;  Virtual and augmented reality, Mixed reality},
correspondence_address1={Christaki, K.; Visual Computing Lab, Information Technologies Institute, Centre for Research and Technology HellasGreece; email: kchristaki@iti.gr},
editor={Huet B., Kompatsiaris I., Vrochidis S., Mezaris V., Cheng W., Gurrin C.},
publisher={Springer Verlag},
issn={03029743},
isbn={9783030057152},
language={English},
abbrev_source_title={Lect. Notes Comput. Sci.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{NoAuthor2019,
title={4th Iberoamerican Workshop on Human-Computer Interaction, HCI-Collab 2018},
journal={Communications in Computer and Information Science},
year={2019},
volume={847},
page_count={257},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058539745&partnerID=40&md5=d927d9d26c952b122af8091c61870873},
abstract={The proceedings contain 18 papers. The special focus in this conference is on Human-Computer Interaction. The topics include: Gesture-based interaction for virtual reality environments through user-defined commands; high-level libraries for emotion recognition in music: A review; integrating collaborative aspects in the design an interactive system in teaching of literacy to children with moderate cognitive impairment; mobile learning applications: Exploring location sensing mechanisms; proposal of an open hardware-software system for the recognition of emotions from physiological variables; usability evaluation of learning objects with augmented reality for smartphones: A reinterpretation of nielsen heuristics; world of knowledge: An application for learning assistance in the reading process for children in the literacy period; XP / architecture (XA): A collaborative learning process for agile methodologies when teams grow; academic emotions in programming learning: Women’s impact on the software sector; an empiric study of the use of mobile technology by users with intellectual disability; an information visualization application case to understand the world happiness report; childProgramming evolution, a method to increase the computational thinking skills in school; collaborative strategy with augmented reality for the development of algorithmic thinking; data acquisition system for the monitoring of attention in people and development of interfaces for commercial devices; debugging block-based programs; Design of interactive toy as support tool in STEM education for children with special needs.},
editor={Agredo-Delgado V., Ruiz P.H.},
publisher={Springer Verlag},
issn={18650929},
isbn={9783030052690},
language={English},
abbrev_source_title={Commun. Comput. Info. Sci.},
document_type={Conference Review},
source={Scopus},
}

@ARTICLE{JiménezToledo201970,
author={Jiménez Toledo, J.A. and Collazos, C.A. and Ortega Cantero, M. and Redondo, M.Á.},
title={Collaborative strategy with augmented reality for the development of algorithmic thinking},
journal={Communications in Computer and Information Science},
year={2019},
volume={847},
pages={70-82},
doi={10.1007/978-3-030-05270-6_6},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058525986&doi=10.1007%2f978-3-030-05270-6_6&partnerID=40&md5=fe5e2c72afc779a9c5f2cea34e285af7},
affiliation={Institución Universitaria CESMAG, Pasto, Colombia; Universidad del Cauca, Popayán, Colombia; Universidad de Castilla La Mancha, Castilla-La Mancha, Spain},
abstract={The development of algorithmic thinking is one of the most important concerns in the teaching-learning processes that must be taken into account for the development of a first Computer Programming course under the imperative paradigm. This article presents the results of the research obtained by combining collaborative processes with augmented reality tools as a didactic strategy for the development of algorithmic thinking in fundament programming teaching. The research was developed with students of first course of computer programming under a quasi-experimental design with the application of post-tests, whose data obtained were analyzed with the Student’s T-distribution. One of the activities of greater effort in the didactic area is to try to obtain maximum levels of attention in the student in each of the academic meetings in order to ensure better learning outcomes with the proposed strategies, for that reason, the study showed that the interactive didactic strategy enhanced the development of algorithmic thinking effectively. © 2019, Springer Nature Switzerland AG.},
author_keywords={Algorithmic thinking;  Augmented reality;  Collaborative strategy;  Computer programming},
keywords={Augmented reality;  Computer programming;  Curricula;  Learning algorithms;  Planning;  Students;  Teaching, Algorithmic thinking;  Augmented reality tools;  Collaborative process;  Collaborative strategies;  Computer programming course;  Programming teaching;  Quasi-experimental designs;  Teaching-learning process, Human computer interaction},
correspondence_address1={Jiménez Toledo, J.A.; Institución Universitaria CESMAGColombia; email: jajimenez@iucesmag.edu.co},
editor={Agredo-Delgado V., Ruiz P.H.},
publisher={Springer Verlag},
issn={18650929},
isbn={9783030052690},
language={English},
abbrev_source_title={Commun. Comput. Info. Sci.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Paravizo2019330,
author={Paravizo, E. and Braatz, D.},
title={Employing game engines for ergonomics analysis, design and education},
journal={Advances in Intelligent Systems and Computing},
year={2019},
volume={822},
pages={330-338},
doi={10.1007/978-3-319-96077-7_35},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052082253&doi=10.1007%2f978-3-319-96077-7_35&partnerID=40&md5=f556bf93a000d62446755f684e995143},
affiliation={Department of Production Engineering, Federal University of Sao Carlos, Sao Carlos, 13 565 905, Brazil},
abstract={Game Engines (GEs) are digital platforms generally employed to develop computer games and 3D applications using pre-existing modules and functionality (and thus speeding up development process). Several studies already investigate GEs application for education and training, collaborative design, facilities simulation and design, operational simulations and for the development of virtual and augmented reality applications. In this paper we present three virtual environments developed in a free to use GE and analyze them in terms of their goals, intended audience, interaction possibilities and overall design. Results highlight GEs affordances such as the development of high-quality graphics 3D environments, their real-time system nature, the possibility for digital human manikin’s customization, user agency, versatility in terms of possible interactions programming, among others, which make GEs powerful tools for ergonomics analysis, design and education. © Springer Nature Switzerland AG 2019.},
author_keywords={Digital human modelling;  Game engines;  Simulation;  Virtual environments},
keywords={Augmented reality;  Computer games;  Interactive computer systems;  Quality control;  Real time systems;  Virtual reality, Collaborative design;  Digital human modelling;  Education and training;  Game Engine;  High-quality graphics;  Operational simulations;  Simulation;  Virtual and augmented reality, Ergonomics},
correspondence_address1={Paravizo, E.; Department of Production Engineering, Federal University of Sao CarlosBrazil; email: esdras@dep.ufscar.br},
editor={Fujita Y., Bagnara S., Tartaglia R., Albolino S., Alexander T.},
publisher={Springer Verlag},
issn={21945357},
isbn={9783319960760},
language={English},
abbrev_source_title={Adv. Intell. Sys. Comput.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Chin2019927,
author={Chin, K.-Y. and Wang, C.-S. and Chen, Y.-L.},
title={Effects of an augmented reality-based mobile system on students’ learning achievements and motivation for a liberal arts course},
journal={Interactive Learning Environments},
year={2019},
volume={27},
number={7},
pages={927-941},
doi={10.1080/10494820.2018.1504308},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050666555&doi=10.1080%2f10494820.2018.1504308&partnerID=40&md5=f66ab291ec4055468a5a68d3e19263c6},
affiliation={Department of Digital Humanities, Aletheia University, New Taipei City, Taiwan; Department of Computer Science and Information Engineering, Aletheia University, New Taipei City, Taiwan; Department of Computer Science & Information Engineering, National Taipei University of Technology, Taipei City, Taiwan},
abstract={Although Augmented Reality (AR) technology has already been adopted into mobile learning environments, additional effort must be put towards providing strong evidence that AR-based mobile systems are excellent educational tools that make a positive impact in or outside of the classroom. Our study utilized a similar AR-based mobile learning system developed to authentically teach a liberal arts course at a Taiwanese university. Under controlled study environments, we were able to design a system that could impart relevant concepts from the course to students outside of the traditional classroom setting. Experimental results demonstrated that students with the opportunity to learn through the proposed system demonstrated higher learning motivation, had better learning performance and comprehension abilities than those studying via the conventional outdoor instruction approach. Moreover, the questionnaire survey conducted after our study revealed that “confidence” was the most highly rated motivational factor among students who used the proposed system, suggesting that students were quite motivated to learn using the novel system supplemented with technological advances because they felt more sure of their knowledge and performance. Thus, we believe that using the proposed system can effectively improve the learning outcomes of students enrolled in the liberal arts course, with the particular benefit of boosting confidence in gaining new knowledge, which leads to an improvement of overall learning performance and motivation. © 2018, © 2018 Informa UK Limited, trading as Taylor & Francis Group.},
author_keywords={augmented reality;  evaluation of CAL systems;  Human computer interaction;  interactive learning environments;  mobile learning},
correspondence_address1={Chen, Y.-L.; Department of Computer Science & Information Engineering, National Taipei University of TechnologyTaiwan; email: ylchen@csie.ntut.edu.tw},
publisher={Routledge},
issn={10494820},
language={English},
abbrev_source_title={Interact. Learn. Environ.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Fan20191553,
author={Fan, H.},
title={Application of augmented reality in the compilation and publication of cartographic textbooks},
journal={Advances in Intelligent Systems and Computing},
year={2019},
volume={809},
pages={1553-1559},
doi={10.1007/978-3-319-95588-9_138},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050617462&doi=10.1007%2f978-3-319-95588-9_138&partnerID=40&md5=34700add5bda34e2d17cfc756408554a},
affiliation={Beijing Institute of Technology, Beijing, China},
abstract={With the rapid development of network and information technology, the textbook is not only limited to the publication of the paper media, but also closely related to the Internet. Traditional teaching materials of cartography began to transform and upgrade to various forms, such as the combination of various new media forms and traditional books, the application of virtual reality VR technology and augmented reality AR technology in the publication of new form textbooks. This paper introduces the concept of augmented reality (AR) and feature technology, the basic paradigm and application mode of augmented reality technology is applied to the analysis of the publication of textbooks; compiling and writing introduces how to make use of the augmented reality technology and teaching resources for new forms of teaching. AR augmented reality technology in the mobile phone APP into the difficult understanding of the graphic graphics into a three-dimensional model, and can be multi angle, zoom, narrow the interactive view. The combination of AR augmented reality technology and cartography teaching materials can bring more 3D three-dimensional experience and enhance readability of textbooks, which not only makes learning easier, but also makes classroom learning more vivid and interesting. © 2019, Springer International Publishing AG, part of Springer Nature.},
author_keywords={AR;  Augmented reality technology;  Compilation and publication of cartographic textbooks},
keywords={Argon;  Augmented reality;  E-learning;  Engineering education;  Maps;  Teaching;  Textbooks;  Virtual reality, Application modes;  Augmented reality technology;  Classroom learning;  Feature technologies;  Teaching materials;  Teaching resources;  Three-dimensional model;  Traditional teachings, Cellular telephone systems},
correspondence_address1={Fan, H.; Beijing Institute of TechnologyChina; email: fhl@bit.edu.cn},
editor={Cocchiarella L.},
publisher={Springer Verlag},
issn={21945357},
isbn={9783319955872},
language={English},
abbrev_source_title={Adv. Intell. Sys. Comput.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Koesoema2019471,
author={Koesoema, A.P. and Swito, Y.S. and Riyani, A. and Aulia, M.N. and Utama, D.Q. and Azhar, T.N.},
title={Design of a smart multimodal earthquake response mobile application},
journal={IFMBE Proceedings},
year={2019},
volume={68},
number={1},
pages={471-474},
doi={10.1007/978-981-10-9035-6_87},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048283931&doi=10.1007%2f978-981-10-9035-6_87&partnerID=40&md5=a73c0762635a297b1181cf74ab6ddb9f},
affiliation={Indonesian EHealth and Telemedicine Society, Bandung, Indonesia; Biomedical Engineering, Institut Teknologi Bandung, Bandung, Indonesia; UNISBA, Bandung, Indonesia},
abstract={Indonesia is located in the Pacific Ring of fire, putting it under constant risk of natural disasters such as volcanic eruptions, earthquakes, and tsunamis. Earthquakes are one of the biggest threat of natural disasters in Indonesia and can strike anytime in any area. A key example is the 2004 Aceh earthquake, which caused a large tsunami, killing more than 160,000 people and destroyed more than 200 shops and homes. While Indonesia has significantly improved its disaster mitigation systems in the past decade, problems remain. Seismological stations are still relatively few and in between, community readiness and resilience for earthquakes remains low, and response activities are often hampered by lack of equipment, such as for finding potential survivors trapped in rubble. In order to help alleviate these issues, this paper describes the design of a smart multimodal earthquake response mobile application. The proposed system has four main functionalities, namely (1) broadcast of earthquake alert to mobile phones from the local earthquake measurement centre, (2) smart voice activated interactive guide to guide community members on how to react to an earthquake event and arrive to a safe place based on their current situation, (3) A system to search for trapped survivors based on Bluetooth and wifi hotspot emitted by survivors, and (4) recording of earthquake waves based on mobile phone accelerators to be used to build a more granular geospatial database on earthquake features. The system implements machine learning algorithm, utilizes voice, picture and text activated interface to match any situation’s need, and basic augmented reality to help guide users to a safe place. © Springer Nature Singapore Pte Ltd. 2019.},
author_keywords={First keyword;  Second keyword;  Third keyword},
keywords={Augmented reality;  Biomedical engineering;  Cellular telephone systems;  Cellular telephones;  Disasters;  Learning algorithms;  Learning systems;  mHealth;  Mobile computing;  Mobile phones;  Telephone sets;  Tsunamis;  Volcanoes, Disaster mitigation;  Earthquake measurements;  Earthquake response;  First keyword;  Geo-spatial database;  Mobile applications;  Second keyword;  Third keyword, Earthquakes},
correspondence_address1={Koesoema, A.P.; Indonesian EHealth and Telemedicine SocietyIndonesia; email: apkoesoema@gmail.com},
editor={Ibbott G.S., Lhotska L., Sukupova L., Lackovic I.},
publisher={Springer Verlag},
issn={16800737},
language={English},
abbrev_source_title={IFMBE Proc.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Mahmoudi201813,
author={Mahmoudi, M.T. and Zeraati, F.Z. and Yassini, P.},
title={A Color Sensing AR-Based Interactive Learning System for Kids},
journal={12th National and the 6th International Conference on e-Learning and e-Teaching, ICELET 2018},
year={2018},
pages={13-20},
doi={10.1109/ICELET.2018.8586762},
art_number={8586762},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061143230&doi=10.1109%2fICELET.2018.8586762&partnerID=40&md5=e47cc49e9aa9513f47a8864e462f72b9},
affiliation={Multimedia Research Group, IT Research Faculty, ICT Research Institute, Tehran, Iran; Computer Engineering and IT Department, AmirKabir University of Technology, Tehran, Iran},
abstract={In the last decade, there has been a rapid growth in applying Augmented Reality (AR) and Internet of Things (IoT) as emerging technologies in linking physical and virtual objects for educational purposes. Realizing the complex concepts in a way that learner be able to interact with, will not only elevate the learning passion, but also has a significant positive role on learning performance and student's engagement. According to the aforementioned points, in this paper, we propose a color sensing AR-Based interactive learning system for kids which helps them to scan and explore the colors and learn their corresponding words in Spanish language. Our aim is to explore the role of such an AR-IoT-based system on students' learning performance. To do this, an embedded system including a color sensor and a raspberry pi board was implemented and provided for the kids. By placing the sensor on the specially designed colored book, the light's color frequency is measured and RGB code is sent over the cloud using MQTT protocol. On the web application side, color data is fetched from the cloud server and learners will be provided with a real-time feedback with the corresponding animations and multimedia content that teaches colors in Spanish language. Students' learning performance was assessed using paired t-test based upon the results of their pre-test and post-test, before and after interacting with the system. The successful experimental results were achieved proving the effectiveness of the system on learning performance. © 2018 IEEE.},
author_keywords={Augmented reality;  color sensing;  interactive learning;  internet of things},
keywords={Augmented reality;  Color;  E-learning;  Educational technology;  Internet of things;  Students, Emerging technologies;  Interactive learning;  Interactive learning systems;  Internet of Things (IOT);  Learning performance;  Multimedia contents;  Real-time feedback;  Spanish language, Learning systems},
publisher={Institute of Electrical and Electronics Engineers Inc.},
isbn={9781538664964},
language={English},
abbrev_source_title={Natl. Int. Conf. e-Learn. e-Teach., ICELET},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Medina-Carrion2018,
author={Medina-Carrion, A. and Arias-Espinoza, P. and Robles-Bykbaev, V. and Robles-Bykbaev, Y. and Pesantez-Aviles, F. and Ortega, J.},
title={An interactive educational tool based on augmented reality, mobile applications and comic strips to teach children the Cañari and Inca cultures in the Ecuadorian context},
journal={Congreso Argentino de Ciencias de la Informatica y Desarrollos de Investigacion, CACIDI 2018},
year={2018},
doi={10.1109/CACIDI.2018.8584190},
art_number={8584190},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060682692&doi=10.1109%2fCACIDI.2018.8584190&partnerID=40&md5=4aeadd0ab4f97564d3b14d96e199e05a},
affiliation={GI-IATa, UNESCO Department on Support Technologies for Educational Inclusion, Universidad Politécnica Salesiana, Cuenca, Ecuador, Ecuador; Museo Pumapungo, Ministerio de Cultura Del Ecuador, Cuenca, Ecuador},
abstract={According to the United Nations Educational, Scientific and Cultural Organization (UNESCO), due of the rapidity of cultural change, safeguarding the world's tangible and intangible cultural heritage has become an increasingly complex and multidimensional undertaking. Therefore, it is fundamental for the children and youth of today to learn the culture, values, and traditions that define their identity as well as the identity of their nation. For these reasons in this paper, we present an interactive app aimed at supporting both teaching and rescuing the heritage of Cañari and Inca indigenous cultures. Our mobile app can be used at children's home or during the guided visits of one of the most important museums in Ecuador: the Pumapungo Museum. Likewise, the app can identify QR codes to show multimedia material to children, contains several 3D objects that are presented using Augmented Reality (AR), and incorporates a Natural Language Processing (NLP) module to determine the children's learning progress. In this line, it is important mentioning that children use the app to create small »stories» about the learned concepts. The app was tested in real guided visits in the museum with 30 children from three different schools (low and middle -income), and the results show high levels of interest in the contents and the app. © 2018 IEEE.},
author_keywords={Augmented reality (AR);  Expert System;  Interactive Application;  Mobile applications;  Natural language processing (NLP)},
keywords={Augmented reality;  Expert systems;  Mobile computing, Educational tools;  Intangible cultural heritages;  Interactive applications;  Learning progress;  Mobile applications;  Multimedia materials;  NAtural language processing;  United Nations educational , Scientific and Cultural Organization, Natural language processing systems},
publisher={Institute of Electrical and Electronics Engineers Inc.},
isbn={9781538654477},
language={English},
abbrev_source_title={Congr. Argent. de Cienc. de la Inform. y Desarro. de Investig., CACIDI},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Xi2018,
author={Xi, M. and Adcock, M. and McCulloch, J.},
title={Future agriculture farm management using augmented reality},
journal={2018 IEEE Workshop on Augmented and Virtual Realities for Good, VAR4Good 2018},
year={2018},
doi={10.1109/VAR4GOOD.2018.8576887},
art_number={8576887},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060465133&doi=10.1109%2fVAR4GOOD.2018.8576887&partnerID=40&md5=295e8ab0c72880b60597ade13c2df2cf},
affiliation={CSIRO, Australia},
abstract={Augmented reality (AR) technology is blooming in the past few years with a growing number of low-cost AR devices becoming available to the general public. AR techniques have demonstrated the capacity to optimise task efficiency in a broad range of industries and provide engaging entertainment and education experiences. However, the potential of AR has not yet been fully explored. One of the extremely underexplored areas is its application in broad agriculture sector. As a major source of food, agriculture has always been a national priority. Agriculture farming is highly labour-intensive and heavily relies on individual farmer's expertise, resulting in challenging farm management issues. We argue that AR can make critical contributions to the optimum management of agriculture farms. We take aquaculture ponds as an example, and presented three use cases to show how AR can potentially support more efficient farm management activities: water quality management, remote collaboration, and boardroom discussion. © 2018 IEEE.},
author_keywords={Artificial, augmented, and virtual realities;  Augmented reality;  Decision making;  Farm management;  H.5.1 [Information Interfaces and Presentation (e.g., HCI)]: Multimedia Information Systems;  Interactive data visualisation},
keywords={Augmented reality;  Data visualization;  Farms;  Information management;  Quality management;  Virtual reality;  Water conservation;  Water management;  Water quality, Agriculture sectors;  Aquaculture ponds;  Artificial , augmented;  Farm management;  ITS applications;  MultiMedia Information Systems;  Remote collaboration;  Task efficiencies, Decision making},
publisher={Institute of Electrical and Electronics Engineers Inc.},
isbn={9781538659779},
language={English},
abbrev_source_title={IEEE Workshop Augment. Virtual Realities Good, VAR4Good},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Setiawan2018,
author={Setiawan, A. and Rostianingsih, S. and Reinaldo Widodo, T.},
title={Application of Compound Bonding Based On Augmented Reality},
journal={MATEC Web of Conferences},
year={2018},
volume={248},
doi={10.1051/matecconf/201824805007},
art_number={05007},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059181688&doi=10.1051%2fmatecconf%2f201824805007&partnerID=40&md5=faa414c514fdb0946ded34f4c5f8a38f},
affiliation={Informatics Department, Christian University, Petra, 60236, Indonesia},
abstract={Augmented reality technology is very important in visualizing real objects or concepts. The advancement of computing equipment enables 3D modelling to be performed virtually with relatively easy processes. The appearance of 3D models in virtual is very interesting because it can be combined with interactive multimedia applications so that users can control the course of the application as needed. This augmented reality application has been through process testing, system testing on different mobile devices, and marker testing. The results of process testing indicate that every process on the application goes according to existing model design. Test results show that applications created using the library vuforia and Unity can run well. High school students show that as many as 84.6% who agree with using this application is more interesting than the usual method of learning so as to be able to recognize compound bonding using this application well. © 2018 The Authors.},
keywords={Augmented reality;  Interactive computer systems;  Mobile telecommunication systems;  Multimedia systems, 3D modelling;  Augmented reality applications;  Augmented reality technology;  High school students;  Interactive multimedia;  Method of learning;  Real objects;  System testing, Three dimensional computer graphics},
correspondence_address1={Setiawan, A.; Informatics Department, Christian UniversityIndonesia; email: alexxander@petra.ac.id},
editor={Desmiarti R., Mahyoedin Y., Hazmi A., Suherman H., Hadiguna R.A.},
publisher={EDP Sciences},
issn={2261236X},
language={English},
abbrev_source_title={MATEC Web Conf.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Chao2018248,
author={Chao, W.-H. and Yang, C.-Y. and Chang, R.-C.},
title={A Study of the Interactive Mathematics Mobile Application Development},
journal={1st IEEE International Conference on Knowledge Innovation and Invention, ICKII 2018},
year={2018},
pages={248-249},
doi={10.1109/ICKII.2018.8569126},
art_number={8569126},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060715471&doi=10.1109%2fICKII.2018.8569126&partnerID=40&md5=b0f0f854e6f34b1a496a909d7a55091b},
affiliation={Department of Digital Media Design, Chienkuo Technology University, Changhua City, Taiwan; College of Creative Design, Asia University, Taichung City, Taiwan; Department of Creative Product and Game Design, Chienkuo Technology University, Taichung City, Taiwan; Department of Technology Crime Investigation, Taiwan Police College, Taipei, Taiwan},
abstract={This study has developed an interactive learning App through Augmented Reality (AR) technology. This AR math learning App provides with interactive operations such as combination, stacking, dismantling, multi-angle rotation, and so on. Teachers can apply this App to teach by replacing teaching materials like traditional stack cartons or videos. Students can repeatedly hand-operate and practice through mobile devices to increase the understanding of the concept of space and understanding 3D body. The study has adopted standard way of experiments to implement the learning effects evaluation of 5th grade elementary students and finds there are significant differences in learning outcomes. The study also applies the technology accepting models and semi-structured interviews to understand how teachers and students react after applying the App. The experiments indicate that the AR mathematics learning App developed by the study can make learners easily apply and maintain a positive attitude, which shows it can improve the motivation of learning. © 2018 IEEE.},
author_keywords={Augmented Reality;  Interactive learning;  Mathematics;  Mobile App},
keywords={Augmented reality;  Educational technology;  Learning systems;  Mathematical techniques;  Mobile computing;  Patents and inventions;  Students, Elementary students;  Interactive learning;  Interactive operations;  Mathematics learning;  Mobile app;  Mobile application development;  Semi structured interviews;  Teaching materials, E-learning},
editor={Meen T.-H.},
publisher={Institute of Electrical and Electronics Engineers Inc.},
isbn={9781538652671},
language={English},
abbrev_source_title={IEEE Int. Conf. Knowl. Innov. Invent., ICKII},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Wang2018301,
author={Wang, P.-H. and Hsu, T.},
title={Application of amplified reality to the cognitive effect of children with attention deficit hyperactivity disorder(ADHD)-An example of Italian Chicco-app interactive building blocks},
journal={1st IEEE International Conference on Knowledge Innovation and Invention, ICKII 2018},
year={2018},
pages={301-302},
doi={10.1109/ICKII.2018.8569170},
art_number={8569170},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060694485&doi=10.1109%2fICKII.2018.8569170&partnerID=40&md5=7b21ee44f10ce21b7ac2f86ed8b94ed7},
affiliation={Department of Digital Multimedia Arts Center, Taipei, Taiwan},
abstract={For children with attention deficit hyperactivity disorder (ADHD), most are mixed symptoms, such as Asperger syndrome (AS), Tourette's syndrome (TS), Anxiety disorders, and so on, just collectively known as ADHD, but the most obvious symptoms are inattention, learning disabilities, emotional disorders, sensory integration abnormalities. Therefore, this research focuses on building blocks and Augmented Reality (AR) links, using the building blocks of animals as the theme, coupled with the operation of building blocks to enhance patience, touch, construction and other capabilities, through the interaction of AR and dynamic performance can attract attention to ADHD children's eyes and attention. There are two objectives in this study: Firstly, is to have a positive interaction with AR for children under six years of age who have ADHD. Secondly is to increase the difficulty of interaction, improve the continuous response to designed AR and attract; Not only use the building blocks to interact, but also through the AR increase in children's patience, initiative, associated with the combination of AR and tablet. From this trend, it can increase the child's touch operation action. Finally, through interviews, experimental teaching, observation and evaluation, this study explores the effects of APP interactive blocks on the learning of ADHD children. Building Blocks. © 2018 IEEE.},
author_keywords={ADHD Children;  Augmented Reality;  Building Blocks;  Interactivity},
keywords={Augmented reality;  Diseases;  E-learning;  Patents and inventions, ADHD Children;  Attention deficit hyperactivity disorder;  Building blockes;  Experimental teachings;  Interactivity;  Learning disabilities;  Positive interaction;  Tourette's syndromes, Buildings},
editor={Meen T.-H.},
publisher={Institute of Electrical and Electronics Engineers Inc.},
isbn={9781538652671},
language={English},
abbrev_source_title={IEEE Int. Conf. Knowl. Innov. Invent., ICKII},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Guler2018,
author={Guler, O. and Yucedag, I.},
title={Developing an CNC lathe augmented reality application for industrial maintanance training},
journal={ISMSIT 2018 - 2nd International Symposium on Multidisciplinary Studies and Innovative Technologies, Proceedings},
year={2018},
doi={10.1109/ISMSIT.2018.8567255},
art_number={8567255},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060795531&doi=10.1109%2fISMSIT.2018.8567255&partnerID=40&md5=c1ba6579ed83daf935b309b44847c9ae},
affiliation={Electrical-Electronic and Computer Engineering, Duzce University, Duzce, Turkey; Computer Engineering, Duzce University, Duzce, Turkey},
abstract={In this study, developing an augmented reality training application for CNC (computer numerical control) lathe looms for industrial maintenance and repair training was described. The content has been developed for the CNC LATHE TEARS module, which is trained in the field of Machine Technologies to be operated on mobile like smart phone, tablet, etc. devices. First a training scenario was prepared for the development of the application. Then three dimensional model of a CNC lathe was modelled. Models designed to develop the augmented reality application have been transferred to the Unity3D game engine software, and using the Vuforia plug-in, a marker-based augmented reality application has been developed to work on android operating system based mobile devices like smartphone, tablet, etc. It is considered that using the developed application in the training of the students of the Machine Technologies Area in the institutions providing vocational and technical education in the official and private institutions affiliated to the Ministry of National Education, motivation of the students and the success rates of the courses will increase. At the same time, the developed application will provide facilitate the training of the users, increase the quality in production and faster maintenance and installation. © 2018 IEEE.},
author_keywords={augmented reality;  CNC Lathe;  interactive system;  mobile software},
keywords={Augmented reality;  Computer control systems;  Education computing;  Lathes;  Repair;  Smartphones;  Students, Augmented reality applications;  CNC lathe;  Computer numerical control;  Industrial maintenance;  Interactive system;  Mobile softwares;  Three-dimensional model;  Vocational and technical educations, Application programs},
publisher={Institute of Electrical and Electronics Engineers Inc.},
isbn={9781538641842},
language={English},
abbrev_source_title={ISMSIT - Int. Symp. Multidiscip. Stud. Innov. Technol., Proc.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Chen2018255,
author={Chen, I.-C.},
title={The application of augmented reality in English phonics learning performance of ESL young learners},
journal={Proceedings - 2018 1st International Cognitive Cities Conference, IC3 2018},
year={2018},
pages={255-259},
doi={10.1109/IC3.2018.000-7},
art_number={8567219},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060395737&doi=10.1109%2fIC3.2018.000-7&partnerID=40&md5=7ac444556481491b28f8a5e3c9563407},
affiliation={Graduate School of Education Communications and Technology, National Taipei Uviversity of Education, Taipei, Taiwan},
abstract={Phonics is an essential foundation needed to build up reading and writing abilities for English learning. However, most students who learned English as a second language have not learned phonics systematically and appropriately, resulting in failed pronunciation in reading and writing English words. For eliminating struggles and barriers in the process of English learning, the new technology and interactive apps are a dynamic avenue assisting with understanding and retention for ESL elementary students. The study was conducted with augmented reality (AR) technology to integrate virtual objects and video clips into the interactive learning environment for second language learning. The effects of students' phonics learning performance were assessed. The results indicated that AR technology had validated the possibility of carrying out digital immersive language learning and embodied cognition, regardless of the drills of rote memorization. The concerns of the curriculum design based on the incorporation of the AR technology and learning materials are discussed further to improve phonics efficiency and competency for English as second language learners. © 2018 IEEE.},
author_keywords={Augmented reality;  ESL;  Phonics learning},
keywords={Augmented reality;  Computer aided instruction;  Students, Elementary students;  Embodied cognition;  English as a second language;  English as second languages;  Interactive learning environment;  Learning materials;  Learning performance;  Phonics learning, Learning systems},
correspondence_address1={Chen, I.-C.; Graduate School of Education Communications and Technology, National Taipei Uviversity of EducationTaiwan; email: lisa2chen2@gmail.com},
publisher={Institute of Electrical and Electronics Engineers Inc.},
isbn={9781538650592},
language={English},
abbrev_source_title={Proc. - Int. Cogn. Cities Conf., IC3},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Wilujeng2018,
author={Wilujeng, S. and Chamidah, D. and Wahyuningtyas, E.},
title={Learning development model biological material «flowers wijaya kusuma (Epiphyllum anguliger)" by using augmented reality media to facilitate independent learning students},
journal={IOP Conference Series: Materials Science and Engineering},
year={2018},
volume={434},
number={1},
doi={10.1088/1757-899X/434/1/012101},
art_number={012101},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058325229&doi=10.1088%2f1757-899X%2f434%2f1%2f012101&partnerID=40&md5=50a786d55e321b555a187c967693252d},
affiliation={Universitas Wijaya Kusuma Surabaya, Surabaya, Indonesia},
abstract={With the development of technology today, android mobile have many benefits for humans in various fields, namely in the field of information, education, business and communication. This study aims to create a media application as a model of biology learning to introduce flowers Wijaya Kusuma to biology students are classified as a rare flower and has a uniqueness in the blossoming of flowers that sometimes humans rarely to be able to find where and when the right time for the flowering process Wijaya Kusuma. Based on that, the researchers analyzed and looked for solutions how to introduce the interest of Wijaya Kusuma to the students in the biology learning process by utilizing Augmented Reality (AR) technology. AR as the incorporation of real and virtual objects in real environments, runs interactively in real time and there is integration between the three dimensions (3D). Merging of real and virtual objects is possible with the appropriate display technology. In this research-based augmented reality application created with the marker method which uses a marker for the detection of objects in combining the digital world and the real world. There are 5 markers a marker to display animations and 3D objects as well as information of interest Wijaya Kusuma, the information delivered include voice and text that can make the application interactive. This application is very useful for biology students who study the course of Plant Physiology. © Published under licence by IOP Publishing Ltd.},
keywords={Augmented reality;  Biological materials;  Object detection;  Plants (botany);  Students, Augmented reality applications;  Development model;  Display technologies;  Flowering process;  Independent learning;  Media application;  Plant physiology;  Real environments, Education computing},
editor={Nandiyanto A.B.D., Abdullah A.G.},
publisher={Institute of Physics Publishing},
issn={17578981},
language={English},
abbrev_source_title={IOP Conf. Ser. Mater. Sci. Eng.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Agustina2018,
author={Agustina, R. and Sutadji, E. and Purnomo and Suprianto, D. and Kusumawati, E. and Hudha, M.N.D. and Afif, M.},
title={Analysis of implementation Augmented Reality (AR) introduction of temple and ancient objects based on android to increasing student learning outcomes},
journal={IOP Conference Series: Materials Science and Engineering},
year={2018},
volume={434},
number={1},
doi={10.1088/1757-899X/434/1/012265},
art_number={012265},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058305104&doi=10.1088%2f1757-899X%2f434%2f1%2f012265&partnerID=40&md5=278173ad8ee866e1c233a62a09811b3c},
affiliation={Science and Technology Faculty, Universitas Kanjuruhan Malang, Indonesia; Faculty of Engineering, State University of Malang, Indonesia; Information Technology, State Polytechnic of Malang, Indonesia; Animal Husbandry Faculty, Universitas Kanjuruhan Malang, Indonesia},
abstract={Malang is one of the tourist areas in Indonesia which has many tourist attractions, among them the form of the temple. The temple and the Archaeological Museum of history that cannot be eliminated from our country, this time temples and Archaeological Objects rarely known or even visited by the public. This is particularly worrying given the duty as good citizens, especially the younger generation successor to the nation is to maintain and preserve the cultural heritage of their ancestors. distance and time is a major obstacle that makes the temples and archaeological objects are less attractive to the younger generation especially school students, therefore designed an application that implements Augmented Reality to support the introduction of interactive learning Temples and Archaeological Objects based on Android. A questionnaire was developed using the USE Questionnaire with modifications as needed research. While the analysis of data using Likert scale calculations. Based on the results of the analysis of the implementation of the game as a learning medium can be concluded that the application can be applied and get approval from the user of 85.85%. Based on the result of student learning result test, it can be concluded that the application with Augmented Reality technology helps them to study the temples and ancient objects, with the increase of Student Learning Result of 36.67% © Published under licence by IOP Publishing Ltd.},
keywords={Android (operating system);  Augmented reality;  Historic preservation;  Surveys, Analysis of data;  Archaeological objects;  Augmented reality technology;  Cultural heritages;  Interactive learning;  Student learning outcomes;  Tourist attractions;  Younger generations, Students},
editor={Nandiyanto A.B.D., Abdullah A.G.},
publisher={Institute of Physics Publishing},
issn={17578981},
language={English},
abbrev_source_title={IOP Conf. Ser. Mater. Sci. Eng.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Seo2018,
author={Seo, J.H. and Payne, A. and Malone, E. and Smith, B.M. and Cook, M. and Sueda, S. and Heymann, B. and Bruner, M. and Pine, M.},
title={Muscle Action VR: To support embodied learning foundations of biomechanics in musculoskeletal system},
journal={SIGGRAPH Asia 2018 Virtual and Augmented Reality, SA 2018},
year={2018},
doi={10.1145/3275495.3275505},
art_number={a12},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061337455&doi=10.1145%2f3275495.3275505&partnerID=40&md5=51dc23fef0328b9b8e7a12dcd5e34158},
affiliation={Soft Interaction Lab, Dept. of Visualization, TAMU, United States; Dept. of Veterinary Integrative Biosciences, TAMU, United States; Dept. of Computer Science, TAMU, United States; Dept. of Visualization, TAMU, United States},
abstract={Traditional anatomy education has struggled with teaching students muscle movements in the mindset of three-dimensional anatomical structure. We present Muscle Action VR, an embodied learning virtual reality system that allows students to explore the effects that muscles have on the body. This application was created for studying musculoskeletal structures through playful and creative engagement, while staying accurate to anatomical structures and terminology. Users learn the basics of the biomechanics of human anatomy by either moving their own body with VIVE trackers, or directly manipulating specific muscles using VIVE controllers. We believe this application contributes to teach three-dimensional spatial awareness and foundational biomechanics in anatomy education. © 2018 Copyright held by the owner/author(s).},
author_keywords={Anatomy education;  Biomechanics;  Embodied learning;  Muscle movement;  Virtual reality},
keywords={Augmented reality;  Biomechanics;  Biophysics;  Interactive computer graphics;  Students;  Virtual reality, Anatomical structures;  Anatomy educations;  Embodied learning;  Human anatomy;  Muscle movement;  Musculo-skeletal structures;  Spatial awareness;  Virtual reality system, Muscle},
publisher={Association for Computing Machinery, Inc},
isbn={9781450360289},
language={English},
abbrev_source_title={SIGGRAPH Asia Virtual Augment. Reality, SA},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Brown2018620,
author={Brown, R. and Turkay, S. and Sitbon, L.},
title={Educational virtuality: Cognitive benefits, design processes and new frontiers},
journal={ACM International Conference Proceeding Series},
year={2018},
pages={620-622},
doi={10.1145/3292147.3295498},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061296184&doi=10.1145%2f3292147.3295498&partnerID=40&md5=cd3c7f2f4d1cfccef2ee903a61f512ac},
affiliation={School of Electrical Engineering and Computer Science, QUT Brisbane, Qld, Australia},
abstract={Virtuality, often expressed via technologies such as Virtual Reality (VR) or Augmented Reality (AR) has become a staple of media news, cultural artefacts (e.g. Ready Player One) and much research in universities and IT companies. Since the inception of the Oculus Rift as an accessible head mounted display (HMD) for building VR applications the industry has exploded into a potentially $108 billion industry by 2021 [1]. Australia has industry and research communities as well performing research into the use of VR in entertainment, video, cultural heritage as well as low level hardware topics such as implementations of wireless VR HMDs. Various groups in Australia are collaborating and forming a robust presence in the research and startup spheres. We wish to establish with this workshop a focus for the research community in Australia in the direction of education, in particular, to deal with issues local to Australia in areas of inclusiveness and diversity. In particular, this workshop aims to draw together a group of VR/AR researchers to explore the boundaries of immersive virtuality in education and to push into new territories identified from the workshop. © 2018 Copyright is held by the owner/author(s).},
author_keywords={Augmented Reality;  Disability;  Distance;  Diversity;  Education;  Virtual Reality;  Virtuality},
keywords={Augmented reality;  Education;  Helmet mounted displays;  Human computer interaction;  Interactive computer systems;  Virtual reality, Cultural heritages;  Disability;  Distance;  Diversity;  Head mounted displays;  Research communities;  Via technologies;  Virtuality, E-learning},
editor={Morrison A., Buchanan G., Waycott J., Billinghurst M., Stevenson D., Choi J.H.-J., Billinghurst M., Kelly R., McKay D., Lugmayr A.},
publisher={Association for Computing Machinery},
isbn={9781450361880},
language={English},
abbrev_source_title={ACM Int. Conf. Proc. Ser.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{PridhviKrishna201872,
author={Pridhvi Krishna, M.V. and Mehta, S. and Verma, S. and Rane, S.},
title={Mixed reality in smart computing education system},
journal={Proceedings of the International Conference on Smart Systems and Inventive Technology, ICSSIT 2018},
year={2018},
pages={72-75},
doi={10.1109/ICSSIT.2018.8748813},
art_number={8748813},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069206004&doi=10.1109%2fICSSIT.2018.8748813&partnerID=40&md5=0905d45c812c42725c51353a87c54262},
affiliation={Computer Engineering, Army Institute of Technology, Pune, MH, India},
abstract={One of the technologies that has been showing possibilities of application in educational environments is the Mixed Reality (MR) comprising of both Augmented Reality(AR) and virtual Reality(VR), in addition to its application to other fields such as tourism, advertising, video games, among others. The primary reason for this research work is to depict and condense trials with production training and education applications utilizing mixed reality gadgets. The entry of new and further developed mobile devices opens up more opportunities for the applications to develop and be circulated. This paper tries to build upon the current state of mixed reality and its application in education. The first segment describes basic structure of mixed reality and its different parts. Following segments give a definitive structure of some experimental applications that were developed for the mixed reality, with the inference taken from the data of experiment done by the National university of Columbia on secondary school students and lastly, the paper shows the benefits of those applications over the traditional teaching methods and the basic user reactions to them. © 2018 IEEE.},
author_keywords={Augmented Reality;  High-End;  Mixed Reality;  Mobile Devices;  Teaching-Learning Processes;  Virtual Reality;  Virtualization},
keywords={Augmented reality;  Interactive computer graphics;  Mobile computing;  Virtual reality;  Virtualization, Educational environment;  Experimental application;  High-End;  ITS applications;  Secondary schools;  Teaching methods;  Teaching-learning process;  Training and education, Mixed reality},
publisher={Institute of Electrical and Electronics Engineers Inc.},
isbn={9781538658734},
language={English},
abbrev_source_title={Proc. Int. Conf. Smart Syst. Inventive Technol., ICSSIT},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Thiwanka2018,
author={Thiwanka, N. and Chamodika, U. and Priyankara, L. and Sumathipala, S. and Weerasuriya, G.T.},
title={Augmented Reality Based Breadboard Circuit Building Guide Application},
journal={2018 3rd International Conference on Information Technology Research, ICITR 2018},
year={2018},
doi={10.1109/ICITR.2018.8736156},
art_number={8736156},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068469846&doi=10.1109%2fICITR.2018.8736156&partnerID=40&md5=f7768f21e0746f5a94ea931d8801eea1},
affiliation={Faculty of Information Technology, University of Moratuwa, Moratuwa, Sri Lanka},
abstract={Building circuits on breadboards is an activity which requires a lot of attention and thinking. If there is a way to guide this process by using modern technologies, the learning process can be made more effective and interactive. This study proposes a solution that provides students with an augmented reality visualization of the expected circuit on a breadboard before they actually make the circuit. The proposed system can be divided into four main modules based on their functionality (a) extracting possible information from the electronic components, (b) scanning circuit diagrams for identifying circuit symbols and their connectivity, (c) finding the appropriate arrangement of the electronic components on the breadboard and (d) using augmented reality to visualize the circuit on a breadboard. This solution provides an innovative approach to facilitate the learning process of students by making electronic circuit building interesting and interactive. © 2018 IEEE.},
author_keywords={augmented reality;  convolutional neural networks;  deep learning;  image processing;  transfer learning},
keywords={Augmented reality;  Deep learning;  Deep neural networks;  Engineering research;  Image processing;  Network components;  Neural networks;  Timing circuits, Circuit diagrams;  Convolutional neural network;  Electronic component;  Innovative approaches;  Learning process;  Modern technologies;  Reality visualization;  Transfer learning, Electric network analysis},
publisher={Institute of Electrical and Electronics Engineers Inc.},
isbn={9781728114705},
language={English},
abbrev_source_title={Int. Conf. Inf. Technol. Res., ICITR},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Schwelling2018,
author={Schwelling, E. and Yoo, K.},
title={Automatic 3D modeling of artwork and visualizing audio in an augmented reality environment},
journal={Proceedings of the ACM Symposium on Virtual Reality Software and Technology, VRST},
year={2018},
doi={10.1145/3281505.3281617},
art_number={3281617},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060960404&doi=10.1145%2f3281505.3281617&partnerID=40&md5=c4196a4c30552609f623934437de05a1},
affiliation={University of Maryland, College Park, MD, United States},
abstract={In recent years, traditional art museums have begun to use AR/VR technology to make visits more engaging and interactive. This paper details an application which provides features designed to be immediately engaging and educational to museum visitors within an AR view. The application superimposes an automatically generated 3D representation over a scanned artwork, along with the work’s authorship, title, and date of creation. A GUI allows the user to exaggerate or decrease the depth scale of the 3D representation, as well as to search for related works of music. Given this music as audio input, the generated 3D model will act as an audio visualizer by changing depth scale based on input frequency. © 2018 Copyright held by the owner/author(s).},
author_keywords={3D model generation;  Art museum;  Audio visualization;  Augmented reality;  Education;  Music},
keywords={Audio acoustics;  Augmented reality;  Education;  Museums;  Three dimensional computer graphics;  Virtual reality, 3d representations;  Art museums;  Audio visualization;  Automatic 3D modeling;  Automatically generated;  Input frequency;  Museum visitor;  Music, 3D modeling},
editor={Spencer S.N.},
publisher={Association for Computing Machinery},
isbn={9781450360869},
language={English},
abbrev_source_title={Proc. ACM Symp. Virtual Reality Softw. Technol. VRST},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Schwelling2018,
author={Schwelling, E. and Yoo, K.},
title={Automatic 3D modeling of artwork and visualizing audio in an augmented reality environment},
journal={Proceedings of the ACM Symposium on Virtual Reality Software and Technology, VRST},
year={2018},
doi={10.1145/3281505.3281576},
art_number={3281576},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060950321&doi=10.1145%2f3281505.3281576&partnerID=40&md5=ee44c70f5fe4e2f046d55dff26ef34bc},
affiliation={University of Maryland, College Park, MD, United States},
abstract={In recent years, traditional art museums have begun to use AR/VR technology to make visits more engaging and interactive. This paper details an application which provides features designed to be immediately engaging and educational to museum visitors within an AR view. The application superimposes an automatically generated 3D representation over a scanned artwork, along with the work’s authorship, title, and date of creation. A GUI allows the user to exaggerate or decrease the depth scale of the 3D representation, as well as to search for related works of music. Given this music as audio input, the generated 3D model will act as an audio visualizer by changing depth scale based on input frequency. © 2018 Copyright held by the owner/author(s).},
author_keywords={3D model generation;  Art museum;  Audio visualization;  Augmented reality;  Education;  Music},
keywords={Audio acoustics;  Augmented reality;  Education;  Museums;  Three dimensional computer graphics;  Virtual reality, 3d representations;  Art museums;  Audio visualization;  Automatic 3D modeling;  Automatically generated;  Input frequency;  Museum visitor;  Music, 3D modeling},
editor={Spencer S.N.},
publisher={Association for Computing Machinery},
isbn={9781450360869},
language={English},
abbrev_source_title={Proc. ACM Symp. Virtual Reality Softw. Technol. VRST},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Seki2018,
author={Seki, E. and Kamei, S. and Hada, H.},
title={plARy: Sound augmented reality system using video game background music},
journal={Proceedings of the ACM Symposium on Virtual Reality Software and Technology, VRST},
year={2018},
doi={10.1145/3281505.3281624},
art_number={3281624},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060931667&doi=10.1145%2f3281505.3281624&partnerID=40&md5=437817bd6e7e0a59ade91d467c572ebe},
affiliation={Tokyo University of Technology, Tokyo, Japan; Nagasaki, Japan},
abstract={The authors of this paper explored the possibility of enhancing reality interpretation by synchronizing real-life situation with video-game soundtrack. “plARy” is a music based augmented reality application that immerses users in a world of video games with playing soundtracks, enhancing user’s interpretation of the real world. By playing known game music according to the locations of individual users, they will recall the scenes and emotions experienced while playing the game based on users’ previous learning. The authors of this paper implemented a system that uses Apple iBeacon for proximity detection and evaluated it through experiment. From participants reviews, many people answered that they felt they had imagined a world of the game, and felt that the background music became associated with locations. © 2018 Copyright held by the owner/author(s).},
author_keywords={Augmented Reality;  Location-based;  Music;  Video game},
keywords={Augmented reality;  Felt;  Interactive computer graphics;  Location;  Sound recording;  Virtual reality, Augmented reality applications;  Augmented reality systems;  Background musics;  Location based;  Music;  Proximity detection;  Real-world;  Video game, Human computer interaction},
editor={Spencer S.N.},
publisher={Association for Computing Machinery},
isbn={9781450360869},
language={English},
abbrev_source_title={Proc. ACM Symp. Virtual Reality Softw. Technol. VRST},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Niu2018434,
author={Niu, X. and Xu, X. and Cheng, L. and Cai, S.},
title={A comparative study on achievement degree of teaching objectives based on an interactive AR physical-simulation experimental procedure},
journal={ICCE 2018 - 26th International Conference on Computers in Education, Main Conference Proceedings},
year={2018},
pages={434-439},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060027994&partnerID=40&md5=9a242b5a09bff9d951d8a051152b7673},
affiliation={VR/AR + Education Lab., School of Educational Technology, Faculty of Education, Beijing Normal University, China; Beijing Advanced Innovation Center for Future Education, Beijing Normal University, China; Joint Laboratory for Mobile Learning, Ministry of Education-China Mobile Communications Corporation, Beijing Normal University, China},
abstract={The progress of mobile devices and augmented reality (AR) plays a great role in integrating information technology and classroom teaching. By integrating field research into exploration-based experimental teaching activities, this study developed an interactive AR physical-simulation experimental procedure and created an evaluation model of Knowledge-Attitude-Process teaching objectives. During classroom teaching, the AR physical-simulation experimental procedure can present experimental models intuitively to encourage students to really interact with the AR experimental environment and enhance learning and teaching effects of experimental courses. This study researched influences of the procedure on achievement of teaching objectives of students. In this study, 70 eighth-grade students were randomly divided into an experimental group and a control group. According to descriptive statistics analysis of results of pre-tests, post-tests and questionnaire surveys, the achievement degree of teaching objectives of students who used this procedure was better than that of those who used an ordinary physical-simulation laboratory. Therefore, the interactive AR physical-simulation experimental procedure played an active role in helping students master scientific experiments and improving their inquiry ability. © 2018 Asia-Pacific Society for Computers in Education. All rights reserved.},
author_keywords={Augmented reality;  Interaction;  Scientific inquiry},
keywords={Augmented reality;  Education computing;  Surveys, Descriptive statistics;  Experimental environment;  Experimental procedure;  Experimental teachings;  Integrating information;  Interaction;  Scientific experiments;  Scientific inquiry, Students},
editor={Rodrigo M.M.T., Yang J.-C., Wong L.-H., Chang M.},
publisher={Asia-Pacific Society for Computers in Education},
isbn={9789869401289},
language={English},
abbrev_source_title={ICCE - Int. Conf. Comput. Educ., Main Conf. Proc.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Vidal2018589,
author={Vidal, E.C.E., Jr. and Mendoza, M.L. and Samaco, J.D. and Santos, J.M. and Diy, W.D. and Dl Casano, J. and Agapito, J.L. and Rodrigo, M.M.T.},
title={Igpaw: Loyola - Design of a campus-wide augmented reality game using MAGIS},
journal={ICCE 2018 - 26th International Conference on Computers in Education, Main Conference Proceedings},
year={2018},
pages={589-594},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060015853&partnerID=40&md5=1de7e110b8c33458bbf73fae612f1bb2},
affiliation={Ateneo Laboratory for the Learning Sciences, Ateneo de Manila University, Philippines; Ateneo de Naga University, Naga City, Philippines},
abstract={We present Igpaw: Loyola, a new location-based mobile AR (augmented reality) adventure game designed to be played within the campus grounds of the Ateneo de Manila University. Igpaw: Loyola improves upon its predecessor, Igpaw: Intramuros, by upgrading gameplay mechanics to accommodate lengthier learning modules, improving the usability of both interactive (AR) and navigation (non-AR) portions of the game, and enhancing the game authoring process with the help of an improved version of the MAGIS (Mobile Augmented-Reality Game-Engine for Instructional Support) framework. A preliminary user evaluation is also presented. © 2018 Asia-Pacific Society for Computers in Education. All rights reserved.},
author_keywords={Augmented reality;  Educational game design;  Usability},
keywords={Augmented reality, Adventure games;  Authoring process;  Educational game;  Instructional support;  Learning modules;  Mobile augmented reality;  Usability;  User evaluations, Education computing},
editor={Rodrigo M.M.T., Yang J.-C., Wong L.-H., Chang M.},
publisher={Asia-Pacific Society for Computers in Education},
isbn={9789869401289},
language={English},
abbrev_source_title={ICCE - Int. Conf. Comput. Educ., Main Conf. Proc.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Cahyono2018299,
author={Cahyono, B. and Firdaus, M.B. and Budiman, E. and Wati, M.},
title={Augmented Reality Applied to Geometry Education},
journal={Proceedings - 2nd East Indonesia Conference on Computer and Information Technology: Internet of Things for Industry, EIConCIT 2018},
year={2018},
pages={299-303},
doi={10.1109/EIConCIT.2018.8878553},
art_number={8878553},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074888917&doi=10.1109%2fEIConCIT.2018.8878553&partnerID=40&md5=3b728c5eeaacf579d9164097a022043e},
affiliation={Faculty of Computer Science and Information Technology, Mulawarman University, Samarinda, Indonesia},
abstract={Educational media for students to understand 3D geometry is currently conventional, schools and teaching staff find it difficult to get teaching aids as educational media tools to build 3D space. In terms of cognitive aspects, students also find it difficult to understand objects that build 3D space, because without teaching aids they are only able to imagine or imagine themselves building 3D space objects. Augmented reality (AR) is a good medium for deep collaborative simulation. This AR modeling uses marker based where the marker is incorporated in 2D geometry. In this study, we design and build applications of interactive education models on cubes, tubes, conical geometry objects as a means of learning elementary school mathematics. It is expected that this application can be a tool for mathematics teachers in delivering 3D space building material. The results obtained are 3D geometry modeling successfully read the marker and if the 3D AR model is clicked then a formula will appear from each geometry. © 2018 IEEE.},
author_keywords={augmented reality;  geometry;  interactive educational model application},
keywords={Augmented reality;  Education computing;  Geometry;  Students, Cognitive aspects;  Collaborative simulation;  Conical geometry;  Design and build;  Educational models;  Elementary schools;  Interactive education;  Mathematics teacher, 3D modeling},
editor={Haviluddin H., Wibawa A.P., Purnawansyah P., Riza L.S., Azis H., Salim Y., Malani R., Gaffar A.F.O., Darwis H., Astuti W., Fattah F., Satra R., Herman H., Hasanuddin T., Manga A.R.},
publisher={Institute of Electrical and Electronics Engineers Inc.},
isbn={9781538680483},
language={English},
abbrev_source_title={Proc. - East Indonesia Conf. Comput. Inf. Technol.: Internet Things Ind., EIConCIT},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Luna2018181,
author={Luna, J. and Treacy, R. and Hasegawa, T. and Campbell, A. and Mangina, E.},
title={Words Worth Learning-Augmented Literacy Content for ADHD Students},
journal={2018 IEEE Games, Entertainment, Media Conference, GEM 2018},
year={2018},
pages={181-188},
doi={10.1109/GEM.2018.8516483},
art_number={8516483},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056993616&doi=10.1109%2fGEM.2018.8516483&partnerID=40&md5=9ee95d57812915d537ea1f83908f721e},
affiliation={School of Computer Science, University College Dublin, Dublin, Ireland; WordsWorth Learning Limited, Dublin, Ireland},
abstract={3-9% school-aged children in Ireland are estimated to be affected by ADHD (Attention Deficit Hyperactivity Disorder), according to HSE (Health Service Executive). Typical co-morbid conditions include: Anxiety disorder, oppositional defiant disorder, conduct disorder, depression, sleep problems, epilepsy, learning difficulties, etc. As such, unless early intervention properly takes place, performance of children with ADHD at school tends to be compromised (e.g. leaving school early and substance abuse etc.). The current work presents a preliminary investigation of creating 3D Learning Objects (3DLO) using Augmented Reality (AR), following the IEEE Learning Objects standards, to enhance an established online literacy programme, WordsWorthLearning (WWL). The methodology and experimentation of creating AR 3DLO is proposed, followed by a pilot evaluation, aiming to provide a foundation of a system that can support interactive educational content, service, assessment, and feedback for children with ADHD and their parents and teachers. © 2018 IEEE.},
author_keywords={3D Learning Objects;  Assistive Technology;  Attention Deficit Hyperactivity Disorder (ADHD);  Augmented Reality (AR)},
keywords={Augmented reality;  Diseases;  IEEE Standards, Assistive technology;  Attention deficit hyperactivity disorder;  Co-morbid conditions;  Early intervention;  Educational contents;  Health services;  Learning difficulties;  Learning objects, Geriatrics},
publisher={Institute of Electrical and Electronics Engineers Inc.},
isbn={9781538663042},
language={English},
abbrev_source_title={IEEE Games, Entertain., Media Conf., GEM},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Nurpandi2018,
author={Nurpandi, F. and Gumelar, A.},
title={Augmented Reality Chemical Reaction with User-Centered Design},
journal={MATEC Web of Conferences},
year={2018},
volume={218},
doi={10.1051/matecconf/201821804012},
art_number={04012},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056900369&doi=10.1051%2fmatecconf%2f201821804012&partnerID=40&md5=5d59c9db7783c2566e9bdb6bffc011aa},
affiliation={Informatics Engineering Program, Faculty of Engineering, Suryakancana University, Indonesia},
abstract={One of chemistry is the chemical element that is represented by the symbol on the periodic table. The low level of activity, interest, and the result of chemistry learning in school is caused by the students generally having difficulty in solving problems related to chemical reactions. In addition, most of the chemical concepts are abstract so it is difficult to imagine the structure of molecules clearly. Augmented Reality can integrate digital elements with the real world in real time and follow the circumstances surrounding environment. Augmented Reality can provide a new more interactive concept in the learning process because users can directly interact naturally. By using Augmented Reality, the atoms in the periodic table will be scanned using a camera from an Android-based smartphone that has installed this app. The scan results are then compared with existing data and will show the molecular structure in three-dimensional form. Users can also observe reactions between atoms by combining multiple markers simultaneously. Augmented Reality application is built using the concept of user-centered design and Unity with personal license as development tools. By using this app, studying chemical reactions no longer requires a variety of chemicals that could be harmful to users. © The Authors, published by EDP Sciences, 2018.},
keywords={Augmented reality;  Chemical elements;  Chemical reactions;  E-learning;  Human computer interaction;  Indicators (chemical), Augmented reality applications;  Chemical concepts;  Development tools;  Digital elements;  Learning process;  Periodic table;  Structure of molecules;  Surrounding environment, User centered design},
correspondence_address1={Nurpandi, F.; Informatics Engineering Program, Faculty of Engineering, Suryakancana UniversityIndonesia; email: finsa@unsur.ac.id},
editor={Martiningsih W., Praptodiyono S., Wiryadinata R., Saraswati I., Santoso M.I.},
publisher={EDP Sciences},
issn={2261236X},
language={English},
abbrev_source_title={MATEC Web Conf.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Elkoubaiti2018189,
author={Elkoubaiti, H. and Mrabet, R.},
title={How are augmented and virtual reality used in smart classrooms?},
journal={ACM International Conference Proceeding Series},
year={2018},
pages={189-196},
doi={10.1145/3289100.3289131},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058625080&doi=10.1145%2f3289100.3289131&partnerID=40&md5=c9e08a48f74a3c7a1d18c7a3ebe007fc},
affiliation={Smart Systems Laboratory ENSIAS, Mohammed V University, Rabat, Morocco},
abstract={Recently, a considerable interest has been imparted to augmented and virtual reality (AR/VR) technologies. In education particularly, AR and VR hold a great promise to reshape learning process. They are powerful tools to present and visualize information, and they have the potential to transform classrooms into experiential learning spaces. While AR creates an accurate fusion of digital elements in the real world, VR provides a realistic feeling of presence in the virtual world. However, they rely on many enabling technologies and technical requirements, which need to be specified and satisfied. In this paper, we will present the main components of AR and VR technologies, as well as their main uses in a smart classroom. Actually, AR and VR are beneficial tools to present educational content and experiments to students. They facilitate the work of instructors in numerous subjects and grades. The paper also provides the key aspects of safe, reliable and interactive learning experiences based on these technologies. It discusses technical requirements including latency, field of view, resolution, frame rate, network requirements and measurements for the privacy and security of AR and VR applications. © 2018 Association for Computing Machinery.},
author_keywords={Augmented reality;  Internet of Things;  Smart classroom;  Virtual reality},
keywords={Augmented reality;  Internet of things;  Learning systems, Augmented and virtual realities;  Educational contents;  Enabling technologies;  Experiential learning;  Network requirements;  Privacy and security;  Smart classroom;  Technical requirement, Virtual reality},
editor={El Bouanani F.},
publisher={Association for Computing Machinery},
isbn={9781450365079},
language={English},
abbrev_source_title={ACM Int. Conf. Proc. Ser.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{NoAuthor2018,
title={UIST 2018 Adjunct - Adjunct Publication of the 31st Annual ACM Symposium on User Interface Software and Technology},
journal={UIST 2018 Adjunct - Adjunct Publication of the 31st Annual ACM Symposium on User Interface Software and Technology},
year={2018},
page_count={240},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056830941&partnerID=40&md5=ae8f6a5e8a18985bb5469129d72c6cf2},
abstract={The proceedings contain 77 papers. The topics discussed include: Pushables: a DIY approach for fabricating customizable and self-contained tactile membrane dome switches; Mindgame: mediating people’s EEG alpha band power through reinforcement learning; SweatSponse: closing the loop on notification delivery using skin conductance responses; augmented collaboration in shared space design with shared attention and manipulation; aAalto interface metrics (AIM): a service and codebase for computational gui evaluation; shared autonomy for an interactive AI system; DynamicSlide: reference-based interaction techniques for slide-based lecture videos; touch180: finger identification on mobile touchscreen using fisheye camera and convolutional neural network; OmniEyeball: spherical display equipped with omnidirectional camera and its application for 360-degree video communication; AmbientLetter: letter presentation method for discreet notification of unknown spelling when handwriting; post-literate programming: linking discussion and code in software development teams; Juggling 4.0: learning complex motor skills with augmented reality through the example of juggling; reversing voice-related biases through haptic reinforcement; augmenting human hearing through interactive auditory mediated reality; and reMi: translating ambient sounds of moment into tangible and shareable memories through animated paper.},
publisher={Association for Computing Machinery, Inc},
isbn={9781450359498},
language={English},
abbrev_source_title={UIST Adjun. - Adjun. Publ. Annu. ACM Symp. User Interface Softw. Technol.},
document_type={Conference Review},
source={Scopus},
}

@CONFERENCE{Wardhono201849,
author={Wardhono, W.S. and Arwani, I. and Wijaya, H.},
title={Learning media development for basic arithmetic concept with interactive augmented reality},
journal={ACM International Conference Proceeding Series},
year={2018},
pages={49-52},
doi={10.1145/3284497.3284511},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060590140&doi=10.1145%2f3284497.3284511&partnerID=40&md5=d6055b699127862db7456b2790fe2687},
affiliation={Universitas Brawijaya Jl., Veteran no. 8, Malang, Jawa Timur Jl, Indonesia},
abstract={Demands and needs for learning media are now increasingly complex. These demands become a challenge to build an interactive instruction system that is designed and implemented as a basic arithmetic learning media prototype in Mathematics. Every student's learning interest in Mathematics, especially basic concept of Arithmetic, might be increased by stimulating the visual senses with an Augmented Reality technology. It allows students to interact with the learning media as a visual object that is incorporated into the real world through video display. The prototype that has been developed in this research used Augmented Reality Technology that is integrated with the basic concept of arithmetic involving its operands and operators as physical marker and visual objects that appear on the Smartphone screen with a real-world background captured by the camera. This application was developed by applying Linked List Concept to store a temporary sequence of markers that are successfully read by the device then processed in sequences as simple arithmetic operations. The results of the implementation testing show a low risk of complexity and meet all the designed functions. Then the application is ready to be tested for usability as a learning media. © 2018 Association for Computing Machinery.},
author_keywords={Interactive Augmented Reality;  Learning Media;  Linked List;  Software development;  Waterfall Method},
keywords={Augmented reality;  Educational technology;  Software design;  Software engineering;  Students, Arithmetic operations;  Augmented reality technology;  Implementation testing;  Interactive instructions;  Learning media;  Linked List;  Operands and operators;  Waterfall methods, E-learning},
publisher={Association for Computing Machinery},
isbn={9781450365994},
language={English},
abbrev_source_title={ACM Int. Conf. Proc. Ser.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{NoAuthor2018,
title={ACM International Conference Proceeding Series},
journal={ACM International Conference Proceeding Series},
year={2018},
page_count={90},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060579970&partnerID=40&md5=3757c3e0f23b911920346736e741c121},
abstract={The proceedings contain 16 papers. The topics discussed include: the application research of digital technology in the education for major of machinery in new engineering background; impact of fine motor skill development app on handwriting performance in children with dysgraphia: a pilot study; architecture of an adaptive personalized learning environment (APLE) for content recommendation; application of blended learning in English fiction literature course; the undergraduate course teaching and assessment reform of wireless sensor network for engineering education certification; the development of electronic assembly technology course aided by video and flash courseware and teaching effectiveness verified by radio assembly and shakedown test; and learning media development for basic arithmetic concept with interactive augmented reality.},
publisher={Association for Computing Machinery},
isbn={9781450365994},
language={English},
abbrev_source_title={ACM Int. Conf. Proc. Ser.},
document_type={Conference Review},
source={Scopus},
}

@CONFERENCE{Javaheri2018365,
author={Javaheri, H. and Gobbi, M. and Gruenerbl, A. and Lukowicz, P. and Monger, E.},
title={Demo:”Stayin' Alive”: An interactive augmented - Reality CPR tutorial},
journal={UbiComp/ISWC 2018 - Adjunct Proceedings of the 2018 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2018 ACM International Symposium on Wearable Computers},
year={2018},
pages={365-368},
doi={10.1145/3267305.3267569},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058332219&doi=10.1145%2f3267305.3267569&partnerID=40&md5=1a929d1ccb3ab37be5aa55c2aa1c690b},
affiliation={DFKI GmbH, Kaiserslautern, Germany; University of Southampton, Southampton, United Kingdom; DFKI GmbH, TU Kaiserslautern, Kaiserslautern, Germany},
abstract={Education is the Achilles heel of successful resuscitation in cardiac arrest. Therefore, we aim to contribute to the educational efficiency by providing a novel augmented-reality (AR) guided interactive cardiopulmonary resuscitation (CPR) "trainer". For this trainer, a mixed reality smart glass, Microsoft HoloLens, and a CPR manikin covered with pressure sensors were used. To introduce the CPR procedure to a learner, an application with an intractable virtual teacher model was designed. The teaching scenario consists of the two main parts, theory and practice. In the theoretical part, the virtual teacher provides all information about the CPR procedure. Afterward, the user will be asked to perform the CPR cycles in three different stages. In the first two stages, it is aimed to gain the muscle memory with audio and optical feedback system. In the end, the performance of the participant is evaluated by the virtual teacher. © 2018 Copyright is held by the owner/author(s).},
author_keywords={Augmented-Reality;  CPR;  Interactive Ubiquitous Teaching},
keywords={Augmented reality;  Computation theory;  Mixed reality;  Resuscitation;  Wearable computers, Achilles heel;  Cardiac arrest;  Cardiopulmonary resuscitation;  Different stages;  MicroSoft;  Smart glass;  Teacher models;  Theory and practice, Ubiquitous computing},
publisher={Association for Computing Machinery, Inc},
isbn={9781450359665},
language={English},
abbrev_source_title={UbiComp/ISWC - Adjun. Proc. ACM Int. Jt. Conf. Pervasive Ubiquitous Comput. Proc. ACM Int. Symp. Wearable Comput.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Amiraslanov2018331,
author={Amiraslanov, O. and Lukowicz, P. and Javaheri, H. and Bian, S.},
title={Demo: Preparation for future learning: Augmented-reality enhanced interactive science labs},
journal={UbiComp/ISWC 2018 - Adjunct Proceedings of the 2018 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2018 ACM International Symposium on Wearable Computers},
year={2018},
pages={331-334},
doi={10.1145/3267305.3267637},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058299681&doi=10.1145%2f3267305.3267637&partnerID=40&md5=b81d421040362e66e2beea53cd5e10a7},
affiliation={DFKI GmbH, Kaiserslautern, Germany},
abstract={This demo presents an interactive experiment environment for physics and electrical engineering students and aims to provide a deep insight into the basic electrical theories (i.e Ohm's, Kirchoff's law) using real-time sensing system with augmented-reality (AR) visualization enhancements. To this end, a system was designed to measure the current, voltage, AC frequency and RFID based 2D positioning. A mixed reality glass, HoloLens, was used to provide the visualization and augmentation. An application is designed for HoloLens to provide different visualization of nodal measurements and detected circuit schematic. Using this interactive experiment setting, the goal is to reduce the cognitive load of a learner while allowing more enjoyable and intuitive learning experience. © Copyright held by the owner/author(s).},
author_keywords={Augmented Reality;  Electronics Lab;  Learning;  Learning;  Physics Experiments},
keywords={Augmented reality;  Computation theory;  Environmental regulations;  Ubiquitous computing;  Visualization;  Wearable computers, Cognitive loads;  Electrical engineering students;  Electrical theory;  Learning;  Learning experiences;  Physics experiments;  Preparation for Future Learning;  Real time sensing, Mixed reality},
publisher={Association for Computing Machinery, Inc},
isbn={9781450359665},
language={English},
abbrev_source_title={UbiComp/ISWC - Adjun. Proc. ACM Int. Jt. Conf. Pervasive Ubiquitous Comput. Proc. ACM Int. Symp. Wearable Comput.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Su2018259,
author={Su, B. and Tang, T.Y. and Winoto, P.},
title={Poster: Story teller: A Contextual-based Educational Augmented-Reality Application for Preschool Children},
journal={UbiComp/ISWC 2018 - Adjunct Proceedings of the 2018 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2018 ACM International Symposium on Wearable Computers},
year={2018},
pages={259-262},
doi={10.1145/3267305.3267671},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058280760&doi=10.1145%2f3267305.3267671&partnerID=40&md5=f16bd11457fbb082b69d69c162137572},
affiliation={Dept. Computer Science, Wenzhou-Kean University, Wenzhou, Zhejiang, China; Media Lab, Wenzhou-Kean University, Wenzhou, Zhejiang, China},
abstract={An augmented reality (AR) application, Story Teller, is designed to teach preschool children some Chinese words. In order to train their motor skill, holdable items are used as the AR markers, which can be combined to construct a story. To retain children's interest, varying stories may be presented in different location and time. © 2018 Copyright is held by the owner/author(s).},
author_keywords={Augmented Reality;  Context;  Interactive Education},
keywords={Augmented reality;  Wearable computers, Ar markers;  Augmented reality applications;  Context;  Interactive education;  Motor skills;  Pre-school children, Ubiquitous computing},
correspondence_address1={Tang, T.Y.; Media Lab, Wenzhou-Kean UniversityChina; email: yatang@kean.edu},
publisher={Association for Computing Machinery, Inc},
isbn={9781450359665},
language={English},
abbrev_source_title={UbiComp/ISWC - Adjun. Proc. ACM Int. Jt. Conf. Pervasive Ubiquitous Comput. Proc. ACM Int. Symp. Wearable Comput.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Ancioto201865,
author={Ancioto, A.S.R. and Freitas, L.F.D.S. and Guimaraes, M.D.P.},
title={Simulator for teaching magnetic disk scheduling algorithms},
journal={Proceedings - 2018 20th Symposium on Virtual and Augmented Reality, SVR 2018},
year={2018},
pages={65-74},
doi={10.1109/SVR.2018.00021},
art_number={8802492},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072064308&doi=10.1109%2fSVR.2018.00021&partnerID=40&md5=abdf2d056d314bd5e39d0fb2356c337e},
affiliation={Centro Universitário Campo Limpo Paulista, (Unifaccamp)/Instituto Federal de Educação, Ciência e Tecnologia (IFSP) Campo Limpo Paulista-SP, Pirituba-SP, Brazil},
abstract={Disk scheduling algorithms are fundamental to operational systems, managing schedule I/O requests arriving for a disk. They aim to make the systems efficient, fast, and fair, allowing to improve the seek time. This papeŕs goal is to present an immersive and interactive virtual reality simulator for teaching magnetic disk scheduling algorithms. This application simulates the First Come-First Served (FCFS) algorithm. The results of a usability and learning are presented. © 2018 IEEE.},
author_keywords={Disk scheduling;  Memory management;  Operational system;  Virtual reality},
keywords={Augmented reality;  Nonvolatile storage;  Scheduling;  Virtual reality, Disk scheduling;  Disk scheduling algorithms;  First come first served;  Interactive virtual reality;  Magnetic disk;  Memory management;  Operational systems;  Seek time, Scheduling algorithms},
publisher={Institute of Electrical and Electronics Engineers Inc.},
isbn={9781728106045},
language={Portuguese},
abbrev_source_title={Proc. - Symp. Virtual Augment. Real., SVR},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{BravoPillon201821,
author={Bravo Pillon, C. and Pierre Da Silva, R. and Rocha MacHado, L.},
title={Augmented reality application development about nutrition for the elderly},
journal={Proceedings - 13th Latin American Conference on Learning Technologies, LACLO 2018},
year={2018},
pages={21-24},
doi={10.1109/LACLO.2018.00014},
art_number={8783970},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071027454&doi=10.1109%2fLACLO.2018.00014&partnerID=40&md5=9546f0fe0cfa523ed7bb29e7efe79521},
affiliation={Programa de Pós-Graduąão em Design, Universidade Federal Do Rio Grande Do sul, UFRGS, Porto Alegre, Brazil; Departamento de Design e Expressão Gráfica, Universidade Federal Do Rio Grande Do sul, UFRGS, Porto Alegre, Brazil; Programa de Pós-Graduąão em Informática Na Educąão, Universidade Federal Do Rio Grande Do sul, UFRGS, Porto Alegre, Brazil},
abstract={Each year increases the number of the elderly around the world, and, in this prospect, new challenges come up, both in relation to culture as in health. The misinformation is one of leading causes that contributes for an inappropriate nutrition between the elderly. The educational material plays a large role in raising awareness to adopt a healthy diet. In this way, the aim of this paper is to present the development and application process of an augmented reality application about nutrition for the elderly. The methodology adopted in this research is divided in four stages: research, development, evaluation and results analysis. In this paper, the first two stages of the methodology are emphasized. The results present the development process of a digital educational material aimed at the elderly, which uses the augmented reality technology. Therefore, the application might complement the learning of the elderly about nutrition in a playful, dynamic, and interactive way. © 2018 IEEE.},
author_keywords={Application;  Augmented reality;  Digital educational material;  Elderly;  Nutritional orientation},
keywords={Applications;  Augmented reality;  E-learning, Augmented reality applications;  Augmented reality technology;  Development and applications;  Development process;  Educational materials;  Elderly;  Healthy diet;  Interactive way, Nutrition},
publisher={Institute of Electrical and Electronics Engineers Inc.},
isbn={9781728103822},
language={Portuguese},
abbrev_source_title={Proc. - Lat. Am. Conf. Learn. Technol., LACLO},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{GarcíaArias2018476,
author={García Arias, L.F. and Duque Mendez, N.D. and DIas Flores, C.},
title={Augmented reality learning resources in anatomy},
journal={Proceedings - 13th Latin American Conference on Learning Technologies, LACLO 2018},
year={2018},
pages={476-483},
doi={10.1109/LACLO.2018.00085},
art_number={8783620},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070996610&doi=10.1109%2fLACLO.2018.00085&partnerID=40&md5=1974ab2bc961531fa7ae79e5c02871f6},
affiliation={Ingeniero Electrónico, Universidad Nacional de Colombia, Colombia; Departamento de Informática y Computación, Universidad Nacional de Colombia, Colombia; Departamento de Ciencias Exactas y Sociales, Universidade Federal de Ciências da Saúde de Porto Alegre, Brazil},
abstract={Augmented reality can be applied in different areas of knowledge and one of the most explored fields has been health. The objective of this article is to present the results obtained from the evaluation of learning resources developed using augmented reality technology. The evaluation was made by students of health undergraduate programs who participated in the Academic Day of the Biomedicine program of a Brazilian higher education institution. 8 educational resources were evaluated, all related to the area of general anatomy. The resources were evaluated by 41 students who answered a validated questionnaire for the evaluation of educational resources with questions about: learning, interactivity, engagement, attractiveness, functionality and autonomy. The evaluation was considered valid. The challenge is to find interactive alternatives that stimulate and simultaneously incorporate content, with a depth appropriate to the objective of the subject. Critics in the evaluation will serve as the basis for adjustments in the next learning resources to be developed. © 2018 IEEE.},
author_keywords={Augmented reality;  General anatomy;  Learning resource},
keywords={Augmented reality, Augmented reality technology;  Educational resource;  General anatomy;  Higher education institutions;  Interactivity;  Learning resource;  Reality learning;  Undergraduate program, Students},
publisher={Institute of Electrical and Electronics Engineers Inc.},
isbn={9781728103822},
language={Spanish},
abbrev_source_title={Proc. - Lat. Am. Conf. Learn. Technol., LACLO},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Zoghi2018,
author={Zoghi, B. and Bhutra, G. and Parameswaran, A.},
title={A novel use for wearable augmented reality in engineering education},
journal={Computers in Education Journal},
year={2018},
volume={9},
number={4},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058960305&partnerID=40&md5=b97ad2a59cb5098f196248bcc71b1b20},
affiliation={Texas AandM, United States; Facebook Inc., United States; Texas AandM University, College Station, United States},
abstract={The rapid advances in virtual technology has led to great improvement in educational tools. The benefits of using augmented and virtual reality to assist teaching are increased student motivation, better learning experience, interaction with peers through internet and interaction with real world objects. Increased investments in virtual technologies, enhanced user experience and benefits of using virtual technology for teaching makes augmented reality one of the leading technologies for future of education. This project aims at developing a wearable headset based augmented reality application to assist teaching HVAC systems to students. The application has a guided walkthrough of the HVAC system as well as a manipulatable 3D hologram. Unity3D Game Engine has been used to develop the application while Microsoft HoloLens has been used as the platform for implementing the augmented reality application. The application has been implemented and tested to receive feedback. © 2018 American Society for Engineering Education. All rights reserved.},
author_keywords={Augmented Reality;  Educational Technologies;  Head Mounted Display;  Interactive Technology;  Microsoft HoloLens;  Teaching Aids},
keywords={Augmented reality;  Climate control;  Educational technology;  Helmet mounted displays;  Students;  User interfaces;  Virtual reality;  Wearable computers, Augmented and virtual realities;  Augmented reality applications;  Head mounted displays;  Interactive technology;  Learning experiences;  MicroSoft;  Teaching aids;  Wearable augmented realities, Engineering education},
publisher={American Society for Engineering Education},
issn={10693769},
coden={CEJOE},
language={English},
abbrev_source_title={Comput. Educ. J.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Chiu20189995,
author={Chiu, P.-H. and Tseng, P.-H. and Feng, K.-T.},
title={Interactive Mobile Augmented Reality System for Image and Hand Motion Tracking},
journal={IEEE Transactions on Vehicular Technology},
year={2018},
volume={67},
number={10},
pages={9995-10009},
doi={10.1109/TVT.2018.2864893},
art_number={8432093},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052580883&doi=10.1109%2fTVT.2018.2864893&partnerID=40&md5=af886786f4d6c22d72865c0712db3216},
affiliation={Department of Electrical and Computer Engineering, National Chiao Tung University, Hsinchu, 300, Taiwan; Department of Electronic Engineering, National Taipei University of Technology, Taipei, 10608, Taiwan},
abstract={In recent years, augmented reality (AR) is considered a promising technology that combines virtual information such as videos, images, and three-dimensional objects with a real camera view in mobile platforms. Interactive AR further provides human-computer interaction to allow the user to interact with virtual objects on the mobile display. In this paper, we proposed a cloud-based mobile augmented reality interactive system (MARIS), which includes MARIS-I for image target tracking and MARIS-H for hand motion tracking. MARIS-I estimates the position of the image target by adopting a feature-based mean-shift algorithm, which is feasible for real-time applications with its small region feature detection. MARIS-H provides two tracking modes for fingertip and back of hand tracking to enhance user experiences (UX) for interaction. Either the center position for the back of hand or fingertip is first estimated by particle filtering technique, which calculates the weighting of each particle according to hand or fingertip model. Afterward, the contour of the fingertip is estimated by level-set-based contour evolution in the fingertip tracking mode. Furthermore, we implement a device/cloud architecture for the proposed MARIS to decrease memory requirement and computational complexity on the device side. Experimental results show that MARIS including MARIS-I and MARIS-H can outperform other existing methods for image and hand motion tracking, respectively. The proposed MARIS is demonstrated in a picture book to provide fruitful interactive UX for digital learning systems. © 1967-2012 IEEE.},
author_keywords={Augmented reality;  motion tracking;  particle filtering},
keywords={Augmented reality;  Cameras;  Clutter (information theory);  Feature extraction;  Human computer interaction;  Interactive computer systems;  Motion analysis;  Real time systems;  Target tracking;  Virtual reality, Digital learning system;  Hand motion tracking;  Human Computer Interaction (HCI);  Mobile augmented reality;  Mobile handsets;  Real-time application;  Three-dimensional (3D) objects;  User experiences (ux), Palmprint recognition},
correspondence_address1={Feng, K.-T.; Department of Electrical and Computer Engineering, National Chiao Tung UniversityTaiwan; email: ktfeng@mail.nctu.edu.tw},
publisher={Institute of Electrical and Electronics Engineers Inc.},
issn={00189545},
coden={ITVTA},
language={English},
abbrev_source_title={IEEE Trans. Veh. Technol.},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Alshi2018930,
author={Alshi, G. and Dandiwala, M. and Cazi, M. and Pawar, R.},
title={Interactive Augmented Reality-Based System for Traditional Educational Media Using Marker-Derived Contextual Overlays},
journal={Proceedings of the 2nd International Conference on Electronics, Communication and Aerospace Technology, ICECA 2018},
year={2018},
pages={930-935},
doi={10.1109/ICECA.2018.8474884},
art_number={8474884},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060844930&doi=10.1109%2fICECA.2018.8474884&partnerID=40&md5=257343760ae00d160a5aeb1d40924495},
affiliation={Sardar Patel Institute of Technology, Andheri, Mumbai, India},
abstract={Augmented reality is making an impact across different sectors of society. Drawing from this fact, the system proposed herein aims to aid educators by making the process of learning interactive, enjoyable and effective. Using this, theoretical contents of books are enhanced using computer vision, 3D models and Human-Computer interaction (HCI). This enhancement is made available to students in the form of a mobile phone application through an AR interface. One can hover over data or information in the book and get the augmented experience in terms of 3D models, audio or videos. Augmented reality is fast becoming an important part of human life with emerging technologies such as tracking techniques, computer vision systems, graphics, mobile computing gaining traction. The proposed approach aims to interesting and motivational compared to old teaching methods. The paper also discusses the educational settings where the suggested model can be used, along with a detailed description of the prototype, its applications, and responses. © 2018 IEEE.},
author_keywords={3D object;  Augmented Reality;  Interactive Learning;  Markers;  Overlay;  Tradition Teaching Practices},
keywords={Augmented reality;  Computer vision, 3D object;  Interactive learning;  Markers;  Overlay;  Teaching practices, Human computer interaction},
publisher={Institute of Electrical and Electronics Engineers Inc.},
isbn={9781538609651},
language={English},
abbrev_source_title={Proc. Int. Conf. Electron., Commun. Aerosp. Technol., ICECA},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Tumkor20181734,
author={Tumkor, S.},
title={Personalization of engineering education with the mixed reality mobile applications},
journal={Computer Applications in Engineering Education},
year={2018},
volume={26},
number={5},
pages={1734-1741},
doi={10.1002/cae.21942},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053847723&doi=10.1002%2fcae.21942&partnerID=40&md5=724b3050e5744ae6ce3fa0afe71a140a},
affiliation={University of Pittsburgh, Johnstown, PA, United States},
abstract={Geometric visualization, the spatial perception of problems, and geometric reasoning are always considered essential skills for an engineering student. Although the student can learn geometric visualization eventually, some students with the missing visualization skills cannot follow the instructions to solve the engineering problems. Immersive mixed reality (MR) technologies have been used by the author to help students with object visualization problems. MR technologies virtually project the objects and allow students observing three dimensional (3D) representation of two dimensional (2D) sketches in front of them, while also rotating the virtual model as they wish. These educational mobile applications have been tested in engineering drawing classes and overall improvement of student visualization skills has been reported. In this study, the research question is if some students benefit more from the immersive technologies. Some students have previous CAD experiences from their high school education or interest in technology as a hobby. Playing video games gives students some visualization skills too. Pre- and post- mental rotation tests (MRTs) are analyzed along with their pre-existing educational and video game experiences to evaluate the level of benefits of MR technology in class. © 2018 Wiley Periodicals, Inc.},
author_keywords={augmented reality;  engineering graphics visualization;  mixed reality;  mobile applications;  personalized education;  spatial cognition},
keywords={Augmented reality;  Computer aided design;  Education computing;  Geometry;  Interactive computer graphics;  Mixed reality;  Mobile computing;  Problem solving;  Visualization, Engineering graphics;  Geometric visualizations;  Immersive technologies;  Mixed reality technologies;  Mobile applications;  Spatial cognition;  Three dimensional (3D) representation;  Two Dimensional (2 D), Students},
correspondence_address1={Tumkor, S.; University of PittsburghUnited States; email: tumkor@pitt.edu},
publisher={John Wiley and Sons Inc.},
issn={10613773},
coden={CAPEE},
language={English},
abbrev_source_title={Comput Appl Eng Educ},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Han2018,
author={Han, P.-H. and Lin, J.-W. and Hsieh, C.-H. and Hsu, J.-H. and Hung, Y.-P.},
title={Target: Limbs movement guidance for learning physical activities with a video see-through head-mounted display},
journal={ACM SIGGRAPH 2018 Posters, SIGGRAPH 2018},
year={2018},
doi={10.1145/3230744.3230776},
art_number={a26},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054824175&doi=10.1145%2f3230744.3230776&partnerID=40&md5=d7eb163858fab0b9c6e41a0952a65436},
affiliation={National Taiwan University, Taiwan; Tainan National University of the Arts, Japan},
abstract={In the aging society, people are paying more attention to having good exercise habits. The advancement of technology grants the possibility of learning various kinds of exercises using multi-media equipment, for example, watching instruction videos. However, it is difficult for users to learn accurate movements due to lack of feedback information. To explore what augmented reality (AR) or virtual reality (VR) technologies can assist the users, lots of research on movement guidance and evaluation has been purposed and developed. Chua et al. [Chua et al. 2003] built a Tai Chi Chuan training system in virtual reality environment. They created a virtual coach in front of the user. Integrated with motion capture system, users can see their movement in VR and compare it to the coach's movement. However, these systems can only let the users see their avatars instead of themselves. LightGuide [Sodhi et al. 2012] used a projector hanging from the ceiling and projected visual information on users' hands to guide hand movements. It could only guide users in a fixed space with their hands being under the projection zone. OutsideMe [Yan et al. 2015] used Kinect to capture the skeleton, RGB and depth images of users. They enabled users to see their body movements as external observers through a video see-through head-mounted display (VST-HMD). AR-Arm [Han et al. 2016] showed semitransparent arms to indicate the correct movement of Tai Chi Chuan. Users could follow the virtual arms intuitively to achieve accurate arm movement. In this paper, we present a full-body movement guidance system for learning physical activities with a VST-HMD. It contains a method for skeleton calibration and two interfaces for movement guidance: Coach-Surrounding Guidance and Ball-Following Guidance. We conducted a user study to evaluate the system on posture and movement learning. © 2018 Copyright held by the owner/author(s).},
author_keywords={Augmented reality;  Body movement guidance},
keywords={Augmented reality;  Biofeedback;  Interactive computer graphics;  Multimedia systems;  Musculoskeletal system;  Virtual reality, Body movements;  Feed back information;  Full-body movement;  Motion capture system;  Physical activity;  Video see-through head-mounted display;  Virtual-reality environment;  Visual information, Helmet mounted displays},
publisher={Association for Computing Machinery, Inc},
isbn={9781450358170},
language={English},
abbrev_source_title={ACM SIGGRAPH Posters, SIGGRAPH},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Tsvetkova2018,
author={Tsvetkova, I. and Kinaneva, D. and Hristov, G. and Raychev, J. and Zahariev, P.},
title={A complex workflow for development of interactive and impressive educational content using capabilities of animated augmented reality trends},
journal={2018 17th International Conference on Information Technology Based Higher Education and Training, ITHET 2018},
year={2018},
doi={10.1109/ITHET.2018.8424776},
art_number={8424776},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052209691&doi=10.1109%2fITHET.2018.8424776&partnerID=40&md5=50dd3ea1716b33eed126b54873d46ae0},
affiliation={Department of Telecommunications, University of Ruse 'Angel Kanchev', Ruse, Bulgaria},
abstract={The modern Information and Communication Technologies (ICT) have changed the way we perceive and interact with the surrounding environments. One of the many new ways to receive information in the digital world is trough Augmented Reality (AR) products. This new technology provides the means for real time integration of digital content directly over the visible surrounding objects. In this way, the AR products provide the students with new ways for improvement of their skills and knowledge. Engaging students actively in their own learning process is an important pre-requisite for knowledge building. Using AR in the education process will help the students memorize the contents much easier and they will gain knowledge faster. In this paper we present a complex workflow for the development of interactive and impressive educational contents and for the improvement of the students learning perceptions. For the creation of these modern educational learning materials, the animated AR trends are used. Based on the presented workflow, four AR applications are developed and discussed. Another benefit from the proposed workflow is represented by the integration of the augmented reality applications with the existing textbooks or with other learning materials. In this way, there is no need to reprint the old textbooks or to create new ones. © 2018 IEEE.},
author_keywords={3D models;  Augmented reality;  virtual reality},
keywords={Augmented reality;  Computer aided instruction;  Education computing;  Textbooks;  Virtual reality, 3D models;  Augmented reality applications;  Educational contents;  Information and Communication Technologies;  Knowledge building;  Learning materials;  Real time integration;  Surrounding environment, Students},
publisher={Institute of Electrical and Electronics Engineers Inc.},
isbn={9781538646236},
language={English},
abbrev_source_title={Int. Conf. Inf. Technol. Based High. Educ. Train., ITHET},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Asadi2018128,
author={Asadi, A.-R. and Hemadi, R.},
title={Augmented Reality Game Creator for on-site Job Training},
journal={2018 2nd National and 1st International Digital Games Research Conference: Trends, Technologies, and Applications, DGRC 2018},
year={2018},
pages={128-133},
doi={10.1109/DGRC.2018.8712020},
art_number={8712020},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066463276&doi=10.1109%2fDGRC.2018.8712020&partnerID=40&md5=dd48b3957fec9f4ff17635d88e68853f},
affiliation={Antidisciplinary Research and Development Association, Tehran, Iran},
abstract={Various serious games for education and especially training have emerged in recent years. Applying augmented reality to serious games makes it possible to develop games that are played in real environments of corporations instead of virtual worlds and using cell phones as the platform makes developing and training with such games easier and more accessible. This paper explains a prototype of a system which consists of a serious game authoring application and a playable client that can be implemented by companies and organizations without requiring programming or 3D modeling skills. © 2018 IEEE.},
author_keywords={Augmented Reality;  Corporate Training;  Serious Games},
keywords={3D modeling;  Augmented reality;  Computer systems programming;  Interactive computer graphics;  Three dimensional computer graphics;  Virtual reality, Cell phone;  Corporate trainings;  Job trainings;  Real environments;  Virtual worlds, Serious games},
publisher={Institute of Electrical and Electronics Engineers Inc.},
isbn={9781728111148},
language={English},
abbrev_source_title={Natl. Int. Digit. Games Res. Conf.: Trends, Technol., Appl., DGRC},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Collins201845,
author={Collins, J. and Regenbrecht, H. and Lanalotz, T.},
title={Back to the Future: Constructivist Learning in Virtual Reality},
journal={Adjunct Proceedings - 2018 IEEE International Symposium on Mixed and Augmented Reality, ISMAR-Adjunct 2018},
year={2018},
pages={45-46},
doi={10.1109/ISMAR-Adjunct.2018.00030},
art_number={8699219},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065550560&doi=10.1109%2fISMAR-Adjunct.2018.00030&partnerID=40&md5=b0ab26c82465dd9d5fdb5f9ddf466647},
affiliation={University of Otago, New Zealand},
abstract={A proposal was first made in 1971 for a study attempting to investigate radical constructivism as a valid learning theory, though the study was never formally conducted. This work describes our Virtual Reality interactive four-dimensional Hypercube system used as our investigative medium, and our initial implementation of the historic study proposal for validation. Our lessons learned are leading to further experimentation and investigation into learning applications in Virtual Reality. © 2018 IEEE.},
author_keywords={Education;  Learning;  Pedagogy;  Virtual Reality},
keywords={Augmented reality;  Education;  Virtual reality, Constructivist learning;  Hypercube systems;  Learning;  Learning Theory;  Pedagogy, E-learning},
publisher={Institute of Electrical and Electronics Engineers Inc.},
isbn={9781538675922},
language={English},
abbrev_source_title={Adjun. Proc. - IEEE Int. Symp. Mixed Augment. Real., ISMAR-Adjunct},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Mehta201845,
author={Mehta, V. and Devraj and Chugh, H. and Banerjee, P.},
title={Applications of Augmented Reality in Emerging Health Diagnostics: A Survey},
journal={2018 International Conference on Automation and Computational Engineering, ICACE 2018},
year={2018},
pages={45-51},
doi={10.1109/ICACE.2018.8687114},
art_number={8687114},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064874584&doi=10.1109%2fICACE.2018.8687114&partnerID=40&md5=7e3f482b2b9d954e5df0d4c63d681896},
affiliation={Nalanda Foundation, New Delhi, India; Department of Pharmaceutical Engineering and Technology, Indian Institute of Technology (Banaras Hindu University), Varanashi, Uttar Pradesh, 221005, India},
abstract={Augmented reality (AR) is virtual recreation of the nature from real space to the virtual space. It helps people to feel and experience the other enhanced side of our environment. Since many years, it has been one of the most thriving domains of computer science that helps people to connect to the world in a more interactive way. Augmented reality has many applications till date where its outcomes can be found in various domains ranging from entertainment, healthcare, education, rehabilitation, military, and navigation to maintenance. This article gives a review of augmented reality applications in healthcare industry which is one of the rapidly burgeoning field under AR. Such technology aids the medical practitioner to get a visual of the patient's internal body state. This paper also discusses impending plans and innovations which potentially could establish disruption in healthcare sector over the next decade. This review provides beneficial consolidation of numerous AR integration in the field of healthcare for beginners of this technology. © 2018 IEEE.},
author_keywords={3D objects;  Amalgam;  Augmented Reality;  Virtual environment;  Virtual Reality},
keywords={Diagnosis;  Health care;  Mercury amalgams;  Military applications;  Virtual reality, 3D object;  Augmented reality applications;  Healthcare industry;  Healthcare sectors;  Interactive way;  Medical practitioner;  Technology aids;  Virtual spaces, Augmented reality},
publisher={Institute of Electrical and Electronics Engineers Inc.},
isbn={9781538654644},
language={English},
abbrev_source_title={Int. Conf. Autom. Comput. Eng., ICACE},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Putiorn201877,
author={Putiorn, P. and Nobnop, R. and Buathong, P. and Soponronnarit, K.},
title={Understanding Teachers' Perception Toward the Use of an Augmented Reality-Based Application for Astronomy Learning in Secondary Schools in Northern Thailand},
journal={6th Global Wireless Summit, GWS 2018},
year={2018},
pages={77-81},
doi={10.1109/GWS.2018.8686716},
art_number={8686716},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064753625&doi=10.1109%2fGWS.2018.8686716&partnerID=40&md5=598201bd453e5f68a2f43b028a40d8ab},
affiliation={Mae Fah Luang University, School of Information Technology, Chiang Rai, Thailand},
abstract={Augmented Reality (AR) as a technology is evolving along with increasing use of human technology. There is no doubt that a Smartphone is an important device that everyone can carry and use in their everyday life. The integration of the mobile device and AR technology has been increasingly adopted in various fields including Education. In this paper, we present the developmental process of an AR application to facilitate science learning for high school students in Chiang Rai province, Thailand. The AR-based Astronomy application was developed and implemented via students' Smartphones, and used as a medium of interaction in the classroom environment. Furthermore, to assess the usefulness of this application from the teachers' point of view, the experiment was conducted with secondary school students, and then evaluated by 38 pre-service teachers. Overall, the results showed benefits in using the AR application for improving students' learning engagement and enjoyment. Additionally, female pre-service teachers observed that the students perceived more enjoyment when compared with male teachers, who felt that students faced more pressure/tension while using the AR application. The usability test significantly indicated that female teachers preferred to use AR in their class more frequently than their counterparts. Moreover, the disparity between urban and rural schools still remains, where rural teachers found that AR technology would be complicated to use in rural schools' context. © 2018 IEEE.},
author_keywords={Astronomy;  Augmented Reality;  Interactive Media;  Mobile Learning},
keywords={Astronomy;  Augmented reality;  Engineering education;  Smartphones, Classroom environment;  High school students;  Interactive media;  Mobile Learning;  Northern Thailand;  Pre-service teacher;  Secondary schools;  Teachers' perceptions, Students},
publisher={Institute of Electrical and Electronics Engineers Inc.},
isbn={9781538642887},
language={English},
abbrev_source_title={Glob. Wirel. Summit, GWS},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Al-Hammadi20181,
author={Al-Hammadi, F.Y. and Aldarwish, A.F. and Alasmakh, A.H. and Zemerly, M.J.},
title={Augmented reality in educational games: City of Life (COL) emirati sustainability-edutainment interactive game},
journal={2018 Advances in Science and Engineering Technology International Conferences, ASET 2018},
year={2018},
pages={1-7},
doi={10.1109/ICASET.2018.8376921},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049980274&doi=10.1109%2fICASET.2018.8376921&partnerID=40&md5=8e078a0a121ab712e09c63056e7fb495},
affiliation={Electrical and Computer Engineering Department, Khalifa University, Abu Dhabi, United Arab Emirates},
abstract={Learning about sustainability Is not just a simple matter of memorizing facts. Sustainability education necessitates the employment of features that inspire discussion and develop decision-making skills. Video games have a huge potential to be fully functional learning environments for learning about sustainability. City of Life is an interactive mobile game application that teaches students at various levels of study about some sustainability aspects, which encompass the issues and tasks for achieving the sustainable development goals identified by the United Nation (UN). Its main theme is city building, where the player will be able to build their very own unique sustainable city using eye-catching, realistic, UAE-culture relevant buildings; further, it employs educational parts using attractive stylish mechanics such as Augmented Reality, with some mini-games to entertain and verify the player's educational knowledge. © 2018 IEEE.},
author_keywords={Augmented Reality;  City Building;  Education;  Edutainment;  Mobile game application;  Sustainability},
keywords={Augmented reality;  Computer aided instruction;  Decision making;  Education;  Sustainable development, Decision-making skills;  Educational knowledge;  Edutainment;  Interactive games;  Learning environments;  Mobile games;  Sustainability education;  Sustainable cities, Human computer interaction},
publisher={Institute of Electrical and Electronics Engineers Inc.},
isbn={9781538623992},
language={English},
abbrev_source_title={Adv. Sci. Eng. Technol. Int. Conf., ASET},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{NoAuthor2018,
title={Proceedings of the 29th International Conference on Cybernetics and Informatics, K and I 2018},
journal={Proceedings of the 29th International Conference on Cybernetics and Informatics, K and I 2018},
year={2018},
volume={2018-January},
page_count={235},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051218173&partnerID=40&md5=fb608691f109c6e2b1b2b49dd9363c67},
abstract={The proceedings contain 39 papers. The topics discussed include: LQR power control of wind generator; connection between 3D engine unity and microcontroller Arduino: a virtual smart house; robust stability and desired model method; interactive and virtual/mixed reality applications for mechatronics education developed in unity engine; the tools for verifying the control algorithms for speed and positional servo drives; augmented reality as an instrument for teaching industrial automation; a comparative analysis of constraint programming and metaheuristics for job-shop scheduling; multimedia support for education of mechatronics; proposal of system for visual evaluation of lemna minor bioassays; hardware and software design for one channel ECG measurement using MSP430 microcontroller; comparison of inverted pendulum stabilization with PID, LQ, and MPC control; virtual laboratory with experiment manager implemented into Moodle; two approaches to the adaptive cruise control (ACC) design; numerical acceleration of data processing using MATLAB for the needs of expert systems; and trajectories optimization of mobile robotic systems using discrete Kalman filtration.},
editor={Kozak S., Kozakova A., Ciganek J.},
publisher={Institute of Electrical and Electronics Engineers Inc.},
isbn={9781538644218},
language={English},
abbrev_source_title={Proc. Int. Conf. Cybern. Inform., K I},
document_type={Conference Review},
source={Scopus},
}

@CONFERENCE{NoAuthor2018,
title={Proceedings - 2018 6th International Conference on Learning and Teaching in Computing and Engineering, LaTiCE 2018},
journal={Proceedings - 2018 6th International Conference on Learning and Teaching in Computing and Engineering, LaTiCE 2018},
year={2018},
page_count={141},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070730757&partnerID=40&md5=4514182d08a7942a51e6a1a2292c9270},
abstract={The proceedings contain 25 papers. The topics discussed include: active learning for out-of-class activities by using interactive mobile apps; social constructivism learning through project based learning with scaffolding in flipped classroom; flipped classroom strategy to help underachievers in java programming; knowledge sequencing in online courses for introductory programming; an activity theory framework to explore social media and nostalgia as coping tools for international students; development and validation of problem solving task based-integrated STEM; the use of different kinds of robots to spark student interest in learning computational thinking; culturally relevant approach to encourage school children learn computer science concepts: using game based education strategy for student learning effectiveness and motivation; and designing an augmented reality application to learn three-dimensional views.},
publisher={Institute of Electrical and Electronics Engineers Inc.},
isbn={9781538678978},
language={English},
abbrev_source_title={Proc. - Int. Conf. Learn. Teach. Comput. Eng., LaTiCE},
document_type={Conference Review},
source={Scopus},
}

@BOOK{Pádua2018396,
author={Pádua, L. and Adão, T. and Narciso, D. and Cunha, A. and Magalhães, L. and Peres, E.},
title={Towards modern cost-effective and lightweight Augmented Reality setups},
journal={Virtual and Augmented Reality: Concepts, Methodologies, Tools, and Applications},
year={2018},
volume={1},
pages={396-423},
doi={10.4018/978-1-5225-5469-1.ch019},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046605312&doi=10.4018%2f978-1-5225-5469-1.ch019&partnerID=40&md5=626d7e45cd5e2428982beb8b85b54c74},
affiliation={University of Trás-os-Montes e Alto Douro, Portugal; INESC TEC, Portugal, University of Trás-os-Montes e Alto Douro, Portugal; ALGORITMI Center, University of Minho, Portugal},
abstract={Augmented Reality (AR) has been widely used in areas such as medicine, education, entertainment and cultural heritage to enhance activities that include (but are not limited to) teaching, training and amusement, through the completion of the real world with viewable and usually interactive virtual data (e.g. 3D models, geo-markers and labels). Despite the already confirmed AR benefits in the referred areas, many of the existing AR systems rely on heavy and obsolete hardware bundles composed of several devices and numerous cables that usually culminate in considerably expensive solutions. This issue is about to be tackled through the recent technological developments which currently enable the production of small-sized boards with remarkable capabilities - such as processing, visualization and storage - at relatively low prices. Following this line of reasoning, this paper proposes and compares five different multi-purpose AR mobile units, running Windows or Android operating systems, having in mind low-cost and lightweight requirements and different levels of immersion: a laptop computer, two tablets, a smartphone and smartglasses. A set of tests was carried out to evaluate the proposed unit performance. Moreover, a set of users' assessments was also conducted, highlighting an overall acceptance regarding the use of the proposed units in AR applications. This paper is an extension of a previous work (Pádua et al., 2015) in which a conceptual architecture for mobile units - complying with AR requirements (including visualization, processing, location and communication) for indoor or outdoor utilization - was presented, along with a shorter set of lightweight and cost-effective AR mobile units and respective performance tests. © 2018, IGI Global.},
keywords={Augmented reality;  Cost effectiveness;  Costs;  Digital storage;  Laptop computers;  Medical education;  mHealth;  Visualization, AR application;  Conceptual architecture;  Cost effective;  Cultural heritages;  Mobile units;  Multi-purpose;  Performance tests;  Technological development, Computer operating systems},
correspondence_address1={Pádua, L.; University of Trás-os-Montes e Alto DouroPortugal},
publisher={IGI Global},
isbn={9781522554707; 1522554696; 9781522554691},
language={English},
abbrev_source_title={Virtual and Augment. Real.: Concepts, Methodol., Tools, and Appl.},
document_type={Book Chapter},
source={Scopus},
}

@CONFERENCE{Zubir2018,
author={Zubir, F. and Suryani, I. and Ghazali, N.},
title={Integration of Augmented Reality into College Yearbook},
journal={MATEC Web of Conferences},
year={2018},
volume={150},
doi={10.1051/matecconf/201815005031},
art_number={05031},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042743772&doi=10.1051%2fmatecconf%2f201815005031&partnerID=40&md5=4b104acd03d26daf7453820a7b36d682},
affiliation={Centre for International Languages, Universiti Malaysia Perlis, Malaysia; Academy of Language Studies, Universiti Teknologi MARA, Malaysia},
abstract={Augmented reality (AR) has been used in many schools and colleges in developed countries. Apart from enhancing teaching to be more interactive, inventive and resourceful, the use of AR also has been reported to boost learning by fostering creativity and imagination, enhancing collaboration and team work, and making learning more engaging and stimulating. Despite the potentials of AR in enhancing school materials, this technology often has teachers and learners as the end users rather than developers. Given the benefits of AR in education, this study experimented on having the teachers and learners as developers in incorporating the use of AR to enhance the college yearbook. This paper describes the processes taken by the teachers and learners in integrating AR into a conventional reading material; specifically a college yearbook. In this study, an open source AR application is used and 32 markers are created. The method involves five major development processes which starts with planning, content, AR integration development, printing and finally AR integration construction. The 32 markers can be divided into a few sections which can be classified according to the types of content. At the end of this paper, the significance and challenges of this project are presented. © The Authors, published by EDP Sciences, 2018.},
keywords={Augmented reality;  Integration, AR application;  Developed countries;  Development process;  End users;  Integration constructions;  Open sources;  Team work, Teaching},
correspondence_address1={Zubir, F.; Centre for International Languages, Universiti Malaysia PerlisMalaysia; email: faharol@unimap.edu.my},
editor={Aljunid Syed Junid S.A., Rashidi C.B.M., Mohd Salleh M.A.A.},
publisher={EDP Sciences},
issn={2261236X},
language={English},
abbrev_source_title={MATEC Web Conf.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{SoutoMaior2018,
author={Souto Maior, C.B. and Moura, M.C. and de Santana, J.M.M. and do Nascimento, L.M. and Macedo, J.B. and Lins, I.D. and Droguett, E.L.},
title={Real-time SVM classification for drowsiness detection using eye aspect ratio},
journal={PSAM 2018 - Probabilistic Safety Assessment and Management},
year={2018},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063126080&partnerID=40&md5=2f7bfbfb55e73c9d50bf1c86f7385d28},
affiliation={Center for Risk Analysis and Environmental Modeling, Department of Production Engineering, Federal University of Pernambuco, Recife, Brazil; Mechanical Engineering Department, University of Chile, Santiago, Chile},
abstract={The execution of monotonous tasks that require high levels of attention is increasingly common due to automation and technological development. When such tasks have critical roles in guaranteeing the safety of work environments – such as in industrial control rooms and airport traffic control towers –, it is essential that operators retain adequate levels of alertness, so that demands for action are fulfilled. This paper presents a model for the detection of drowsiness based on processing video streams of a person’s face. Different from intrusive methods based on biological approach (e.g. Electroencephalogram and Electrooculogram), which require specific devices, we use computer vision and machine learning to present a prototypal version of a real-time system with personal feedback to monitor and detect when the user (operator) might be drowsy directly from a web camera. Drowsiness detection relies on automatic face detection and evaluation of the Eye Aspect Ratio, which allows monitoring user’s alertness state by classification with Support Vector Machines. Using such system, it is possible to alert the user of the danger of falling asleep, so that adequate actions can be taken, reducing the risk of human error and preventing accidents. © 2018 International Association for Probablistic Safety Assessment and Management (IAPSAM). All rights reserved.},
author_keywords={Augmented reality;  Computer vision;  Drowsiness detection;  Human reliability;  Work safety},
keywords={Accident prevention;  Aircraft accidents;  Aspect ratio;  Augmented reality;  Computer vision;  Human computer interaction;  Interactive computer systems;  Real time systems;  Support vector machines;  Traffic control, Airport traffic control;  Automatic face detection;  Biological approach;  Drowsiness detection;  Human reliability;  Industrial controls;  Technological development;  Work safety, Face recognition},
correspondence_address1={Souto Maior, C.B.; Center for Risk Analysis and Environmental Modeling, Department of Production Engineering, Federal University of PernambucoBrazil; email: caiomaior@hotmail.com},
publisher={International Association for Probablistic Safety Assessment and Management (IAPSAM)},
language={English},
abbrev_source_title={PSAM - Probab. Saf. Assess. Manag.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{NoAuthor2018,
title={20th International Conference on Human-Computer Interaction, HCI 2018},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2018},
volume={10901 LNCS},
page_count={1782},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061557257&partnerID=40&md5=47d15d94926562b24363b8f785c33848},
abstract={The proceedings contain 135 papers. The special focus in this conference is on Human-Computer Interaction. The topics include: Interactive stress-free toy design for students studying overseas; assessing patient needs for the enhancement of stroke rehabilitation services: A customer value perspective; towards encouraging a healthier lifestyle and increased physical activity – An app incorporating persuasive design principles; user acceptance factors for mhealth; healthy hankerings: Motivating adolescents to combat obesity with a mobile application; research on office chair based on modern office posture; eudaimonic gamification to engage cancer patients in positive coping strategies; Sports IT and digital wellness:: Three waves of digital transformation in sports and training; an innovative mattress design to improve sleep quality and thermal comfort; development of wireless surgical knife attachment with proximity indicators using aruco marker; interaction and interactivity: In the context of digital interactive art installation; towards cross-generational system design; exploring technology use in dance performances; from interpretation to deduction: A study on the experience design method of digitized communication of cultural heritage; bias in perception of art produced by artificial intelligence; research on personalized learning pattern in traditional handicraft using augmented reality: A case study of cantonese porcelain; an essay about the impact of the digital revolution on higher education in art and design; the application of augmented reality technology in digital display for intangible cultural heritage: The case of cantonese furniture; navigation for visually impaired using haptic feedback; supporting collaboration in human-machine crisis management networks; coRgI: Cognitive reasoning interface; experience maps for mobility.},
editor={Kurosu M.},
publisher={Springer Verlag},
issn={03029743},
isbn={9783319912370},
language={English},
abbrev_source_title={Lect. Notes Comput. Sci.},
document_type={Conference Review},
source={Scopus},
}

@ARTICLE{NoAuthor2018,
title={20th International Conference on Human-Computer Interaction, HCI 2018},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2018},
volume={10903 LNCS},
page_count={1782},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061549284&partnerID=40&md5=93878747cf7aeabe8913087a7e07267b},
abstract={The proceedings contain 135 papers. The special focus in this conference is on Human-Computer Interaction. The topics include: Interactive stress-free toy design for students studying overseas; assessing patient needs for the enhancement of stroke rehabilitation services: A customer value perspective; towards encouraging a healthier lifestyle and increased physical activity – An app incorporating persuasive design principles; user acceptance factors for mhealth; healthy hankerings: Motivating adolescents to combat obesity with a mobile application; research on office chair based on modern office posture; eudaimonic gamification to engage cancer patients in positive coping strategies; Sports IT and digital wellness:: Three waves of digital transformation in sports and training; an innovative mattress design to improve sleep quality and thermal comfort; development of wireless surgical knife attachment with proximity indicators using aruco marker; interaction and interactivity: In the context of digital interactive art installation; towards cross-generational system design; exploring technology use in dance performances; from interpretation to deduction: A study on the experience design method of digitized communication of cultural heritage; bias in perception of art produced by artificial intelligence; research on personalized learning pattern in traditional handicraft using augmented reality: A case study of cantonese porcelain; an essay about the impact of the digital revolution on higher education in art and design; the application of augmented reality technology in digital display for intangible cultural heritage: The case of cantonese furniture; navigation for visually impaired using haptic feedback; supporting collaboration in human-machine crisis management networks; coRgI: Cognitive reasoning interface; experience maps for mobility.},
editor={Kurosu M.},
publisher={Springer Verlag},
issn={03029743},
isbn={9783319912493},
language={English},
abbrev_source_title={Lect. Notes Comput. Sci.},
document_type={Conference Review},
source={Scopus},
}

@ARTICLE{NoAuthor2018,
title={20th International Conference on Human-Computer Interaction, HCI 2018},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2018},
volume={10902 LNCS},
page_count={1782},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061547850&partnerID=40&md5=3d646b55544e3f3864bb70672b31273b},
abstract={The proceedings contain 135 papers. The special focus in this conference is on Human-Computer Interaction. The topics include: Interactive stress-free toy design for students studying overseas; assessing patient needs for the enhancement of stroke rehabilitation services: A customer value perspective; towards encouraging a healthier lifestyle and increased physical activity – An app incorporating persuasive design principles; user acceptance factors for mhealth; healthy hankerings: Motivating adolescents to combat obesity with a mobile application; research on office chair based on modern office posture; eudaimonic gamification to engage cancer patients in positive coping strategies; Sports IT and digital wellness:: Three waves of digital transformation in sports and training; an innovative mattress design to improve sleep quality and thermal comfort; development of wireless surgical knife attachment with proximity indicators using aruco marker; interaction and interactivity: In the context of digital interactive art installation; towards cross-generational system design; exploring technology use in dance performances; from interpretation to deduction: A study on the experience design method of digitized communication of cultural heritage; bias in perception of art produced by artificial intelligence; research on personalized learning pattern in traditional handicraft using augmented reality: A case study of cantonese porcelain; an essay about the impact of the digital revolution on higher education in art and design; the application of augmented reality technology in digital display for intangible cultural heritage: The case of cantonese furniture; navigation for visually impaired using haptic feedback; supporting collaboration in human-machine crisis management networks; coRgI: Cognitive reasoning interface; experience maps for mobility.},
editor={Kurosu M.},
publisher={Springer Verlag},
issn={03029743},
isbn={9783319912431},
language={English},
abbrev_source_title={Lect. Notes Comput. Sci.},
document_type={Conference Review},
source={Scopus},
}

@CONFERENCE{Abdulrazzaq2018,
author={Abdulrazzaq, A.H. and Al-Ani, M.},
title={The needed merge of augmented reality smartphone application with CAS and SDI library services},
journal={IET Conference Publications},
year={2018},
volume={2018},
number={CP747},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061316861&partnerID=40&md5=2e671e09050cd519c104534bfaedb342},
affiliation={University of Bahrain, College of Information Technology, Bahrain; Columbia College, Department of Computer Science, Canada},
abstract={In this study two library services, current awareness service (CAS) and selective dissemination of information service (SDI), provided by University of Bahrain, were considered as examples to develop system prototype. The developed system uses Smartphone Augmented Reality (AR) technology to deliver up-to-date information about library services in an interactive way using multimedia to increase researchers’ (faculty members and students) awareness. The potentials and other perspectives of the proposed system were discussed. Although it can be further investigated, the proposed system could be considered as a new model for current awareness services of any digital library. Findings revealed that Smartphone AR system provides information in a real environment, giving researchers instant assistance and awareness of their needs, and is a good personal learning tool. However, to make the delivery of Smartphone AR system more effective, suggestions for further investigations are provided like Measuring and reviewing acceptance to the application in terms of Awareness, timeliness, coverage ratio, and usage then collected and summarized by focus groups’ thoughts and reactions. © 2018 Institution of Engineering and Technology. All rights reserved.},
author_keywords={Augmented Reality;  Current Awareness Service (CAS);  Library services;  QR code;  Selective Dissemination of Information (SDI);  Smartphone},
keywords={Augmented reality;  Information dissemination;  Information services;  Multimedia services;  Smartphones, Current awareness services;  Library services;  Personal learning;  QR codes;  Real environments;  Selective dissemination of information;  Smart-phone applications;  System prototype, Digital libraries},
publisher={Institution of Engineering and Technology},
isbn={9781785618161; 9781785618437; 9781785618468; 9781785618871; 9781785619427; 9781785619694; 9781839530036; 9781785617911},
language={English},
abbrev_source_title={IET Conf Publ},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Tsiampa2018393,
author={Tsiampa, A.M. and Skolariki, K.},
title={Holographic reality in education: The future of an innovative classroom},
journal={Proceedings of the 15th International Conference on Cognition and Exploratory Learning in the Digital Age, CELDA 2018},
year={2018},
pages={393-394},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060297852&partnerID=40&md5=9315effab787f5d358e2414db4befe53},
affiliation={HAU, Hellenic American Union, Athens, Greece; Deanery of Biomedical Sciences, University of Edinburgh, United Kingdom},
abstract={Latest research suggests that the most effective methods on education are those which utilize technological tools that provide an interactive approach to learning. Exploratory technology which involves augmented reality applications in the regular school program, gives the opportunity to young learners to become autonomous and active in their thinking, by stimulating multidimensionally their brains. Based upon this claim, this paper aims to present and propose the application, in every classroom, of an exploratory technology (specifically holographic reality), adapted to a new model which emphasizes the personal learning style of every student. Τhis will result in the improvement of the learning process since multidimensional stimuli will create new cognitive paths, affecting the level of assimilation, regardless of any possible special learning needs. This new approach will be supported by the latest research findings in the field of Neuroscience and their implications on the process of learning and memory. © 2018 IADIS Press. All Rights Reserved.},
author_keywords={Augmented Environment;  Brain Stimulation;  Holograms;  Holographic Reality;  Learning Disabilities;  Neuroplasticity},
keywords={Application programs;  Augmented reality;  Education computing;  Holograms;  Students, Augmented environments;  Brain stimulation;  Holographic Reality;  Learning disabilities;  Neuroplasticity, E-learning},
editor={Sampson D.G., Sampson D.G., Isaias P., Ifenthaler D., Ifenthaler D., Rodrigues L.},
publisher={IADIS Press},
isbn={9789898533814},
language={English},
abbrev_source_title={Proc. Int. Conf. Cogn. Explor. Learn. Digit. Age, CELDA},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Marar2018103,
author={Marar, R.W. and Jaser, E.},
title={Technology enhanced learning using virtual and augmented realities: An applied method to improve the animation teaching delivery},
journal={IC3K 2018 - Proceedings of the 10th International Joint Conference on Knowledge Discovery, Knowledge Engineering and Knowledge Management},
year={2018},
volume={3},
pages={103-110},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059094475&partnerID=40&md5=e50f6a99dc2f1e7db15106c025685ea1},
affiliation={Princess Sumaya University, Khalil Saket Street, Amman, Jordan},
abstract={This paper presents a software solution to enhance the content and presentation of graphic design and animation related textbooks. Using augmented and virtual reality concepts, a mobile application is developed to improve the static material found in books. This allows users to interact with animated examples and tutorials using their mobile phones and stereoscopic 3D viewers which will enhance information delivery. The application is tested on Google Cardboard with visual content in 3D space. Evaluation of the proposed application demonstrates that it improved the readability of static content and provided new experiences to the reader. © 2018 by SCITEPRESS - Science and Technology Publications, Lda. All rights reserved.},
author_keywords={Animation;  Augmented reality;  Google cardboard;  Interactive media;  Technology enhanced learning;  Virtual reality},
keywords={Animation;  Augmented reality;  Knowledge engineering;  Knowledge management;  Stereo image processing;  Virtual reality, Augmented and virtual realities;  Google cardboard;  Information delivery;  Interactive media;  Mobile applications;  Software solution;  Technology enhanced learning;  Virtual and augmented reality, E-learning},
editor={Salgado A.C., Bernardino J., Filipe J.},
publisher={SciTePress},
isbn={9789897583308},
language={English},
abbrev_source_title={IC3K - Proc. Int. Jt. Conf. Knowl. Discov., Knowl. Eng. Knowl. Manag.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Kazanidis2018245,
author={Kazanidis, I. and Palaigeorgiou, G. and Chintiadis, P. and Tsinakos, A.},
title={Α Pilot Evaluation of a Virtual Reality Educational Game for History Learning},
journal={Proceedings of the European Conference on e-Learning, ECEL},
year={2018},
volume={2018-November},
pages={245-253},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057950246&partnerID=40&md5=1372290833857d86bb60bbf586237aae},
affiliation={Computer and Informatics, Engineering Department, Eastern, Macedonia and Thrace, Institute of Technology, Kavala, Greece; Department of Primary Education, University of Western Macedonia, Florina, Greece},
abstract={Several studies have suggested that the use of ICT may motivate students in history learning and help them develop historical thinking. Virtual and augmented reality, mixed reality and tangible environments and other similar technologies can provide authentic, interactive, and explorative experiences to the students, moving away from the traditional book-based education into new immersive game-based learning experiences. In this study, we present a virtual reality (VR) game for history learning, and the results of a pilot study with students. In the game, the students are moving around virtual Acropolis where six trials are waiting for them. Each trial is related with a Greek myth and students have to complete a number of different activities for each trial in order to proceed to the next one. The aim of the game is to complement third graders’ history learning in schools. The game is free of charge, and the only infrastructure that is necessary is a typical smartphone and a Google Cardboard. A pilot study with twenty-eight (28) primary school students took place in the context of an exhibition focused on gamed-based learning. Data were collected through questionnaires and focus group discussions. Students’ responses revealed their positive attitude towards the VR game since they considered it as simple, innovative, valuable, inspiring, challenging, practical, predictable and appropriate for learning about history. That’s why they also supported that similar environments would have been of great value in schools. Students supported that they were fully focused on the tasks at hand and they felt present in the virtual environment. © The Authors, 2018. All Rights Reserved.},
author_keywords={Game-based learning;  Historical thinking;  History learning;  Virtual reality},
keywords={Augmented reality;  Mixed reality;  Students;  Surveys;  Virtual reality, Educational game;  Free of charge;  Game-based Learning;  Historical thinking;  Pilot studies;  Positive attitude;  Primary schools;  Virtual and augmented reality, E-learning, Books;  Environments;  Evaluation;  Greek;  History;  Questionnaires;  Schools;  Surveys},
editor={Andreatos A., Sgouropoulou C., Ntalianis K.},
publisher={Academic Conferences Limited},
issn={20488637},
isbn={9781912764075},
language={English},
abbrev_source_title={Proc. Eur. Conf. e-Learn., ECEL},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{NoAuthor2018,
title={4th International Conference of the Virtual and Augmented Reality in Education, VARE 2018},
journal={4th International Conference of the Virtual and Augmented Reality in Education, VARE 2018},
year={2018},
page_count={215},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056740614&partnerID=40&md5=a66d2e36fbca485605dc938d27b373b1},
abstract={The proceedings contain 29 papers. The topics discussed include: motostudent and the reality-virtuality continuum; augmented reality: modernizing rural education in India; VR-technology for risk assessment of and accident prevention at machine tools; educational augmented reality systems: benefits of implementation and government support; development and evaluation of work support system by AR using HMD; development and evaluation of the museum support system using an AR technology; alternatives generation via data analytics for decision making using VR; the use of virtual reality training application to increase the effectiveness of workshops in the field of lean manufacturing; knowledge exchange using holograms in the teaching factory concept; the use of augmented reality to promote tourism in Thailand; decision support method for using virtual reality in education based on a cost-benefit- analysis; virtual spaces for collaboration and learning constructing multi user virtual environments for learning; juxtaposing visual layouts – an approach for solving analytical and exploratory tasks through arranging visual interfaces; visualizing law - a norm-graph visualization approach based on semantic legal data; exploring dimensionality reduction effects in mixed reality for analyzing tinnitus patient data; and virtual reality and augmented reality low cost: an experience of heritage education in primary school.},
editor={Bruzzone A.G., Mendivil E.G., Gutierrez J.M., Ginters E., Longo F.},
publisher={Dime University of Genoa},
isbn={9788885741218},
language={English},
abbrev_source_title={Int. Conf. Virtual Augment. Real. in Educ., VARE},
document_type={Conference Review},
source={Scopus},
}

@CONFERENCE{RamirezFlores2018123,
author={Ramirez Flores, P.G. and Mendívil, E.G. and Quintero, H.N.},
title={Virtual spaces for collaboration and learning constructing multi user virtual environments for learning},
journal={4th International Conference of the Virtual and Augmented Reality in Education, VARE 2018},
year={2018},
pages={123-127},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056697421&partnerID=40&md5=f8bbf41cd12acdec47d33029b296120a},
affiliation={Tecnologico de Monterrey, Av. Eugenio Garza Sada, 2501 sur, Monterrey, Nuevo León, Mexico},
abstract={In this paper we present a way of use of virtual environments as Virtual Reality (VR) to conform multi user virtual environments for collaboration and learning, allowing students and professors interact within a virtual space in real-time, reviewing and presenting topics and materials, coaching and tutoring to enhance learning process. We review three technologies on the market who facilitate constructing this kind of spaces and share our experiences on our pilot implementations. This is a research in process and other implementation and evaluations will be done in future works. Copyright © (2015) by CAL-TEK S.r.l.All rights reserved. . All Rights Reserved.},
author_keywords={Distance assistance;  Multi-collaboration systems;  Student engagement;  Virtual reality},
keywords={Augmented reality;  Students;  Virtual reality, Collaboration systems;  Distance assistance;  Enhance learning;  In-process;  Multi-user virtual environment;  Pilot implementation;  Student engagement;  Virtual spaces, E-learning},
editor={Bruzzone A.G., Mendivil E.G., Gutierrez J.M., Ginters E., Longo F.},
publisher={Dime University of Genoa},
isbn={9788885741218},
language={English},
abbrev_source_title={Int. Conf. Virtual Augment. Real. in Educ., VARE},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Longo2018589,
author={Longo, F. and Nicoletti, L. and Padovano, A.},
title={An interactive, interoperable and ubiquitous mixed reality application for a smart learning experience},
journal={International Journal of Simulation and Process Modelling},
year={2018},
volume={13},
number={6},
pages={589-603},
doi={10.1504/IJSPM.2018.095864},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055862181&doi=10.1504%2fIJSPM.2018.095864&partnerID=40&md5=673e99eac666c11450c52d46d946c4eb},
affiliation={Department of Mechanical Energy and Management Engineering (DIMEG), University of Calabria, Italy; Cal-Tek Srl, Via Spagna, Rende (CS), 240-242, Italy},
abstract={This article presents an innovative comprehensive platform that includes an interactive, interoperable and ubiquitous mixed reality application that will bring beyond the way cultural digital resources are created, disseminated, preserved and re-used. As part of an extensive research effort carried out by the authors to foster the utilisation of the most recent technologies in the field of cultural heritage, this article goes further in the design and development of a prototype of an intelligent, interactive and interoperable comprehensive platform for the 21st century museums (I3-CPM). Since I3-CPM explores unconventional ways to deliver cultural contents (virtual and augmented reality, serious games, holography, simulation, knowledge based systems, vocal interaction technologies, etc.), it is expected to provide users with a new and smart learning experience. The OUTSIDE-REAL application is here described as part of the I3-CPM framework: it provides intuitive navigation of mixed reality cultural contents and storytelling through an intelligent knowledge navigator and vocal assistant, called SOPHOS, thus offering the visitors a user-driven, interactive and meaningful learning experience at the cultural heritage site. © 2018 Inderscience Enterprises Ltd.},
author_keywords={Augmented reality;  Cultural heritage;  Digital museum;  Intelligent agents;  Mixed reality;  Smart learning;  Storytelling;  Vocal assistant},
keywords={Augmented reality;  Intelligent agents;  Knowledge based systems;  Museums;  Serious games, Cultural heritages;  Digital museums;  Smart learning;  Storytelling;  Vocal assistant, Mixed reality},
correspondence_address1={Longo, F.; Department of Mechanical Energy and Management Engineering (DIMEG), University of CalabriaItaly; email: f.longo@unical.it},
publisher={Inderscience Enterprises Ltd.},
issn={17402123},
language={English},
abbrev_source_title={Int. J. Simul. Process Model.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{NoAuthor2018,
title={ACM International Conference Proceeding Series},
journal={ACM International Conference Proceeding Series},
year={2018},
page_count={294},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055233094&partnerID=40&md5=8de7a3535a5090a024126f00de0ebeaa},
abstract={The proceedings contain 49 papers. The topics discussed include: a kernelized fuzzy c-means clustering algorithm based on bat algorithm; multi-attribute clustering of student's entrepreneurial potential mapping based on its characteristics and the affecting factors (preliminary study on Indonesian higher education database); single camera body tracking for virtual fitting room application; locomotion, non-isometric mapping and distance perception in virtual reality; augmented reality technology for highway construction project delivery; mobile augmented reality for environmental awareness: a technology acceptance study; guide and retain users: interactive recommender system; background music recommendation system based on user's heart rate and elapsed time; how repetitive are karate kicks performed by skilled practitioners?; enhanced cross-entropy based stopping criteria at low signal-to-noise ratio regions; improving accuracy in Thai sign and symptom classification using context-free grammar approach; combining auditory perception and visual features for regional recognition of Chinese folk songs; similarity retrieval of trademark images by vector graphics based on shape characteristics of component; large scale object measurement based on data fusion of stereo camera's multi-viewpoint images; and an improved coordinate update method for the identification of adaptive hinging hyperplanes model.},
publisher={Association for Computing Machinery},
language={English},
abbrev_source_title={ACM Int. Conf. Proc. Ser.},
document_type={Conference Review},
source={Scopus},
}

@ARTICLE{Azimi201820,
author={Azimi, E. and Molina, C. and Chang, A. and Huang, J. and Huang, C.-M. and Kazanzides, P.},
title={Interactive training and operation ecosystem for surgical tasks in mixed reality},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2018},
volume={11041 LNCS},
pages={20-29},
doi={10.1007/978-3-030-01201-4_3},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054886916&doi=10.1007%2f978-3-030-01201-4_3&partnerID=40&md5=16cde907665de34ad6acadfeed78c41b},
affiliation={Department of Computer Science, Johns Hopkins University, Baltimore, MD  21218, United States; Department of Neurosurgery, Johns Hopkins Hospital, Baltimore, MD  21287, United States},
abstract={Inadequate skill in performing surgical tasks can lead to medical errors and cause avoidable injury or death to the patients. On the other hand, there are situations where a novice surgeon or resident does not have access to an expert while performing a task. We therefore propose an interactive ecosystem for both training and practice of surgical tasks in mixed reality, which consists of authoring of the desired surgical task, immersive training and practice, assessment of the trainee, and remote coaching and analysis. This information-based ecosystem will also provide the data to train machine learning algorithms. Our interactive ecosystem involves a head-mounted display (HMD) application that can provide feedback as well as audiovisual assistance for training and live clinical performance of the task. In addition, the remote monitoring station provides the expert with a real-time view of the scene from the user’s perspective and enables guidance by providing annotation directly on the user’s scene. We use bedside ventriculostomy, a neurosurgical procedure, as our illustrative use case; however the modular design of the system makes it expandable to other procedures. © Springer Nature Switzerland AG 2018.},
author_keywords={Artificial intelligence;  Medical augmented reality;  Surgical simulation and modeling;  Surgical training and assessment},
keywords={Artificial intelligence;  Augmented reality;  Computer aided analysis;  Ecosystems;  Endoscopy;  Helmet mounted displays;  Image analysis;  Learning algorithms;  Learning systems;  Medical imaging;  Robotics;  Surgery, Clinical performance;  Head mounted displays;  Interactive training;  Medical augmented realities;  Modular designs;  Remote monitoring station;  Surgical simulation;  Surgical training, Mixed reality},
correspondence_address1={Azimi, E.; Department of Computer Science, Johns Hopkins UniversityUnited States; email: eazimi1@jhu.edu},
editor={Malpani A., Zenati M.A., Oyarzun Laura C., Celebi M.E., Sarikaya D., Codella N.C., Halpern A., Erdt M., Maier-Hein L., Xiongbiao L., Wesarg S., Stoyanov D., Taylor Z., Drechsler K., Dana K., Martel A., Shekhar R., De Ribaupierre S., Reichl T., McLeod J., Gonzalez Ballester M.A., Collins T., Linguraru M.G.},
publisher={Springer Verlag},
issn={03029743},
isbn={9783030012007},
language={English},
abbrev_source_title={Lect. Notes Comput. Sci.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Ati2018287,
author={Ati, M. and Abdullahi, H. and Kabir, K. and Ahmed, M.},
title={Implementation of augmented reality in the teaching of young children},
journal={Communications in Computer and Information Science},
year={2018},
volume={938},
pages={287-297},
doi={10.1007/978-3-030-01653-1_18},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054877529&doi=10.1007%2f978-3-030-01653-1_18&partnerID=40&md5=1ad0ba5525b8e151a55898b367c28164},
affiliation={Computer Science and Information Technology Department, College of Engineering, Abu Dhabi University, Abu Dhabi, United Arab Emirates; College of Engineering, Abu Dhabi University, Abu Dhabi, United Arab Emirates},
abstract={Learning to write can be exhausting for young children. In traditional teaching, children with different learning abilities are taught with the same rubric. This, in turn, impacts children that need extra attention to catch up with their peers, which leads them to suffer right from the early learning stages. Traditional teaching methods also are so rigid which makes them unable to automatically identify those children with less ability and in need of extra help. Hence, with the rapid development of ICT, innovative learning methods are sought to be important to allow children to be taught with different rubrics. The aim of this research is to improve the learning process for pre-school children via introducing Augmented Reality (AR) into the process, which, in turn, simplifies it as well as identifying children’s abilities. The research introduces gamification to the process in order to ease the burden on children. Furthermore, we are trying to involve both the school as well the home to be part of the educational cycle so that parents are a part of the learning/educational process of their young children. Augmented reality combined with pleasing sound make the learning more interactive and enjoyable. The outcome of this research also helps parents to keep track of their children’s learning. The paper also describes the deployment of the application in local schools as a pilot study so teachers can get feedback on students’ learning curves and to fine tune the work further. © Springer Nature Switzerland AG 2018.},
author_keywords={Augmented reality;  Cloud computing;  Education},
keywords={Augmented reality;  Cloud computing;  Education;  Learning systems, Early learning;  Innovative learning;  Learning abilities;  Learning curves;  Learning process;  Pre-school children;  Traditional teachings;  Young children, Teaching},
correspondence_address1={Ati, M.; Computer Science and Information Technology Department, College of Engineering, Abu Dhabi UniversityUnited Arab Emirates; email: Modafar.ati@adu.ac.ae},
editor={Al-mamory S.O., Alwan J.K., Hussein A.D.},
publisher={Springer Verlag},
issn={18650929},
isbn={9783030016524},
language={English},
abbrev_source_title={Commun. Comput. Info. Sci.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Siouli2018,
author={Siouli, S. and Dratsiou, I. and Antoniou, P.E. and Bamidis, P.D.},
title={Primary school STEM education through co-creative methodologies},
journal={CEUR Workshop Proceedings},
year={2018},
volume={2190},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053103773&partnerID=40&md5=00375849ee37a43aaeb8d4d97e1d9e34},
affiliation={Education Science – Learning Technologies post-graduate program, Faculty of Education Aristotle University of Thessaloniki (AUTH), Thessaloniki, Greece; Lab of Medical Physics, Faculty of Medicine, School of Health Sciences, Aristotle University of Thessaloniki (AUTH), Thessaloniki, Greece},
abstract={Technology Enhanced Learning (TEL) in Science Technology Engineering Mathematics (STEM) Education is a well-established method for engaging learners with difficult and counterintuitive concepts such those in space and astronomy. Co-creative, participatory methods are easily applicable in TEL for STEM due to a multitude of existing platforms and services for creative technology based education. This work describes three co-creative endeavors in astronomy and solar system education for children of primary education. The cases comprised of an exploratory game teaching about the surface of the planet Mars, an interactive Augmented Reality (AR) application exploring the surface of the Moon and a team endeavor for learning through creating a general astronomy quiz. In all cases, participants were excited and engaged with the subject matter and the technology a fact that led to successful educational episodes. Beyond that the core outcome of this work was a first identification of a common co-creative workflow of introduction-toolset provision- implicit creative education –publishing content engagement in all three cases. This co-creative workflow identifies very closely with the core theoretical tenets of constructivist learning theory. In that context this work is the first step towards formal identification of the co-creative workflows with pure educational methodologies. © 2018 CEUR-WS. All Rights Reserved.},
author_keywords={Augmented Reality;  Co-creation;  Primary Education;  Programming;  STEM education;  Technology-Enhanced learning},
keywords={Augmented reality;  Computation theory;  Mathematical programming;  Online systems;  STEM (science, technology, engineering and mathematics), Co-creation;  Constructivist learning theory;  Educational methodologies;  Engineering mathematics;  Participatory methods;  Primary education;  STEM education;  Technology enhanced learning, Engineering education},
editor={Piotrkowicz A., Treasure-Jones T., Fronza I., Pahl C., Dent-Spargo R., Koren I., Antoniou P., Bailey P., Dennerlein S.},
publisher={CEUR-WS},
issn={16130073},
language={English},
abbrev_source_title={CEUR Workshop Proc.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Ding2018170,
author={Ding, Y.-Y. and Han, J.-H. and Cao, Q. and Liu, C.},
title={A Study on Application of AR Three-Dimensional Touch Interaction in Children Education},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2018},
volume={10920 LNCS},
pages={170-184},
doi={10.1007/978-3-319-91806-8_14},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050635245&doi=10.1007%2f978-3-319-91806-8_14&partnerID=40&md5=c1129dc640f2ba95b12b6e4d59d89a3e},
affiliation={Beijing Forestry University, Beijing, China; Baidu University, Beijing, China},
abstract={This essay presents knowledge that application validity and reasonability of AR technology based on three-dimensional (3-D) touch interaction in children education were investigated. Plants were selected as the theme to design a children education mode dependent on AR 3-D touch interaction; through comparative experiments, impacts of 4 learning styles on knowledge learning effects were respectively compared, book reading, AR visual content display, AR screen multi-touch interaction and AR 3-D touch interaction. This article shows that learning by means of AR 3-D touch interaction is more effective and such a method has the ability to keep users interested in learning and enhance their understanding and memory of advanced knowledge. Although the pure AR visual content display plays a certain promotion role in children education, information content about the knowledge displayed is low accompanied with a single interactive mode. In a word, AR visual content display has certain defects. By contrast, children who adopt AR 3-D touch interaction can achieve a better learning effect, which indicates that such an approach possesses application value. © 2018, Springer International Publishing AG, part of Springer Nature.},
author_keywords={Augmented Reality (AR);  Children’s cognition;  Plant education;  Touch interaction},
keywords={Augmented reality;  Human computer interaction, Comparative experiments;  Information contents;  Interactive mode;  Knowledge learning;  Learning effects;  Multi-touch interactions;  Threedimensional (3-d);  Touch interaction, Touch screens},
correspondence_address1={Han, J.-H.; Beijing Forestry UniversityChina; email: hanjing013@126.com},
editor={Marcus A., Wang W.},
publisher={Springer Verlag},
issn={03029743},
isbn={9783319918051},
language={English},
abbrev_source_title={Lect. Notes Comput. Sci.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{NoAuthor2018,
title={10th International Conference on Virtual, Augmented and Mixed Reality, VAMR 2018 Held as Part of HCI International 2018},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2018},
volume={10909 LNCS},
page_count={476},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050588641&partnerID=40&md5=4110aa4ec0293e9a126fc706ff1bcf98},
abstract={The proceedings contain 35 papers. The special focus in this conference is on Virtual, Augmented and Mixed Reality. The topics include: The Use of Virtual and Augmented Reality to Prevent the Physical Effects Caused by Diabetes Melitus Type 2: An Integrative Review; reducing Fear or Anxiety by Simulating Breathing Movements as Physical Contact with an Unrelated Person; the Impact of Augmented Reality on Art Engagement: Liking, Impression of Learning, and Distraction; following the White Rabbit: The Virtual Reality for Games; Cinematic Narration in VR – Rethinking Film Conventions for 360 Degrees; walking with Angest: Subjective Measures for Subjective Evaluation in a Walking Simulator Virtual Reality Game; AI-Based VR Earthquake Simulator; immercity: A Curation Content Application in Virtual and Augmented Reality; VAIR Field - Multiple Mobile VR Shooting Sports; The Effect of Multimodal Feedback on Perceived Exertion on a VR Exercise Setting; Command and Control Collaboration Sand Table (C2-CST); CAE/VR Integration – A Qualitative Assessment of Advanced Visualization for Interactive Conceptual Simulations (ICS) in Industrial Use; Augmented Reality and Mixed Reality Prototypes for Enhanced Mission Command/Battle Management Command and Control (BMC2) Execution; helmet-Mounted Displays to Support Off-Axis Pilot Spatial Orientation; Augmented Reality Views: Discussing the Utility of Visual Elements by Mediation Means in Industrial AR from a Design Perspective; usability Evaluation for Drone Mission Planning in Virtual Reality; cyber Vulnerability: An Attentional Dilemma; trust in Autonomous Systems for Threat Analysis: A Simulation Methodology; mxR Framework for Uncertainty Based Explanation for Uncovering Adversarial Behavior; human-Agent Collaborative Decision-Making Framework for Naval Systems.},
editor={Fragomeni G., Chen J.Y.},
publisher={Springer Verlag},
issn={03029743},
isbn={9783319915807},
language={English},
abbrev_source_title={Lect. Notes Comput. Sci.},
document_type={Conference Review},
source={Scopus},
}

@ARTICLE{NoAuthor2018,
title={10th International Conference on Virtual, Augmented and Mixed Reality, VAMR 2018 Held as Part of HCI International 2018},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2018},
volume={10910 LNCS},
page_count={476},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050503957&partnerID=40&md5=e3ac6764a0dc1b4a80355e1aeba44301},
abstract={The proceedings contain 35 papers. The special focus in this conference is on Virtual, Augmented and Mixed Reality. The topics include: The Use of Virtual and Augmented Reality to Prevent the Physical Effects Caused by Diabetes Melitus Type 2: An Integrative Review; reducing Fear or Anxiety by Simulating Breathing Movements as Physical Contact with an Unrelated Person; the Impact of Augmented Reality on Art Engagement: Liking, Impression of Learning, and Distraction; following the White Rabbit: The Virtual Reality for Games; Cinematic Narration in VR – Rethinking Film Conventions for 360 Degrees; walking with Angest: Subjective Measures for Subjective Evaluation in a Walking Simulator Virtual Reality Game; AI-Based VR Earthquake Simulator; immercity: A Curation Content Application in Virtual and Augmented Reality; VAIR Field - Multiple Mobile VR Shooting Sports; The Effect of Multimodal Feedback on Perceived Exertion on a VR Exercise Setting; Command and Control Collaboration Sand Table (C2-CST); CAE/VR Integration – A Qualitative Assessment of Advanced Visualization for Interactive Conceptual Simulations (ICS) in Industrial Use; Augmented Reality and Mixed Reality Prototypes for Enhanced Mission Command/Battle Management Command and Control (BMC2) Execution; helmet-Mounted Displays to Support Off-Axis Pilot Spatial Orientation; Augmented Reality Views: Discussing the Utility of Visual Elements by Mediation Means in Industrial AR from a Design Perspective; usability Evaluation for Drone Mission Planning in Virtual Reality; cyber Vulnerability: An Attentional Dilemma; trust in Autonomous Systems for Threat Analysis: A Simulation Methodology; mxR Framework for Uncertainty Based Explanation for Uncovering Adversarial Behavior; human-Agent Collaborative Decision-Making Framework for Naval Systems.},
editor={Chen J.Y., Fragomeni G.},
publisher={Springer Verlag},
issn={03029743},
isbn={9783319915838},
language={English},
abbrev_source_title={Lect. Notes Comput. Sci.},
document_type={Conference Review},
source={Scopus},
}

@ARTICLE{Pruna2018261,
author={Pruna, E. and Acurio, A. and Escobar, I. and Cocha, H. and Alpúsig, S. and Bucheli, J.},
title={Virtual training system for crawling skill in infants using mapping 2D: Preliminary test},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2018},
volume={10850 LNCS},
pages={261-268},
doi={10.1007/978-3-319-95270-3_22},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050350025&doi=10.1007%2f978-3-319-95270-3_22&partnerID=40&md5=82d87f6c43f948ac065104b32db1fd17},
affiliation={Universidad de las Fuerzas Armadas ESPE, Sangolquí, Ecuador},
abstract={This paper describes the development of an interactive virtual tool, in order to encourage the ability to crawl in infants. The virtual environment in the system is implemented with the graphics engine Unity3D. The application is tested in the MagixBox platform with a high brightness projector. The environment has colorful and novel designs which are projected on a suitable floor space. User can interact with the projection due to the mapping that makes the infrared sensor and HD 2D camera in MagixBox. The sensor will continually scanning the objects that are close to the projection. The system helps in the process of activities record and saving important data for the assessment by the specialist. © Springer International Publishing AG, part of Springer Nature 2018.},
author_keywords={Therapeutic exercise;  Unity 3D;  Virtual system},
keywords={E-learning;  Infrared detectors;  Mapping;  Virtual reality, Graphics engine;  High brightness;  Infra-red sensor;  Novel design;  Therapeutic exercise;  Virtual systems;  Virtual tool;  Virtual training systems, Augmented reality},
correspondence_address1={Pruna, E.; Universidad de las Fuerzas Armadas ESPEEcuador; email: eppruna@espe.edu.ec},
editor={De Paolis L.T., Bourdot P.},
publisher={Springer Verlag},
issn={03029743},
isbn={9783319952697},
language={English},
abbrev_source_title={Lect. Notes Comput. Sci.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{NoAuthor2018,
title={5th International Conference on Augmented Reality, Virtual Reality, and Computer Graphics, SALENTO AVR 2018},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2018},
volume={10850 LNCS},
page_count={1232},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050345135&partnerID=40&md5=39836cc5cc50d9933efabef1cfa57497},
abstract={The proceedings contain 93 papers. The special focus in this conference is on Augmented Reality, Virtual Reality, and Computer Graphics. The topics include: Virtual Rehabilitation of Carpal Tunnel Syndrome Through Force Feedback; SLT-Game: Support System for Therapies of Children with Communication Disorders; sales Maximization Based on Neuro-Marketing Techniques in Virtual Environments; IMPACT: Immersive Mirror for Pain Control and Treatment; a Microsoft HoloLens Mixed Reality Surgical Simulator for Patient-Specific Hip Arthroplasty Training; haptic Stimulation Glove for Fine Motor Rehabilitation in Virtual Reality Environments; virtual Simulation of Brain Sylvian Fissure Exploration and Aneurysm Clipping with Haptic Feedback for Neurosurgical Training; augmented Reality System for the Complement of Cognitive Therapeutic Exercise in Children: Preliminary Tests; digital-Assisted Repairing of the Six Steeds in Zhao Mausoleum; interactive System Using Myoelectric Muscle Sensors for the Strengthening Upper Limbs in Children; virtual Acoustic Rendering in Old Spaces: Application to an Early-Modern Theatre in València, “L’Olivera”; ViennAR: User-Centered-Design of a Bring Your Own Device Mobile Application with Augmented Reality; comparing Different Storytelling Approaches for Virtual Guides in Digital Immersive Museums; improvements and Implementations of the Spatial Augmented Reality Applied on Scale Models of Cultural Goods for Visual and Communicative Purpose; augmented Reality to Understand the Leonardo’s Machines; optimization Techniques for Photogrammetry Applied to Cultural Heritage and the Action of Transformation Groups; user Experience of Markerless Augmented Reality Applications in Cultural Heritage Museums: ‘MuseumEye’ as a Case Study; augmented Reality for the Enhancement of Apulian Archaeological Areas; virtual Reality Arcade Game in Game-Based Learning for Cultural Heritage.},
editor={De Paolis L.T., Bourdot P.},
publisher={Springer Verlag},
issn={03029743},
isbn={9783319952697},
language={English},
abbrev_source_title={Lect. Notes Comput. Sci.},
document_type={Conference Review},
source={Scopus},
}

@ARTICLE{NoAuthor2018,
title={5th International Conference on Augmented Reality, Virtual Reality, and Computer Graphics, SALENTO AVR 2018},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2018},
volume={10851 LNCS},
page_count={1232},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050300595&partnerID=40&md5=fdb36c0f2a0a4bc9ca270bd287109bf8},
abstract={The proceedings contain 93 papers. The special focus in this conference is on Augmented Reality, Virtual Reality, and Computer Graphics. The topics include: Virtual Rehabilitation of Carpal Tunnel Syndrome Through Force Feedback; SLT-Game: Support System for Therapies of Children with Communication Disorders; sales Maximization Based on Neuro-Marketing Techniques in Virtual Environments; IMPACT: Immersive Mirror for Pain Control and Treatment; a Microsoft HoloLens Mixed Reality Surgical Simulator for Patient-Specific Hip Arthroplasty Training; haptic Stimulation Glove for Fine Motor Rehabilitation in Virtual Reality Environments; virtual Simulation of Brain Sylvian Fissure Exploration and Aneurysm Clipping with Haptic Feedback for Neurosurgical Training; augmented Reality System for the Complement of Cognitive Therapeutic Exercise in Children: Preliminary Tests; digital-Assisted Repairing of the Six Steeds in Zhao Mausoleum; interactive System Using Myoelectric Muscle Sensors for the Strengthening Upper Limbs in Children; virtual Acoustic Rendering in Old Spaces: Application to an Early-Modern Theatre in València, “L’Olivera”; ViennAR: User-Centered-Design of a Bring Your Own Device Mobile Application with Augmented Reality; comparing Different Storytelling Approaches for Virtual Guides in Digital Immersive Museums; improvements and Implementations of the Spatial Augmented Reality Applied on Scale Models of Cultural Goods for Visual and Communicative Purpose; augmented Reality to Understand the Leonardo’s Machines; optimization Techniques for Photogrammetry Applied to Cultural Heritage and the Action of Transformation Groups; user Experience of Markerless Augmented Reality Applications in Cultural Heritage Museums: ‘MuseumEye’ as a Case Study; augmented Reality for the Enhancement of Apulian Archaeological Areas; virtual Reality Arcade Game in Game-Based Learning for Cultural Heritage.},
editor={De Paolis L.T., Bourdot P.},
publisher={Springer Verlag},
issn={03029743},
isbn={9783319952819},
language={English},
abbrev_source_title={Lect. Notes Comput. Sci.},
document_type={Conference Review},
source={Scopus},
}

@ARTICLE{NoAuthor2018,
title={4th International Conference on Immersive Learning Research Network, iLRN 2018},
journal={Communications in Computer and Information Science},
year={2018},
volume={840},
page_count={210},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049093496&partnerID=40&md5=5b7345d36774dbb22b98eaa71a2ff186},
abstract={The proceedings contain 14 papers. The special focus in this conference is on Immersive Learning Research Network. The topics include: Virtual learning environments for promoting self transformation: Iterative design and implementation of Philadelphia land science; learning child development through immersion in Ill-structured problems using a virtual environment; Using HMD-based immersive virtual environments in primary/K-12 education; facilitating undergraduate experimental game design: A pilot study with Celestial harmony; social resiliency in digital games; listen and play: Auditory-motor interaction in a Bard’s tale video game; embodying climate change: Incorporating full body tracking in the design of an interactive rates of change greenhouse gas simulation; prompting connections between content and context: Blending immersive virtual environments and augmented reality for environmental science learning; immersive analytics for the ecological cognitive stimulation approach; an immersive system for 3D floods visualization and analysis; the next generation of disaster management and relief planning: Immersive analytics based approach; the making and evaluation of picts and pixels: Mixed exhibiting in the real and the unreal; fidelity perception of 3D models on the web; mathland: Constructionist mathematical learning in the real world using immersive mixed reality.},
editor={Beck D., Allison C., Ogle T., Pirker J., Gutl C., Richter J., Morgado L., Pena-Rios A.},
publisher={Springer Verlag},
issn={18650929},
isbn={9783319935959},
language={English},
abbrev_source_title={Commun. Comput. Info. Sci.},
document_type={Conference Review},
source={Scopus},
}

@CONFERENCE{Söbke2018,
author={Söbke, H. and Montag, M. and Zander, S.},
title={Educational AR canvas - Towards systematic design of AR learning experiences [Von der AR-App zur Lernerfahrung: Entwurf eines formalen Rahmens zum Einsatz von Augmented Reality als Lehrwerkzeug]},
journal={CEUR Workshop Proceedings},
year={2018},
volume={2092},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048134434&partnerID=40&md5=9603127ad5941255f03b7de873897154},
affiliation={Bauhaus-Universität Weimar, Bauhaus-Institut für zukunftsfähige Infrastruktursysteme, Coudraystr. 7, Weimar, 99423, Germany; Bauhaus-Universität Weimar, Didaktik medialer Lernumgebungen, Geschwister-Scholl-Straße 7, Weimar, 99423, Germany},
abstract={Augmented Reality (AR) technology allows to add further information to real world contexts. Adding information to real world contexts is considered helpful especially in learning scenarios. Thus, AR is regarded as a valuable learning technology. Due to recent technical progress in hardware, software and communication technology the availability of AR for widespread use in learning scenarios has increased significantly. However, so far, there is a lack of specific guidelines for the development of AR-based learning scenarios in formal teaching. This article provides a draft of a guideline to develop AR-based learning scenarios. Methodologically, first, the results of a literature review of the current status of AR tools in learning contexts are described. Thereafter, the media-didactic principles of visual and interactive media in learning contexts are combined to the draft of a description scheme for the use of AR technology in learning contexts. The description scheme - Educational AR Canvas named -is illustrated using a concrete AR-based learning scenario for civil engineering students. The employed app AugView is used for the visualization of the underground hidden water infrastructure. Thus, this article contributes to the further application of AR technology to learning contexts by describing a systematic description schema. © 2018 CEUR-WS. All rights reserved.},
keywords={Augmented reality, Civil engineering students;  Communication technologies;  Description schemes;  Learning experiences;  Learning technology;  Literature reviews;  Systematic designs;  Water infrastructure, E-learning},
editor={Ullrich C., Wessner M.},
publisher={CEUR-WS},
issn={16130073},
language={German},
abbrev_source_title={CEUR Workshop Proc.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Lee2018101,
author={Lee, K.T. and Quek, A.},
title={TARogic: Tangible augmented reality game},
journal={International Journal of Engineering and Technology(UAE)},
year={2018},
volume={7},
number={2},
pages={101-104},
doi={10.14419/ijet.v7i2.14.11463},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045350691&doi=10.14419%2fijet.v7i2.14.11463&partnerID=40&md5=829f375143ce3568842c7f0dc5cfdaa2},
affiliation={Multimedia University, Malaysia},
abstract={Augmented Reality (AR) has been around for the past decade. It has been applied in many fields and one of the common fields is in education. In this paper, we have make use of Tangible Augmented Reality technology in creating an interactive game called TARogic that teaches students on the basic of programming logics. Tangible Augmented Reality is a combination of Augmented Reality (AR) technology and Tangible User Interface (TUI), which uses real environment objects to interact with the Augmented Reality (AR) environment. In this project, we have created a hardware console that uses USB drive as a tangible element to interact with the game. The USB drive is plug on to the console (Arduino module) to transfer the information of the game input to a smartphone via Bluetooth. The output is displayed on the smartphone in the form of Augmented Reality (AR) game objects and environment. By qualitative user evaluation of two groups of participants, 10 for each groups, 60% of the participants were positive with the overall learning experience using TARogic. © 2018 Authors.},
author_keywords={Augmented reality;  Interactive educational game;  Tangible augmented reality;  Tangible user interface},
correspondence_address1={Quek, A.; Multimedia UniversityMalaysia; email: quek.albert@mmu.edu.my},
publisher={Science Publishing Corporation Inc},
issn={2227524X},
language={English},
abbrev_source_title={Int. J. Eng. Technol.},
document_type={Article},
source={Scopus},
}

@ARTICLE{NoAuthor2018,
title={6th EAI International Conference on Interactivity and Game Creation, ArtsIT 2017 and the 2nd International Conference on Design, Learning and Innovation, DLI 2017},
journal={Lecture Notes of the Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering, LNICST},
year={2018},
volume={229},
page_count={529},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044027660&partnerID=40&md5=2f5ab866f79a129413fc13104ae92f4a},
abstract={The proceedings contain 50 papers. The special focus in this conference is on Interactivity and Game Creation. The topics include: In-store shopping experience enhancement: Designing a physical object-recognition interactive renderer; interact with show-window at stores: Exploratory study and design solution for physical retailers’ product demonstration; the impact of virtual reality training on patient-therapist interaction; the influence of biofeedback on exercise correctness and muscle activity; BubbleFeed: Visualizing RSS information in public spaces; expressive human pose deformation based on the rules of attractive poses; reconsidering registration: New perspectives on augmented reality; the engagement effect of players’ agency over their characters’ motivation; self-overlapping maze and map design for asymmetric collaboration in room-scale virtual reality for public spaces; interactive artist – Affective painting in multimedia sensor space; the post-virtual reality: From the interactive experience to the connective experience; sensory augmentation: Toward a dialogue between the arts and sciences; user interfaces and 3D environment scanning for game-based training in mixed-reality spaces; design of a game community based support system for cognitive game accessibility; designing inclusive reflective learning with digital democratic dialogue across boundaries and diversities; promoting inclusion and global democratic citizenship through digital dialogic collaborative learning: Diversity matters!; GLOBE – Learn and innovate digitization by a virtual collaboration exercise and living lab; analysis of motivation in virtual reality stroke rehabilitation; a review on individual assessment of strength training using smartphone applications; playing a city; ideal spaces exhibition; designing user centred intelligent classroom lighting; i-Prolog: A web-based intelligent tutoring system for learning prolog.},
editor={Brooks E., Brooks A.L., Vidakis N.},
publisher={Springer Verlag},
issn={18678211},
isbn={9783319769073},
language={English},
abbrev_source_title={Lect. Notes Inst. Comput. Sci. Soc. Informatics Telecommun. Eng.},
document_type={Conference Review},
source={Scopus},
}

@ARTICLE{Juan2018126,
author={Juan, C. and YuLin, W. and Tjondronegoro Dian, W. and Wei, S.},
title={Construction of interactive teaching system for course of mechanical drawing based on mobile augmented reality technology},
journal={International Journal of Emerging Technologies in Learning},
year={2018},
volume={13},
number={2},
pages={126-139},
doi={10.3991/ijet.v13i02.7847},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042583076&doi=10.3991%2fijet.v13i02.7847&partnerID=40&md5=511d1ad44964a0fc48beccf5507cde96},
affiliation={Wuhan University, Wuhan, China; Jingdezhen University, Jingdezhen, Jiangxi, China; International School of Software, Wuhan University, Wuhan, China; Southern Cross University, Gold Coast, Australia; Shanghai Ocean University, Shanghai, China},
abstract={The teaching aim of mechanical drawing is to cultivate the students' graphic interpreting ability, plotting ability, inter-space imagination and innovation ability. For engineering students in Chinese universities, a mechanical drawing course focused on 3D and 2D inter-space transformation is often difficult to master. The ordinary dull teaching method is insufficient to stimulate students' spatial imagination capability and interest in learning and cannot meet teachers' need to explain complicated graphical relationships. In this paper, we design an interactive teaching system that uses mobile augmented reality to improve the learning efficiency of a mechanical drawing course. To check the effect of the proposed system, we carried out a case study of two classes in mechanical drawing. The results demonstrate that the class for which an interactive teaching system based on mobile augmented reality technology was adopted is significantly superior to the class for which the ordinary dull teaching approach was adopted with regard to the degree of students' proficiency in the course's key, difficult content areas, their spatial imagination capability, and their interest in learning and study after class. © 2018 Kassel University Press GmbH.},
author_keywords={Augmented reality;  Interactive teaching system;  Mechanical drawing;  Multimedia teaching application},
keywords={Augmented reality;  Curricula;  Educational technology;  Students, Chinese universities;  Innovation abilities;  Mechanical drawing;  Mobile augmented reality;  Multimedia teachings;  Space transformations;  Teaching approaches;  Teaching systems, Teaching},
correspondence_address1={Juan, C.; Wuhan UniversityChina; email: ilovesweet@gmail.com},
publisher={Kassel University Press GmbH},
issn={18688799},
language={English},
abbrev_source_title={Int. J. Emerg. Technol. Learn.},
document_type={Article},
source={Scopus},
}

@ARTICLE{NoAuthor2018,
title={11th International Conference on Interactive Mobile Communication Technologies and Learning, IMCL2017},
journal={Advances in Intelligent Systems and Computing},
year={2018},
volume={725},
page_count={976},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042566284&partnerID=40&md5=a736cecbaf44139d0b14b158eee64aa7},
abstract={The proceedings contain 94 papers. The special focus in this conference is on Interactive Mobile Communication Technologies and Learning. The topics include: Design of lifelong learning content using the mobile E-Time capsule system; céos: A collaborative web-based application for improving teaching-learning strategies; An iOS knowledge app to support the course “Developing applications in a programming environment” of the Greek Lyceum; WIP: Design, development and implementation of a “Web technologies” android application for higher education; design of communications system for idea creation in team activity; employing Theatrical interactions and audience engagement to enable creative learning experiences in formal and informal learning: Enriching social and community theatre practices with digital technologies; digital mobile-based behaviour change interventions to assess and promote critical thinking and research skills among undergraduate students; the design of a mobile system for voice e-assessment and vocal hygiene e-training; Mobilizing the semantic interpreter Pythia – Teaching engineering students to integrate GIS and soil data during in situ measurements; designing an augmented reality smartphone application for the enhancement of asthma care education; a game-based learning platform for vocational education and training; an Overview of location-based game authoring tools for education; conceptual framework of microlearning-based training mobile application for improving programming skills; the game as a way to train the mind games of reasoning; pattern-based game apps for collaborative learning about sustainable management of public space; serious games and motivation; trials of the acropolis: Teaching greek mythology using virtual reality and game based learning; design and evaluation of a virtual-reality braille writer-simulator.},
editor={Tsiatsos T., Auer M.E.},
publisher={Springer Verlag},
issn={21945357},
isbn={9783319751740},
language={English},
abbrev_source_title={Adv. Intell. Sys. Comput.},
document_type={Conference Review},
source={Scopus},
}

@CONFERENCE{NoAuthor2017,
title={SIGGRAPH Asia 2017 Posters, SA 2017},
journal={SIGGRAPH Asia 2017 Posters, SA 2017},
year={2017},
page_count={114},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041307375&partnerID=40&md5=e87f96d5f79bfd90ea324ec1cd0a0a18},
abstract={The proceedings contain 57 papers. The topics discussed include: a proposal for wearable controller device and finger gesture recognition using surface electromyography; an application of a halftone pattern coding in augmented reality; aerial light-field image augmented between you and your mirrored image; multi-DOF 3D printing with visual surveillance; real-time temporal quality compensation technique for head mounted displays; improvement of a finger-mounted haptic device using surface contact; seamless video scene transition using hierarchical graph cuts; style-oriented representative paintings selection; liquid wetting across porous anisotropic textiles; motion sickness simulation based on sensorimotor control; aerial image on retroreflective particles; a deep convolutional neural network for continuous zoom with dual cameras; user pose estimation based on multiple depth sensors; 4d computed tomography measurement for growing plant animation; MistFlow : a fog display for visualization of adaptive shape-changing flow; prototyping digital signage systems with high-low tech interfaces; tactile Braille learning system to assist visual impaired users to learn Taiwanese Braille; and DupRobo: an interactive robotic platform for physical block-based autocompletion.},
publisher={Association for Computing Machinery, Inc},
isbn={9781450354059},
language={English},
abbrev_source_title={SIGGRAPH Asia Post., SA},
document_type={Conference Review},
source={Scopus},
}

@CONFERENCE{Mones2017,
author={Mones, B.},
title={Before and after AR/VR: Empowering paradigm shifts in education},
journal={SIGGRAPH Asia 2017 Symposium on Education, SA 2017},
year={2017},
doi={10.1145/3134368.3151011},
art_number={a11},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040194987&doi=10.1145%2f3134368.3151011&partnerID=40&md5=6de1f591dc6c129bbf8134367c36a6b6},
affiliation={University of Washington, Paul G. Allen School of Computer Science and Engineering, Seattle, WA, United States},
abstract={The development and potential of Virtual Reality (VR) and Augmented Reality (AR) technologies have already begun to transform classrooms and teaching in ways unimaginable just ten years ago. The increasing integration of these tools and experiences into educational environments has ushered in the possibility of profound changes in the way we think, learn and communicate. Applications for and in education are at the forefront of these changes. AR/VR can enhance the way teachers teach and students learn on all levels from primary school to post graduate education and in all content areas. This new way of experiencing and understanding the world can bring about great opportunities to improve teaching environments and support teachers in their mission to improve the skills and experiences of their students. AR and VR devices now available have made these experiences more affordable, interfaces for uses in education have improved enormously, and people from countries far and wide are able to contribute and connect in ways never available before. When teachers are able to design content that is delivered using AR or VR environments, and students can explore knowledge in a completely different context, opportunities emerge that allow for unique and exciting learning experiments. This panel brings together international experts in industry and education who are making significant contributions to education using these technologies. The panelists will present their newest and ongoing education initiatives, creative and innovative projects, and their plans and predictions for the future. They will discuss the broader ramifications of the dissemination of these new tools. © 2017 Copyright held by the owner/author(s).},
author_keywords={Animation;  AR;  Education;  VR},
keywords={Animation;  Argon;  Augmented reality;  Interactive computer graphics;  Students;  Teaching;  Virtual reality, Educational environment;  Innovative projects;  International experts;  Paradigm shifts;  Postgraduate education;  Primary schools, Education},
correspondence_address1={Mones, B.; University of Washington, Paul G. Allen School of Computer Science and EngineeringUnited States; email: mones@uw.edu},
publisher={Association for Computing Machinery, Inc},
isbn={9781450354097},
language={English},
abbrev_source_title={SIGGRAPH Asia Symp. Educ., SA},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{NoAuthor2017,
title={ACM International Conference Proceeding Series},
journal={ACM International Conference Proceeding Series},
year={2017},
page_count={598},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046058057&partnerID=40&md5=76c2ffdd37aff30abb45d9fe0540e26a},
abstract={The proceedings contain 73 papers. The topics discussed include: bespoke map customization behavior and its implications for the design of multimedia cartographic tools; mobile and gamified blended learning for language teaching – studying requirements and acceptance by students, parents and teachers in the wild; they are all after you: investigating the viability of a threat model that involves multiple shoulder surfers; creator-centric study of digital art exhibitions on interactive public displays; investigation of smartwatch touch behavior with different postures; a dataset for activity recognition in an unmodified kitchen using smart-watch accelerometers; a web framework for cross-device gestures between personal devices and public displays; LifeTact - utilizing smartwatches as tactile heartbeat displays in video games; Finger-Navi: mobile navigation integrated smartphone with physical finger; clothing integrated augmented reality markers; studying collaborative object positioning in distributed augmented realities; mixed reality application paradigm for multiple simultaneous 3D applications; fragments of Laura: incorporating mobile virtual reality in location aware mobile storytelling experiences; no need to stop – exploring smartphone interaction paradigms while cycling; ArmSwing: using arm swings for accessible and immersive navigation in AR/VR spaces; effect of gender on immersion in collaborative iODV applications; EyeMirror: mobile calibration-free gaze approximation using corneal imaging; detecting uncertain input using physiological sensing and behavioral measurements; and exploring mobile ad formats to increase brand recollection and enhance user experience.},
editor={Williamson J., Schneegass S.},
publisher={Association for Computing Machinery},
isbn={9781450353786},
language={English},
abbrev_source_title={ACM Int. Conf. Proc. Ser.},
document_type={Conference Review},
source={Scopus},
}

@CONFERENCE{Wetzstein2017,
author={Wetzstein, G. and Konrad, R. and Ikoma, H. and Padmanaban, N.},
title={Build your Own VR system an introduction to VR displays and cameras for hobbyists and educators},
journal={ACM SIGGRAPH 2017 Courses, SIGGRAPH 2017},
year={2017},
doi={10.1145/3084873.3084928},
art_number={14},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85033390016&doi=10.1145%2f3084873.3084928&partnerID=40&md5=0ac0919c855de43bfbcd94d05fce68cb},
affiliation={Stanford University, United States},
abstract={Wearable computing is widely anticipated to be the next computing platform for consumer electronics and beyond. In many wearable computing applications, most notably virtual and augmented reality (VR/AR), the primary interface between a wearable computer and a user is a near-eye display. A near-eye display in turn is only a small part of a much more complex system that delivers these emerging VR/AR experiences. Other key components of VR/AR systems include low-latency tracking of the user's head position and orientation, magnifying optics, sound synthesis, and also content creation. In can be challenging to understand all of these technologies in detail as only limited and fragmented educational material on the technical aspects of VR/AR exist today. The proposed SIGGRAPH course serves as a comprehensive introduction to VR/AR technology to conference attendees. It is based on a quarterlong class taught to undergraduate and graduate students at Stanford. The Stanford class (EE 267: Virtual Reality) is a lab-based maker-focused experience that teaches students how to build a head-mounted display (HMD) from scratch in 10 weeks. Every week, a different component is taught and implemented, including the graphics pipeline, stereo rendering, lens distortion with fragment shaders, head orientation tracking with inertial measurement units, positional tracking, spatial sound, and cinematic VR content creation. At the end, the students will have built a VR display from scratch and implemented every part of it. We intend to bring this experience to SIGGRAPH and teach conference attendees the same in a 3.25 h course. All hardware components are low-cost and off-the-shelf; the list will be shared with attendees. For maximum accessibility, all software is implemented in WebGL and using the Arduino platform. Source code will be provided to conference attendees. At the end of the SIGGRAPH course, attendees will leave with a detailed understanding of VR displays and cameras and they will be able to implement these systems themselves, using the provided instructions and code. We hope to reach VR enthusiasts who would like to learn more about the underlying technology of current-generation VR/AR systems and also educators. Wearable computing is a exciting new area not only for SIGGRAPH attendees but also for students at universities, colleges, and other institutions. The authors came up with one way of teaching VR in a hands-on manner to university students and have received overwhelming interest from Stanford students. We would like to share that experience with other educators and hope to inspire some of the attendees to teach VR at their home institution. The authors have published more than 60 scientific publications on topics related to computational cameras and displays and taught more than 5 courses at SIGGRAPH and other conferences on visual computing (Eurographics, CVPR,⋯). More importantly, the authors have developed a full university course on this topic that was taught to undergraduate and graduate students in the Spring of 2016 and will be taught again in the Spring of 2017. Feedback from the students was very positive throughout.},
keywords={Augmented reality;  Cameras;  Computer graphics;  Education;  Helmet mounted displays;  Interactive computer graphics;  Societies and institutions;  Students;  Units of measurement;  Virtual reality;  Wearable computers;  Wearable technology, Computational cameras;  Educational materials;  Hardware components;  Head mounted displays;  Inertial measurement unit;  Orientation tracking;  Scientific publications;  Virtual and augmented reality, Teaching},
publisher={Association for Computing Machinery, Inc},
isbn={9781450350143},
language={English},
abbrev_source_title={ACM SIGGRAPH Courses, SIGGRAPH},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Abdi2017396,
author={Abdi, L. and Takrouni, W. and Meddeb, A.},
title={In-vehicle cooperative driver information systems},
journal={2017 13th International Wireless Communications and Mobile Computing Conference, IWCMC 2017},
year={2017},
pages={396-401},
doi={10.1109/IWCMC.2017.7986319},
art_number={7986319},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027864416&doi=10.1109%2fIWCMC.2017.7986319&partnerID=40&md5=a7ae05d267b7b5b31f2bb0e483d5fbfe},
affiliation={National Engineering School of Tunis, University of Tunis El Manar, NOCCS Laboratory, Tunisia; National Engineering School of Sousse, University of Sousse, NOCCS Laboratory, Tunisia},
abstract={Critical traffic problems such as accidents and traffic congestion require the development of new transportation systems. Research in perceptual and human factors assessment is needed for relevant and correct display of this information for maximal road traffic safety as well as optimal driver comfort. One of the solutions to prevent accidents is to provide information on the surrounding environment of the driver. The development and deployment of cooperative vehicular safety systems undeniably require a combination of dedicated wireless communications, computer vision, and AR technologies as the building blocks of cooperative safety systems. Augmented Reality Head-Up Display (AR-HUD) can facilitate a new form of dialogue between the vehicle and the driver; and enhance ITS by superimposing surrounding traffic information on the users view and keep drivers view on roads. In this paper, we propose a fast deep-learning-based object detection approaches for identifying and recognizing road obstacles types, as well as interpreting and predicting complex traffic situations. A single Convolutional Neural Network (CNN) predicts region of interest and class probabilities directly from full images in one evaluation. We also investigated potential costs and benefits of using dynamic conformal AR cues in improving driving safety. A new AR-HUD approach to create real-time interactive traffic animations was introduced in terms of types of obstacle, rules for placement and visibility, and projection of these on an in-vehicle display. © 2017 IEEE.},
author_keywords={Augmented Reality Head-Up Display;  Convolutional Neural Network;  Cooperative Vehicular Safety systems;  Deep Learning;  Transportation Systems},
keywords={Accidents;  Advanced driver assistance systems;  Augmented reality;  Convolution;  Cooperative communication;  Deep learning;  Image segmentation;  Intelligent vehicle highway systems;  Mobile computing;  Neural networks;  Object detection;  Roads and streets;  Safety engineering;  Security systems;  Traffic control;  Transportation;  Vehicles;  Wireless telecommunication systems, Convolutional neural network;  Driver information systems;  Head up displays;  Interactive traffics;  Surrounding environment;  Transportation system;  Vehicular safety;  Wireless communications, Traffic congestion},
publisher={Institute of Electrical and Electronics Engineers Inc.},
isbn={9781509043729},
language={English},
abbrev_source_title={Int. Wirel. Commun. Mob. Comput. Conf., IWCMC},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Shareef2017,
author={Shareef, Z. and Reddy, S.R.N.},
title={PrEduSense: Smart Education Kit for pre-primary classes using Intel® real sense},
journal={India International Conference on Information Processing, IICIP 2016 - Proceedings},
year={2017},
doi={10.1109/IICIP.2016.7975325},
art_number={7975325},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027447364&doi=10.1109%2fIICIP.2016.7975325&partnerID=40&md5=a08a413a84ea32894d977c5821b1bee4},
affiliation={Department of Computer Science, IGDTUW, Delhi, India},
abstract={The education system has evolved from mere chalk and slate teaching methodology to presentations and smart board used in classrooms nowadays. In order to make teaching more interactive and interesting, applications involving slice of augmented reality are also developed. In this paper PrEduSense: Smart Education Kit for Pre-Primary Classes using Intel® Real Sense is introduced which consists of all the educational modules needed by the school teacher to teach pre-primary students. The concept of Human Computer Interaction is also introduced in this application by incorporating the touchless controller module, gesture recognition module and voice synthesis features of Intel Real Sense Camera. These features make the application further interactive and attractive. © 2016 IEEE.},
author_keywords={Gesture Recognition;  Intel® Real Sense Camera Module F200;  Voice Synthesis},
keywords={Augmented reality;  Cameras;  Gesture recognition;  Human computer interaction;  Speech recognition;  Speech synthesis;  Teaching, Camera modules;  Controller modules;  Education systems;  School teachers;  Synthesis features;  Teaching methodologies;  Touchless, Education},
publisher={Institute of Electrical and Electronics Engineers Inc.},
isbn={9781467369848},
language={English},
abbrev_source_title={India Int. Conf. Inf. Process., IICIP - Proc.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Qamari2017441,
author={Qamari, C.N. and Ridwan, M.R.},
title={Implementation of Android-based augmented reality as learning and teaching media of dicotyledonous plants learning materials in biology subject},
journal={Proceeding - 2017 3rd International Conference on Science in Information Technology: Theory and Application of IT for Education, Industry and Society in Big Data Era, ICSITech 2017},
year={2017},
volume={2018-January},
pages={441-446},
doi={10.1109/ICSITech.2017.8257153},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046657100&doi=10.1109%2fICSITech.2017.8257153&partnerID=40&md5=159760c84cb065e698ca928571ff21c6},
affiliation={Department of Biology Education, Faculty of Teacher Training and Education, Syiah Kuala University, Banda Aceh, Indonesia; Department of Interior Design, Faculty of Arts and Design, Bandung Institute of Technology, Bandung, Indonesia},
abstract={The field of education so far often make use of technology such as presentation slides and also interactive programs as a learning and teaching media. This study attempted to apply the Android-based augmented reality (AR) technology to display the learning materials in the digital format so the students can observe the overall learning object with the help of Android application. The main aim of this study was to understand the level of interest and inputs from the students related to the provided learning object, so it can be developed better in the next chance. This study was done using the qualitative approach method with the results sourced from the observation and simulation research method, using questionnaire form given to 24 students where the questions were based from the direct simulation using Android smartphone. The results show that 85,4% of the overall students are very interested in using AR media, 95,8% stated strongly agree that the biology learning material becomes more easily understood using AR media, 86,5% stated that AR media is very easy and practical to use, 76% stated strongly agree that their Android smartphone can function well to use AR media, and 65,6% stated that the AR cards used in this study can be scanned easily with using the application. Overall, the average percentage of all students' opinions was 81,9%, which was interpreted as a strongly agreed option that AR media is interesting to be applied as a media for studying dicotyledonous plants in the biology subject. © 2017 IEEE.},
author_keywords={android;  augmented reality;  interest;  learning and teaching media},
keywords={Augmented reality;  Big data;  Plants (botany);  Smartphones;  Students, android;  Android applications;  Dicotyledonous plants;  Interactive programs;  interest;  Learning and teachings;  Presentation slides;  Qualitative approach, Android (operating system)},
editor={Riza L.S., Pranolo A., Wibawa A.P., Junaeti E., Wihardi Y., Hashim U.R., Horng S.-J., Drezewski R., Lim H.S., Chakraborty G., Hernandez L., Nazir S.},
publisher={Institute of Electrical and Electronics Engineers Inc.},
isbn={9781509058662},
language={English},
abbrev_source_title={Proc. - Int. Conf. Sci. Inf. Technol.: Theory Appl. IT Educ., Ind. Soc. Big Data Era, ICSITech},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{NoAuthor2017,
title={Proceedings - Web3D 2017: 22nd International Conference on 3D Web Technology},
journal={Proceedings - Web3D 2017: 22nd International Conference on 3D Web Technology},
year={2017},
page_count={210},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021810266&partnerID=40&md5=6a83c50ced685d83d1eeed2d88043284},
abstract={The proceedings contain 21 papers. The topics discussed include: x3ogre: connecting X3D to a state of the art rendering engine; mesh segmentation and texture mapping for dimensional inspection in Web3D; programming driven 3d modeling on the web; evaluating multi-view representations of a Web3D streaming server; WebTorrent based fine-grained P2P transmission of large-scale WebVR indoor scenes; progressive high-quality rendering for interactive information cartography using WebGL; a Web3D forest geo-visualization and user interface evaluation; finding frogs: using game-based learning to increase environmental awareness; text density and display bandwidth: evaluating scalability by model and experiment; semantic model for distributed augmented reality services; and knowledge-based representation of 3D content behavior in a service-oriented virtual environment.},
editor={Spencer S.N.},
publisher={Association for Computing Machinery, Inc},
isbn={9781450349550},
language={English},
abbrev_source_title={Proc. - Web3D: Int. Conf. 3D Web Technol.},
document_type={Conference Review},
source={Scopus},
}

@ARTICLE{Mohamad20174136,
author={Mohamad, A.N. and Bakri, N.N. and Shahibi, M.S. and Noordin, S.A. and Rahman, S.A. and Izhar, T.A.T. and Baharuddin, M.F.},
title={Conceptualising mobile augmented reality (MAR) and E-Learning to enhance library wayfinding},
journal={Advanced Science Letters},
year={2017},
volume={23},
number={5},
pages={4136-4140},
doi={10.1166/asl.2017.8290},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85023782463&doi=10.1166%2fasl.2017.8290&partnerID=40&md5=ac2e98650e9877e48930487ac5b49d27},
affiliation={Faculty of Information Management, Universiti Teknologi MARA, Malaysia; Faculty of Dentistry, Universiti Teknologi MARA, Malaysia},
abstract={Mobile augmented reality (MAR) applications represent a profound opportunity to enhance user experiences on library accessibility into modern and interactive learning environment. Mobile Augmented Reality (MAR) aids library visitors to simplify the complexity of comprehending unfamiliar library territories—say it building, structure, department, facilities, services and collection through the navigation with their own smartphones. E-learning has been studied and used in various domains including library and information science (LIS). Many libraries have incorporated E-learning with education programmes in the library environment. It is worth noting that, from the literature, limited studies used both platforms to improve library wayfinding. Also, inadequate studies suggested conceptual framework for the usage of AR in library navigation although system architecture is usually demonstrated in project-based studies. Realising AR potential, the intention of this paper is to suggest a conceptual framework for MAR and E-learning to enhance user experiences on library navigation. © 2017 American Scientific Publishers All rights reserved.},
author_keywords={E-Learning;  Library accessibility;  Library navigation;  Mobile augmented reality (MAR)},
correspondence_address1={Mohamad, A.N.; Faculty of Information Management, Universiti Teknologi MARAMalaysia},
publisher={American Scientific Publishers},
issn={19366612},
language={English},
abbrev_source_title={Adv. Sci. Lett.},
document_type={Article},
source={Scopus},
}

@ARTICLE{VillotaPismag2017,
author={Villota Pismag, J.K. and Alawneh, H. and Adam, C. and Rawashdeh, S.A. and Mitra, P. and Chen, Y. and Strumolo, G.},
title={Augmented Reality for Improved Dealership User Experience},
journal={SAE Technical Papers},
year={2017},
volume={2017-March},
number={March},
doi={10.4271/2017-01-0278},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018438949&doi=10.4271%2f2017-01-0278&partnerID=40&md5=1f4e1cf1dd10dada074fd2fd06e8d55f},
affiliation={University of Michigan, Dearborn, United States; Ford Motor Company, United States},
abstract={The potential for Augmented Reality (AR) spans many domains. Among other applications, AR can improve the discovery and learning experience for users inspecting a particular item. This paper discusses the use of AR in the automotive context; particularly, on improving the user experience in a dealership show room. Visual augmentation, through a tablet computer or glasses allows users to take part in a self-guided tour in learning about the various features, details, and options associated with a vehicle. The same approach can be applied to other learning scenarios, such as training and maintenance assistance. We evaluated a set of AR Glasses and a general purpose tablet. A table-top showroom was developed demonstrating what the actual user experience would be like for a self-guided dealership tour using natural markers and three-dimensional content spatially registered to physical objects in the user's field of view. Spatial registration is done by tracking two- and three-dimensional markers. The camera position and orientation relative to the markers are calculated and used to augment and present information and graphical content to the user. The developed application is capable of recognizing a vehicle, render accessories, such as a roof rack, and it allows the user to cycle through various features of the vehicle to engage in learning and testing activities. This allows users to learn at their own pace while pursuing their particular interests, and also potentially earning points as part of a rewards program. In addition, a scavenger hunt application was created as another interactive approach to learn about vehicle features and accessories. This paper overviews the solutions surveyed, and presents our selected approach using the Vuforia AR library for marker and object recognition and the Unity game engine for 3D graphics rendering. Particular challenges and lessons-learned in using AR glasses and a tablet are discussed. Copyright © 2017 SAE International.},
keywords={Augmented reality;  Glass;  Object recognition;  Rendering (computer graphics);  Vehicles, Camera positions;  Developed applications;  Interactive approach;  Learning experiences;  Learning scenarios;  Physical objects;  Spatial registrations;  User experience, Three dimensional computer graphics},
correspondence_address1={Rawashdeh, S.A.; University of MichiganUnited States; email: rawashdeh@umich.edu},
publisher={SAE International},
issn={01487191},
language={English},
abbrev_source_title={SAE Techni. Paper.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{NoAuthor2017,
title={Proceedings - 2016 4th International Conference on User Science and Engineering, i-USEr 2016},
journal={Proceedings - 2016 4th International Conference on User Science and Engineering, i-USEr 2016},
year={2017},
page_count={289},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016202980&partnerID=40&md5=a005fcf4c9a43d17e71eddbf35c45cc3},
abstract={The proceedings contain 50 papers. The topics discussed include: accessibility evaluation using web content accessibility guidelines (WCAG) 2.0; accessibility matters: the need of Bahasa Melayu (BM) screen reader for the visually impaired internet users; MyQiraat: an interactive Qiraat mobile application; consequences of consumer interactions in virtual community; individual difference for HCI systems: examining the probability of thinking style signature in online interaction; promoting awareness of depression with a mobile application: a usability study and evaluation; towards the conceptualization of citizen user experience: citizens' preference for emotional design in e-government portal; designing mobile augmented reality experiences using friendly markers; older adults perspective and emotional respond on robot interaction; exploratory study on the relationship of students' perceptions towards the instructors' involvement in second life; conceptual model of game aesthetics for perceived learning in narrative games; the usability and user experience evaluation of web-based online self-monitoring tool: case study human-computer interaction course; and information visualization of students' self-regulated learning strategies while engaged in interactive learning modules: a two-dimensional approach.},
publisher={Institute of Electrical and Electronics Engineers Inc.},
isbn={9781509026319},
language={English},
abbrev_source_title={Proc. - Int. Conf. User Sci. Eng., i-USEr},
document_type={Conference Review},
source={Scopus},
}

@CONFERENCE{NoAuthor2017,
title={Proceedings of the IEEE International Conference on Advanced Materials for Science and Engineering: Innovation, Science and Engineering, IEEE-ICAMSE 2016},
journal={Proceedings of the IEEE International Conference on Advanced Materials for Science and Engineering: Innovation, Science and Engineering, IEEE-ICAMSE 2016},
year={2017},
page_count={723},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85015247509&partnerID=40&md5=7b3f57c5f71aa1f70ee8e968b1af0d5c},
abstract={The proceedings contain 196 papers. The topics discussed include: an innovative IT support and ticketing system for ministry of higher education; exploration of video art and color vision: the application of image change in digital interaction; using digital storytelling to enhance elementary school students' creative thinking; streamlining the histogram equalization of digital images by using decimation approach; in the digital future: revitalizing library management system in afghan educational and cultural settings; analyzing information communication technology and management failures in afghan dynamics; broadband dispersion compensating photonic crystal fiber with a high compensation ratio; quench limit cycle using different dither signal in a servo motor system; a novel translation, rotation, and scale-invariant shape description method for real-time speed-limit sign recognition; mobile outdoor augmented reality project for historic sites in Tainan; a framework of cloud-based collaborative platform to integrate product design requests and contradiction analysis; building up new product development strategy by product pricing and marketing analysis chart; interactive audio-visual performance system controlled by smartphone based on arm movements; virtual reality intervention: a promising deterrent to children's drug addiction; GA-SVM classifying method applied to dynamic evaluation of taekwondo; and using gaze analysis for learning analytics to assess learners of mathematics.},
editor={Meen T.-H., Prior S.D., Lam A.D.K.-T.},
publisher={Institute of Electrical and Electronics Engineers Inc.},
isbn={9781509038695},
language={English},
abbrev_source_title={Proc. IEEE Int. Conf. Adv. Mater. Sci. Eng.: Innov., Sci. Eng., IEEE-ICAMSE},
document_type={Conference Review},
source={Scopus},
}

@CONFERENCE{Lescano2017,
author={Lescano, N.L. and Mamani, S.E. and Illatopa, J.G.},
title={Cultiventura software architecture tool supporting the learning of the Moche culture: Videogames and augmented reality},
journal={Proceedings of the 2016 IEEE 23rd International Congress on Electronics, Electrical Engineering and Computing, INTERCON 2016},
year={2017},
doi={10.1109/INTERCON.2016.7815575},
art_number={7815575},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85013304750&doi=10.1109%2fINTERCON.2016.7815575&partnerID=40&md5=1d296840df0d2f0782a772abd5be1ed4},
affiliation={Applied Research Laboratory, San Martin de Porres University, Lima, Peru},
abstract={This paper aims to describe the software architecture used for the development of Cultiventura, tool that provides technology resources to support the formation of cultural identity in the teaching-learning process through technology of videogame and augmented reality for students of fourth, fifth and sixth elementary school. The design method of architecture in the context of an agile software development process is described. The results indicate that applying the model based on architecture has allowed us to develop the application with better management from the conceptual vision to the software artifact, understanding more appropriately as the essential features are implemented in the organization of the elements Cultiventura taking advantage of the interactive features of the technology to insert cultural concepts that allow students to bring cultural identification through fun and learning. © 2016 IEEE.},
author_keywords={Architecture;  augmented reality;  games;  movile;  software},
keywords={Application programs;  Architecture;  Augmented reality;  Computer software;  Engineering education;  Software architecture;  Software engineering, Agile software development process;  Elementary schools;  games;  Interactive features;  movile;  Software architecture tools;  Teaching-learning process;  Technology resources, Software design},
publisher={Institute of Electrical and Electronics Engineers Inc.},
isbn={9781509013401},
language={English},
abbrev_source_title={Proc. IEEE Int. Congr. Electron., Electr. Eng. Comput., INTERCON},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{NoAuthor2017,
title={ICCE 2017 - 25th International Conference on Computers in Education: Technology and Innovation: Computer-Based Educational Systems for the 21st Century, Workshop Proceedings},
journal={ICCE 2017 - 25th International Conference on Computers in Education: Technology and Innovation: Computer-Based Educational Systems for the 21st Century, Workshop Proceedings},
year={2017},
page_count={653},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054159143&partnerID=40&md5=14d8bf73655d6f2c2b1cd66de96ba87c},
abstract={The proceedings contain 81 papers. The topics discussed include: a study on illustration design in learning infant development; analysis of educational research using CiteSpace applications in CSSCI journals (2012-2016); the relationships of Taiwanese college students' conceptions, approaches, and self-efficacy to learning civil engineering in a flipped classroom; pre-testing the Chinese version of the system usability scale (C-SUS); a science history educational board game with augmented reality integrating collaborative problem solving and scaffolding strategies; a preliminary study of implementing an interactive learning game story book mobile app on science and technology for primary school students; using English learning toys as the emotional analysis tool to evaluate children behavior; a preliminary study of a digital game system to support mathematics learning: using circle and compound shapes as an example; study of game-based learning upon flow experience: an example of mobile app system for visit historical monuments; the implementation of instructional innovations and assistive technologies in emerging developing countries within the Asia-pacific region; the effect of think-pair-share cooperative learning model assisted with ICT on mathematical problem solving ability among junior high school students; a PBL-based professional development framework to incorporating vocational teachers in Thailand: perceptions and guidelines from training workshop; and motivation towards mathematics learning in the technology-enhanced environment.},
editor={Hayashi Y., Supnithi T., Mathews M., Wong S.L., Mohd Ayub A.F., Mitrovic A., Chen W., Yang J.-C.},
publisher={Asia-Pacific Society for Computers in Education},
isbn={9789869401227},
language={English},
abbrev_source_title={ICCE - Int. Conf. Comput. Educ.: Technol. Innov.: Comput.-Based Educ. Syst. 21st Century, Workshop Proc.},
document_type={Conference Review},
source={Scopus},
}

@CONFERENCE{NoAuthor2017,
title={Management Division 2017 - Core Programming Area at the 2017 AIChE Annual Meeting},
journal={Management Division 2017 - Core Programming Area at the 2017 AIChE Annual Meeting},
year={2017},
volume={2017-October},
page_count={145},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050401604&partnerID=40&md5=85615a476518e1f1eb01a28a7a4b7ff8},
abstract={The proceedings contain 13 papers. The topics discussed include: the importance of people in project management; communication - a better understanding; overview of project planning; planning and conducting effective meetings; application of basic project management skills to small scale gas to liquid projects; quantifying reading and online homework completion using an interactive material and energy balances textbook; an open-access gate-to-gate life cycle assessment for graduate researchers; chemical engineering beyond politics; a futuristic world educational system; enhance learning experience by augmented reality tools; a PHD's perspective on driving operational excellence in a manufacturing environment; your career path is like a distillation column; navigating the unpaved roads and knowing the unwritten rules: advancement for teaching-focused faculty; networking for nerds: how to land (or create) your dream job and keep your career moving forward!; solve this! fundamental approach to problem solving in industrial processes i; road map for embedding ethics into ChE undergraduate curricula; and ethical reasoning in the engineering curriculum.},
publisher={AIChE},
isbn={9781510857940},
language={English},
abbrev_source_title={Manag. Div. - Core Program. Area AIChE Annu. Meet.},
document_type={Conference Review},
source={Scopus},
}

@CONFERENCE{Hada201779,
author={Hada, A.R. and Silva, E.M.C. and De Macedo Silva, H.M. and Batista, J.W. and De Albuquerque Santos, L.K.B. and De Azevedo, L.K.S. and Da Silva Azevedo Bandeira, M.L. and Brasil, P.C. and De Souza Bezerra, R.C. and De Medeiros, S.A. and Gomes, A.V. and Maia, D.L.},
title={ReciClô: Development of a game to increase knowledge and social awareness about the recycling process [ReciClô: Desenvolvimento de um jogo para ampliar o conhecimento e sensibilização social sobre o processo de reciclagem]},
journal={CEUR Workshop Proceedings},
year={2017},
volume={2117},
pages={79-85},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049255838&partnerID=40&md5=36926d27574a61791e3329dee0244a4e},
affiliation={Instituto Metrópole Digital, Programa de Pós-graduação em Inovação em Tecnologias Educacionais, Universidade Federal do Rio Grande do Norte, Natal - RN, Brazil},
abstract={The use of games in the educational process can contribute significantly to the development of the child, stimulating creativity and the construction of knowledge. This work presents the process of developing a Learning Object, more specifically a augmented reality mobile game, called Reciclô for teaching the theme "recycling". The methodology used was the ADDIE Instructional Design model, an acronym in English for the development stages: Analysis, Design, Development, Implementation and Evaluation. The use of a game as a methodological tool for teaching aims to make students more engaged and more active in their learning process, providing a more interactive and dynamic experience. © 2017 CEUR-WS. All rights reserved.},
keywords={Augmented reality;  Recycling, Development stages;  Educational process;  Instructional design model;  Learning objects;  Learning process;  Methodological tools;  Recycling process;  Social awareness, Education computing},
editor={Madeira C., Nunes I.D.},
publisher={CEUR-WS},
issn={16130073},
language={Portuguese},
abbrev_source_title={CEUR Workshop Proc.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{NoAuthor20171,
title={11th International Conference on E-Learning and Games, Edutainment 2017},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2017},
volume={10345 LNCS},
pages={1-306},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032472528&partnerID=40&md5=1eaa3f7dd4c0d61dd9947421389dc868},
abstract={The proceedings contain 35 papers. The special focus in this conference is on E-Learning and Games. The topics include: Application of Virtual Simulation Technology in Maintenance Training; the Gamification of Cybersecurity Training; 3D Point Cloud Classification Based on Discrete Conditional Random Field; lightweight Web3D Visualization Framework Using Dijkstra-Based Mesh Segmentation; dynamic Gesture Recognition Based on Edge Feature Enhancement Using Sobel Operator; how Can 3D Game Engines Create Photo-Realistic Interactive Architectural Visualizations?; an Efficient Human Body Contour Extraction Method for Mobile Apps; a Study into Autonomous Scanning for 3D Model Construction; an Improved Augmented Reality Registration Method Based on Visual SLAM; the Analysis and Creation of Mogao Caves’ Three-Dimensional Model; spherical Hybrid Curvature Images of 3D Shapes and Its Applications; webPainter: Collaborative Stroke-Based Rendering Through HTML5 and WebGL; digital Visualization of Design and Construction Process of Traditional Village Dwellings; gPGPU-Based Painterly Rendering for Mobile Environment; generating Stained Glass Animation; web3d Learning Platform of Furniture Layout Based on Case-Based Reasoning and Distance Field; what’s Wrong with the Feedback?; a Measure of Student Engagement for Serious Games and IoT; implementation of the Unity Engine for Developing 2D Mobile Games in Consideration of Start-Up/Student Developers; tenochtitlan - An Interactive Virtual Reality Environment that Encourages Museum Exhibit Engagement; game-Enhanced and Process-Based e-Learning Framework; mobility and Edutainment in ESL Learning via Podcasting; young Peoples’ Views of Online Historical Archives; research on Multidisciplinary Integration in Game Art Higher Education; exploring the Shape of Digital Textbook for the Classroom in the Mobile Age.},
editor={El Rhalibi A., Tian F., Gatzidis C., Tang W., Charles F.},
publisher={Springer Verlag},
issn={03029743},
isbn={9783319658483},
language={English},
abbrev_source_title={Lect. Notes Comput. Sci.},
document_type={Conference Review},
source={Scopus},
}

@ARTICLE{Fernandez201753,
author={Fernandez, F. and Sanchez, A. and Velez, J.F. and Moreno, B.},
title={A cognitive architecture framework for critical situation awareness systems},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2017},
volume={10337 LNCS},
pages={53-62},
doi={10.1007/978-3-319-59740-9_6},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027061815&doi=10.1007%2f978-3-319-59740-9_6&partnerID=40&md5=57d008739b8c2feea74ce4df593d1e3e},
affiliation={ETSIINF, Universidad Politecnica de Madrid, Madrid, Spain; UETSII, Universidad Rey Juan Carlos, Madrid, Spain},
abstract={Goal-oriented human-machine situation-awareness systems focus on the challenges related to perception of the elements of an environment and their state, within a time-space window, the comprehension of their meaning and the estimation of their state in the future. Present computer-supported situation awareness systems provide real-time information fusion from different sources, basic data analysis and recognition, and presentation of the corresponding data using some augmented reality principles. However, a still open research challenge is to develop advanced supervisory systems, platforms and frameworks that support higher-level cognitive activities, integrate domain specific associated knowledge, learning capabilities and decision support. To address these challenges, a novel cognitive architecture framework is presented in this paper, which emphasizes the role of the Associated Reality as a new cognitive layer to improve the perception, understanding and prediction of the corresponding cognitive agent. As a proof of concept, a particular application for railways safety is shown, which uses data fusion and a semantic video infrastructure. © Springer International Publishing AG 2017.},
author_keywords={Cognitive architectures;  Human-machine interactive systems;  Knowledge modelling;  Safety systems;  Semantic video analysis;  Situation awareness},
keywords={Augmented reality;  Bioinformatics;  Data fusion;  Decision support systems;  Real time systems;  Security systems;  Semantics, Cognitive architectures;  Human-Machine Interactive;  Knowledge modelling;  Semantic video analysis;  Situation awareness, Cognitive systems},
correspondence_address1={Sanchez, A.; UETSII, Universidad Rey Juan CarlosSpain; email: angel.sanchez@urjc.es},
editor={Adeli H., Ferrandez Vicente J.M., Toledo Moreo J., Alvarez-Sanchez J.R., de la Paz Lopez F.},
publisher={Springer Verlag},
issn={03029743},
isbn={9783319597393},
language={English},
abbrev_source_title={Lect. Notes Comput. Sci.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{NoAuthor2017,
title={Congress on Computing in Civil Engineering, Proceedings},
journal={Congress on Computing in Civil Engineering, Proceedings},
year={2017},
volume={2017-June},
page_count={428},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026886686&partnerID=40&md5=002dbfeacf4bb207730d0bc50cc2d575},
abstract={The proceedings contain 50 papers. The topics discussed include: simultaneous data exchange between BIM and VR for collaborative decision making; hybridizing topology optimization and evolutionary computation to support computer-aided engineering design; when is a construction educational serious game too serious? striking a balance between engagement and learning; an augmented reality environment for students' learning of steel connection behavior; a new learning model, guided soft classroom, integrating MOOCs into conventional classrooms for university students; automated monitoring of the utilization rate of onsite construction equipment; a personalized HVAC control smartphone application framework for improved human health and well-being; automated change diagnosis of single-column-pier bridges based on 3d imagery data; comparison of traditional laser scanning and mobile lidar technology for AECO applications; a smart construction object (SCO)-enabled proactive data management system for construction equipment management; potential use of cyber-physical systems (cps) for planning and operation of mobile cranes on construction sites; vision-based activity analysis framework considering interactive operation of construction equipment; perspective-based image-to-BIM alignment for automated visual data collection and construction performance monitoring; and modeling the effect of a socio-psychological process on construction workers' safety behavior.},
editor={Lin K.-Y., Tang P., El-Gohary N.},
publisher={American Society of Civil Engineers (ASCE)},
isbn={9780784480830},
coden={CCENE},
language={English},
abbrev_source_title={Comput Civ Eng (New York)},
document_type={Conference Review},
source={Scopus},
}

@ARTICLE{NoAuthor20171,
title={4th International Conference on HCI in Business, Government and Organizations, HCIBGO 2017, held as part of the 19th International Conference on Human-Computer Interaction , HCI 2017},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2017},
volume={10296 LNCS},
pages={1-498},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025141015&partnerID=40&md5=161a08b4e91a46fc4f139083b1691772},
abstract={The proceedings contain 75 papers. The special focus in this conference is on HCI in Business, Government and Organizations. The topics include: Using augmented reality interactive system to support digital electronics learning; an AI system for coaching novice programmers; affective walkthroughs and heuristics; a creative engineering experience; manipulation of mathematical expressions in collaborative environments; designing tools that allows children in the early childhood to program robots; decision making for interactive systems; preschool learning with a fingertip; augmentative and alternative communication in the literacy teaching for deaf children; a model for collaboration in virtual worlds bringing together cultures in conflict; challenges of integrating non-traditional students in higher education and how electronic learning can support inclusion; training socially responsible engineers by developing accessible video games; the use of a new visual language as a supporting resource for people with intellectual disabilities; dashboard for actionable feedback on learning skills; learning analytics and spelling acquisition in German; data analysis of coaching and advising in undergraduate students; learning analytics and its paternalistic influences; development of a dashboard for learning analytics in higher education; mixing and matching learning design and learning analytics; a guidance and evaluation approach for mhealth education applications; collaborative hybrid agent provision of learner needs using ontology based semantic technology and designing a peer feedback mobile application as a professional development tool.},
editor={Zaphiris P., Ioannou A.},
publisher={Springer Verlag},
issn={03029743},
isbn={9783319585147},
language={English},
abbrev_source_title={Lect. Notes Comput. Sci.},
document_type={Conference Review},
source={Scopus},
}

@ARTICLE{Barmpoutis20173,
author={Barmpoutis, A.},
title={Analytical mapping of linear walk from infinite virtual space to finite real space},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2017},
volume={10280},
pages={3-14},
doi={10.1007/978-3-319-57987-0_1},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021664899&doi=10.1007%2f978-3-319-57987-0_1&partnerID=40&md5=f6898381fcdc5209c83068d720e42f71},
affiliation={University of Florida, Gainesville, FL  32611, United States},
abstract={This paper presents a framework for natural traversal of an infinite virtual path using a camera-projector augmented-reality system. In the proposed framework this problem is formulated as an optimization problem using an energy function that is based on several user-experience factors as well as topological constraints in the real and virtual space. The solution is analytically derived by minimizing the cost function with respect to the parameters of the path in the real and virtual space. The obtained optimal path has the form of a zigzag curve and is demonstrated in an interactive application for delivering stimulating slide-show presentations for on-line learning. © 2017, Springer International Publishing AG.},
author_keywords={Locomotion interface;  Magic-mirror augmented reality;  Optimization;  Walking through virtual environments},
keywords={Optimization;  Virtual reality;  Augmented reality;  Cost functions;  Human computer interaction, Analytical mapping;  Augmented reality systems;  Interactive applications;  Locomotion interfaces;  Magic mirrors;  Optimization problems;  Topological constraints;  Walking through, Augmented reality;  Virtual reality},
correspondence_address1={Barmpoutis, A.; University of FloridaUnited States; email: angelos@digitalworlds.ufl.edu},
publisher={Springer Verlag},
issn={03029743},
language={English},
abbrev_source_title={Lect. Notes Comput. Sci.},
document_type={Book Chapter},
source={Scopus},
}

@CONFERENCE{Prokhorov2017245,
author={Prokhorov, A. and Klymenko, I. and Yashina, E. and Morozova, O. and Oleynick, S. and Solyanyk, T.},
title={SCADA systems and augmented reality as technologies for interactive and distance learning},
journal={CEUR Workshop Proceedings},
year={2017},
volume={1844},
pages={245-256},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020495214&partnerID=40&md5=3c54f210bb5c506993f3bbc9d43ca502},
affiliation={National Aerospace University, KhAI, Chkalova str. 17, Kharkiv, Ukraine},
abstract={This paper discusses the use of SCADA systems for creating virtual laboratories for technical and natural sciences. Electronic interactive training material, virtual laboratory work and testing systems have been designed in a unified environment. The authors have established the features of the learning context for virtual laboratory work in the university course of physics as a case study. The paper also considers the capabilities of augmented reality applications in laboratory classes.},
author_keywords={Interactive and distance learning;  SCADA system;  Virtual laboratory work},
keywords={Augmented reality;  Distance education;  E-learning;  Industrial research;  Information management;  Knowledge management;  Laboratories, Augmented reality applications;  Interactive training;  Laboratory class;  Learning context;  Testing systems;  University course;  Virtual laboratories, SCADA systems},
editor={Nikitchenko M., Spivakovsky A., Ermolayev V., Bassiliades N., Kharchenko V., Shyshkina M., Peschanenko V., Mayr H.C., Fill H.-G., Yakovyna V.},
publisher={CEUR-WS},
issn={16130073},
language={English},
abbrev_source_title={CEUR Workshop Proc.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{NoAuthor20171,
title={19th International Conference on Interactive Collaborative Learning, ICL 2016},
journal={Advances in Intelligent Systems and Computing},
year={2017},
volume={545},
pages={1-638},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85010022794&partnerID=40&md5=bebfc68459ba7de4661815f3a39de7db},
abstract={The proceedings contain 56 papers. The special focus in this conference is on Interactive Collaborative Learning. The topics include: Developing an android mobile Bluetooth chat messenger as an interactive and collaborative learning aid; learning technological innovation on mobile applications by means of a spiral of projects; application of non linear story telling in medical education; comparison of two team learning and team entrepreneurship models at a Finnish university of applied sciences; survey of ICT culture of mentor teachers; blended learning and fundamental disciplines; a study on haptic media to support verbal explanations; analysis of interests of applicants in technologically oriented study in the Czech republic and its support; towards an ontology approach in teaching geometry; towards formally prioritizing the activities of group course work inside student teams; augmented reality in engineering; the use of serious games in educational environment; using persuasive system design principles to evaluate two next generation digital learning environments; spatial orientation and 3d geometry; augmenting e-learning tools for STE disciplines and resource constrained environments; forge enabling fire facilities for the elearning community; a remote laboratory architecture for agile learning; developing a common learning platform for foreign language teaching; the implementation of a web application for screening children with dyslexia; studying security of data in cloud computing through cryptographic approach; engineering challenging entrepreneurship practice; entrepreneurship in engineering education; automated and assisted authoring of serious game scenarios and arduino based physics and engineering remote laboratory.},
editor={Auer M.E., Uhomoibhi J., Guralnick D.},
publisher={Springer Verlag},
issn={21945357},
isbn={9783319503394},
language={English},
abbrev_source_title={Adv. Intell. Sys. Comput.},
document_type={Conference Review},
source={Scopus},
}

@ARTICLE{NoAuthor20171,
title={4th International Conference on Robot Intelligence Technology and Applications, RiTA, 2015},
journal={Advances in Intelligent Systems and Computing},
year={2017},
volume={447},
pages={1-610},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84978525572&partnerID=40&md5=eda299302104f901c4202676a1ed20f1},
abstract={The proceedings contain 49 papers. The special focus in this conference is on Ambient, Behavioral, Cognitive, Collective, and Social Robot Intelligence. The topics include: Behavior and path planning for the coalition of cognitive robots in smart relocation tasks; accurate localization in urban environments using fault detection of GPS and multi-sensor fusion; interactive markerless augmented reality system based on visual slam algorithm; control strategy design for throw-in challenge in a humanoid robot soccer game; study on a two-staged control of a lower-limb exoskeleton performing standing-up motion from a chair; adaptive control for directional drilling systems with delay and parameter uncertainty; android-based mobile robotic platform performance testing for real-time navigation; autonomous control of a drone in the context of situated robotics; framework and modeling of a multi-robot simulator for hospital logistics; emotion in robot decision making; multi-robot task allocation using clustering method; gaze control of humanoid robot for learning from demonstration; a novel design of a full length prosthetic robotic arm for the disabled; preliminary study in a novel robotic-assisted femoral shaft fracture reduction system; pet care robot for playing with canines; making a more reliable classifier via random crop pooling; learning with learning robots; ensemble of vector and binary descriptor for loop closure detection; learning with small autonomous robots; design and implementation of double passing strategy for humanoid robot soccer game and development of motion management system for the robot soccer using multiple humanoid robots.},
editor={Karray F., Kim J.-H., Myung H., Jo J., Sincak P.},
publisher={Springer Verlag},
issn={21945357},
isbn={9783319312910},
language={English},
abbrev_source_title={Adv. Intell. Sys. Comput.},
document_type={Conference Review},
source={Scopus},
}

@CONFERENCE{NoAuthor2016,
title={Proceedings of the 3rd Asia-Europe Symposium on Simulation and Serious Gaming - 15th ACM SIGGRAPH Conference on Virtual-Reality Continuum and Its Applications in Industry, VRCAI 2016},
journal={Proceedings of the 3rd Asia-Europe Symposium on Simulation and Serious Gaming - 15th ACM SIGGRAPH Conference on Virtual-Reality Continuum and Its Applications in Industry, VRCAI 2016},
year={2016},
page_count={228},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85009821227&partnerID=40&md5=0498289ae09d1eb9cf240dbaa644c86c},
abstract={The proceedings contain 12 papers. The topics discussed include: a model-based inquiry approach to explore system dynamics and modeling aspects of the prey-predator system; a serious game for interactive teaching of Newton�s laws; VR biology, an interdisciplinary and international student project towards an inquiry-based pedagogy; reflections from research: some considerations for the design of educational simulations (and games); analysis of hot spots and themes on virtual reality technology study in education; MAGIS: mobile augmented-reality games for instructional support; digital tools for enriching informal inquiry-based mobile learning: the design of the TraceReaders location-based augmented reality learning platform; migration and evaluation of a framework for developing embodied cognition learning games; and research and application of running action sequence recognition algorithms based on kinect.},
editor={Spencer S.N.},
publisher={Association for Computing Machinery, Inc},
isbn={9781450346931},
language={English},
abbrev_source_title={Proc. Asia-Europe Symp. Simul. Serious Gaming - ACM SIGGRAPH Conf. Virtual-Real. Contin. Its Appl. Ind., VRCAI},
document_type={Conference Review},
source={Scopus},
}

@CONFERENCE{Ma2016401,
author={Ma, F. and Chen, J. and Tong, Y. and Sun, L.},
title={An improved ANN search algorithm for visual search applications},
journal={Proceedings - VRCAI 2016: 15th ACM SIGGRAPH Conference on Virtual-Reality Continuum and Its Applications in Industry},
year={2016},
volume={1},
pages={401-407},
doi={10.1145/3013971.3014011},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85009818587&doi=10.1145%2f3013971.3014011&partnerID=40&md5=0b5b01e7c08dd11d9997997310593058},
affiliation={Beijing Institute of Technology, Beijing, 100089, China},
abstract={Approximate nearest neighbor search is a kind of significant algorithm to ensure the accuracy and speed for visual search system. In this paper, we ameliorate the search algorithm following the framework of product quantization. Product quantization can generate an exponentially large codebook by a product quantizer and then achieve rapid search with the asymmetric distance computation or symmetric distance computation, while it will still produce a larger distortion in some cases when calculating the approximate distance. Therefore, we design the hierarchical residual product quantization which simultaneously quantifies the input and residual space and meanwhile we extend the asymmetric distance computation to handle this quantization method which is still very efficient to estimate the approximate distance. We have tested our method on several datasets, and the experiment shows that our method consistently improves the accuracy against the-state-of-the-art methods. © 2016 ACM.},
author_keywords={Augmented reality;  Image recognition;  Product quantization;  Visual search},
keywords={Augmented reality;  Image recognition;  Interactive computer graphics;  Learning algorithms;  Product design;  Virtual reality, Asymmetric distances;  Product quantizations;  Residual products;  Residual spaces;  Search Algorithms;  State-of-the-art methods;  Symmetric distances;  Visual search, Nearest neighbor search},
editor={Spencer S.N.},
publisher={Association for Computing Machinery, Inc},
isbn={9781450346924},
language={English},
abbrev_source_title={Proc. - VRCAI: ACM SIGGRAPH Conf. Virtual-Real. Contin. Its Appl. Ind.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{NoAuthor2016,
title={SA 2016 - SIGGRAPH ASIA 2016 Mobile Graphics and Interactive Applications},
journal={SA 2016 - SIGGRAPH ASIA 2016 Mobile Graphics and Interactive Applications},
year={2016},
page_count={74},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85006855018&partnerID=40&md5=6c2f74797994d93553016bbb54fd2825},
abstract={The proceedings contain 23 papers. The topics discussed include: medical learning murmurs simulation with mobile audible augmented reality; efficient remote image-based situational queries through mobile devices; demo: fingertip and card recognition mobile app for interactive play; crowd visualization on low bandwidth mobile devices based on video analysis; demo: BeCasso - artistic image processing and editing on mobile devices; augmented reality annotation for social video sharing; demo: a safe low-cost HMD for underwater VR experiences; Animato: 2D shape deformation and animation on mobile devices; mobile reconstruction and exploration of indoor structures exploiting omnidirectional images; interactive image filtering with multiple levels-of-control on mobile devices; ubiGaze: ubiquitous augmented reality messaging using gaze gestures; back-mirror: back-of-device one-handed interaction on smartphones; an oriented point-cloud view for MR remote collaboration; adaptive multi-rate ray sampling on mobile ray tracing GPU; demo: mobile AR live annotation for printed materials; and demo: iPTAM on mobile phone.},
publisher={Association for Computing Machinery, Inc},
isbn={9781450345514},
language={English},
abbrev_source_title={SA - SIGGRAPH ASIA Mob. Graph. Interact. Appl.},
document_type={Conference Review},
source={Scopus},
}

@CONFERENCE{NoAuthor2016,
title={SA 2016 - SIGGRAPH ASIA 2016 Symposium on Education: Talks},
journal={SA 2016 - SIGGRAPH ASIA 2016 Symposium on Education: Talks},
year={2016},
page_count={17},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85006835182&partnerID=40&md5=974d5b514497eaf5c9a4592b0deecb65},
abstract={The proceedings contain 7 papers. The topics discussed include: virtual reality and augmented reality for education; girls in stem: increasing the number of female students entering technical fields; square ENIX AI academy: AI workshop for blackboard architecture; shading Dory's new friends; combining virtual (oculus rift & gear VR) and augmented reality with interactive applications to enhance tertiary medical and biomedical curricula; visualizing the asynchronous discussion forum data with topic detection; and projects lead to principles: applying project-based learning to animation.},
publisher={Association for Computing Machinery, Inc},
isbn={9781450345453},
language={English},
abbrev_source_title={SA - SIGGRAPH ASIA Symp. Educ.: Talks},
document_type={Conference Review},
source={Scopus},
}

@CONFERENCE{Protopsaltis2016151,
author={Protopsaltis, A. and Mentzelopoulos, M. and Ferguson, J. and Kaloyan, K.},
title={Quiz Cube: An AR mobile learning application},
journal={Proceedings - 11th International Workshop on Semantic and Social Media Adaptation and Personalization, SMAP 2016},
year={2016},
pages={151-155},
doi={10.1109/SMAP.2016.7753401},
art_number={7753401},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85006810326&doi=10.1109%2fSMAP.2016.7753401&partnerID=40&md5=072a3b9ae9dd902ffb2ca7389fd3d9cd},
affiliation={Friedrich-Alexander-Universit't Erlangen-Nuremberg, DE, Germany; University of Westminster, Westminster, United Kingdom},
abstract={The current paper presents the Quiz Cube application and its evaluation. The Quiz Cube application is an AR mobile learning application for students and teachers to easily make and use AR UI system using fiducial marker cubes. AR as a platform is just now reaching its full potential. Since smartphones and mobile devices are now at a sufficiently large user base, it is worth looking at the potential for an extremely small form factor delivery system that is flexible, easily modified, and used by educators and students. An easily modifiable AR learning experience will present an AR Mobile platform development, interactive museums, and the chosen subject in a new style. This method can be shown to improve not only knowledge of the chosen subject through investigation, but a better understanding of development potentials for the mobile devices now ubiquitous to students. The Quiz Cube application was evaluated in three different ways and the results are presented here. © 2016 IEEE.},
author_keywords={Augmented Reality (AR);  mobile learning;  Quick Response Code (QR);  User Interface (UI)},
keywords={Augmented reality;  E-learning;  Education;  Geometry;  Semantics;  Social networking (online);  Students;  Teaching;  User interfaces, Delivery systems;  Development potential;  Interactive museums;  Learning experiences;  Mobile Learning;  Mobile platform;  Quick response code;  Small form factors, Computer aided instruction},
correspondence_address1={Protopsaltis, A.; Friedrich-Alexander-Universit't Erlangen-Nuremberg, DEGermany; email: aprotopsaltis@gmail.com},
editor={Anagnostopoulos I., Paraskakis I.},
publisher={Institute of Electrical and Electronics Engineers Inc.},
isbn={9781509052455},
language={English},
abbrev_source_title={Proceedings - Int. Workshop Semant. Soc. Media Adapt. Personalization, SMAP},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Antkowiak2016,
author={Antkowiak, D. and Kohlschein, C. and Krooß, R. and Speicher, M. and Meisen, T. and Jeschke, S. and Werner, C.J.},
title={Language therapy of aphasia supported by augmented reality applications},
journal={2016 IEEE 18th International Conference on e-Health Networking, Applications and Services, Healthcom 2016},
year={2016},
doi={10.1109/HealthCom.2016.7749511},
art_number={7749511},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85006355334&doi=10.1109%2fHealthCom.2016.7749511&partnerID=40&md5=a1efbedc6e937bfcfd783d5241113aa8},
affiliation={RWTH Aachen University, Institute of Information Management in Mechanical Engineering, Aachen, Germany; Bitstars GmbH, Institute of Information Management in Mechanical Engineering, Aachen, Germany; University Hospital RWTH Aachen, Department of Neurology, Aachen, Germany},
abstract={In Europe there are more than 580 000 people who suffer from aphasia - an acquired speech and language disorder that occurs because of brain damage, primarily as a result of a stroke. Especially with regards to demographic change, health care systems have to face present and future challenges to improve aphasia therapy. Thereby, immediate therapeutic measures are decisive for best possible and long-term success in language therapy. Regarding essential requirements, on the one hand, therapy intensity and frequency have to be increased significantly while on the other hand, measures need to be adjusted along everyday activities. A very promising approach to meet this requirements are augmented reality applications. They can be used to create a highly natural exercise situation, in which patients interact and practice with their personal possessions at home. This facilitates the successful and continuous transfer of learnings for the patient, contrary to being solely dependent on clinical therapy units. This paper gives an overview of the concept of a real-time software providing augmented and dynamic language therapy, which is interactive and utilizes simple user interface design, for home-based training. © 2016 IEEE.},
author_keywords={3D scanning;  3D tracking;  Aphasia therapy;  augmented reality;  speech recognition;  therapy frequency},
keywords={Augmented reality;  Speech recognition;  User interfaces, 3D tracking;  3D-scanning;  Aphasia therapy;  Augmented reality applications;  Demographic changes;  Real-time software;  therapy frequency;  User interface designs, Patient treatment},
publisher={Institute of Electrical and Electronics Engineers Inc.},
isbn={9781509033706},
language={English},
abbrev_source_title={IEEE Int. Conf. e-Health Netw., Appl. Serv., Healthcom},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Chang2016355,
author={Chang, C.-Y. and Hsu, S.-C. and Chang, C.-T. and Chen, J.-C. and Zeng, J.-N.},
title={Using pinch technology to achieve augmented reality in multiple devices},
journal={Proceedings - 2016 International Conference on Networking and Network Applications, NaNA 2016},
year={2016},
pages={355-359},
doi={10.1109/NaNA.2016.65},
art_number={7564168},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84991215036&doi=10.1109%2fNaNA.2016.65&partnerID=40&md5=15ae3c53b9404d6902a385254c919543},
affiliation={Dept. of Computer Science and Information Engineering, Tamkang University, Taiwan; Graduate School of Art and Technology, Taipei National University of the Arts, Taiwan; Dept. of Information Management, Hsiuping University of Science and Technology, Taiwan},
abstract={The applications of Mobile Technologies have received much attention in recent years. They are widely applied in various terrains, including E-commerce, Health-care, disaster relief, reconstruction and education learning. However, to our knowledge, few exhibitions of integration of advanced mobile technology and creative applications can be found in previous study. This paper presents a frame work that integrates mobile technologies and Bluetooth communication technology to implement screen combination effects on Android devices. To achieve the Augmented Reality, the proposed system integrates a lot of advanced mechanisms, including Interactive Arts, Display arts, wireless communication, sensor and localization. The proposed mechanism not only increase the interactions between participates but also create novel applications that extend the usage of mobile technologies. © 2016 IEEE.},
author_keywords={Android;  Augmented Reality;  Bluetooth;  interactive installations},
keywords={Android (operating system);  Augmented reality;  Bluetooth;  Disaster prevention;  Exhibitions;  Wireless telecommunication systems, Android;  Bluetooth communications;  Combination effects;  Interactive arts;  Interactive installations;  Mobile Technology;  Novel applications;  Wireless communications, Telecommunication equipment},
correspondence_address1={Chang, C.-Y.; Dept. of Computer Science and Information Engineering, Tamkang UniversityTaiwan; email: cychang@mail.tku.edu.tw},
publisher={Institute of Electrical and Electronics Engineers Inc.},
isbn={9781467398039},
language={English},
abbrev_source_title={Proc. - Int. Conf. Netw. Netw. Appl., NaNA},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{NoAuthor2016,
title={2016 IEEE Virtual Reality Workshop on K-12 Embodied Learning through Virtual and Augmented Reality, KELVAR 2016},
journal={2016 IEEE Virtual Reality Workshop on K-12 Embodied Learning through Virtual and Augmented Reality, KELVAR 2016},
year={2016},
page_count={28},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84994403360&partnerID=40&md5=fafb736605e2c96060d17bedacdecfe1},
abstract={The proceedings contain 5 papers. The topics discussed include: voxar puzzle motion: an innovative AR application proposed using design techniques; towards the development of guidelines for educational evaluation of augmented reality tools; Neozoa: an immersive, interactive sandbox for the study of competing ant species; exploration of kinesthetic gaming for enhancing elementary math education using culturally responsive teaching methodologies; and mobile tracked displays as engaging and effective learning platforms.},
publisher={Institute of Electrical and Electronics Engineers Inc.},
isbn={9781509023448},
language={English},
abbrev_source_title={IEEE Virtual Real. Workshop K-12 Embodied Learn. Virtual Augment. Real., KELVAR},
document_type={Conference Review},
source={Scopus},
}

@CONFERENCE{NoAuthor2016307,
title={2015 IEEE Games Entertainment Media Conference, GEM 2015},
journal={2015 IEEE Games Entertainment Media Conference, GEM 2015},
year={2016},
pages={307},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964089273&partnerID=40&md5=33479bd06a6f6438a25d93fa661e6ba2},
abstract={The proceedings contain 60 papers. The topics discussed include: back-pointer - Fitts' law analysis of natural mobile camera based interactions; convulsive treatment game-based training app; gamification: how to gamify learning and instruction; quantifying the differential impact of sensor noise in augmented reality gaming input; effects of interior bezel size and configuration on gaming performance with large tiled displays; applications of the illimitable space system in the context of media technology and on-stage performance: a collaborative interdisciplinary experience; are virtual learning environments appropriate for dyscalculic students?; external automatic defibrillator game-based learning app; toward an effective approach to collaboration education: a taxonomy for game design; uniform vs. non-uniform scaling of shooter games on large displays; 4PEG: a structured rating system for games for learning; and presenting a standard slot machine as an interactive racing game.},
publisher={Institute of Electrical and Electronics Engineers Inc.},
isbn={9781467374521},
language={English},
abbrev_source_title={IEEE Games Entertainment Media Conference, GEM 2015},
document_type={Conference Review},
source={Scopus},
}

@CONFERENCE{Chen2016,
author={Chen, C.-P. and Wang, C.-H.},
title={Construction of a synchronized multi-display augmented reality simulation module for learning tidal effects},
journal={2015 IEEE 2nd International Conference on InformationScience and Security, ICISS 2015},
year={2016},
doi={10.1109/ICISSEC.2015.7370990},
art_number={7370990},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964612327&doi=10.1109%2fICISSEC.2015.7370990&partnerID=40&md5=aca1e96db9a9845f39e39bb1dd3eb7f5},
affiliation={Department of Visual Communication Design, Taipei College of Maritime Technology, New Taipei City, Taiwan; Department of Graphic Arts and Communications, National Taiwan Normal University, Taipei, Taiwan},
abstract={In recent years, Augmented Reality (AR) has been widely employed in educational settings. Most instructional ARs developed so far only dubbed a single interactive AR image onto a single object. However, more complicated concept learning may require liking two or more correlated phenomenon. The correlation between the revolution of moon and tidal effects on earth is one of such correlated concepts. In this study, a multi-image instructional AR toolkit was developed that is capable of synchronously illustrating the relation of moon revolution and tidal effects. By rotating the earth-moon physical model, students will be able to view on computer screen the phases of the moon and coordinated tidal effects on earth synchronously. Student's satisfactions on AR operations, screen interfaces, and desire to use the AR toolkit were fare. The results of this study would inspire the development of more innovative AR toolkits for instructional applications. © 2015 IEEE.},
author_keywords={Augmented reality;  E-learning;  Phases of moon;  Synchronized multi-display;  Tidal effect},
keywords={Augmented reality;  E-learning;  Information science, Computer screens;  Concept learning;  Educational settings;  Multi displays;  Physical model;  Simulation modules;  Student's satisfaction;  Tidal effects, Moon},
publisher={Institute of Electrical and Electronics Engineers Inc.},
isbn={9781467386111},
language={English},
abbrev_source_title={IEEE Int. Conf. Inf. Sci. Secur., ICISS},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{NoAuthor2016,
title={ASCILITE 2016 - Conference Proceedings - 33rd International Conference of Innovation, Practice and Research in the Use of Educational Technologies in Tertiary Education: Show Me the Learning},
journal={ASCILITE 2016 - Conference Proceedings - 33rd International Conference of Innovation, Practice and Research in the Use of Educational Technologies in Tertiary Education: Show Me the Learning},
year={2016},
page_count={108},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071939466&partnerID=40&md5=5b5f2d35b224d488581485b17801a438},
abstract={The proceedings contain 107 papers. The topics discussed include: Enabler or inhibitor? educational technology in self and peer assessment; the design process of university teachers: a descriptive model; attentional and cognitive processing of analytics visualizations: can design features affect interpretations and decisions about learning and teaching?; confidence drives exploration strategies in interactive simulations; using a video-based critique process to support studio pedagogies in distance education – a tool and pilot study; preliminary exploration of student behavioral outcomes using blackboard collaborate in fully online courses; application of personal learning environment to an independent study experience; a national strategy to promote open educational practices in higher education in Australia; staying the distance: using digital readiness tools to support effective transitions into higher education for flexible learners; head start online: a MOOC for effectively supporting flexible learner transition into higher education; and introducing pre-service education students to university experiences through an augmented reality game.},
publisher={Australasian Society for Computers in Learning in Tertiary Education (ASCILITE)},
language={English},
abbrev_source_title={ASCILITE - Conf. Proc. - Int. Conf. Innov., Pract. Res. Use Educ. Technol. Tert. Educ.: Show Me Learn.},
document_type={Conference Review},
source={Scopus},
}

@ARTICLE{Own2016189,
author={Own, C.-M.},
title={Making without makerspace, another study of authentic learning with augmented reality technology},
journal={Lecture Notes in Educational Technology},
year={2016},
number={9789811059292},
pages={189-201},
doi={10.1007/978-981-10-5930-8_11},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031730973&doi=10.1007%2f978-981-10-5930-8_11&partnerID=40&md5=b14b1f4cf51ba3451d24e494d0be8a50},
affiliation={School of Computer Software, Tianjin University, Tianjin, China},
abstract={A “makerspace” is an area in a library where users can use tools and equipment to design, build and create all sorts of different things. It may be a dedicated room or a multipurpose space in which a collection of raw materials and resources can be utilized as desired. However, the makerspace is not always in everyplace and for everyone to use. In this study, we explore a new way to integrate advanced display technology into educational activities for students with different disabilities. An interactive augmented reality application was developed to facilitate the learning of robot building. The result shows that AR system could help the school students to finish their robot building independent of teacher’s assistant. With the use of AR display technology, the participants demonstrated improve ability to complete construction tasks when compared to the use of traditional paper-based methods. Performance data indicated that the use of AR technology could enhance learning motivation and frustration tolerance in students and the authentic learning principle is further identified. © Springer Nature Singapore Pte Ltd. 2018.},
author_keywords={Augmented reality;  Authentic learning;  Makerspace},
correspondence_address1={Own, C.-M.; School of Computer Software, Tianjin UniversityChina; email: chungming.own@mail.tju.edu.cn},
publisher={Springer International Publishing},
issn={21964963},
language={English},
abbrev_source_title={Lect. Notes Educ. Technol.},
document_type={Book Chapter},
source={Scopus},
}

@ARTICLE{Cai2016115,
author={Cai, S.},
title={Case studies of augmented reality applications for authentic learning},
journal={Lecture Notes in Educational Technology},
year={2016},
number={9789811059292},
pages={115-134},
doi={10.1007/978-981-10-5930-8_8},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031714815&doi=10.1007%2f978-981-10-5930-8_8&partnerID=40&md5=6277334ca8d10121ebc04f32eaf3309a},
affiliation={Advanced Technology Innovation Center for Future Education, Beijing Normal University, Beijing, No.19, XinJieKouWai St., HaiDian District, Beijing, 100875, China; Faculty of Education, School of Educational Technology, Beijing Normal University, Beijing, No.19, XinJieKouWai St., HaiDian District, Mailbox 65, Beijing, 100875, China},
abstract={The advancement of Augmented Reality technology is having a great influence on the design of learning activities in schools. In this chapter, a serial of simulation cases based on 3D Augmented Reality (AR) environments are presented, including probability learning in mathematics, convex imaging and magnetic field learning in physics, inquiry-based microparticles interactive presentation in chemistry and EFL children’s vocabulary studying in language learning, etc. By AR technology, the camera detects the presetting markers which will later generate 3D virtual objects, interposing the virtual objects on the real scene to produce a blended environment. Experimental results show that in an AR-based authentic learning environment, students adopt a natural interactive method and enjoy the same experience as in real environments due to the abandonment of mouse and keyboard devices. It facilitates an innovative and fascinating learning mode which eliminates isolated feelings in learning. Furthermore, the AR-based learning environment is able to interpose objects which are inaccessible in real life due to high expenses, safety consideration or other factors in real-world settings. © Springer Nature Singapore Pte Ltd. 2018.},
author_keywords={Augmented Reality;  Authentic learning;  Natural interaction},
correspondence_address1={Cai, S.; Advanced Technology Innovation Center for Future Education, Beijing Normal University, Beijing, No.19, XinJieKouWai St., HaiDian District, China; email: caisu@bnu.edu.cn},
publisher={Springer International Publishing},
issn={21964963},
language={English},
abbrev_source_title={Lect. Notes Educ. Technol.},
document_type={Book Chapter},
source={Scopus},
}

@CONFERENCE{NoAuthor2016,
title={Proceedings of the 2016 International Conference on Virtual Systems and Multimedia, VSMM 2016},
journal={Proceedings of the 2016 International Conference on Virtual Systems and Multimedia, VSMM 2016},
year={2016},
page_count={477},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026289554&partnerID=40&md5=f915da851cd55345de11bd444c520514},
abstract={The proceedings contain 69 papers. The topics discussed include: BradPhys to BradViz or from archaeological science to heritage science; the Gonzagas' palace: architecture of time. an interactive application for the discovery of the architectural history of Palazzo Ducale in Mantua; workings of Asia-Pacific spatiotemporal research: an international institute in Taiwan; privacy preservation of ROI of medical image using squint pixel and PLSB hiding technique; towards a conceptual framework for privacy protection in the use of interactive 360 degree video surveillance; evaluating digital resources in cultural heritage: lessons from the ScotDigiCH network; calm down buddy! it's just a game: behavioral patterns observed among teamwork MMO players in WARGAMING's World of Tanks; automated network for knowledge transfer between resource management agencies: real-time monitoring/database for household waste management in high-rise residential buildings in Malaysia; developing a narrative experience in a post-media environment; evaluation study of a snack box for children designed to prompt discussion about natural heritage at museums; a comparative study of walkthrough paradigms for virtual environments using Kinect based natural interaction; applications for advance 3D imaging, modelling, and printing techniques for the biological sciences; using scents to connect to intangible heritage engaging the visitor olfactory dimension: three museum exhibition case studies; market potential for a location based and augmented reality system for utilities management; development of service oriented mobile AR applications for museum learning activities; and LARA: a location-based and augmented reality assistive system for underground utilities' networks through GNSS.},
editor={Addison A.C., Thwaites H., Lun L.S.},
publisher={Institute of Electrical and Electronics Engineers Inc.},
isbn={9781467389938},
language={English},
abbrev_source_title={Proc. Int. Conf. Virtual Syst. Multimed., VSMM},
document_type={Conference Review},
source={Scopus},
}

@ARTICLE{Winzer2016292,
author={Winzer, P. and Steffen, T.A.},
title={Interest in and willingness to pay for mobile applications in museums},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2016},
volume={10056 LNCS},
pages={292-301},
doi={10.1007/978-3-319-50182-6_26},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85006069331&doi=10.1007%2f978-3-319-50182-6_26&partnerID=40&md5=565a93578cd03b2df51fb72067e88df1},
affiliation={Faculty of Design, Computer Science, Media, Hochschule RheinMain, University of Applied Sciences, Unter den Eichen 5, Wiesbaden, 65195, Germany},
abstract={Mobile applications (apps) are becoming more important for museums. In our research project SPIRIT, we develop a mobile location-based serious game, which enhances museum communications in an entertaining way. By integrating elements of interactive digital storytelling through augmented reality, e.g. interactions with virtual characters, the app converts history lessons into vibrant adventures. By using the app, mobile devices are transformed into “magical equipment”, which leads users to the spirit of the past in certain places on site. This paper examines selected economic issues of museum apps, focusing on the potential interest in and willingness to pay for these apps. We present selected findings from two empirical surveys, in which valid questionnaires of over 200 museums and over 1,600 museum visitors were analyzed. © Springer International Publishing AG 2016.},
keywords={Augmented reality;  E-learning;  Mobile computing;  Mobile telecommunication systems;  Surveys, Economic issues;  Empirical surveys;  Integrating element;  Interactive Digital Storytelling;  Mobile applications;  Mobile location;  Virtual character;  Willingness to pay, Museums},
correspondence_address1={Steffen, T.A.; Faculty of Design, Computer Science, Media, Hochschule RheinMain, University of Applied Sciences, Unter den Eichen 5, Germany; email: Tamara.Steffen@hs-rm.de},
editor={Bottino R., Jeuring J., Veltkamp R.C.},
publisher={Springer Verlag},
issn={03029743},
isbn={9783319501819},
language={English},
abbrev_source_title={Lect. Notes Comput. Sci.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Cory20161567,
author={Cory, J.},
title={Augmented reality (AR) in the service of sustainable education and design},
journal={CESB 2016 - Central Europe Towards Sustainable Building 2016: Innovations for Sustainable Future},
year={2016},
pages={1567-1573},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84986893431&partnerID=40&md5=76243efacf4c1fd781346c7e30e4b89e},
affiliation={17 Kiryat Seffer St., Haifa, Israel},
abstract={The Porter School of Environmental Studies (PSES) is the first LEED Platinum project in Israel and one of the very few around the world to get 92 points in the LEED certification. Designed by Geotectura Studio in collaboration with Axelrod-Grobman Architects and Chen Architects, the building soon became a focal point for environmentalists to learn about sustainability. An augmented reality application was developed in order to raise the awareness and to educate scholars and the public about some of the ecological aspects of this building. The application demonstrates the underlying environmental strategies that influenced the architectural design of the Porter School of Environmental Studies in Tel Aviv, Israel. The app was developed using augmented reality technology to visualize the narrative behind the architectural design in real-time through the deployment of several interactive features. In this project certain aspects of the building design are demonstrated through a series of animations that help communicate the design agenda in a novel way. The application consists of seven specific features which include sun path, wind circulation, lighting strategy, mechanical strategy, sustainable material strategy, program strategy, and environmental skin. A 3D model of the building is separated into layers to highlight specific components of the design and help to better understand the integrated functionalities of the architectural agenda. Each one of these 3D layers can be viewed in isolation via a series of buttons, focusing on the BIM and environmental process of the design. This paper will address the potential use of augmented reality in the service of sustainable education and design.},
author_keywords={Augmented reality;  LEED;  Sustainability;  The porter school of environmental stu},
keywords={Application programs;  Architecture;  Augmented reality;  Buildings;  D region;  Design;  Energy efficiency;  Environmental design;  Environmental management;  Intelligent buildings;  Sustainable development, Augmented reality applications;  Augmented reality technology;  Environmental process;  Environmental strategy;  Environmental studies;  Sustainable educations;  Sustainable materials;  The porter school of environmental stu, Architectural design},
correspondence_address1={Cory, J.17 Kiryat Seffer St., Israel; email: gooda@shenkar.ac.il},
editor={Sojkova K., Tywoniak J., Lupisek A., Hajek P.},
publisher={Grada Publishing},
isbn={9788027102488},
language={English},
abbrev_source_title={CESB - Cent. Eur. Towards Sustain. Build.: Innov. Sustain. Future},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{NoAuthor20161,
title={4th International Conference on Distributed, Ambient and Pervasive Interactions, DAPI 2016 held as part of 18th International Conference on Human-Computer Interaction, HCI International 2016},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2016},
volume={9749},
pages={1-505},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84978891154&partnerID=40&md5=d0bd33398cb7c6457fcf7b7e64908813},
abstract={The proceedings contain 45 papers. The special focus in this conference is on Developing Smart Environments, Recognition Techniques in Ambient Intelligence, Tracking, Human Behavior in Smart Environments and Affect in Intelligent Environments. The topics include: Towards ubiquitous services design and development approach; exploring design for multi-device, multi-environment and multimodal connected experiences; investigating low-cost wireless occupancy sensors for beds; user interface design for ambient assisted living systems; establishing guidelines for user quality of experience in ubiquitous systems; towards big data interactive visualization in ambient intelligence environments; end-user development tools for the smart home; the interaction design research about 3d demo animation in smart home; a formal model for context-aware semantic augmented reality systems; memory and learning neural circuits correlated with the creative processes in design; data-driven smart home system for elderly people based on web technologies; a unified framework for remote collaboration using interactive AR authoring and hands tracking; exploring machine learning object classification for interactive proximity surfaces; machine learning and location fingerprinting to improve UX in a ubiquitous application; exploring the ergonomic issues of user-defined mid-air gestures for interactive product exhibition; facial tracking-assisted hand pointing technique for wall-sized displays; user-independent face landmark detection and tracking for spatial AR interaction; mid-air gestures for virtual modeling with leap motion and mental model development using collaborative 3d virtual environments.},
editor={Streitz N., Markopoulos P.},
publisher={Springer Verlag},
issn={03029743},
isbn={9783319398617},
language={English},
abbrev_source_title={Lect. Notes Comput. Sci.},
document_type={Conference Review},
source={Scopus},
}

@CONFERENCE{NoAuthor20161,
title={1st ICA European Symposium on Cartography, EuroCarto 2015},
journal={Lecture Notes in Geoinformation and Cartography},
year={2016},
pages={1-480},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84978196178&partnerID=40&md5=8092c432ce1fc6eb1cf6bfefbc5e40be},
abstract={The proceedings contain 28 papers. The special focus in this conference is on Cartographic Modelling and Design. The topics include: A displacement method for maps showing dense sets of points of interest; a concept for multidimensional point symbols; model of the dynamic labelling of populated places in Slovakia for the purposes of the state map series; methodology for automating the cartometric evaluation of urban topographic maps of brazil; structuring relations between user tasks and interactive tasks using a visual problem-solving approach; visual analysis of floating taxi data based on interconnected and timestamped area selections; spatial-temporal modeling of linguistic regions and processes with combined indeterminate and crisp boundaries; hybrid approach for large-scale energy performance estimation based on 3D city model data and typological classification; modern methodology and new tools for planetary mapping; licences and open data in cartography; some remarks on the question of pseudocylindrical projections with minimum distortions for world maps; a semi-automatic approach for determining the projection of small scale maps based on the shape of graticule lines; semantic approach to spatial thinking; a key course in geospatial engineering; a review of research investigations related to user-centred design for geo-information products; a project of volunteered geographic information using mobile mapping collection; contextual adaptability of navigational spatial descriptions; user requirements analysis for a mobile augmented reality tool supporting geography fieldwork; landmark-based pedestrian navigation using augmented reality and machine learning and the role of service-oriented mapping in spatial and regional sciences.},
editor={Gartner G., Jobst M., Huang H.},
publisher={Kluwer Academic Publishers},
issn={18632351},
isbn={9783319196015},
language={English},
abbrev_source_title={Lect. Notes Geoinformation Cartogr.},
document_type={Conference Review},
source={Scopus},
}

@ARTICLE{NoAuthor20161,
title={5th International Conference on Design, User Experience, and Usability, DUXU 2016 Held as Part of 18th International Conference on Human-Computer Interaction, HCI International 2016},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2016},
volume={9748},
pages={1-438},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84977509734&partnerID=40&md5=18e0d5aa4a2c828a3e3e1da836093dac},
abstract={The proceedings contain 41 papers. The special focus in this conference is on Mobile DUXU, DUXU in Information Design and Visualization. The topics include: Comparison of mobile input methods; user context logging in automated usability tests for mobile software; qwerty based portrait soft keyboard; service modeling for situation-aware communication method decision; aspect-oriented approach for user interaction logging of iOS applications; comparing android app permissions; touch zone sizing for mobile devices in military applications; applying flow theory to predict user-perceived performance of tablets; study of smart watch interface usability evaluation based on eye-tracking; balancing tradeoffs in the design of an interactive art installation on surveillance and big data; learning from the users for spatio-temporal data visualization explorations on social events; data-intensive analytics for cat bonds by considering supply chain risks; a framework to evaluate user empowerment in decision-making experiences with participatory GIS; an image analysis tool for analyzing information loss caused by viewers and environments; systematic application of circle-similar shapes to visualize database-homogeneity in a big data environment; the exploration of user knowledge architecture based on mining user generated contents; open data evolution in information systems research; multisensory physical environments for data representation; creative interaction for plasma physics; authoring tools for augmented reality; virtual display of 3d computational human brain using oculus rift and designing affordances for virtual reality-based services with natural user interaction.},
editor={Marcus A.},
publisher={Springer Verlag},
issn={03029743},
isbn={9783319404059},
language={English},
abbrev_source_title={Lect. Notes Comput. Sci.},
document_type={Conference Review},
source={Scopus},
}

@ARTICLE{NoAuthor20161,
title={3rd International Conference on Augmented Reality, Virtual Reality, and Computer Graphics, AVR 2016},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2016},
volume={9769},
pages={1-402},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976618817&partnerID=40&md5=6c82f5f54cc7312ed6c94f59d4b05fa1},
abstract={The proceedings contain 31 papers. The special focus in this conference is on Applications of VR/AR in Medicine. The topics include: A novel tabletop and tablet-based display system to support learner-centric ophthalmic anatomy education; using a short video animation to assist with the diagnosis of sleep disorders in young children; configurable software framework for 2D/3D video see-through displays in medical applications; application of a new wearable augmented reality video see-through display to aid percutaneous procedures in spine surgery; challenges in the effectiveness of image tagging using consumer-grade brain-computer interfaces; new opportunities and challenges; improving endovascular intraoperative navigation with real-time skeleton-based deformation of virtual vascular structures; a wearable augmented reality platform for telemedicine; development of a low-cost obstetric simulator; interactive painting and lighting in dynamic multi-projection mapping; a virtual reality environment for teaching purposes; a VR-WEB-BIM for the future maintenance of Milan’s cathedral; a virtual experience across the buried history; improved way findings for archaeological parks through mobile augmented reality; augmenting smart objects for cultural heritage; the presentation of heterogeneous data using hybrid platform; automatic analysis of eye-tracking data for augmented reality applications and immersive learning environment for visual arts.},
editor={De Paolis L.T., Mongelli A.},
publisher={Springer Verlag},
issn={03029743},
isbn={9783319406503},
language={English},
abbrev_source_title={Lect. Notes Comput. Sci.},
document_type={Conference Review},
source={Scopus},
}

@ARTICLE{NoAuthor20161,
title={10th International Conference on E-Learning and Games, Edutainment 2016},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2016},
volume={9654},
pages={1-425},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976604937&partnerID=40&md5=58e592a0a8982b1a2265cda67a858472},
abstract={The proceedings contain 36 papers. The special focus in this conference is on E-Learning and Game. The topics include: Visual exploration of virtual lives in multiplayer online games; educational folktale e-book with collage illustratable tool; the design of augmented reality-based learning system applied in u-learning environment; a web-AR based real-time tangible edugame for molecular docking; research on virtual training system in aerospace based on interactive environment; web3D online virtual education platform for touring huangyangjie battlefield scenario over internet; emotional dialogue trees for game based training; development and analysis of a games-based crisis scenario generation system; a study of the teaching methods in the course of the programming of high-level language based on moodle platform; exploring olfaction for enhancing multisensory and emotional game experience; real-time weighted median filtering with the edge-aware 4d bilateral grid; nose tip detection and face localization from face range image based on multi-angle energy; a class of variable degree trigonometric polynomial spline and its applications; visualization of multi-dimensional information of electromagnetic environment based on three dimensional spheres; remote rendering for mobile devices literature overview; research of mesh layout algorithm based on greedy optimization strategy; an interactive 2D-to-3D cartoon modeling system; monet-style images generation using recurrent neural networks; image stylization for yunnan out-of-print woodcut through virtual carving and printing; cross-platform cloth simulation API for games; object proposal refinement based on contour support for augmented reality and sketch-based retrieval in large-scale image database via position-aware silhouette matching.},
editor={Tian F., El Rhalibi A., Pan Z., Liu B.},
publisher={Springer Verlag},
issn={03029743},
isbn={9783319402581},
language={English},
abbrev_source_title={Lect. Notes Comput. Sci.},
document_type={Conference Review},
source={Scopus},
}

@CONFERENCE{NoAuthor2016,
title={Proceedings of the 12th International Conference on Mobile Learning 2016},
journal={Proceedings of the 12th International Conference on Mobile Learning 2016},
year={2016},
page_count={183},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976443446&partnerID=40&md5=16a999c12a96e744ec6b8e51d78fb6e9},
abstract={The proceedings contain 26 papers. The topics discussed include: mobile devices and spatial enactments of learning: iPads in lower secondary schools; m-learning challenges in teaching crosscutting themes in the education of young people and adults; mobile learning: pedagogical strategies for using applications in the classroom; experiencing a mobile game and its impact on teachers' attitudes towards mobile learning; exploring mobile affordances in the digital classroom; design, development and evaluation of a field learning video blog; development and evaluation of a classroom interaction system; visual environment for designing interactive learning scenarios with augmented reality; the development of an interactive mathematics app for mobile learning; conceptualizing an m-learning system for seniors; sensorimotor distractions when learning with mobile phones on-the-move; and personal biometric information from wearable technology tracked and followed using an e-portfolio a case study of e-health literacy development with emerging technology in Hong Kong higher education.},
editor={Isaias P., Rodrigues L., Sanchez I.A.},
publisher={IADIS},
isbn={9789898533494},
language={English},
abbrev_source_title={Proc. Int. Conf. Mob. Learn.},
document_type={Conference Review},
source={Scopus},
}

@CONFERENCE{Ferguson2015383,
author={Ferguson, J. and Mentzelopoulos, M. and Protopsaltis, A. and Economou, D.},
title={Small and flexible web based framework for teaching QR and AR mobile learning application development},
journal={Proceedings of 2015 International Conference on Interactive Mobile Communication Technologies and Learning, IMCL 2015},
year={2015},
pages={383-385},
doi={10.1109/IMCTL.2015.7359624},
art_number={7359624},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84962429206&doi=10.1109%2fIMCTL.2015.7359624&partnerID=40&md5=fa8f36abb91399e3ca120889fb65438f},
affiliation={University of Westminster, United Kingdom; Friedrich-Alexander-Universität, Erlangen-Nuremberg, Germany},
abstract={The current paper presents an AR development framework for students to easily make and use small QR linked interactive learning web pages on mobile devices targeted primarily for museums. This framework is extrapolated from an AR UI system using fiducial marker cubes. AR as a platform is just now reaching its full potential. Since smartphones and mobile devices are now at a sufficiently large user base, it is worth looking at the potential for an extremely small form factor delivery system that is flexible, easily modified, and used by educators and students. An easily modifiable AR learning experience will present AR, QR Mobile platform development, interactive museums, and the chosen subject in a new style. This method of flipped learning can be shown to improve not only knowledge of the chosen subject through investigation, but a better understanding of development potentials for the mobile devices now ubiquitous to students. © 2015 IEEE.},
author_keywords={Augmented Reality (AR);  Flipped;  Mobile learning;  QR;  User Interface (UI)},
keywords={Augmented reality;  Computer aided instruction;  E-learning;  Engineering education;  Mobile devices;  Students;  User interfaces;  Websites, Application development;  Development potential;  Flipped;  Interactive learning;  Interactive museums;  Learning experiences;  Mobile Learning;  Web-based framework, Mobile telecommunication systems},
publisher={Institute of Electrical and Electronics Engineers Inc.},
isbn={9781467382434},
language={English},
abbrev_source_title={Proc. Int. Conf. Interact. Mob. Commun. Technol. Learn., IMCL},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{NoAuthor2015,
title={Proceedings of 2015 International Conference on Interactive Mobile Communication Technologies and Learning, IMCL 2015},
journal={Proceedings of 2015 International Conference on Interactive Mobile Communication Technologies and Learning, IMCL 2015},
year={2015},
page_count={448},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84962365850&partnerID=40&md5=813082dd0bb8bb49f557c82834f26357},
abstract={The proceedings contain 92 papers. The topics discussed include: role of biotechnology simulation and remotely triggered virtual labs in complementing university education; CyberAware: a mobile game-based app for cybersecurity education and awareness; 10 user interface elements for mobile learning application development; interactive storytelling and mobile augmented reality applications for learning and entertainment - a rapid prototyping perspective; everyday devices taught and explained to primary school children by following the energy transformations, using web-based software; how does personality affect wiki-mediated learning?; mobile learning and biotechnology education via remote labs: deployment-based study on real time shared resources; introducing an innovative robot-based mobile platform for programming learning; remote interactive mobile learning application in electronics learning; and gamification designs in wearable enhanced learning for healthy ageing.},
publisher={Institute of Electrical and Electronics Engineers Inc.},
isbn={9781467382434},
language={English},
abbrev_source_title={Proc. Int. Conf. Interact. Mob. Commun. Technol. Learn., IMCL},
document_type={Conference Review},
source={Scopus},
}

@CONFERENCE{NoAuthor2015,
title={Proceedings of the 7th Latin American Conference on Human Computer Interaction, CLIHC 2015},
journal={Proceedings of the 7th Latin American Conference on Human Computer Interaction, CLIHC 2015},
year={2015},
page_count={133},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84979657006&partnerID=40&md5=80bd58b0cdbdaf0df4e3d0dff23e8df6},
abstract={The proceedings contain 21 papers. The topics discussed include: usability and consumption influence of fashion blogs: an exploratory study; influence of a head-mounted display on user experience and performance in a virtual reality-based sports application; enhancing interfaces for network security administrators with legacy attributes; evaluation of the emotional answer in HRI on a game situation; application requirements for deaf students to use in inclusive classrooms; methodology for digital interactive products development for mobile devices, which support learning processes in a university environment; florch: challenges on developing a new social network accessible for senescent users; and the user model, vocabulary and logical architecture for adaptive augmented reality.},
publisher={Association for Computing Machinery, Inc},
isbn={9781450339605},
language={English},
abbrev_source_title={Proc. Lat. Am. Conf. Hum. Comput. Interact., CLIHC},
document_type={Conference Review},
source={Scopus},
}

@CONFERENCE{NoAuthor2015,
title={ACM International Conference Proceeding Series},
journal={ACM International Conference Proceeding Series},
year={2015},
volume={16-19-November-2015},
page_count={380},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84979790769&partnerID=40&md5=4c58500f5a929f8ac906405f7f05ad8c},
abstract={The proceedings contain 66 papers. The topics discussed include: a model to analyze and design educational games with pedagogical foundations; annotation and anonymity: playful photo-sharing by visiting groups of teenagers; diversity through specificity design lessons learned from the games [4Diversity] jams; in sync with fair play! delivering a synchronized and cheat-preventing second screen gaming experience; intelligent user interfaces in digital games for empowerment and inclusion; need to touch, wonder of discovery, and social capital: experiences with interactive playful seats; a percussion learning system using rhythm internalization with haptic indications; Acting 2.0: when entertainment technology helps actors to perform; artificial companions as personal coach for children: the interactive drums teacher; co-creating embodied sketches. playing as a method to design with children; design and evaluation of educational kinesthetic game to encourage collaboration for kindergarten children; designing microgames for assessment: a case study in rapid prototype iteration; emotion sharing during live sports broadcasts: studying its potential and the users' preferences; enhanced exemplar based inpainting algorithm for hiding the augmented reality marker; and entertainment applications for tapping on a bathtub edge using embedded acoustic sensors.},
publisher={Association for Computing Machinery},
isbn={9781450338523},
language={English},
abbrev_source_title={ACM Int. Conf. Proc. Ser.},
document_type={Conference Review},
source={Scopus},
}

@CONFERENCE{Mandanici2015451,
author={Mandanici, M.},
title={Interactive spaces: Models and algorithms for reality-based music applications},
journal={Proceedings of the 2015 ACM International Conference on Interactive Tabletops and Surfaces, ITS 2015},
year={2015},
pages={451-456},
doi={10.1145/2817721.2820986},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84962896281&doi=10.1145%2f2817721.2820986&partnerID=40&md5=320b6992f85eda38d0a280699b3bdebb},
affiliation={CSC-Sound and Music Computing Group, Department of Information Engeneering, University of Padova, Italy},
abstract={Reality-based interfaces have the property of linking the user's physical space with the computer digital content, bringing in intuition, plasticity and exprebiveneb. Moreover, applications designed upon motion and gesture tracking technologies involve a lot of psychological features, like space cognition and implicit knowledge. All these elements are the background of three presented music applications, employing the characteristics of three different interactive spaces: a user centered three dimensional space, a floor bi-dimensional camera space, and a small sensor centered three dimensional space. The basic idea is to deploy the application's spatial properties in order to convey some musical knowledge, allowing the users to act inside the designed space and to learn through it in an enactive way. © Copyright 2015 by the Abociation for Computing Machinery, Inc. (ACM).},
author_keywords={Blended interaction;  Learning environments;  Sound augmented reality},
keywords={Algorithms;  Augmented reality;  Computer aided instruction, Blended interaction;  Implicit knowledge;  Interactive spaces;  Learning environments;  Models and algorithms;  Music applications;  Psychological features;  Three dimensional space, Interactive devices},
correspondence_address1={Mandanici, M.; CSC-Sound and Music Computing Group, Department of Information Engeneering, University of PadovaItaly; email: mandanici@dei.unipd.it},
publisher={Association for Computing Machinery, Inc},
isbn={9781450338998},
language={English},
abbrev_source_title={Proc. ACM Int. Conf. Interact. Tabletops Surfaces, ITS},
document_type={Conference Paper},
source={Scopus},
}

@BOOK{Corrêa20151238,
author={Corrêa, A.G.D.},
title={Interactive books in augmented reality for mobile devices: A case study in the learning of geometric figures},
journal={Mobile Computing and Wireless Networks: Concepts, Methodologies, Tools, and Applications},
year={2015},
volume={3-4},
pages={1238-1256},
doi={10.4018/978-1-4666-8751-6.ch053},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84958725469&doi=10.4018%2f978-1-4666-8751-6.ch053&partnerID=40&md5=4557fdd184bcca29bc22bfe3b06197f6},
affiliation={Universidade Presbiteriana Mackenzie, Brazil},
abstract={One of the methods of teaching that has brought significant contributions to the field of education is augmented reality. This technology transformed learning into a more motivating, enjoyable, fun, and interesting activity. This chapter contributes an augmented reality application for mobile devices that complements and supports the learning of geometric figures. The application, called AGeRA, consists of a geometry book and software capable of reading special markers inserted into the book's content. When this book is placed in front of the camera of a mobile device, 3D objects, sounds, animations, and other interactive elements leap from book pages making learning more fun and exciting. Preliminary tests were made with teachers and students and showed good acceptance of the application to support the teaching of geometry. © 2016, IGI Global. All rights reserved.},
keywords={Acceptance tests;  Application programs;  Augmented reality;  Geometry;  Mobile devices;  Teaching, 3D object;  Augmented reality applications;  Interactive books;  Interactive elements;  Methods of teachings, Education},
correspondence_address1={Corrêa, A.G.D.; Universidade Presbiteriana MackenzieBrazil},
publisher={IGI Global},
isbn={9781466687523; 1466687517; 9781466687516},
language={English},
abbrev_source_title={Mob. Comput. and Wirel. Netw.: Concepts, Methodol., Tools, and Appl.},
document_type={Book Chapter},
source={Scopus},
}

@BOOK{Ispir20151490,
author={Ispir, B.},
title={Interactive media steer in educational printing materials},
journal={Mobile Computing and Wireless Networks: Concepts, Methodologies, Tools, and Applications},
year={2015},
volume={3-4},
pages={1490-1499},
doi={10.4018/978-1-4666-8751-6.ch065},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84958701575&doi=10.4018%2f978-1-4666-8751-6.ch065&partnerID=40&md5=37e6e0d60969caa3ef3e7c159950997b},
affiliation={Anadolu University, Turkey},
abstract={The development of digital technology has been highly accelerated since the 2000s. New media environments, which increase interactivity, have been provided to users. With technological convergence, all environments in the category of new media have had the opportunity to work together. With the support of digital technologies, traditional media have also started to include elements that will allow interaction. Support of digital technology does not allow us to see that traditional media is an interactive media but it permits interactive media guidance. Newspapers, books, and magazines, which are located in the category of traditional media, support readers by directing them to interactive media with augmented reality applications. Augmented reality applications in printed materials has been used in many fields. In particular, course books, which protects the existence as the basic learning material of distance learning, can support its content with augmented reality applications. The features of augmented reality applications that allow the presentation of additional information, such as visual, audio, animated text, are discussed in this chapter. © 2016, IGI Global. All rights reserved.},
keywords={Augmented reality;  Curricula;  Distance education;  Human computer interaction, Augmented reality applications;  Digital technologies;  Interactive media;  Interactivity;  Learning materials;  Printed materials;  Printing materials;  Technological convergence, Education},
correspondence_address1={Ispir, B.; Anadolu UniversityTurkey},
publisher={IGI Global},
isbn={9781466687523; 1466687517; 9781466687516},
language={English},
abbrev_source_title={Mob. Comput. and Wirel. Netw.: Concepts, Methodol., Tools, and Appl.},
document_type={Book Chapter},
source={Scopus},
}

@CONFERENCE{Yangguang201581,
author={Yangguang, L. and Yue, L. and Xiaodong, W.},
title={Multiplayer Collaborative Training System Based on Mobile AR Innovative Interaction Technology},
journal={Proceedings - 2014 International Conference on Virtual Reality and Visualization, ICVRV 2014},
year={2015},
pages={81-85},
doi={10.1109/ICVRV.2014.66},
art_number={7281047},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84962145308&doi=10.1109%2fICVRV.2014.66&partnerID=40&md5=1ad00330c274ed4d49b09219eabb512e},
affiliation={School of Optoelectronics, Beijing Institute of Technology, China; School of Computer Science, Beijing Institute of Technology, China},
abstract={The applications of Augmented Reality (AR) in such mobile devices as phones and pads can enhance the users' experiences both in virtual and real world. In this paper the design and implementation of a Multiplayer Collaborative Training System (MCTS) is presented. It is a combination of virtual and physical reality, which builds virtual worlds with changeable scenes, brings authentic user experience and records process for analyzing and evaluation. Players are trained in a closed environment, which is composed of projectors, multimedia devices and physical scene. The application of mobile AR device guides the entire training process, and users make effective interaction with mobile devices to start and finish training mission. In the proposed system five innovative methods are implemented to improve interaction quality. An experiment case is devised with a series of tasks and conundrums for players, experimental results show that the MCTS can contribute more effective educations on team consciousness through the use of mobile AR technology and multimodal interaction to integrate virtual and real experience. © 2014 IEEE.},
author_keywords={Augmented Reality;  Collaborative Education;  Mixed Reality;  Mobile Human-Computer Interaction},
keywords={Augmented reality;  Distributed computer systems;  Interactive computer graphics;  Mixed reality;  User interfaces;  Visualization, Collaborative education;  Collaborative training;  Design and implementations;  Effective interactions;  Interaction quality;  Interaction technology;  Mobile human computer interaction;  Multi-Modal Interactions, Human computer interaction},
editor={Shen X., Zhang X., Zhou Z., Zhang G., Luo X.},
publisher={Institute of Electrical and Electronics Engineers Inc.},
isbn={9781479968541},
language={English},
abbrev_source_title={Proc. - Int. Conf. Virtual Real. Vis., ICVRV},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{NoAuthor2015,
title={INISTA 2015 - 2015 International Symposium on Innovations in Intelligent SysTems and Applications, Proceedings},
journal={INISTA 2015 - 2015 International Symposium on Innovations in Intelligent SysTems and Applications, Proceedings},
year={2015},
page_count={468},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84969141836&partnerID=40&md5=7ae299193229ec8b0b7276d995db5e6a},
abstract={The proceedings contain 68 papers. The topics discussed include: toward gamification of knowledge base construction; simple programming scheme for industrial robot manipulators; implementation of frontier-based exploration algorithm for an autonomous robot; a comparative study on machine learning algorithms for indoor positioning; a novel multi-sensor and multi-topological database for indoor positioning on fingerprint techniques; and comparison of consumer purchase intention between interactive and augmented reality shopping platforms through statistical analyses.},
publisher={Institute of Electrical and Electronics Engineers Inc.},
isbn={9781467390965},
language={English},
abbrev_source_title={INISTA - Int. Symp. Innov. Intell. SysT. Appl., Proc.},
document_type={Conference Review},
source={Scopus},
}

@BOOK{DePaolis2015908,
author={De Paolis, L.T. and Vaškevičius, E. and Vidugiriene, A.},
title={Multimedia technologies in education},
journal={Gamification: Concepts, Methodologies, Tools, and Applications},
year={2015},
volume={2-4},
pages={908-929},
doi={10.4018/978-1-4666-8200-9.ch045},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84958927802&doi=10.4018%2f978-1-4666-8200-9.ch045&partnerID=40&md5=30969f0b05f8a040cb4bcb4ff63b70ee},
affiliation={University of Salento, Italy; Vytautas Magnus University, Lithuania},
abstract={As different means of information visualization become more popular and available both as commercial or open source products, there is an opportunity to use them in the education process by providing students with a larger variety of tools for mastering the required information and skills related to a learning object. The chapter discusses the use of various multimedia tools and edutainment (any entertaining application that has an educational role) in education and e-learning. The need and opportunities of applying 3D models, virtual and augmented reality, and certain means for controlling interactive learning environments are described in detail. Examples of 3D modeling, virtual, and augmented reality applications in history, arts, and medicine (surgery) education are provided. © 2015, IGI Global. All rights reserved.},
keywords={Augmented reality;  Computer aided instruction;  Education computing;  Educational technology;  Information systems;  Multimedia systems;  Students;  Three dimensional computer graphics, Augmented reality applications;  Education process;  Information visualization;  Interactive learning environment;  Learning objects;  Multimedia technologies;  Open source products;  Virtual and augmented reality, Education},
correspondence_address1={De Paolis, L.T.; University of SalentoItaly},
publisher={IGI Global},
isbn={9781466682016; 1466682000; 9781466682009},
language={English},
abbrev_source_title={Gamification: Concepts, Methodol., Tools, and Appl.},
document_type={Book Chapter},
source={Scopus},
}

@CONFERENCE{Mercier-Ganady2015197,
author={Mercier-Ganady, J. and Marchal, M. and Lécuyer, A.},
title={The mind-window: Brain activity visualization using tablet-based ar and EEG for multiple users},
journal={ACM International Conference Proceeding Series},
year={2015},
volume={11},
pages={197-198},
doi={10.1145/2735711.2735809},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84954188073&doi=10.1145%2f2735711.2735809&partnerID=40&md5=49961161033dee7216cbc6259e93297d},
affiliation={INRIA, INSA, Rennes, France; INSA Rennes, INRIA, France; INRIA, France},
abstract={In this poster we introduce a novel approach, called the "Mind-Window", for real-time visualization of brain activity. The Mind-Window enables one or multiple users to visualize the brain activity of another person as if her skull was transparent. Our approach relies on the use of multiple tablet PCs that the observers can move around the head of the observed person wearing an EEG cap. A 3D virtual brain model is superimposed onto the head of the observed person using augmented reality by tracking a 3D marker placed on top of the head. The EEG cap records the electrical fields emitted by the brain, and they are processed in real-time to update the display of the virtual brain model. Several visualization techniques are proposed such as an interactive cutting plane which can be manipulated with touch-based inputs on the tablet. The Mind-Window could be used for various application purposes such as for Education as teaching tool to learn brain anatomy/activity and EEG features, e.g., electrodes localization, electrical patterns, etc. Copyright 2015 ACM.},
keywords={Augmented reality;  Brain models;  Neurophysiology;  Personal computers;  Visualization, Brain activity;  Brain anatomy;  Cutting planes;  Electrical field;  Multiple user;  Real time visualization;  Teaching tools;  Visualization technique, Brain},
publisher={Association for Computing Machinery},
isbn={9781450333498},
language={English},
abbrev_source_title={ACM Int. Conf. Proc. Ser.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Yin2015784,
author={Yin, Z.-X. and Cheng, C.-Y. and Tsai, C.-Y.},
title={Improving elementary students' environmental education using dual interactive teaching models},
journal={Workshop Proceedings of the 23rd International Conference on Computers in Education, ICCE 2015},
year={2015},
pages={784-786},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040455229&partnerID=40&md5=139d118f93ca3e52f70f97b03bdd736b},
affiliation={Department of Computer Science and Information Engineering, Southern Taiwan University of Science and Technology, Tainan, Taiwan; Department of Creative Product Design, Southern Taiwan University of Science and Technology, Tainan, Taiwan; Gembryo School, Beijing, China},
abstract={Learning from living with it's subtle and tine aspects are an important startup of Bionic Science in early child's education. Our research team tries to design and create an educational system to help students learning from nature to nature and explore the power of technology in everyday life. By exploring the theme of urban bugs' eco-development, characteristics, habits, and further convey the concept of prevention to personal health education. Our teaching kits has two highlight features, firstly, the high quality of 3D visual effects, and another is the application of Augmented Reality (AR) app to create the "Immersive" "Interactive" and "Imaginative" learning experience.},
author_keywords={Ar;  Ebook;  Elearning;  Fire ants;  Science education},
keywords={Argon;  Augmented reality;  E-learning;  Education computing;  Students, Ebook;  Educational systems;  Elementary students;  Environmental education;  Fire ants;  Learning experiences;  Science education;  Students learning, Education},
editor={Wu Y-T., Kojiri T., Kong S.C., Qiu F., Ogata H., Supnithi T., Wang Y., Chen W.},
publisher={Asia-Pacific Society for Computers in Education},
isbn={9784990801472},
language={English},
abbrev_source_title={Workshop Proc. Int. Conf. Comput. Educ., ICCE},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Zhizhimontova2015238,
author={Zhizhimontova, E. and Magee, J.},
title={Control yourself: A mixed-reality natural user interface},
journal={Communications in Computer and Information Science},
year={2015},
volume={528},
pages={238-242},
doi={10.1007/978-3-319-21380-4_42},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84951860859&doi=10.1007%2f978-3-319-21380-4_42&partnerID=40&md5=ca6b26cf88f72feb248a785f9b6e79ce},
affiliation={Math and Computer Science Department, Clark University, 950 Main St, Worcester, MA  01610, United States},
abstract={Control Yourself is a natural user interaction system with a camera and depth sensor, a processor and a display. The user’s image is separated from the background of a camera’s output and rendered in the program in real-time. The result is that a display shows a video of a person inside the application. The software also recognizes various types of movement such as gestures, changing positions, moving in frame and multiplayer interaction. The technology utilizes the obtained gestures and movements for GUI transformations and creation and for positioning the image or mesh of a user with the background removed. Users of the system can manipulate virtual objects and various features of the program by using gestures and movements while seeing themselves as if they were viewing a mirror with an augmented reality around them. This approach allows users to interact with software by natural movements via intuitive gestures. © Springer International Publishing Switzerland 2015.},
author_keywords={Augmented reality;  Computer vision;  Control yourself;  Depth camera;  Interactive games;  Interactive games;  Kinect;  Mixed reality;  Project-based learning},
keywords={Augmented reality;  Cameras;  Computer games;  Computer vision;  User interfaces;  Virtual reality, Depth camera;  Interactive games;  Kinect;  Mixed reality;  Project based learning, Human computer interaction},
correspondence_address1={Magee, J.; Math and Computer Science Department, Clark University, 950 Main St, United States; email: jmagee@clarku.edu},
editor={Stephanidis C.},
publisher={Springer Verlag},
issn={18650929},
isbn={9783319213798},
language={English},
abbrev_source_title={Commun. Comput. Info. Sci.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{NoAuthor20151,
title={15th International Conference on Computational Science and Its Applications, ICCSA 2015},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2015},
volume={9159},
pages={1-272},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84948968203&partnerID=40&md5=ac7680cba2c2004a375fbce2110d14f1},
abstract={The proceedings contain 21 papers. The special focus in this conference is on Software Quality, Virtual Reality and Applications. The topics include: Adding constraint building mechanisms to a symbolic execution engine developed for detecting runtime errors; comparison of software quality in the work of children and professional developers based on their classroom exercises; characterization of source code defects by data mining conducted on GitHub; measuring software component quality using static code analysis; validation of the city metaphor in software visualization; a systematic mapping on agile UCD across the major agile and HCI conferences; boosting the software quality of parallel programming using logical means; systematic mapping studies in modularity in it courses; mobile application verification; comparison of static analysis tools for quality measurement of RPG programs; novel software engineering attitudes for bussiness-oriented information systems; challenges and possibilities of use of augmented reality in education; immersive and interactive simulator to support educational teaching and dragging and dropping components for multi-projection virtual reality applications based on pc clusters.},
editor={Rocha A.M.A.C., Torre C., Gervasi O., Misra S., Taniar D., Apduhan B.O., Murgante B., Gavrilova M.L., Misra S.},
publisher={Springer Verlag},
issn={03029743},
isbn={9783319214122},
language={English},
abbrev_source_title={Lect. Notes Comput. Sci.},
document_type={Conference Review},
source={Scopus},
}

@ARTICLE{NoAuthor20151,
title={9th International Conference on Universal Access in Human-Computer Interaction, UAHCI 2015 Held as Part of 17th International Conference on Human-Computer Interaction, HCI International 2015},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2015},
volume={9177},
pages={1-736},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84947291110&partnerID=40&md5=f0ab2b36119269a7b307a297245b4faa},
abstract={The proceedings contain 73 papers. The special focus in this conference is on Universal Access to Education, Universal Access to Health Applications, Games for Learning and Therapy. The topics include: Criteria for designing blended learning materials for inclusive education; interaction design of digital teaching improves teaching and learning effectiveness; exploring the interactivity issues of the stereoscopic 3d systems for design education; stem scalable model for enhancing secondary and postsecondary student on-line services; a TUI-based storytelling for promoting inclusion in the preschool classroom; delivering user-centered content on an inclusive mobile platform; universal access to media and the California community colleges online education initiative; leveraging virtual worlds for electronic mentoring; integrating motion-capture augmented reality technology as an interactive program for children; accessible robotics programming for visually impaired users; the evolution of an online approach to preparing young students with disabilities for college and careers; quality analysis of polish universities based on Poe method; comparison research between ICT-based design and traditional design for hearing impaired children; haptics-enabled surgical training system with guidance using deep learning; a goal- and context-driven approach in mobile period tracking applications; rehabilitation of balance-impaired stroke patients through audio-visual biofeedback; a virtual reality system for occupational therapy with hand motion capture and force feedback and a virtual reality lower-back pain rehabilitation approach.},
editor={Stephanidis C., Antona M., Stephanidis C.},
publisher={Springer Verlag},
issn={03029743},
isbn={9783319206837},
language={English},
abbrev_source_title={Lect. Notes Comput. Sci.},
document_type={Conference Review},
source={Scopus},
}

@ARTICLE{NoAuthor20151,
title={2nd International Conference on Learning and Collaboration Technologies, LCT 2015},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2015},
volume={9192},
pages={1-736},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84947072993&partnerID=40&md5=651130a0447db0e12b7d236489c9a0ba},
abstract={The proceedings contain 74 papers. The special focus in this conference is on Technology-Enhanced Learning, Adaptive, Personalised Learning and Assessment. The topics include: An eye-tracking analysis of spatial contiguity effect in educational animations; using augmented reality technology in assisting english learning for primary school students; gesture-based nursing educational training support system; dual-coding strategy for the chinese characters learners; assessments of user centered design framework for M-learning application development; design and evaluation of a learning assistant system with optical head-mounted display OHMD; prediction of learner native language by writing error pattern; an exploration of mobile collaborative writing interface design; a tablet-based lego mindstorms programming environment for children; voice-based computer mediated communication for individual practice to increase speaking proficiency; a robotic platform controlled by smartphone; the use of augmented reality interfaces for on-site crisis preparedness; design solutions for interactive multi-video multimedia learning objects; automatic pronunciation error detection and feedback generation for CALL applications; feedback in computer-based concept mapping tools; model for detecting student difficulties in solving formative assessments; enhancing the learner’s performance analysis using SMEUS semantic e-learning system and business intelligence technologies; creation of meaningful-learning and continuous evaluation education system; a computational model to determine desirability of events based on personality for performance motivational orientation learners; recommendation engine for an online drill system; usability of educational technology APIs and ontological design to support cognitive plasticity for creative immersive experience in computer aided learning.},
editor={Zaphiris P., Ioannou A.},
publisher={Springer Verlag},
issn={03029743},
isbn={9783319206080},
language={English},
abbrev_source_title={Lect. Notes Comput. Sci.},
document_type={Conference Review},
source={Scopus},
}

@CONFERENCE{Poletti2015789,
author={Poletti, G.},
title={Work in progress: Mobile technology for teaching in higher education},
journal={IEEE Global Engineering Education Conference, EDUCON},
year={2015},
volume={2015-April},
pages={789-792},
doi={10.1109/EDUCON.2015.7096061},
art_number={7096061},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84946100317&doi=10.1109%2fEDUCON.2015.7096061&partnerID=40&md5=e5e6b592694c859652d556061d4735f9},
affiliation={University di Ferrara, Se (Center for Communication Technologies, Innovation and Distance Learning), Italy},
abstract={This article describes the research and application of new technologies to support classroom lessons. In particular traces the theoretical and applications that are in development and testing in some of the teachings of the degree courses in 'Science and Technologies of Communication' and 'Science and Technology for Cultural Heritage'. Development of applications, APP and augmented reality, are both a tool for teaching that a development tool that students use to expand their individual skills in the field of multimedia communications, interactive and distributed. © 2015 IEEE.},
author_keywords={augmented reality;  education;  ICT;  interaction},
keywords={Augmented reality;  Curricula;  Education;  Multimedia systems;  Students;  Teaching, Cultural heritages;  Development and testing;  ICT;  Individual skills;  interaction;  Multi-media communications;  Research and application;  Science and Technology, Engineering education},
correspondence_address1={Poletti, G.; University di Ferrara, Se (Center for Communication Technologies, Innovation and Distance Learning)Italy},
publisher={IEEE Computer Society},
issn={21659559},
isbn={9781479919086},
language={English},
abbrev_source_title={IEEE Global Eng. Edu. Conf., EDUCON},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{NoAuthor20151,
title={2nd International Conference on Augmented and Virtual Reality, AVR 2015},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2015},
volume={9254},
pages={1-514},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84944688660&partnerID=40&md5=b1625ea3f3b3712aed3521cc1bc324d8},
abstract={The proceedings contain 46 papers. The special focus in this conference is on Applications in Cultural Heritage, Augmented and Mixed Reality. The topics include: Advanced interaction with paintings by augmented reality and high resolution visualization; cloud computing and augmented reality for cultural heritage; accurate onsite georeferenced subsurface utility model visualisation; the augmented reality story book project; an interactive and collaborative system for augmented reality books; robust model based tracking using edge mapping and refinement; augmented reality, embodied cognition and learning; collaborative augmented reality game; device registration for 3D geometry-based user-perspective rendering in hand-held video see-through augmented reality; creativity support in projection-based augmented environments; serious games for rehabilitation using head-mounted display and haptic devices; scalable medical viewer for virtual reality environments; a pre-operative planning module for an augmented reality application in maxillo-facial surgery; augmented reality assisted brain tumor extraction in mice; a proposed hardware-software architecture for virtual reality in industrial applications; using haptic forces feedback for immersive and interactive simulation in industrial context; applying aesthetic rules in virtual environments by means of semantic web technologies; bilateral control of a robotic arm through brain signals; natural user interfaces for virtual character full body and facial animation in immersive virtual worlds; design and preliminary evaluation of free-hand travel techniques for wearable immersive virtual reality systems with egocentric sensing; perception of basic emotions from facial expressions of dynamic virtual avatars and touchless interaction for command and control in military operations.},
editor={De Paolis L.T., Mongelli A.},
publisher={Springer Verlag},
issn={03029743},
isbn={9783319228877},
language={English},
abbrev_source_title={Lect. Notes Comput. Sci.},
document_type={Conference Review},
source={Scopus},
}

@CONFERENCE{NoAuthor2015,
title={Proceedings - 2015 International Conference on Learning and Teaching in Computing and Engineering, LaTiCE 2015},
journal={Proceedings - 2015 International Conference on Learning and Teaching in Computing and Engineering, LaTiCE 2015},
year={2015},
page_count={247},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84942759910&partnerID=40&md5=0e075d78bef239cf8ee18d8b2c57a40e},
abstract={The proceedings contain 42 papers. The topics discussed include: interactive learning content for introductory computer science course using the ViLLE exercise framework; effect of medium of instruction on programming ability acquired through screencast; teaching high school computer science with videos of historical figures - an augmented reality approach; students' experiences on using Nerepa: a web-based system for students to learn financial analysis methods; evaluation of programming competency using student error patterns; integrating cognitive apprenticeship strategy with the use of online forum in developing product assignments; harmful study habits in online learning environments with automatic assessment; observation system for assessment of learning engagement in various pedagogies; and investigating the psychometric structure of bebras contest: towards measuring computational thinking skills.},
publisher={Institute of Electrical and Electronics Engineers Inc.},
isbn={9781479999675},
language={English},
abbrev_source_title={Proc. - Int. Conf. Learn. Teach. Comput. Eng., LaTiCE},
document_type={Conference Review},
source={Scopus},
}

@ARTICLE{Lee2015689,
author={Lee, K.-F. and Chin, K.-Y. and Lin, J.-M.},
title={Interactive augmented reality system for supporting museum guided instruction},
journal={Frontiers in Artificial Intelligence and Applications},
year={2015},
volume={274},
pages={689-698},
doi={10.3233/978-1-61499-484-8-689},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84926429790&doi=10.3233%2f978-1-61499-484-8-689&partnerID=40&md5=9c7f7aab190df87cd8b7b7a55f70f22b},
affiliation={Department of Information Engineering and Computer Science, Feng Chia University, Taichung City, 407, Taiwan; Department of Digital Humanities, Aletheia University, New Taipei City, 251, Taiwan},
abstract={With advances in information communication technology, a growing number of studies now use computer-assisted instruction to support traditional museum instruction. However, due to limited budgets and manpower, most museums in Taiwan do not plan or provide digital guided services for students. Although students can use museums, they usually do not learn sufficient information without expert assistance, and they are easily distracted during museum instruction. For these reasons, developing augmented reality (AR) technologies for learning have gained considerable attention in educational application. Many researchers integrated teaching and AR technologies to enhance students' learning performance. Therefore, this study proposes an Augmented Reality Supported Mobile Self-Guided System (AR-MSGS), and applies innovative AR technologies to a museum's learning environment. The proposed AR-MSGS will use AR technologies to display virtual information superimposed on top of real life objects. The virtual information can only be viewed through the screen of the mobile device, and is invisible to others in the real-world. In addition, we will use QR codes and the digital content server to develop interactive 3D virtual materials, for students to learn information intuitively and easily. We hope this research project is able to provide a strong case for promoting the use of AR technology in educational tasks, especially those related to learning activities based around museums instruction. The ultimate goal of this study is to encourage the widespread use of AR technologies in promoting Taiwanese digital education. © 2015 The authors and IOS Press. All rights reserved.},
author_keywords={2D Barcode;  Augmented Reality;  interactive learning environments;  museum guided instruction},
keywords={Augmented reality;  Budget control;  Computer aided instruction;  Education;  Engineering education;  Intelligent control;  Intelligent systems;  Mobile devices;  Students, 2d barcode;  Augmented reality systems;  Computer Assisted Instruction;  Educational Applications;  Information communication technology;  Interactive learning environment;  Learning environments;  Learning performance, E-learning},
correspondence_address1={Lin, J.-M.; Department of Information Engineering and Computer Science, Feng Chia UniversityTaiwan},
editor={Chu W.C.-C., Yang S.J.-H., Chao H.-C.},
publisher={IOS Press},
issn={09226389},
isbn={9781614994831},
language={English},
abbrev_source_title={Front. Artif. Intell. Appl.},
document_type={Conference Paper},
source={Scopus},
}
