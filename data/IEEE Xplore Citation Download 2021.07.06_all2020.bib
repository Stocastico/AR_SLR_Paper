@INPROCEEDINGS{9229922,
author={Brilian, Ilham and Bagus Nur Rahma Putra, Andika and Suhartadi, Syarif and Partono, Partono},
booktitle={2020 4th International Conference on Vocational Education and Training (ICOVET)}, title={Augmented Reality Based Learning Media as Interactive Learning Innovation to Enhanced Vocational School Learning Outcomes},
year={2020},
volume={},
number={},
pages={97-100},
abstract={Progress in the industrial world has reached industry 4.0, in this progress it has led to the development of education as well as entering the era of education 4.0. One of the advances in the era of education 4.0 is the Augmented Reality learning media. The purpose of the study was to test the effectiveness of the effects of Augmented Reality Learning media that are in line with the needs of current and future students, the ARTorque application product as an interactive learning innovation to improve the learning outcomes of SMK students. The Quasi Experiment research design with steps: Determination of the experimental and control class, Instrument Testing, The experimental class was given the treatment of Augmented Reality learning media and the control class was not given treatment and used conventional learning. Output results obtained are normality test, homogeneity test and t test results.},
keywords={Media;Augmented reality;Industries;Technological innovation;Distributed databases;Electronic learning;Training;Impact;Learning Media;Augmented Reality;Learning Outcomes},
doi={10.1109/ICOVET50258.2020.9229922},
ISSN={},
month={Sep.},}
@INPROCEEDINGS{9163704,
author={Martin, Sergio and Parra, Gerardo and Cubillo, Joaquín and Quintana, Blanca and Gil, Rosario and Perez, Clara and Castro, Manuel},
booktitle={2020 XIV Technologies Applied to Electronics Teaching Conference (TAEE)}, title={Design of an Augmented Reality System for Immersive Learning of Digital Electronic},
year={2020},
volume={},
number={},
pages={1-6},
abstract={This article describes the development of two mobile applications for learning Digital Electronics. The first application is an interactive app for iOS where you can study the different digital circuits, and which will serve as the basis for the second: a game of questions in augmented reality.},
keywords={Augmented reality;Education;Logic gates;Mobile applications;Tools;Cameras;Libraries;Digital Electronics;Augmented Reality;Mobile Application;Immersive Learning},
doi={10.1109/TAEE46915.2020.9163704},
ISSN={},
month={July},}
@INPROCEEDINGS{9298003,
author={Yuhana, Umi Laili and Hariadi, Ridho Rahman and Mukramin, Mukramin and Fabroyir, Hadziq and Arifiani, Siska},
booktitle={2020 International Conference on Computer Engineering, Network, and Intelligent Multimedia (CENIM)}, title={AUGGO: Augmented Reality and Marker-based Application for Learning Geometry in Elementary Schools},
year={2020},
volume={},
number={},
pages={116-120},
abstract={Suitable learning media can be used to achieve learning goals. The more interactive the learning media, the learning process will be more interactive. This paper proposes a learning media named Auggo. Auggo is an Augmented Reality (AR) and marker-based application as an interactive media to learn geometry in Elementary School. To show the impact of Auggo, this research conducts a test to 14 students in elementary school as participants. The test was carried out using the Two-Group Paired Sample T-Test method with those 14 elementary school students. Participants were divided into 2 groups: 7 participants as Group A (experimental class) and 7 participants as Group B (control class). Assessment of participants showed the results of the pretest to posttest in Group A increased by 26%, while Group B only increased by 10.29%. These results indicate that the AR-based AUGGO application can help students in improving the understanding of space concept.},
keywords={Media;Geometry;Three-dimensional displays;Games;Informatics;Augmented reality;Shape;learning media;Augmented Reality;Geometry;Elementary School},
doi={10.1109/CENIM51130.2020.9298003},
ISSN={},
month={Nov},}
@INPROCEEDINGS{9243292,
author={Subandi and Joniriadi and Syahidi, Aulia Akhrian and Mohamed, Amran},
booktitle={2020 Third International Conference on Vocational Education and Electrical Engineering (ICVEE)}, title={Mobile Augmented Reality Application with Multi-Interaction for Learning Solutions on the Topic of Computer Network Devices (Effectiveness, Interface, and Experience Design)},
year={2020},
volume={},
number={},
pages={1-6},
abstract={Application of Mobile Augmented Reality (AR) as a learning solution in innovation facing the education era 5.0. for vocational students on the computer network device topic, we promote in this paper. The purpose of this study is to apply AR technology-based applications by maximizing all of its interactions in the learning process about computer network devices so that students can know and understand their functions, then conduct an assessment of User Interface (UI) and User Experience (UX). The detection approach uses a marker-based tracking method, by bringing up 3D objects, rotating and touching, information and tool functions in the form of text, and producing sounds as information clues. A total of 30 students from one of the vocational high schools have been involved to use this application. After being analyzed for the current situation the students were very enthusiastic in following the learning process, then in the analysis of student understanding results obtained an average value of N-Gain was 67.41 which was proven that AR application could improve learning effectiveness, the results of the UI assessment with a value of 98.70% have a very strongly agree predicate to the application interface has been met, and the results of the assessment of the experience of users with a value of 98.94% have a very strongly agree predicate to the experience of using the application has been fulfilled.},
keywords={Three-dimensional displays;Education;User interfaces;Tools;Computer networks;User experience;Augmented reality;augmented reality;education era 5.0;human-computer interaction;user experience;user interface},
doi={10.1109/ICVEE50212.2020.9243292},
ISSN={},
month={Oct},}
@INPROCEEDINGS{9155202,
author={Harrington, Maria C. R.},
booktitle={2020 6th International Conference of the Immersive Learning Research Network (iLRN)}, title={Connecting User Experience to Learning in an Evaluation of an Immersive, Interactive, Multimodal Augmented Reality Virtual Diorama in a Natural History Museum the Importance of Story},
year={2020},
volume={},
number={},
pages={70-78},
abstract={Reported are the findings of user experience and learning outcomes from a July 2019 study of an immersive, interactive, multimodal augmented reality (AR) application, used in the context of a museum. The AR Perpetual Garden App is unique in creating an immersive multisensory experience of data. It allowed scientifically naïve visitors to walk into a virtual diorama constructed as a data visualization of a springtime woodland understory and interact with multimodal information directly through their senses. The user interface comprised of two different AR data visualization scenarios reinforced with data based ambient bioacoustics, an audio story of the curator's narrative, and interactive access to plant facts. While actual learning and dwell times were the same between the AR app and the control condition, the AR experience received higher ratings on perceived learning. The AR interface design features of "Story" and "Plant Info" showed significant correlations with actual learning outcomes, while "Ease of Use" and "3D Plants" showed significant correlations with perceived learning. As such, designers and developers of AR apps can generalize these findings to inform future designs.},
keywords={Data visualization;Virtual reality;Forestry;History;Biomedical acoustics;Three-dimensional displays;Games;augmented reality;bioacoustics;data visualization;immersive;information fidelity;informal learning;interactive;multimodal;museums;narrative;photorealistic;place illusion;presence;virtual dioramas;virtual reality},
doi={10.23919/iLRN47897.2020.9155202},
ISSN={},
month={June},}
@INPROCEEDINGS{9073879,
author={Bhatti, Zeeshan and Bibi, Maymoona and Shabbir, Naila},
booktitle={2020 3rd International Conference on Computing, Mathematics and Engineering Technologies (iCoMET)}, title={Augmented Reality based Multimedia Learning for Dyslexic Children},
year={2020},
volume={},
number={},
pages={1-7},
abstract={Augmented reality is a visual technology which combines virtual objects into the real environment, in real time. In this research work, a heuristic model of multimedia learning would be developed using Augmented Reality for a type of neurological disorder known as Dyslexia. Dyslexia is complex mental brain related syndromes, affecting the children in various ways including verbal and nonverbal communications, social interactions, understanding instructions, reading, writing, learning, problems, etc. The use of interactive Augmented Reality based multimedia application to facilitate and provide pedagogy for such type of special children would ascertain a unique and new dimension of treating and helping such young hearts in overcoming their disabilities in a very fun and easy way. The research encompasses designing a framework based on cognitive learning for interactive multimedia learning app using augmented reality technology, that would be centric to autism effected children's and would enable them to interact with such system.},
keywords={Augmented reality;Three-dimensional displays;Education;Solid modeling;Shape;Real-time systems;Dyslexia;Augmented Reality;Multimedia Learning;Serious Games},
doi={10.1109/iCoMET48670.2020.9073879},
ISSN={},
month={Jan},}
@INPROCEEDINGS{9339660,
author={Ali, Dayana Farzeeha and Johari, Nusaila and Omar, Marlissa and Sunar, Mohd Shahrizal},
booktitle={2020 6th International Conference on Interactive Digital Media (ICIDM)}, title={ARMLAAPPS: Augmented Reality Application in Microeconomics},
year={2020},
volume={},
number={},
pages={1-5},
abstract={Augmented Reality (AR) is a technology that combines both virtual and real environments simultaneously. It is designed to let users experience activities in a way close to real-world experience within a safe environment. It can also supplement the difficult information presented in a conventional approach to enhance users' understanding of the complex concept. It has been used widely in various fields due to the effectiveness of this technology. However, the application of AR is scarcely explored, especially for the Microeconomics field. Therefore, this study aims to develop and investigate augmented reality application development to enhance students' visualization skills in Microeconomic courses. Through this study, a mobile augmented reality application called Augmented Reality Mobile Learning Apps (ARMLAAPPS) was developed to give an interactive learning experience that can enhance students' visualization skills and help students learn more efficiently and in a more flexible way. After the development process, the evaluation of ARMLAAPPS is conducted to identify the effectiveness of the ARMLAAPPS in enhancing visualization skills among Microeconomics students in higher institutions. Based on the results, this study has successfully developed the ARMLAAPPS, and it has proven to be effective in improving students' visualization when learning Microeconomics.},
keywords={Visualization;Three-dimensional displays;Microeconomics;Media;User experience;Augmented reality;augmented reality;microeconomics;visualization skills;mobile learning;higher institutions},
doi={10.1109/ICIDM51048.2020.9339660},
ISSN={},
month={Dec},}
@INPROCEEDINGS{9149526,
author={Pérez-Muñóz, A. and Castro-Idrovo, D. and Robles-Bykbaev, Y. and Robles-Bykbaev, V. and Pesántez-Avilés, F.},
booktitle={2020 IEEE World Conference on Engineering Education (EDUNINE)}, title={An interactive application based on augmented reality and rules-based reasoning to support educational activities of high school students},
year={2020},
volume={},
number={},
pages={1-5},
abstract={The following topics are dealt with: computer aided instruction; educational institutions; educational courses; teaching; engineering education; further education; computer science education; human factors; Internet; educational administrative data processing.},
keywords={Augmented reality;Mathematics;Tools;Expert systems;Three-dimensional displays;Training;Augmented reality;Mathematics;Support Decision System;Children and youth},
doi={10.1109/EDUNINE48860.2020.9149526},
ISSN={},
month={March},}
@INPROCEEDINGS{9258078,
author={Chen, Hong-Yunn and Yang, Chen-Yu and Liu, Xu-Ying and Chou, Cheng-Fu},
booktitle={2020 IEEE International Conference on Consumer Electronics - Taiwan (ICCE-Taiwan)}, title={On Deep Learning Based Feedback and Precoding For Multi-user Millimeter-Wave Enabled VR/AR},
year={2020},
volume={},
number={},
pages={1-2},
abstract={Virtual reality (VR)/augmented reality (AR) and its applications have attracted significant and increasing attention recently. However, the stringent quality of service (QoS) requirements and better spectral efficiency have posed the challenges such as higher bandwidth, lower latency and better reliability on the VR/AR communication system. This paper proposes a deep-learning-based (DL-based) precoding and feedback method for mitigating the channel interference of multi-users VR/AR environments. That is, our DL-based method uses the VR/AR channel state information (CSI) to do radio resource allocation for maximizing the millimeter-wave network throughput. Numerical results show that our DL-based design could significantly enhance the throughput.},
keywords={Precoding;Wireless communication;Conferences;Resource management;Throughput;Signal to noise ratio;Resists;Massive MIMO;virtual reality;augmented reality;precoder feedback;Deep Learning},
doi={10.1109/ICCE-Taiwan49838.2020.9258078},
ISSN={2575-8284},
month={Sep.},}
@INPROCEEDINGS{9381152,
author={Gaona, Yuliana Jiménez and Carrillo Mayenquer, Irene and Malla, Darwin Castillo and Gonzalez, Yadira Ludeña},
booktitle={2020 XV Conferencia Latinoamericana de Tecnologias de Aprendizaje (LACLO)}, title={Immersive and Collaborative learning: an educational resource for mathematical training in medicine},
year={2020},
volume={},
number={},
pages={1-7},
abstract={Advances in molecular biology and medicine are generating new technologies and opportunities, where mathematics is a science that has a fundamental role, especially to enhance and contribute to human health through research. This science helps to develop different future scenarios; such as an epidemic, dissemination of a virus, clinical analysis, diagnostic tests, pharmacokinetics, among others, demonstrating that health science professionals are constantly using and interpreting mathematical data collected. However, the teaching of this science has been limited to passive learning, where the student is only a recipient of information, generating low academic performance and increased student dropout. Based on this, an immersive and collaborative learning methodology is proposed for the teaching of mathematics in students of the first medical year at the Universidad Técnica Particular de Loja. The methodology involves distributing students into two experimental and control groups. The first group contains 48 students and the control group 72 students. The experimental group used clinical cases, mathematical models, TIC's and augmented reality applications to provide solutions to medical issues. The other group learned mathematics in a traditional way. As a result, teachers perceive a more active participation (>50%) by the experimental group based on their academic averages and the results of the survey; the latter results indicated that a medium-high average feels motivated to learn mathematics and to know its applicability in bioscience.},
keywords={Training;Epidemics;Collaborative work;Molecular biology;Mathematical model;Medical diagnostic imaging;Viruses (medical);collaborative learning immersive learning augmented reality;mathematical innovation;educational technology},
doi={10.1109/LACLO50806.2020.9381152},
ISSN={},
month={Oct},}
@INPROCEEDINGS{9001692,
author={Rosni, Nurul Shuhadah and Kadir, Zahidah Abd and Mohamed Noor, Megat Norulazmi Megat and Abdul Rahman, Zaidatul Husna and Bakar, Nurulain Abu},
booktitle={2020 14th International Conference on Ubiquitous Information Management and Communication (IMCOM)}, title={Development of mobile markerless augmented reality for cardiovascular system in anatomy and physiology courses in physiotherapy education},
year={2020},
volume={},
number={},
pages={1-5},
abstract={This paper focuses on the development of markerless Augmented Reality (AR) using ARCore platform, where interactive three-dimensional (3D) content was designed and developed based on the learning outcome syllabus to enhance the visualization and understanding of the anatomy and physiology for cardiovascular system topic. Currently, learning method is based on 2D images and slides, plastic models and cadavers have to deal with students' experience issues such as lack of interactive, uneasy feeling with dead body and cadavers storing and donation. Therefore, more advances using technology such as Augmented Reality (AR) in learning method are needed to overcome the current gap and enhance the students' learning. Thus, this study aims to develop markerless AR specifically focus on the cardiovascular system for undergraduate physiotherapy program at UniKL, RCMP. In this study, we describe a method used to create markerless AR content using 3D data from MRI images and 3D unity as an authoring tool. We present three processes, where the first design consideration based on author's previous works derived from systematic search strategy were outlined, the second 3D model was developed using a real object and subsequently converted to an AR asset that can be linked to a unique markerless using ARCore platform and the third AR content creation using 3D unity authoring tool. This application provides a better visualization for the anatomical parts to support for an innovative and flexible learning process. We have successfully analyzed the design consideration using a systematic search strategy and developed the markerless AR specifically for cardiovascular system in anatomy and physiology courses. This study has contributed to knowledge in design and development of AR used in physiotherapy education. Therefore, this will be a step forward to an exploration of design-based research for an AR benefit in experienced-learning approach application.},
keywords={Three-dimensional displays;Cardiovascular system;Search problems;Physiology;Education;Systematics;Solid modeling;augmented reality;markerless AR;ARCore;physiotherapy education;anatomy and physiology;cardiovascular system},
doi={10.1109/IMCOM48794.2020.9001692},
ISSN={},
month={Jan},}
@INPROCEEDINGS{9155148,
author={Krüger, Jule M. and Bodemer, Daniel},
booktitle={2020 6th International Conference of the Immersive Learning Research Network (iLRN)}, title={Different Types of Interaction with Augmented Reality Learning Material},
year={2020},
volume={},
number={},
pages={78-85},
abstract={In this paper, a study with the focus on interactivity in augmented reality (AR) applications concerning the influence of different forms of interaction with AR learning material is presented. While research on multimedia learning often distinguishes between mental and physical interaction with learning material, other research fields state that physical interaction is necessary to interact mentally. To look at how this distinction may play a role in AR-based learning material, an experimental study with a 2x2 design manipulating mental and physical interaction was conducted, including learning material on the topic of power plants. The data (N = 128) were collected and analyzed, showing that, although not expected, learning was better in groups in which either more physical or more mental interaction was applied, but not in groups in which both were high. The results are discussed under the potential idea of cognitive overload.},
keywords={Cognition;Power generation;Task analysis;Three-dimensional displays;Visualization;Augmented reality;augmented reality;multimedia learning;interactivity;interactive learning;technology-enhanced learning},
doi={10.23919/iLRN47897.2020.9155148},
ISSN={},
month={June},}
@INPROCEEDINGS{9151605,
author={Kenoui, Mouna and Mehdi, Mohamed Ait},
booktitle={2020 1st International Conference on Communications, Control Systems and Signal Processing (CCSSP)}, title={Teach-Me DNA: an Interactive Course Using Voice Output in an Augmented Reality System},
year={2020},
volume={},
number={},
pages={260-265},
abstract={In this paper, we present an interactive system partly based on voice output in an augmented reality environment. Using a chatbot technology, this system allows the user to engage bidirectional communication with a conversational agent. The present system builds upon our previous work in which the user interacts with 3D virtual objects via voice commands. We describe, in the current document, how we integrate speech output using the Text to Speech Service (TTS API) available on the IBM Watson platform, the goal being to obtain an even more interactive system. We also employ Speech Synthesis Markup Language (SSML) to control some features of the natural-sounding speech thus produced. Moreover, we developed Teach-Me DNA, an interactive application that gives the user (pupil, student) the opportunity to learn and/or revise the DNA molecule's basics as a part of a biological course. On one hand, and via voice inputs the user is simply able to perform 3D selections and 3D manipulations of the molecule and its several components in order to learn about their 3D features and properties, this first part dealing with the vocal entries was fully documented in a previous work. On another hand, TeachMe DNA is here enriched by producing a natural speech when reacting to the user's requests. In fact, an agent's voice is used to respond in real time to student's questions. Definitions and/or explanations are thus given in a very natural way which might immerse more significantly the student in the proposed learning environment based on augmented reality technology.},
keywords={Three-dimensional displays;Augmented reality;Speech recognition;Education;DNA;Real-time systems;Tools;HCI;Natural Interaction;Speech Recognition;Voice Output;Augmented Reality;Pedagogical Agent;Chatbot;IBM Watson;Cloud Application;Biomedical Course;Education},
doi={10.1109/CCSSP49278.2020.9151605},
ISSN={},
month={May},}
@INPROCEEDINGS{9299533,
author={Tsvetkova, Ivanka Dimitrova and Borodzhieva, Adriana Naydenova},
booktitle={2020 28th National Conference with International Participation (TELECOM)}, title={Analysis of Measurements for Investigating Amplitude Modulation Using Interactive Methods},
year={2020},
volume={},
number={},
pages={74-77},
abstract={Teachers use different approaches to engage students with the learning process and make the material more interesting. Interactive tools and augmented reality (AR) applications are a great way to increase the students' participation. The paper demonstrates the use of AR and the interactive approach in the discipline “Radio Communication Technologies”. It describes what students need to do in the laboratory exercises on the topic of Amplitude Modulation.},
keywords={Amplitude modulation;Oscilloscopes;Signal generators;Frequency modulation;Radio communication;Telecommunications;Task analysis;amplitude modulation;augmented reality;interactive methods;radio communications},
doi={10.1109/TELECOM50385.2020.9299533},
ISSN={},
month={Oct},}
@INPROCEEDINGS{9320889,
author={Azawi, Rula Al and Al-Obaidy, Mohaned and Qaddoum, Kefaya},
booktitle={2020 Seventh International Conference on Information Technology Trends (ITT)}, title={Mobile Augmented Reality (MAR) in Distance Learning: Present and Future},
year={2020},
volume={},
number={},
pages={140-145},
abstract={Covid-19 pandemic affects our life suddenly and dramatically. The most affected area was our teaching methods. Students and teachers move to distance learning without good experience and background especially for non-IT teachers.In this paper, we will discuss the opportunity to enhance distance learning and how to make it more effective, easier, and more enjoyable by activating Augmented Reality (AR) in the education field.Recently, AR has been used in various contexts to enhance our experience in mobile and wearable devices. This paper discusses the use of AR in the field of education where it has been observed that learning results have been improved. This type of application required specialized teams of software to create and maintain it and we will explain the benefits and limitations of using AR in distance learning. Using AR in education will provide powerful paradigms for the next generation advanced learning system.},
keywords={Education;Augmented reality;Three-dimensional displays;Software;Computer aided instruction;Hardware;Tools;Teaching strategies;interactive learning environment;e-learning;augmented reality;Virtual Learning Environment and Mobile Learning},
doi={10.1109/ITT51279.2020.9320889},
ISSN={},
month={Nov},}
@INPROCEEDINGS{9247820,
author={Lee, Liew Set and Aluwee, Sayed Ahmad Zikri Sayed and Meng, Goh Chuan and Palanisamy, Pradeep and Subramaniam, Ramani},
booktitle={2020 International Conference on Computational Intelligence (ICCI)}, title={Interactive Tool Using Augmented Reality (AR) for Learning Knee and Foot Anatomy Based on CT Images 3D Reconstruction},
year={2020},
volume={},
number={},
pages={281-286},
abstract={Anatomy is the branch of biological science in medical education that focuses on structured parts of living things, especially the human body. Traditional teaching methods and learning materials of human body anatomy are usually available in the form of textbooks with pictures and images or artificial anatomy mannequins. There are still not enough to help the students in understanding it with actual and accurate knowledge about our human body anatomy. It is because students are challenging in learning the human anatomy body part by through imagining it's real and lack of interaction and hard to understand with those 2D images model on the textbooks. Although there are artificial anatomy mannequins available for learning, it is limited in number and access. Technological developments, especially applications based on 3D, are expected to help the learning process of this science subject. In this study, we proposed to develop an augmented reality (AR) mobile application for learning human anatomy knee and foot through medical 3-dimensional (3D) reconstruction based on medical images. By using this application, students expected can easily understand human anatomy using 3D image visualisation on the mobile computing platform.},
keywords={Knee;Visualization;Image segmentation;Three-dimensional displays;Human anatomy;Learning (artificial intelligence);Biomedical imaging;knee and foot anatomy;medical images segmentation;3D visualisation;augmented reality (AR);mobile application;education technology},
doi={10.1109/ICCI51257.2020.9247820},
ISSN={},
month={Oct},}
@INPROCEEDINGS{9056153,
author={Zhu, Minglu and Sun, Zhongda and Zhang, Zixuan and Shi, Qiongfeng and Chen, Tao and Liu, Huicong and Lee, Chengkuo},
booktitle={2020 IEEE 33rd International Conference on Micro Electro Mechanical Systems (MEMS)}, title={Sensory-Glove-Based Human Machine Interface for Augmented Reality (AR) Applications},
year={2020},
volume={},
number={},
pages={16-19},
abstract={We propose a glove based Human Machine Interface (HMI) designed for Virtual Reality (VR) and Augmented Reality (AR) applications. The proposed sensory glove uses facile designed triboelectric sensors to realize multi-dimensional motion recognition of gestures, and piezoelectric mechanical stimulators are also equipped for achieving the haptic feedback to user regarding the interactive events from virtual world. The developed HMI leverages machine learning technology to achieve real time object recognition, hence, we can manipulate virtual objects in VR/AR space by projecting sensory information from glove.},
keywords={Piezoelectric transducers;Mechanical sensors;Force;Object recognition;Machine learning;Triboelectric;piezoelectric;human machine interface;augmented reality;machine learning},
doi={10.1109/MEMS46641.2020.9056153},
ISSN={2160-1968},
month={Jan},}
@INPROCEEDINGS{9155197,
author={Liu, Changhao and Wu, Shuo and Wu, Shuming and Cai, Su},
booktitle={2020 6th International Conference of the Immersive Learning Research Network (iLRN)}, title={An AR-Based Case Study of Using Textual and Collaborative Scaffolding for Students with Different Self-Efficacy to Learn Lever Principles},
year={2020},
volume={},
number={},
pages={9-15},
abstract={With the deepening application of augmented reality (AR) in education, researches pay more attention to the evaluation of learning results rather than consider how to use teaching strategies to support personalized teaching. This study developed an AR science curriculum incorporating textual and collaborative scaffolding, and taught it in elementary school science classes to help students learn about scientific knowledge of lever principle. To explore the effects of different self-efficacy and scaffolding teaching strategies on students' learning conceptions and cognitive load, a two times two experiment was conducted on an elementary school. The results show that the use of textual and collaborative scaffolding in AR teaching can help students with low self-efficacy to pay attention to the conceptions of deep learning and effectively reduce the cognitive load of students.},
keywords={Collaboration;Task analysis;Instruments;Educational technology;Tools;Real-time systems;augmented reality;scaffolding;learning conceptions;cognitive load;self-efficacy},
doi={10.23919/iLRN47897.2020.9155197},
ISSN={},
month={June},}
@INPROCEEDINGS{9262690,
author={Gallego, Neil Patrick Del},
booktitle={2020 22nd Symposium on Virtual and Augmented Reality (SVR)}, title={A Proposed Learning Content for Teaching Handheld Augmented Reality in a Classroom Setting},
year={2020},
volume={},
number={},
pages={111-118},
abstract={Augmented reality is an interactive experience wherein digital objects are placed on the physical environment. Augmented reality (AR) applications have gained popularity especially when smartphones gained capable camera sensors, gyroscope, and other sensors. However, there has been a lack of framework or recommendations on how to formally teach developing mobile AR applications in a classroom setting. In this paper, we present a learning content, called ARVRDEV Courseware, that aims to teach undergraduate students how to develop augmented reality applications deployed on handheld devices. We carefully designed the lessons of the course, consistent with AR techniques from literature, and designed hands-on activities not typically presented in publicly available materials. A pilot run of the course was offered at De La Salle University, where a total of 76 undergraduate students took the course as an elective during their 4th year. We analyzed the effectiveness of the hands-on activities based on the assessment results of the students and discussed the outstanding projects developed by the students, which are observed to be inspired by the hands-on activities designed for the course.},
keywords={Cameras;Augmented reality;Engines;Tools;Tutorials;Three-dimensional displays;Proteins;augmented reality;computing education;course design;application},
doi={10.1109/SVR51698.2020.00030},
ISSN={},
month={Nov},}
@INPROCEEDINGS{9155152,
author={Chung, Cheng-Yu and Hsiao, I-Han},
booktitle={2020 6th International Conference of the Immersive Learning Research Network (iLRN)}, title={Computational Thinking in Augmented Reality: An Investigation of Collaborative Debugging Practices},
year={2020},
volume={},
number={},
pages={54-61},
abstract={The uniqueness of Augmented Reality (AR) is its affordance to support learning abstract concepts by rich information, visualization and the integration of user-content interaction. Research has shown that abstract idea and invisible phenomena can be learned better with the support of AR. However, high complexity and conceptual Computational Thinking (CT), such as algorithm design and related programming concepts, are rarely studied empirically in the intersection with immersive technology. This study is aimed at addressing this issue and providing a piece of quantitative and empirical evidence to AR-supported Computer Science discipline-based learning. We designed a mobile AR-enabled application based on a CT framework and related AR affordances in the literature. This app can contextualize a programming debugging task and support program editing & CT learning. A controlled laboratory study was designed and conducted. The result of statistical analyses shows that participants with the AR support made better quality of programs with lower errors and less amount of code edits, compared to those without the AR support.},
keywords={Visualization;Task analysis;Debugging;Programming profession;Problem-solving;Computed tomography;augmented reality;debugging practices;learn to code;computational thinking;computer science education;collaborative learning;mobile app},
doi={10.23919/iLRN47897.2020.9155152},
ISSN={},
month={June},}
@INPROCEEDINGS{9320882,
author={Xanthidis, Dimitrios and Manolas, Christos and Paul, Sujni and Xanthidou, Ourania Koutzampasopoulou},
booktitle={2020 Seventh International Conference on Information Technology Trends (ITT)}, title={Virtual and Augmented Reality: Enhancing the learning experience in higher education in the U.A.E. Current standing research directions},
year={2020},
volume={},
number={},
pages={206-211},
abstract={In addition to the established and widespread technological tools and trends of the past decades, such as the surge of mobile computing, high-speed networks and social media, new technologies utilizing the increased power and capabilities of modern computers is developing rapidly. Perhaps, no better example of this can be found than the rapid developments in Virtual and Augmented Reality (VR/AR), that have recently made the step from the laboratories and specialized, bespoke training applications of the past, to the mainstream. Advances in VR/AR have opened the floodgates to digital internships, virtual labs, and novel collaborative and experiential learning. The magnitude and impact of these emerging technologies is also evident on the significant interest in their application and use in various commercial, professional, and industrial contexts. Examples of these include, but are not limited to, the entertainment industries, specialized training, corporate demonstrations and conferencing, and prototyping and modelling in the technical and engineering areas. Since universities play a vital role in moulding tomorrow's talents, integrating such technologies can help them not only by supporting teaching and learning, but also by contributing to related research and enhancing the learning technology frameworks in their entirety. The aim of this research paper is to briefly discuss the position of these emerging technologies in the educational sector in general, and explore what their role, impact, and structure may be in the educational systems of the future with a focus on higher education in the U.A.E. Eventually, it will contribute by suggesting areas of interest for its future use in higher education in the U.A.E.},
keywords={Three-dimensional displays;Training;Tools;Market research;Technological innovation;Visualization;Solid modeling;Higher Education;Augmented Reality;Virtual Reality;Learning Object;U.A.E.},
doi={10.1109/ITT51279.2020.9320882},
ISSN={},
month={Nov},}
@INPROCEEDINGS{9274671,
author={Hidayat, Wahyu Nur and Damayanti, Hilga and Pratiwi, Luthfiah Setya and Sutikno, Tri Atmadji and Patmanthara, Syaad},
booktitle={2020 3rd International Conference on Computer and Informatics Engineering (IC2IE)}, title={Fun Learning with Flashcard using Augmented Reality for Learning Daily Prayers of Kindergarten Students},
year={2020},
volume={},
number={},
pages={349-354},
abstract={Prayer learning is one of the biggest contributors to improving early childhood memorization skills. Prayer learning for kindergarten students is still monotonous and unattractive. Especially during the C-19 pandemic, students cannot memorize together with their classmates. Therefore, there is a need for learning media that can help students to learn and memorize with fun and interesting. The purpose of developing daily prayer learning media by utilizing Augmented Reality (AR) based flash card images is to make it easier for kindergarten students to learn more interesting and interactive prayers. The flash card is an AR marker that can be scanned through the application and brings up videos and 3D animations of daily prayer learning. That way, students become more interested in having interactive multimedia assistance. Media development is carried out with the waterfall method, which is preceded by the need analysis to trials application. Media testing was carried out by individual testing using a questionnaire with two aspects, namely software engineering aspects and visual communication aspects. Overall, media development is in accordance with user needs and can run well on the Android smartphone platform. Based on the results of the media expert's validation, this media was declared valid with a value of the software engineering aspect and the visual communication aspect of 86%. In the future, a large-scale trial will be conducted to determine the effectiveness of the learning implementation using this media.},
keywords={Augmented reality;Media;Three-dimensional displays;Education;Testing;Games;Videos;daily prayer learning;mobile learning;augmented reality;flashcard;3d animation},
doi={10.1109/IC2IE50715.2020.9274671},
ISSN={},
month={Sep.},}
@INPROCEEDINGS{9254048,
author={Cruzado, Johny Pretell and Huaman, Davis Huaytan and Capa, Jimmy Rodas and Bellizza, Mirtha Quipas},
booktitle={2020 IEEE Engineering International Research Conference (EIRCON)}, title={IdeAR: Augmented Reality Applied to Reading Comprehension Stories},
year={2020},
volume={},
number={},
pages={1-4},
abstract={A problem in many schools is the difficulty of students to understand texts, which is due to multiple factors, including habits and motivation to read. On the other hand, augmented reality is a didactic technology which, when applied to the educational area, becomes a dynamic, interactive activity and arouses interest in the student. This study shows the results obtained after the application of augmented reality for reading comprehension through stories in fourth grade primary students. A mobile application based on augmented reality named “IdeAR” was implemented using Mobile-D methodology. For empirical demonstration the statistical sample included two sections of students from a public school in Lima city, where the experimental group showed improvements in memory level and content understanding. Finally, this work is important for the educational sector because it provides a tool that favors teaching with a STEAM approach.},
keywords={Conferences;Urban areas;Education;Tools;Mobile applications;Augmented reality;augmented reality;reading comprehension},
doi={10.1109/EIRCON51178.2020.9254048},
ISSN={},
month={Oct},}
@INPROCEEDINGS{9288425,
author={Herbert, Bradley M. and Wigley, Grant and Ens, Barrett and Billinghurst, Mark},
booktitle={2020 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)}, title={Perceptions of Integrating Augmented Reality into Network Cabling Tutors},
year={2020},
volume={},
number={},
pages={231-236},
abstract={As networks become increasingly complex, professionals must familiarise themselves with the cabling rack to administer the network effectively. In line with this industry goal, we compared the usability, task load and perceptions of three similar network cabling tutoring systems: (1) a hand-held Augmented Reality (AR)-based cabling tutor (HAR); (2) a head-mounted AR-based cabling tutor (HMD) and (3) a 2-Dimensional (2D)-based cabling tutor (HH). While usability of different modalities have been compared previously, none of those comparisons used knowledge modelling approaches. So, in our comparison, each tutor uses knowledge space modelling (KSM) approaches to detect learner mistakes and show arrows on the rack to indicate the source of the mistake. While adding an AR sub-system to a network cabling tablet-based tutor may not necessarily improve usability, participants reported higher engagement over the AR hand held tablet when using the Head-Mounted Display (HMD) condition. Several potential reasons were identified to account for the side effect such as the potential for the AR sub-system to potentially influence learning perceptions; the additional physical effort of needing to point the tablet at the rack and perceived performance degradation.},
keywords={Training;Visualization;Computational modeling;Resists;Usability;Task analysis;Augmented reality;Human-centered computing;Visualization;Visualization techniques;Augmented Reality;Human Computer Interaction (HCI);HCI design and evaluation methods},
doi={10.1109/ISMAR-Adjunct51615.2020.00068},
ISSN={},
month={Nov},}
@INPROCEEDINGS{9339630,
author={Omar, Yuhanis binti and Darusman, Abu Hassan bin},
booktitle={2020 6th International Conference on Interactive Digital Media (ICIDM)}, title={A Conceptual Framework for Designing Mobile Augmented Reality Self-Directed Learning Practical Module on Direct-On-Line Motor Control},
year={2020},
volume={},
number={},
pages={1-5},
abstract={The pandemic of SARS-COVID-19 has given a major impact on many educational institutions. In this situation, Teaching and Learning (T&L) become an issue, especially for the practical learning session that requires certain teaching aid using the latest technology. Currently, T&L was delivered through an online medium. Direct On-Line (DOL) starter in automation is a method of starting a 3-phase induction motor that is connected directly across its 3-phase supply. Its starter applies the full line voltage to the motor terminals. However, during this pandemic, the lab session for doing the wiring and testing for DOL motor control is limited to a demonstration by the lecturer via video, and students will do the wiring on paper or using the software. Mobile learning can be an alternative learning tool for this group of students. Therefore, this paper aims to propose a conceptual framework for designing a mobile Augmented Reality (AR) Self-Directed Learning (SDL) practical module on DOL motor control for subjects related to industrial automation. The framework consists of an SDL, a motivational Flow Theory (engagement), User Experience Design (UX-D) using an AR environment to learn the practical part of DOL motor control.},
keywords={Wiring;Motor drives;Automation;Induction motors;Pandemics;Education;Mobile applications;self-directed learning;augmented reality;user experience;mobile application;DOL motor control},
doi={10.1109/ICIDM51048.2020.9339630},
ISSN={},
month={Dec},}
@INPROCEEDINGS{9306513,
author={Marašević, Jovana and Gavrovska, Ana},
booktitle={2020 28th Telecommunications Forum (TELFOR)}, title={Virtual Reality and WebRTC implementation for Web educational application development},
year={2020},
volume={},
number={},
pages={1-4},
abstract={Real-time collaborative web tools are of great importance in communication between everyone nowadays. WebRTC and similar solutions enable web real-time communication. On the other hand, immersive technologies, like the ones related to Augmented Reality and Virtual Reality, have become particularly valuable for educational platforms. In this paper, WebRTC and VR based web application development has been considered. The application and experimental results focus on the advantages and new possibilities that WebRTC and virtual reality bring. This can be of interest not only for teaching and communication between proffesors and students, but also for education of children with physical disabilities or developmental disorders, like autism.},
keywords={WebRTC;Streaming media;Virtual reality;Protocols;Three-dimensional displays;Education;Browsers;Virtual Reality;A-frame;WebRTC;communication;education;Augmented Reality;E-learning},
doi={10.1109/TELFOR51502.2020.9306513},
ISSN={},
month={Nov},}
@INPROCEEDINGS{9356216,
author={Imteaj, Ahmed and Hadi Amini, M.},
booktitle={2020 19th IEEE International Conference on Machine Learning and Applications (ICMLA)}, title={FedAR: Activity and Resource-Aware Federated Learning Model for Distributed Mobile Robots},
year={2020},
volume={},
number={},
pages={1153-1160},
abstract={Smartphones, autonomous vehicles, and the Internet-of-things (IoT) devices are considered the primary data source for a distributed network. Due to a revolutionary breakthrough in internet availability and continuous improvement of the IoT devices capabilities, it is desirable to store data locally and perform computation at the edge, as opposed to share all local information with a centralized computation agent. A recently proposed Machine Learning (ML) algorithm called Federated Learning (FL) paves the path towards preserving data privacy, performing distributed learning, and reducing communication overhead in large-scale machine learning (ML) problems. This paper proposes an FL model by monitoring client activities and leveraging available local computing resources, particularly for resource-constrained IoT devices (e.g., mobile robots), to accelerate the learning process. We assign a trust score to each FL client, which is updated based on the client's activities. We consider a distributed mobile robot as an FL client with resource limitations either in memory, bandwidth, processor, or battery life. We consider such mobile robots as FL clients to understand their resource-constrained behavior in a real-world setting. We consider an FL client to be untrustworthy if the client infuses incorrect models or repeatedly gives slow responses during the FL process. After disregarding the ineffective and unreliable client, we perform local training on the selected FL clients. To further reduce the straggler issue, we enable an asynchronous FL mechanism by performing aggregation on the FL server without waiting for a long period to receive a particular client's response.},
keywords={Training;Performance evaluation;Machine learning;Collaborative work;Mobile robots;Reliability;Task analysis;Federated Learning;resource-limitations;trust;mobile robot;straggler;Internet-of-Things;distributed computing;model aggregation},
doi={10.1109/ICMLA51294.2020.00185},
ISSN={},
month={Dec},}
@ARTICLE{9234650,
author={Sereno, Mickael and Wang, Xiyao and Besancon, Lonni and Mcguffin, Michael J and Isenberg, Tobias},
journal={IEEE Transactions on Visualization and Computer Graphics}, title={Collaborative Work in Augmented Reality: A Survey},
year={2020},
volume={},
number={},
pages={1-1},
abstract={In Augmented Reality (AR), users perceive virtual content anchored in the real world. It is used in medicine, education, games, navigation, maintenance, product design, and visualization, in both single-user and multi-user scenarios. Multi-user AR has received limited attention from researchers, even though AR has been in development for more than two decades. We present the state of existing work at the intersection of AR and Computer-Supported Collaborative Work (AR-CSCW), by combining a systematic survey approach with an exploratory, opportunistic literature search. We categorize 65 papers along the dimensions of space, time, role symmetry (whether the roles of users are symmetric), technology symmetry (whether the hardware platforms of users are symmetric), and output and input modalities. We derive design considerations for collaborative AR environments, and identify under-explored research topics. These include the use of heterogeneous hardware considerations and 3D data exploration research areas. This survey is useful for newcomers to the field, readers interested in an overview of CSCW in AR applications, and domain experts seeking up-to-date information.},
keywords={Collaboration;Augmented reality;Collaborative work;Visualization;Hardware;Three-dimensional displays;Introductory and Survey;Computer-Supported Cooperative Work;Virtual and Augmented Reality;Immersive Analytics},
doi={10.1109/TVCG.2020.3032761},
ISSN={1941-0506},
month={},}
@INPROCEEDINGS{9288462,
author={Collins, Jonny and Langlotz, Tobias and Regenbrecht, Holger},
booktitle={2020 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)}, title={Virtual Reality in Education: A Case Study on Exploring Immersive Learning for Prisoners},
year={2020},
volume={},
number={},
pages={110-115},
abstract={Our research presented here tries to bridge the gap between technology-oriented lab work and the praxis of introducing VR technology into difficult to deploy-to contexts-in our case prisoners with high learning needs. We have developed a prototypical immersive VR application designed for delivering low-level literacy and numeracy content to illiterate adults. This development has been taken to the commercial sector and is currently under product development. The target population for the application are those currently held in a correctional facility, but who have the motivation and determination to educate themselves. In this paper we discuss the current lifecycle of this project including the development, initial tests, and an exploratory study we conducted. We conclude with a discussion of logistical issues, potential research opportunities, and current outcomes.},
keywords={Education;Sociology;Virtual environments;Product development;Statistics;Augmented reality;Guidelines;VR education;learning;in-the-field;Applied computing;Education;Interactive learning environments;Human-centered computing;Human computer interaction (HCI);Interaction paradigms;Virtual reality},
doi={10.1109/ISMAR-Adjunct51615.2020.00042},
ISSN={},
month={Nov},}
@INPROCEEDINGS{9288434,
author={Silva, Manuel and Teixeira, Luis},
booktitle={2020 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)}, title={Developing an eXtended Reality platform for Immersive and Interactive Experiences for Cultural Heritage: Serralves Museum and Coa Archeologic Park},
year={2020},
volume={},
number={},
pages={300-302},
abstract={Digital Heritage and Digital Humanities focus on distinct typologies of heritage: tangible and intangible Cultural Heritage (CH) objects and their preservation, education, and research versus the application of digital technologies to support research in the humanities. Both allow scholars to go beyond textual sources to integrate digital tools into the humanistic study. This project aims at supporting a new way of experiencing CH in the Serralves Museum and Coa Archeologic Park through more involving and culturally-qualified user experience. The main goal is to understand the potential of eXtended Reality within CH while also proposing the idea of developing a digital experience platform: an authoring tool based on an engine with core experiences functions that can be applied for developing multiple experiences for CH. This platform will contribute to new approaches, technologies, and tools for creating, processing, and delivering immersive and interactive content for engaging and meaningful experiences in these specific CH environments.},
keywords={Extended reality;Education;Tools;User experience;Cultural differences;Augmented reality;Engines;Cultural Heritage;Serralves Museum;Coa Archeological Park;Immersive and Interactive Experience;eXtended Reality;Platform},
doi={10.1109/ISMAR-Adjunct51615.2020.00084},
ISSN={},
month={Nov},}
@INPROCEEDINGS{9090480,
author={Pittman, Corey and LaViola, Joseph J.},
booktitle={2020 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)}, title={PhyAR: Determining the Utility of Augmented Reality for Physics Education in the Classroom},
year={2020},
volume={},
number={},
pages={760-761},
abstract={Physics is frequently cited as a difficult roadblock and hindrance to retention in STEM majors. In this paper, we present the results of a study exploring the potential utility and use cases of augmented reality in secondary and post secondary physics courses. To gather meaningful information, we developed PhyAR, prototype physics education application in augmented reality. We collected feedback and opinions from a qualitative study of university students with STEM backgrounds. Our findings point towards a clear desire to see the use of more interactive 3D AR content in physics courses.},
keywords={Augmented reality;Physics education;Three-dimensional displays;Prototypes;Visualization;Magnetometers;Augmented Reality;Physics Education;Qualitative Interview},
doi={10.1109/VRW50115.2020.00231},
ISSN={},
month={March},}
@INPROCEEDINGS{9288385,
author={Herbert, Bradley M. and Hoff, William and Billinghurst, Mark},
booktitle={2020 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)}, title={Usability Considerations of Hand Held Augmented Reality Wiring Tutors},
year={2020},
volume={},
number={},
pages={277-282},
abstract={The following topics are dealt with: augmented reality; virtual reality; human computer interaction; data visualisation; medical computing; learning (artificial intelligence); user experience; mobile computing; computer aided instruction; helmet mounted displays.},
keywords={Wiring;Training;Prototypes;User interfaces;Usability;Task analysis;Augmented reality;Human-centered computing;Human computer interaction (HCI);Interaction paradigms;Mixed / augmented reality Human-centered computing;Human computer interaction (HCI);HCI design and evaluation methods;User studies},
doi={10.1109/ISMAR-Adjunct51615.2020.00078},
ISSN={},
month={Nov},}
@INPROCEEDINGS{9245260,
author={Begic, Mija and Cirimotic, Marko and Farkas, Ivona and Skoric, Ivan and Car, Zeljka and Rasan, Ivana and Zilak, Matea},
booktitle={2020 43rd International Convention on Information, Communication and Electronic Technology (MIPRO)}, title={Software Prototype Based on Augmented Reality for Mastering Vocabulary},
year={2020},
volume={},
number={},
pages={446-451},
abstract={Interactive experience of Augmented Reality that is created by deploying virtual objects in a real user environment, and its augmentation by audio-visual elements as well as the possibility of touch, provides added value for learning, especially regarding content multimodal presentation, increasing learner's motivation and level of engagement. This is very promising, especially in the field of education and rehabilitation, where current research slightly takes focus in this technological direction. To conduct this type of research, the prerequisite is to have a quality prototype with features, easy to understand and use by users of different cognitive skills, and yet sophisticated enough to carry out the research. The paper presents software prototype based on Augmented Reality aimed for mastering vocabulary for children with complex communication needs. The solution was developed in the multidisciplinary cooperation of students and teachers from the technical field and professionals from the education and rehabilitation field. The overall development process and initial evaluation are described, as well as the developed prototype from the technological and user perspective.},
keywords={Vocabulary;Education;Prototypes;Software;Planning;Augmented reality;Investment;Augmented Reality;virtual objects;learning;education;rehabilitation;children;mastering vocabulary},
doi={10.23919/MIPRO48935.2020.9245260},
ISSN={2623-8764},
month={Sep.},}
@INPROCEEDINGS{9357261,
author={Batuwanthudawa, B.I. and Jayasena, K.P.N},
booktitle={2020 2nd International Conference on Advancements in Computing (ICAC)}, title={Real- Time Location based Augmented Reality Advertising Platform},
year={2020},
volume={1},
number={},
pages={174-179},
abstract={Augmented Reality (AR) is growing rapidly and is becoming more mature and robust technology, combining virtual information with a real-time performance environment. Most of the Augmented reality applications available today & popular because of the interactive virtual objects placed in the real environment. For education, navigation, tourism & many sectors use this technology due to clear understand of real objects appear as it is as virtual objects, in front of you. Like that, the Marketing sector also uses AR technology to brand themselves interactively. Most of them are marker-based AR applications which the virtual contents are showing when the AR camera directs to a target such as paper advertisement. On other hand marker-less AR advertising applications are developed for individual businesses from AR supported plugins, apps rare to see & as unique published app. From this research, I proposed a real-time marker-less augmented reality platform, streaming & showcasing virtual marketing assets in front of shops for common business use. The main objective of this research is to develop a real-time location-based Augmented Reality platform to improve marketing & sales aspects of businesses. The users can easily find the exact location of the shop though AR objects. This novel marketing concept engages more customers to business and enhances the usability of AR application among users though easy to access on their selling products. The users can use app in native platforms(both android & IOS) and ready to access interactive virtual 3D objects with animation as marketing materials placed in front of shops. This platform solved the existing problems of location-based AR application which are interactivity of AR & adequately perform as real-time platform extract data from a live real-time server & show the locations through AR camera.},
keywords={Navigation;Education;Cameras;Real-time systems;Advertising;Augmented reality;Business;Augmented Reality;Advertising Platform;Location based AR;Unity Engine},
doi={10.1109/ICAC51239.2020.9357261},
ISSN={},
month={Dec},}
@INPROCEEDINGS{9156000,
author={Rane, Archana and John, Varun N and Murthy, Sahana},
booktitle={2020 IEEE 20th International Conference on Advanced Learning Technologies (ICALT)}, title={GeoMaps: An interactive application to enhance map comprehension skills of students},
year={2020},
volume={},
number={},
pages={254-258},
abstract={Geography education requires the use of spatial thinking and reasoning to understand and interpret maps. Effective usage of geographical maps is a crucial skill to be developed for students. However, it has been found that students' ability to use maps to describe and analyze natural phenomena to find solutions to geographical problems is inadequate. One reason for this shortcoming is difficulty in comprehension of maps given in textbooks or reference books, which is preliminarily due to inherent limitations with paper-based maps. Sophisticated technology-based map applications are available like interactive maps, Augmented reality-based maps, 3D view maps, etc. But there are few learning activities around these, leaving the students confused as to how these can be used in different contexts to solve problems. GeoMaps is an interactive application to improve map comprehension skills of students, which includes ability to identify, correlate and synthesize information from multiple perspectives in a map. The activities in GeoMaps are based on authentic geography problems. To solve these problems, students can overlay multiple maps to correlate various features, and choose corresponding filters to focus on particular information. The preliminary feedback from potential users is promising, encouraging us to explore this idea at a broader context.},
keywords={Rivers;Geography;Tools;Three-dimensional displays;Cognition;Education;Satellites;component;spatial skills;geography;maps;interactive maps;map comprehension skills},
doi={10.1109/ICALT49669.2020.00083},
ISSN={2161-377X},
month={July},}
@INPROCEEDINGS{9262659,
author={Silva, Leonardo Souza and Aranha, Renan Vinicius and Ribeiro, Matheus A. O. and Nakamura, Ricardo and Nunes, Fatima L. S.},
booktitle={2020 22nd Symposium on Virtual and Augmented Reality (SVR)}, title={3D visualization of temporal data: exploring Visual Attention and Machine Learning},
year={2020},
volume={},
number={},
pages={443-452},
abstract={Temporal data visualization supports planning and decision-making processes as it helps understanding patterns and relationships among time-based data. In many fields of study, users deal with a large volume of valuable information, which is usually analyzed based on temporal aspects. In this scenario, the use of three-dimensional space opens interesting opportunities in time representation, interpretation, and exploration of temporal data. Approaches based on Virtual Reality (VR) techniques are still underexplored to visualize temporal data, most of the times as an extension of the bi-dimensional space, although they can provide more natural interaction in real time. Visual Attention (VA) has grown in relevance in many study areas due to its ability to help humans explore a complex visual scene. Contributing to overcome the limited use of three-dimensional (3D) space in temporal data visualization, in this article, we present a VR approach named 3D BlocKARL to support interactive visualization of temporal data. The environment is built based on VA concepts. Our approach uses a rule-based Machine Learning method, generating new ways to visualize temporal information in 3D environments. The results of two controlled experiments with volunteers shows that the visualizations generated by our approach had a good acceptance and were able to decrease the mistake rate while performing a specific task when compared to a traditional approach.},
keywords={Data visualization;Three-dimensional displays;Visualization;Image color analysis;Task analysis;Machine learning;Tools;Information Visualization;Temporal Data;Visual Attention;Ruled-based learning method;Human-Computer Interaction;Virtual Reality},
doi={10.1109/SVR51698.2020.00072},
ISSN={},
month={Nov},}
@ARTICLE{8812921,
author={Cen, Ling and Ruta, Dymitr and Al Qassem, Lamees Mahmoud Mohd Said and Ng, Jason},
journal={IEEE Transactions on Learning Technologies}, title={Augmented Immersive Reality (AIR) for Improved Learning Performance: A Quantitative Evaluation},
year={2020},
volume={13},
number={2},
pages={283-296},
abstract={Technology-enhanced learning has attracted increasing attention of educational community focused on improvement of traditional classroom learning. Augmented immersive reality (AIR) technologies enhance users' perception of reality by augmenting it with computer-generated components such as audio, video, 2/3-D graphics, GPS data, etc. The AIR introduces new dimensions of learning experience that ensure better attention, focus, and entertainment, thereby boosting students' motivation and attainment. This work presents an award winning AIR-based educational mobile system, code-named AIR-EDUTECH, that was developed to help high school students learn chemistry. The AIR-EDUTECH introduced new AIR features to help students better understand and learn basic concepts of molecular chemistry. It offers immersive 3D visualization and visual interaction with the examined structures that provides a broader and more retentive knowledge and improves intuition around forming basic chemical reactions. The system was introduced and tested in a field study with 45 students in the 11th grade chemistry class, and its impact was evaluated by the formal assessment quiz along with the feedback from survey conducted after the trial. Collected data have been subjected to an in-depth multi-modal quantitative analysis that revealed that AIR-EDUTECH stimulated significant improvements in understanding and retention of the taught content as well as turned learning chemistry into a fun, interesting and interactive experience. It also uncovered a hidden structure of taught knowledge dependencies and highlighted the role that AIR technology could play in reinforcing the retention of critical knowledge that may otherwise widen student knowledge gaps.},
keywords={Education;Chemicals;Three-dimensional displays;Cameras;Visualization;Statistical analysis;Mobile learning;Augmented Reality (AR);Augmented Immersive Reality (AIR);AIR-EDUTECH;education data mining.},
doi={10.1109/TLT.2019.2937525},
ISSN={1939-1382},
month={April},}
@INPROCEEDINGS{9284282,
author={Chen, Xing and Liu, Guizhong},
booktitle={2020 IEEE International Conference on Edge Computing (EDGE)}, title={Joint Optimization of Task Offloading and Resource Allocation via Deep Reinforcement Learning for Augmented Reality in Mobile Edge Network},
year={2020},
volume={},
number={},
pages={76-82},
abstract={Mobile edge computing (MEC) has been recognized as emerging techniques in 5G to provide powerful computing capabilities for the Ultra Reliable Low Latency Communication (URLLC) applications. In this paper, a MEC enable multi-user wireless network is considered by offloading the computation task to MEC server, reducing latency and energy consumption of user terminal for Augmented Reality (AR) application. The joint optimization problem of resource allocation and task offloading is studied to minimize the energy consumption of each user subject to the delay requirement and the limited resources. We propose a deep reinforcement learning algorithm based on a multi-agent deep deterministic policy gradient (MADDPG) to solve this problem. Simulation results show that the proposed algorithm can greatly reduce energy consumption of the users.},
keywords={Energy consumption;Heuristic algorithms;Simulation;Reinforcement learning;Ultra reliable low latency communication;Resource management;Task analysis;Mobile Edge Computing;Deep Reinforcement Learning;Augmented Reality},
doi={10.1109/EDGE50951.2020.00019},
ISSN={},
month={Oct},}
@INPROCEEDINGS{9103475,
author={Salman, Shaik Mohammed and Sitompul, Taufik Akbar and Papadopoulos, Alessandro Vittorio and Nolte, Thomas},
booktitle={2020 IEEE International Conference on Fog Computing (ICFC)}, title={Fog Computing for Augmented Reality: Trends, Challenges and Opportunities},
year={2020},
volume={},
number={},
pages={56-63},
abstract={Augmented reality applications are computationally intensive and have latency requirements in the range of 15- 20 milliseconds. Fog computing addresses these requirements by providing on-demand computing capacity and lower latency by bringing the computational resources closer to the augmented reality devices. In this paper, we reviewed papers providing custom solutions for augmented reality using the fog architecture and identified that the ongoing research trends towards balancing quality-of-experience, energy, and latency for both single and collaborative multi-device augmented reality applications. Furthermore, some works also focus on providing architectures for fog-based augmented reality systems and also on the training of machine learning algorithms in the fog layers to improve user experience. Based on these findings, we provide some challenges and research directions that can facilitate the adoption of fog-based augmented reality systems.},
keywords={Computer architecture;Edge computing;Cloud computing;Task analysis;Augmented reality;Optimization;Market research;fog computing;edge computing;cloudlets;augmented reality;trends;challenges;opportunities},
doi={10.1109/ICFC49376.2020.00017},
ISSN={},
month={April},}
@INPROCEEDINGS{9262701,
author={Souza, Vinicius and Maciel, Anderson and Nedel, Luciana and Kopper, Regis and Loges, Klaus and Schlemmer, Eliane},
booktitle={2020 22nd Symposium on Virtual and Augmented Reality (SVR)}, title={The Effect of Virtual Reality on Knowledge Transfer and Retention in Collaborative Group-Based Learning for Neuroanatomy Students},
year={2020},
volume={},
number={},
pages={92-101},
abstract={There are many uses for virtual reality (VR) in education, and there is a consensus about its contribution in the teaching and learning processes. However, the majority of the studies assess the effectiveness of an individual learning in VR, and there is a need to explore more on the effects of VR using different levels of immersion and collaboration. This paper presents an experiment to investigate knowledge transfer in a group-based learning game. We introduce a VR serious game to support teaching and learning processes in neuroanatomy health education. A between-subjects experiment was conducted with 23 students to jointly assess learning, knowledge retention, and sense of presence. As a control condition, grouped students assembled a physical model of the human brain, while in the experimental condition, a virtual brain was assembled. In each group, one participant assembled the brain, while the others observed and verbally collaborated in a group-based learning strategy. Results shown high mean scores in the virtual condition. When comparing the knowledge test performance before and immediately after the experiment, we found significant difference only for the virtual condition. The same can be observed for retention. Because of the promising results achieved and motivated by the need of more engaging new tools for remote learning - fully used in quarantine conditions, such as the current one because of the Covid-19 pandemic - we conducted a pilot user study to evaluate the learning effect of a remote version of our collaborative VR game.},
keywords={Education;Games;Training;Neuroanatomy;Collaboration;Three-dimensional displays;Solid modeling;Virtual Reality;Presence;User Evaluation},
doi={10.1109/SVR51698.2020.00028},
ISSN={},
month={Nov},}
@INPROCEEDINGS{9049708,
author={Chen, Dawei and Xie, Linda Jiang and Kim, BaekGyu and Wang, Li and Hong, Choong Seon and Wang, Li-Chun and Han, Zhu},
booktitle={2020 International Conference on Computing, Networking and Communications (ICNC)}, title={Federated Learning Based Mobile Edge Computing for Augmented Reality Applications},
year={2020},
volume={},
number={},
pages={767-773},
abstract={The past decade has witnessed the prosperous growth of augmented reality (AR) devices, as they provide immersive and interactive experience for customers. AR applications have the properties of high data rate and latency sensitivity. Currently, the available bandwidth is relatively limited to transmit and process enormous generated data. Meanwhile, it is challenging for AR to accurately detect and classify the object in order to perfectly combine the corresponding virtual contents with the real world. In this work, we focus on how to solve the computation efficiency, low-latency object detection and classification problems of AR applications. Firstly, we introduce and analyze the practical mathematical model of AR, and connect the AR operating principles with the object detection and classification problem. To address this problem and reduce the executing latency simultaneously, we propose a framework collaborating mobile edge computing paradigm with federated learning, both of which are decentralized configurations. To evaluate our method, numerical results are calculated based on the open source data CIFAR-10. Compared to centralized learning, our proposed framework requires significantly fewer training iterations.},
keywords={},
doi={10.1109/ICNC47757.2020.9049708},
ISSN={2325-2626},
month={Feb},}
@INPROCEEDINGS{9202283,
author={Moparthi, Nageswarara Rao and Sagar, P. Vidya and Balakrishna, G.},
booktitle={2020 7th International Conference on Smart Structures and Systems (ICSSS)}, title={Usage for Inside Design by AR and VR Technology},
year={2020},
volume={},
number={},
pages={1-4},
abstract={The Article defines the usage of AR & VR for interior beautifying. This innovative phase of digital/arithmetical technology, virtual techniques had a greater impression on enhancing the picturing of architectural based applications. Thus, the new technology of Augmented Reality and Virtual Reality contracts more benefits of the digital architectural plan as well as construction fields. Augmented Reality & Virtual Reality is deliberated as one of the substantial design approaches for internal design. In this view, the virtual equipment can be displayed and modified by choosing the appropriate style, look or placement of the furniture agreeing of the user have an interactive capability. The article describes about the significance of the applications that increase the quality of furniture arrangements.},
keywords={Augmented reality;Three-dimensional displays;Layout;Visualization;Tools;Conferences;Furniture arrangement;interior design;layout interface;interaction;virtual reality;augmented reality},
doi={10.1109/ICSSS49621.2020.9202283},
ISSN={},
month={July},}
@ARTICLE{9184009,
author={Ahn, Jaewon and Lee, Joohyung and Niyato, Dusit and Park, Hong-Shik},
journal={IEEE Transactions on Vehicular Technology}, title={Novel QoS-Guaranteed Orchestration Scheme for Energy-Efficient Mobile Augmented Reality Applications in Multi-Access Edge Computing},
year={2020},
volume={69},
number={11},
pages={13631-13645},
abstract={In this study, we focus on improving the energy efficiency of multiple mobile augmented reality (MAR) devices (MDs) with different MAR applications, which are connected to a single multi-access edge computing (MEC) server, through the centralized orchestration of the MEC server. To achieve this, a trade-off between the accuracy, latency, and energy consumption of each MD is considered as intertwined costs. Accordingly, we minimize a sum of intertwined costs including the energy consumption, latency and accuracy loss of multiple MDs, while satisfying the maximum latency constraint and the minimum accuracy constraint of each MAR application. With rigorous analysis, we design a theoretical framework for the optimization of MD performance by jointly managing the frame resolution of the image to offload to the MEC server from MDs, and the computation capacity distribution over MDs in the case of the limited computation capacity of the MEC server. Our numerical analysis validates that the proposed scheme significantly reduces the number of service-level agreement violations, such as exceeding the maximum latency constraint, compared with the existed algorithm. Specifically, the proposed work significantly improve costs of service latency, accuracy loss, and energy consumption of MDs for MEC-assisted MAR services compared with baseline schemes.},
keywords={Object detection;Servers;Energy consumption;Optimization;Quality of service;Image resolution;Image edge detection;Augmented reality;energy efficiency;multi-access edge computing;QoS guaranteed;object detection;optimization},
doi={10.1109/TVT.2020.3020982},
ISSN={1939-9359},
month={Nov},}
@INPROCEEDINGS{9156141,
author={Flores, Huber},
booktitle={2020 IEEE International Conference on Pervasive Computing and Communications Workshops (PerCom Workshops)}, title={Edge Intelligence Enabled by Multi-Device Systems: (PerCrowd 2020 Panel)},
year={2020},
volume={},
number={},
pages={1-2},
abstract={Edge intelligence focuses on pushing the data processing of resource-intensive AI-based applications to the Edge of the network. Indeed, Edge computing enables machine and deep learning models to be trained and provisioned in proximity of users without minimal or none cloud support. This enables the creation of a new type of end applications with low energy footprint and better decision making capabilities. For instance, applications for autonomous driving, health monitoring, and augmented reality, among others. Unfortunately, the lack of dense and potent computing infrastructure on the Edge is a critical limitation that prevents the adoption of Edge intelligence. On the other hand, the ever-increasing availability of programmable smart devices in everyday environments is giving rise to computing scenarios that involve collaboration between multiple devices. Examples of such scenarios range from resource sharing (e.g., mobile device crowds for sensing and computing) to scenarios requiring active collaboration between multiple devices (e.g., opportunistic device-to-device networks). The theme of the panel is to overview how multi-device collaborative systems can be exploited to enable Edge intelligence for end applications. In particular, the panel is interested on discussing the exploitation of computational resources of smart devices for executing distributed AI-based applications, as well as, the self-organization of smart devices to enable federated learning architectures that can train machine and deep learning models incrementally.},
keywords={Mobile computing;Conferences;Collaboration;Computer science;Machine learning;Smart devices;Sensors;Edge Intelligence;Federated learning;Deep and machine learning;Artificial Intelligence;Pervasive computing;Device-to-Device collaboration;Opportunistic crowd;Context-awareness;Mobile devices;Mobile crowds;Multi-Device sensing;Multi-Device computing},
doi={10.1109/PerComWorkshops48775.2020.9156141},
ISSN={},
month={March},}
@INPROCEEDINGS{9090465,
author={Harrington, Maria C. R.},
booktitle={2020 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)}, title={Observation of Presence in an Ecologically Valid Ethnographic Study Using an lmmersive Augmented Reality Virtual Diorama Application},
year={2020},
volume={},
number={},
pages={812-813},
abstract={The main research question is centered on the usefulness of immersive Augmented Reality (AR) applications for informal learning activities. Can users experience presence – or a sense of being there - when using AR apps? To begin to approach this question an ethnographic study was conducted in July, 2019 in a museum with 56 volunteer participants to document behavior and measure learning, attitudes, and emotional outcomes of an AR application. Reported are the preliminary results of behavior indicative of presence observed in the study, and insights gained that are useful in understanding future designs.},
keywords={Conferences;Virtual reality;Three-dimensional displays;User interfaces;Augmented reality;bioacoustics;data visualization;embodiment;immersive;informal learning;interactive;multimodal;museums;presence},
doi={10.1109/VRW50115.2020.00257},
ISSN={},
month={March},}
@INPROCEEDINGS{9339655,
author={Yusof, Cik Suhaimi and Ahmad, Nazwa and Ismail, Ajune Wanis and Sunar, Mohd Shahrizal},
booktitle={2020 6th International Conference on Interactive Digital Media (ICIDM)}, title={Mathematics Lesson using Accelerometer Sensor Interaction in Handheld Augemented Reality Application for Kindergarten},
year={2020},
volume={},
number={},
pages={1-6},
abstract={Handheld Augmented Reality (AR) is a combination of the virtual content and real world that gives a chance for the user to interact with virtual objects in real time using handheld device. Recent handheld device equipped with additional sensing like gyroscope, barometer, accelerometer and proximity sensor make possible to explore full potential for interaction in application. This become interesting topic to improve the human perception and to enhance the understanding of complex 3D scenarios. The traditional educational method is not necessarily effective for the children. Sometimes student's incapable to recall the ideas and it seem struggle to solve the problem in learning process. Therefore, the purpose of this project is to develop mathematics lesson using accelerometer sensor interaction in handheld AR application for kindergarten. There are four phases to complete this study. The first phase is preliminary investigation and analyse in handheld application for Mathematics lesson. Then, second phase is to design the details of application operational framework. The third phase is to develop Mathematics lesson application with accelerometer interaction. Last phase is to evaluate the user perception of the application. Unity 3D and Vuforia SDK are used as editors and library respectively through the development process. The evaluation has been done by respondents who are the ages from 6 to 9 years old. The results have proved that the application can help better to improve Mathematics learning skill by using accelerometer interaction through handheld AR application. The application enhances the teaching method for students to learn an addition and subtraction more efficiently and in interactive ways.},
keywords={Accelerometers;Three-dimensional displays;Handheld computers;Color;Mathematics;Usability;Testing;augmented reality;accelerometer sensor interaction;handheld device;mathematics lesson application},
doi={10.1109/ICIDM51048.2020.9339655},
ISSN={},
month={Dec},}
@INPROCEEDINGS{9089476,
author={Jakl, Andreas and Lienhart, Anna-Maria and Baumann, Clemens and Jalaeefar, Arian and Schlager, Alexander and Schöffer, Lucas and Bruckner, Franziska},
booktitle={2020 IEEE Conference on Virtual Reality and 3D User Interfaces (VR)}, title={Enlightening Patients with Augmented Reality},
year={2020},
volume={},
number={},
pages={195-203},
abstract={Enlightening Patients with Augmented Reality (EPAR) enhances patient education with new possibilities offered by Augmented Reality. Medical procedures are becoming increasingly complex and printed information sheets are often hard to understand for patients. EPAR developed an augmented reality prototype that helps patients with strabismus to better understand the processes of examinations and eye surgeries. By means of interactive storytelling, three identified target groups based on user personas were able to adjust the level of information transfer based on their interests. We performed a 2-phase evaluation with a total of 24 test subjects, resulting in a final system usability score of 80.0. For interaction prompts concerning virtual 3D content, visual highlights were considered to be sufficient. Overall, participants thought that an AR system as a complementary tool could lead to a better understanding of medical procedures.},
keywords={Education;Three-dimensional displays;Augmented reality;Surgery;Human computer interaction;Usability;Prototypes;Human-centered computing;Mixed / augmented reality Human-centered computing;Interface design prototyping Human-centered computing;Interaction design theory;concepts and paradigms Human-centered computing;Usability testing},
doi={10.1109/VR46266.2020.00038},
ISSN={2642-5254},
month={March},}
@INPROCEEDINGS{9210302,
author={Velaora, Maria and van Roy, Richard and Guéna, François},
booktitle={2020 Fourth World Conference on Smart Trends in Systems, Security and Sustainability (WorldS4)}, title={ARtect, an augmented reality educational prototype for architectural design},
year={2020},
volume={},
number={},
pages={110-115},
abstract={ARtect is an Augmented Reality application developed with Unity 3D, which envisions an educational interactive and immersive tool for architects, designers, researchers, and artists. This digital instrument renders the competency to visualize custom-made 3D models and 2D graphics in interior and exterior environments. The user-friendly interface offers an accurate insight before the materialization of any architectural project, enabling evaluation of the design proposal. This practice could be integrated into learning architectural design process, saving resources of printed drawings, and 3D carton models during several stages of spatial conception.},
keywords={Three-dimensional displays;Solid modeling;Tools;Two dimensional displays;Computer architecture;Augmented reality;Visualization;2d graphic;3d models;application;architecture;augmented reality;education;design},
doi={10.1109/WorldS450073.2020.9210302},
ISSN={},
month={July},}
@INPROCEEDINGS{9284711,
author={Wolf, Erik and Döllinger, Nina and Mal, David and Wienrich, Carolin and Botsch, Mario and Latoschik, Marc Erich},
booktitle={2020 IEEE International Symposium on Mixed and Augmented Reality (ISMAR)}, title={Body Weight Perception of Females using Photorealistic Avatars in Virtual and Augmented Reality},
year={2020},
volume={},
number={},
pages={462-473},
abstract={The appearance of avatars can potentially alter changes in their users' perception and behavior. Based on this finding, approaches to support the therapy of body perception disturbances in eating or body weight disorders by mixed reality (MR) systems gain in importance. However, the methodological heterogeneity of previous research has made it difficult to assess the suitability of different MR systems for therapeutic use in these areas. The effects of MR system properties and related psychometric factors on body-related perceptions have so far remained unclear. We developed an interactive virtual mirror embodiment application to investigate the differences between an augmented reality see-through head-mounted-display (HMD) and a virtual reality HMD on the before-mentioned factors. Additionally, we considered the influence of the participant's body-mass-index (BMI) and the BMI difference between participants and their avatars on the estimations. The 54 normal-weight female participants significantly underestimated the weight of their photorealistic, generic avatar in both conditions. Body weight estimations were significantly predicted by the participants' BMI and the BMI difference. We also observed partially significant differences in presence and tendencies for differences in virtual body ownership between the systems. Our results offer new insights into the relationships of body weight perception in different MR environments and provide new perspectives for the development of therapeutic applications. Index Terms: Human-centered computing-Human computer interaction (HCI)-Empirical studies in HCI; Human-centered computing-Human computer interaction (HCI)-Mixed / augmented reality; Human-centered computing-Human computer interaction (HCI)-Virtual reality.},
keywords={Avatars;Medical treatment;Estimation;Resists;Mirrors;Indexes;Augmented reality;Mixed reality;immersion;presence;embodiment;virtual body ownership;agency;body image;eating disorders},
doi={10.1109/ISMAR50242.2020.00071},
ISSN={1554-7868},
month={Nov},}
@INPROCEEDINGS{9356048,
author={Zhang, Huanle and Han, Bo and Ip, Cheuk Yiu and Mohapatra, Prasant},
booktitle={2020 IEEE 17th International Conference on Mobile Ad Hoc and Sensor Systems (MASS)}, title={Slimmer: Accelerating 3D Semantic Segmentation for Mobile Augmented Reality},
year={2020},
volume={},
number={},
pages={603-612},
abstract={Three-Dimensional (3D) semantic segmentation is an essential building block for interactive Augmented Reality (AR). However, existing Deep Neural Network (DNN) models for segmenting 3D objects are not only computation-intensive but also memory heavy, hindering their deployment on resource-constrained mobile devices. We present the design, implementation and evaluation of Slimmer, a generic and model-independent framework for accelerating 3D semantic segmentation and facilitating its real-time applications on mobile devices. In contrast to the current practice that directly feeds a point cloud to DNN models, Slimmer is motivated by our observation that these models remain high accuracy even if we remove a fraction of points from the input, which can significantly reduce the inference time and memory usage of these models. Our design of Slimmer faces two key challenges. First, the simplification method of point clouds should be lightweight. Otherwise, the reduced inference time may be canceled out by the incurred overhead of input-data simplification. Second, Slimmer still needs to accurately segment the removed points from the input to create a complete segmentation of the original input, again, using a lightweight method. Our extensive performance evaluation demonstrates that, by addressing these two challenges, Slimmer can dramatically reduce the resource utilization of a representative DNN model for 3D semantic segmentation. For example, if we can tolerate 1% accuracy loss, the reduction could be ~20% for inference time and ~9% for memory usage. The reduction increases to around ~27% for inference time and ~15% for memory usage when we can tolerate 2% accuracy loss.},
keywords={Solid modeling;Three-dimensional displays;Semantics;Mobile handsets;Space exploration;Acceleration;Augmented reality},
doi={10.1109/MASS50613.2020.00079},
ISSN={2155-6814},
month={Dec},}
@INPROCEEDINGS{9320872,
author={Mohamad, Ani Munirah and Salleh, Anis Shuhaiza Md and Nor, Mohd Zakhiri Md and Yusuff, Yusramizza Md Isa},
booktitle={2020 Seventh International Conference on Information Technology Trends (ITT)}, title={Impacts of Augmented Reality in Legal Studies: Students’ Reflections},
year={2020},
volume={},
number={},
pages={151-155},
abstract={The use of augmented reality (AR) in education is relatively new particularly for legal studies. Yet, its use and application may benefit students of law schools not only in helping them to be more interactive in the learning process, but also engaging them in a more experiential education whereby students' learning motivation can be improved. Scarcity of past research and literature on the application of AR in legal studies has led to this study to be carried out primarily to bridge the gaps in the existing literature. Based on the above premises, this article focuses on exploring the impacts of AR in the context of legal studies from the perspective of the students. By employing a pure qualitative methodology, this article engaged with a case study method, whereby one of the law schools of a higher learning institution in Malaysia has been chosen. Survey data from the Google Form was exported for the purpose of analysis in the computer-aided qualitative analysis software (CAQDAS) ATLAS.ti version 8.4. In order to make data ready for analysis, codes were built using a purely inductive approach. It was found that the application of AR has had a significant impact on students of law school particularly within the domains of active learning, unique learning and helpfulness for their studies. The implication for the study is better understanding of the impacts of AR in legal studies among law students. Hopefully, the paper would shed light into the body of literature of technological studies, AR and virtual reality, particularly within the context of higher education.},
keywords={Market research;Information technology;augmented reality;legal studies;reflections;ATLAS.ti;impact study},
doi={10.1109/ITT51279.2020.9320872},
ISSN={},
month={Nov},}
@INPROCEEDINGS{9320880,
author={Iwin Thanakumar Joseph, S and Raj, S Benson Edwin and Kiyasudeen, Jamal Mohamed},
booktitle={2020 Seventh International Conference on Information Technology Trends (ITT)}, title={Virtual Reality – A Paradigm shift in Education Pedagogy},
year={2020},
volume={},
number={},
pages={72-79},
abstract={Quality and Innovation in the current pedagogical system is the core research topics in recent years for upgrading the life of next generation smart kids. Virtual reality plays a major role in bringing new trends in the education system. The current trend in educational technologies mainly focused on electronic learning and mobile based learning approach to enhance the quality of education in terms of informative and interactive learning. Virtual reality has become predominant in most of the applications such as education, healthcare, training, entertainment and so on. This research article gives the overall view of the impact of virtual reality in pedagogical field, its present and future.},
keywords={Virtual reality;Education;Training;Market research;Information technology;Three-dimensional displays;Conferences;Virtual Reality;Augmented Reality;Education;Training;Mixed Reality},
doi={10.1109/ITT51279.2020.9320880},
ISSN={},
month={Nov},}
@INPROCEEDINGS{9142502,
author={Wang, Guangjun and Lu, Zhichao and Zhang, Yufei and Qian, Yu and Zhao, Haiying and Liu, Deyang},
booktitle={2020 IEEE 2nd International Conference on Computer Science and Educational Informatization (CSEI)}, title={Application of Mixed Reality Technology in Education with the case of a Huangmei Opera Cultural Education System},
year={2020},
volume={},
number={},
pages={301-305},
abstract={Mixed reality is an emerging technology that allows virtual world objects and real world objects to coexist and interact in real time. Its positioning lies between virtual reality and augmented reality, providing users with an immersive experience of combining virtual and real. In this article, we take the Huangmei Opera cultural educational system as an example, and use the current mainstream mixed reality hardware platform and its supporting content production softwares to implement interactive games and virtual museums about Huangmei Opera culture and knowledge. And to explore the application of mixed reality in education.},
keywords={Virtual reality;Cultural differences;Solid modeling;Spatial databases;Education;Three-dimensional displays;Mathematical model;Mixed Reality;Hololens;Huangmei opera;Unity;Virtual museum;Cultural Education},
doi={10.1109/CSEI50228.2020.9142502},
ISSN={},
month={June},}
@INPROCEEDINGS{9031145,
author={Dave, Akshay and Kang, Mirue and Hwang, Jihyun and Lorenzo, Mia and Oh, Paul},
booktitle={2020 10th Annual Computing and Communication Workshop and Conference (CCWC)}, title={Towards Smart Classroom: Affordable and Simple Approach to Dynamic Projection Mapping for Education},
year={2020},
volume={},
number={},
pages={0942-0947},
abstract={In order to transform the traditional classroom into an interactive space, we developed a projection mapping toolbox: an affordable, simple alternative to complex systems. Our system uses Python and Microsoft Kinect V2 for dynamic projection mapping (PM). We demonstrated three ways PM can be used to make Augmented Reality (AR) applications for classroom use. We projected free body diagrams onto boxes, made AR quiz tacking for teachers, and made an AR game. The goal of the projection mapping toolbox is to help students learn more efficiently and raise academic achievement.},
keywords={Cameras;Education;Transforms;Hardware;Sensors;Calibration;Mathematical model;education;smart classroom;dynamic projection mapping;augmented reality;marker tracking},
doi={10.1109/CCWC47524.2020.9031145},
ISSN={},
month={Jan},}
@INPROCEEDINGS{9213556,
author={Yantong, Guo and Bing, Xia and Xiaofeng, Xu},
booktitle={2020 IEEE International Conference on Advances in Electrical Engineering and Computer Applications( AEECA)}, title={Design Experiment of Spatial Dimension of Infographics in the Background of AR—Take the Beijing 2022 Winter Olympics as an Example},
year={2020},
volume={},
number={},
pages={939-942},
abstract={The intervention of augmented reality technology conforms to the development trend of infographic design. The cross-synergy of various design fields endows the rich media characteristics of infographic design, and provides the public with a blend of virtual and real information through a multi-level sensory experience. Context, forming an integrated, realtime and interactive infographic design. This article is devoted to the research on the expansion of the spatial dimension of the infographic design. In the infographic design of the Beijing 2022 Winter Olympics, based on the image recognition and LBS geographic location recognition technology, the spatial dimension expansion function of augmented reality technology in the infographic design is explored Relying on display devices such as handheld mobile terminals and HoloLens2, it realizes the functions of information transmission, route guidance and popular science education, and attempts to provide a more humanistic and artistic design display.},
keywords={Visualization;Augmented reality;Image recognition;Art;Games;Target recognition;Real-time systems;infographic design;AR;spatial dimension;rich media},
doi={10.1109/AEECA49918.2020.9213556},
ISSN={},
month={Aug},}
@INPROCEEDINGS{9259677,
author={Popa, Didi-Liliana and Mocanu, Mihai-Lucian and Popa, Radu-Teodoru and Bărbulescu, Lucian-Florentin and Bărbulescu, Linda Nicoleta and Ciobîrcă, Cătălin},
booktitle={2020 24th International Conference on System Theory, Control and Computing (ICSTCC)}, title={Augmented and mixed reality for collaborative cardiac planning using 3D and 4D medical imaging data},
year={2020},
volume={},
number={},
pages={384-389},
abstract={Heart problems are "number one public enemy" and fighting it means to use different weapons. A crucial moment is that of diagnosis heart ischemic conditions, which has to be sooner. Doctors can use multiple diagnostic modalities like 3D and 4D medical imaging data. Integrating medical images from different medical modalities is a difficult task. Vitrual reality has proven to be a choice for healthcare. Particularly, augmented reality is used for their advantages. We propose a method and a platform that can be used for treatment planning and simulation, education and patient awareness in cardiology, for collaborative cardiac planning, using 3D and 4D data like Cardiac 3D CT or 4D Echocardiography. This application can have a module for AR/mixed reality for communication with the glasses because this can also be important in the education and training of medical students, providing a close to reality virtual 3D environment.},
keywords={Medical services;Heart;Biomedical imaging;Three-dimensional displays;Medical diagnostic imaging;Surgery;Solid modeling;augmented reality;medical imaging;mixed reality;4d image},
doi={10.1109/ICSTCC50638.2020.9259677},
ISSN={2372-1618},
month={Oct},}
@INPROCEEDINGS{9233543,
author={Wang, Xiaofei and Chen, Chenfei and Li, Zhaotong},
booktitle={2020 IEEE International Conference on Mechatronics and Automation (ICMA)}, title={Augmented Reality and Quick Response Code Technology in Engineering Drawing Course},
year={2020},
volume={},
number={},
pages={1493-1498},
abstract={Augmented reality (AR) technology is a cutting technology. It can enhance the perception of reality and provide more information of the real world. AR technology is used in many fields, like medical, industry, and education. In this paper, AR is introduced into engineering drawing course. Engineering drawing course is difficult to learn as it is a knowledge that students rarely contact with. To have a close contact with the models and the views, a convenient AR application (AR app) is proposed in the paper. With the help of the AR app, virtual models and real views are combined well. The models can be moved and rotated by touching the screen. Some videos of model assembly and disassembly can be obtained when scanning the quick response code (QR code). Thus, it is convenient for students to use mobile phone to study engineering drawing effectively. The interactive teaching environment enhances students' spatial thinking and cultivates their sense of innovation.},
keywords={},
doi={10.1109/ICMA49215.2020.9233543},
ISSN={2152-744X},
month={Oct},}
@ARTICLE{8993789,
author={Desselle, Mathilde R. and Brown, Ross A. and James, Allan R. and Midwinter, Mark J. and Powell, Sean K. and Woodruff, Maria A.},
journal={Computing in Science Engineering}, title={Augmented and Virtual Reality in Surgery},
year={2020},
volume={22},
number={3},
pages={18-26},
abstract={Augmented and virtual reality are transforming the practice of healthcare by providing powerful and intuitive methods of exploring and interacting with digital medical data, as well as integrating data into the physical world to create natural and interactive virtual experiences. These immersive technologies use lightweight stereoscopic head-mounted displays to place users into simulated and realistic three-dimensional digital environments, unlocking significant benefits from the seamless integration of digital information with the healthcare practitioner and patient's experience. This review article explores some of the current and emerging technologies and applications in surgery, their benefits and challenges around immersion, spatial awareness and cognition, and their reported and projected use in learning environments, procedure planning and perioperative contexts and in the surgical theatre. The enhanced access to information, knowledge, and experience enabled by virtual and augmented reality will improve healthcare approaches and lead to better outcomes for patients and the wider community.},
keywords={Surgery;Training data;Three-dimensional displays;Virtual reality;Hospitals;Augmented reality;I.6.3 Applications < I.6 Simulation;Modeling;and Visualization < I Computing Methodologie;J.8.h Health care < J.8 Internet Applications < J Computer Applications;J.3.b Health < J.3 Life and Medical Sciences < J Computer Applications},
doi={10.1109/MCSE.2020.2972822},
ISSN={1558-366X},
month={May},}
@ARTICLE{8954779,
author={Czarnowski, Jan and Laidlow, Tristan and Clark, Ronald and Davison, Andrew J.},
journal={IEEE Robotics and Automation Letters}, title={DeepFactors: Real-Time Probabilistic Dense Monocular SLAM},
year={2020},
volume={5},
number={2},
pages={721-728},
abstract={The ability to estimate rich geometry and camera motion from monocular imagery is fundamental to future interactive robotics and augmented reality applications. Different approaches have been proposed that vary in scene geometry representation (sparse landmarks, dense maps), the consistency metric used for optimising the multi-view problem, and the use of learned priors. We present a SLAM system that unifies these methods in a probabilistic framework while still maintaining real-time performance. This is achieved through the use of a learned compact depth map representation and reformulating three different types of errors: photometric, reprojection and geometric, which we make use of within standard factor graph software. We evaluate our system on trajectory estimation and depth reconstruction on realworld sequences and present various examples of estimated dense geometry.},
keywords={Simultaneous localization and mapping;Cameras;Real-time systems;Image reconstruction;Geometry;Probabilistic logic;Optimization;Deep learning in robotics and automation;mapping;SLAM},
doi={10.1109/LRA.2020.2965415},
ISSN={2377-3766},
month={April},}
@ARTICLE{9050793,
author={Chiu, Po-Sheng and Chang, Jia-Wei and Lee, Ming-Che and Chen, Ching-Hui and Lee, Da-Sheng},
journal={IEEE Access}, title={Enabling Intelligent Environment by the Design of Emotionally Aware Virtual Assistant: A Case of Smart Campus},
year={2020},
volume={8},
number={},
pages={62032-62041},
abstract={With the advent of the 5G and Artificial Intelligence of Things (AIoT) era, related technologies such as the Internet of Things, big data analysis, cloud applications, and artificial intelligence have brought broad prospects to many application fields, such as smart homes, autonomous vehicles, smart cities, healthcare, and smart campus. At present, most university campus app is presented in the form of static web pages or app menus. This study mainly developed a Deep Neural Network (DNN) based emotionally aware campus virtual assistant. The main contributions of this research are: (1) This study introduces the Chinese Word Embedding to the robot dialogue system, effectively improving dialogue tolerance and semantic interpretation. (2) The traditional method of emotion identification must first tokenize the Chinese sentence, analyze the clauses and part of speech, and capture the emotional keywords before being interpreted by the expert system. Different from the traditional method, this study classifies the input directly through the convolutional neural network after the input sentence is converted into a spectrogram by Fourier Transform. (3) This study is presented in App mode, which is easier to use and economical. (4) This system provides a simple voice response interface, without the need for users to find information in complex web pages or app menus.},
keywords={Speech recognition;Mobile handsets;Deep learning;Emotion recognition;Neural networks;Education;Augmented reality;smart campus;convolutional neural network;recurrent neural network;emotional recognition;chinese word embedding},
doi={10.1109/ACCESS.2020.2984383},
ISSN={2169-3536},
month={},}
@ARTICLE{9090999,
author={Li, Liang and Qiao, Xiuquan and Lu, Qiong and Ren, Pei and Lin, Ruibin},
journal={IEEE Access}, title={Rendering Optimization for Mobile Web 3D Based on Animation Data Separation and On-Demand Loading},
year={2020},
volume={8},
number={},
pages={88474-88486},
abstract={Based on advances in image processing technology and Web-enabling technologies for mobile devices, mobile Augmented Reality (AR) and Virtual Reality (VR) has developed rapidly. The rendering and interaction of 3D models is an important part of AR and VR applications and is closely related to user experience. However, since the existing WebGL 3D JavaScript libraries for Web-based mobile 3D (represented by three.js and babylon.js) load the entire model file at once, large-size 3D models with complex interactions cannot be rendered smoothly due to limited data transmission, the weak computation capabilities of mobile Web browsers, and the latency of 3D model rendering. In this paper, we first propose model-animation data separation and an on-demand loading mechanism to improve the data request and loading process of Web 3D models. The main mechanisms are the following: (1) The model data are segmented into topological data and animation data sequences, and only the necessary data of the model are loaded when the Web-based mobile 3D model is first rendered. (2) The 3D model animation data sequence is semantically decomposed, and a multigranular model animation data service is established to provide continuous animation data support. (3) An asynchronous request-response mechanism is used to optimize the loading method of the model data. The model rendering mechanism uses an on-demand request and rendering method to transform the centralized loading process of the 3D model into a decentralized process. According to the testing and verification results, this optimization method can reduce the latency of mobile Web 3D in model data transmission and rendering by 24.72% for the experiment models. The interaction experience of Web-based mobile AR and VR is substantially improved relative to existing Web 3D rendering engines and rendering mechanisms, especially in complex interactive service scenarios.},
keywords={Three-dimensional displays;Load modeling;Solid modeling;Data models;Computational modeling;Rendering (computer graphics);Loading;Mobile Web 3D;rendering interactive computing;on-demand loading;interfacing data services;augmented reality;virtual reality},
doi={10.1109/ACCESS.2020.2993613},
ISSN={2169-3536},
month={},}
@INPROCEEDINGS{9304919,
author={Boutros, Fadi and Damer, Naser and Raja, Kiran and Ramachandra, Raghavendra and Kirchbuchner, Florian and Kuijper, Arjan},
booktitle={2020 IEEE International Joint Conference on Biometrics (IJCB)}, title={On Benchmarking Iris Recognition within a Head-mounted Display for AR/VR Applications},
year={2020},
volume={},
number={},
pages={1-10},
abstract={Augmented and virtual reality is being deployed in different fields of applications. Such applications might involve accessing or processing critical and sensitive information, which requires strict and continuous access control. Given that Head-Mounted Displays (HMD) developed for such applications commonly contains internal cameras for gaze tracking purposes, we evaluate the suitability of such setup for verifying the users through iris recognition. In this work, we first evaluate a set of iris recognition algorithms suitable for HMD devices by investigating three well-established handcrafted feature extraction approaches, and to complement it, we also present the analysis using four deep learning models. While taking into consideration the minimalistic hardware requirements of stand-alone HMD, we employ and adapt a recently developed miniature segmentation model (EyeMMS) for segmenting the iris. Further, to account for non-ideal and non-collaborative capture of iris, we define a new iris quality metric that we termed as Iris Mask Ratio (IMR) to quantify the iris recognition performance. Motivated by the performance of iris recognition, we also propose the continuous authentication of users in a non-collaborative capture setting in HMD. Through the experiments on a publicly available OpenEDS dataset, we show that performance with EER = 5% can be achieved using deep learning methods in a general setting, along with high accuracy for continuous user authentication.},
keywords={Iris recognition;Resists;Feature extraction;Image segmentation;Cameras;Pupils;Authentication},
doi={10.1109/IJCB48548.2020.9304919},
ISSN={2474-9699},
month={Sep.},}
@INPROCEEDINGS{9027491,
author={Maasthi, Manasvi J and Gururaj, HL and Janhavi, V and Harshitha, K and Swathi, B H},
booktitle={2020 International Conference on COMmunication Systems NETworkS (COMSNETS)}, title={An Interactive Approach Deployed for Rhinoplasty using Mixed Reality},
year={2020},
volume={},
number={},
pages={680-682},
abstract={Mixed reality is one of the trending technology. It provides an excellent platform to the users, as it includes good graphics and animations. Mixed reality provides many applications in gaming, education, healthcare etc. This domain, can be considered for medical purposes i.e., rhinoplasty, which is a surgical procedure used to correct the nose and other parts of the face [1]. Sometimes the result obtained after the surgery, is not convincing. This paper illustrates the method to overcome this problem by using Mixed Reality Toolkit(MRTK) over Unity gaming platform. Therefore the patient and the doctor can have discussion and edit according to the patient's convenience and further proceed to surgery.},
keywords={Surgery;Three-dimensional displays;Face;Augmented reality;Animation;Mixed Reality;Rhinoplasty;Mixed Reality Toolkit;Unity},
doi={10.1109/COMSNETS48256.2020.9027491},
ISSN={2155-2509},
month={Jan},}
@ARTICLE{8823985,
author={Asgary, Ali and Bonadonna, Costanza and Frischknecht, Corine},
journal={IEEE Transactions on Engineering Management}, title={Simulation and Visualization of Volcanic Phenomena Using Microsoft Hololens: Case of Vulcano Island (Italy)},
year={2020},
volume={67},
number={3},
pages={545-553},
abstract={This article describes an interactive holographic visualization of volcanic eruption application for Microsoft HoloLens device. The aim of the project is to use this technology to visualize different eruptive phenomena on an active volcano for public education, emergency training, preparedness planning purposes, and raising awareness among tourists. We have selected La Fossa volcano on Vulcano island (Italy) as a case study and, thus, the application is named HoloVulcano. Unity game engine and Microsoft Visual Studio were used to develop the HoloVulcano augmented/virtual reality visualization application. The current version of HoloVulcano visualizes volcanic phenomena typically associated with unrest (fumaroles) and explosive eruptions (e.g. eruptive plumes, ejection of ballistic blocks, bombs, and pyroclastic density currents). The eruption types are developed based on existing literature using Unity game engine's particle systems component. HoloVulcano is a Microsoft HoloLens device application. Wearing the HoloLens, users can interact with the application through voice, gazing, and gestures and view different volcanic phenomena from different sites and angles on the island. HoloVulcano can be used by emergency managers and teachers for training, emergency exercises, and public education.},
keywords={Visualization;Training;Volcanoes;Solid modeling;Explosions;Holovulcano;microsoft hololens;modeling and simulation;virtual reality (VR);visualization;volcanic phenomena;Vulcano island},
doi={10.1109/TEM.2019.2932291},
ISSN={1558-0040},
month={Aug},}
@INPROCEEDINGS{9284728,
author={Yakura, Hiromu and Goto, Masataka},
booktitle={2020 IEEE International Symposium on Mixed and Augmented Reality (ISMAR)}, title={Enhancing Participation Experience in VR Live Concerts by Improving Motions of Virtual Audience Avatars},
year={2020},
volume={},
number={},
pages={555-565},
abstract={While participating in live concerts is a promising application of virtual reality (VR), it falls short of our participation experience in the real world. In particular, to increase the engagement of participants, previous studies emphasized the importance of social experience among audience members, such as the sense of co-presence elicited by sharing physical reactions or body movements synchronized with music. In this respect, a common strategy in existing platforms is to present avatars of remote human participants in a VR venue and make every avatar imitate movements of the corresponding participant. However, this strategy implicitly assumes that a not small number of users connect simultaneously to watch the same content and thus is not applicable when only a few users gather or a user is watching alone. Therefore, with the aim of providing better experience to a user who participates in live concerts as one of the audience, we examine computational approaches to enhancing the sense of co-presence through virtual audience avatars. We propose four methods of presenting avatar movements: copying the user's own movements, copying other users' movements, repeating beat-synchronous movements, and synthesizing machine-learning-based movements. We compare their effectiveness in a user experiment and discuss application scenarios and design implications that open up new ways of active media consumption in VR environments.},
keywords={Art;Avatars;Immersive experience;Media;Synchronization;Human-centered computing;Human computer interaction (HCI);Interaction paradigms;Virtual reality; Human-centered computing;Human computer interaction (HCI);Interactive systems and tools;Applied computing;Arts and humanities;Performing arts},
doi={10.1109/ISMAR50242.2020.00083},
ISSN={1554-7868},
month={Nov},}
@INPROCEEDINGS{9212868,
author={Zhang, Yameng and Liu, Tong and Zhu, Yanmin and Yang, Yuanyuan},
booktitle={2020 IEEE/ACM 28th International Symposium on Quality of Service (IWQoS)}, title={A Deep Reinforcement Learning Approach for Online Computation Offloading in Mobile Edge Computing},
year={2020},
volume={},
number={},
pages={1-10},
abstract={With the explosion of mobile smart devices, many computation intensive applications have emerged, such as interactive gaming and augmented reality. Mobile edge computing is put forward, as an extension of cloud computing, to meet the low-latency requirements of the applications. In this paper, we consider an edge computing system built in an ultra-dense network with numerous base stations, and heterogeneous computation tasks are successively generated on a smart device moving in the network. An optimal task offloading strategy, as well as optimal CPU frequency and transmit power scheduling, is desired by the device user, to minimize both task completion latency and energy consumption in a long-term. However, due to the stochastic computation tasks and dynamic network conditions, the problem is particularly difficult to solve. Inspired by reinforcement learning, we transform the problem into a Markov decision process. Then, we propose an online offloading approach based on a double deep Q network, in which a specific neural network model is also provided to estimate the cumulative reward achieved by each action. We also conduct extensive simulations to compare the performance of our proposed approach with baselines.},
keywords={Task analysis;Edge computing;Energy consumption;Base stations;Servers;Computational modeling;Mobile edge computing;ultra-dense network;computation offloading;deep reinforcement learning},
doi={10.1109/IWQoS49365.2020.9212868},
ISSN={1548-615X},
month={June},}
@ARTICLE{8937822,
author={Shaker, Alfred and Lin, Xiangxu and Kim, Do Yeon and Kim, Jong-Hoon and Sharma, Gokarna and Devine, Mary Ann},
journal={Computing in Science Engineering}, title={Design of a Virtual Reality Tour System for People With Intellectual and Developmental Disabilities: A Case Study},
year={2020},
volume={22},
number={3},
pages={7-17},
abstract={This study focuses on VR as a form of therapy for individuals with intellectual and developmental disabilities (IDDs). The research aim is to develop an immersive and interactive VR system that is tailored for IDD individuals, for which most currently available VR experience systems are not optimized. Being intimately familiar with a place through an interactive VR tour will help alleviate social anxiety-very provident to IDD individuals. Accordingly, we create a hotspot-based VR tour system, which can provide an almost lifelike experience of visiting and learning about the location. We have conducted experiments with nondisabled individuals, acting as the control group, and IDD individuals, acting as the experimental group, to evaluate the tour system and compare the results between two groups. Our experiments show that the VR tour has a positive impact on the IDD individuals. In this article, we present the design of our VR tour system and its evaluation results.},
keywords={Virtual environments;Medical treatment;Task analysis;Autism;Testing;Virtual reality;Augmented reality},
doi={10.1109/MCSE.2019.2961352},
ISSN={1558-366X},
month={May},}
