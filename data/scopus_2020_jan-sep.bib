Scopus
EXPORT DATE: 1 October 2020

@ARTICLE{Sanderasagran2020559,
author={Sanderasagran, A.N. and Aziz, A.A. and Idris, D.M.N.D.},
title={Real-time computational fluid dynamics flow response visualisation and interaction application based on augmented reality},
journal={Journal of Information and Communication Technology},
year={2020},
volume={19},
number={4},
pages={559-581},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090223613&partnerID=40&md5=75f5d547ac56b3b00815ff8b62783dc0},
affiliation={Faculty of Mechanical and Automotive Engineering Technology, Universiti Malaysia, Pahang, Malaysia},
abstract={The behaviour of fluid flow is a complex paradigm for cognitive interpretation and visualisation. Engineers need to visualise the behaviour mechanics of flow field response in order to enhance the cognitive ability in problem solving. Therefore, mixed reality related technology is the solution for enhanced virtual interactive learning environment. However, there are limited augmented reality platforms on fluid flow interactive learning. Therefore, an interactive education application is proposed for students and engineers to interact and understand the complex flow behaviour pattern subjected to elementary geometry body relative to external flow. This paper presented the technical development of a real-time flow response visualisation augmented reality application for computational fluid dynamics application. It was developed with the assistance of several applications such as Unity, Vuforia, and Android. Particle system modules available in the Unity engine were used to create a two-dimensional flow stream domain. The flow visualisation and interaction were limited to two-dimensional and the numerical fluid continuum response was not analysed. The physical flow response pattern of three simple geometry bodies was validated against ANSYS simulated results based on visual empirical observation. The particle size and number of particles emitted were adjusted in order to emulate the physical representation of fluid flow. Colour contour was set to change according to fluid velocity. Visual validation indicated trivial dissimilarities between FLUENT generated results and flow response exhibited by the proposed augmented reality application. © 2020 Universiti Utara Malaysia Press.},
author_keywords={Augmented reality;  Computational fluid dynamics;  Image target;  Particle system;  Unity engine;  Vuforia},
document_type={Article},
source={Scopus},
}

@ARTICLE{Andras20202359,
author={Andras, I. and Mazzone, E. and van Leeuwen, F.W.B. and De Naeyer, G. and van Oosterom, M.N. and Beato, S. and Buckle, T. and O’Sullivan, S. and van Leeuwen, P.J. and Beulens, A. and Crisan, N. and D’Hondt, F. and Schatteman, P. and van Der Poel, H. and Dell’Oglio, P. and Mottrie, A.},
title={Artificial intelligence and robotics: a combination that is changing the operating room},
journal={World Journal of Urology},
year={2020},
volume={38},
number={10},
pages={2359-2366},
doi={10.1007/s00345-019-03037-6},
note={cited By 4},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076105418&doi=10.1007%2fs00345-019-03037-6&partnerID=40&md5=0357d4fe422ca1e5582f1fe4edb30841},
affiliation={ORSI Academy, Melle, Belgium; Department of Urology, Iuliu Hatieganu University of Medicine and Pharmacy, Cluj-Napoca, Romania; Department of Urology, Onze Lieve Vrouw Hospital, Aalst, Belgium; Department of Urology and Division of Experimental Oncology, URI, Urological Research Institute, IRCCS San Raffaele Scientific Institute, Milan, Italy; Interventional Molecular Imaging Laboratory, Department of Radiology, Leiden University Medical Centre, Leiden, Netherlands; Department of Urology, Antoni Van Leeuwenhoek Hospital, The Netherlands Cancer Institute, Amsterdam, Netherlands; Department of Pathology, Faculdade de Medicina, Universidade de São Paulo, São Paulo, Brazil; Department of Urology, Catharina Hospital, Eindhoven, Netherlands; Netherlands Institute for Health Services (NIVEL), Utrecht, Netherlands},
abstract={Purpose: The aim of the current narrative review was to summarize the available evidence in the literature on artificial intelligence (AI) methods that have been applied during robotic surgery. Methods: A narrative review of the literature was performed on MEDLINE/Pubmed and Scopus database on the topics of artificial intelligence, autonomous surgery, machine learning, robotic surgery, and surgical navigation, focusing on articles published between January 2015 and June 2019. All available evidences were analyzed and summarized herein after an interactive peer-review process of the panel. Literature review: The preliminary results of the implementation of AI in clinical setting are encouraging. By providing a readout of the full telemetry and a sophisticated viewing console, robot-assisted surgery can be used to study and refine the application of AI in surgical practice. Machine learning approaches strengthen the feedback regarding surgical skills acquisition, efficiency of the surgical process, surgical guidance and prediction of postoperative outcomes. Tension-sensors on the robotic arms and the integration of augmented reality methods can help enhance the surgical experience and monitor organ movements. Conclusions: The use of AI in robotic surgery is expected to have a significant impact on future surgical training as well as enhance the surgical experience during a procedure. Both aim to realize precision surgery and thus to increase the quality of the surgical care. Implementation of AI in master–slave robotic surgery may allow for the careful, step-by-step consideration of autonomous robotic surgery. © 2019, Springer-Verlag GmbH Germany, part of Springer Nature.},
author_keywords={Artificial intelligence;  Autonomous surgery;  Machine learning;  Robotic surgery;  Surgical navigation},
document_type={Review},
source={Scopus},
}

@ARTICLE{Trista20201518,
author={Trista, S. and Rusli, A.},
title={Historiar: Experience indonesian history through interactive game and augmented reality},
journal={Bulletin of Electrical Engineering and Informatics},
year={2020},
volume={9},
number={4},
pages={1518-1524},
doi={10.11591/eei.v9i4.1979},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085608326&doi=10.11591%2feei.v9i4.1979&partnerID=40&md5=8f54ff23af1671f6eb98deb1f61a5e62},
affiliation={Department of Informatics, Universitas Multimedia Nusantara, Indonesia},
abstract={History has a vital function in shaping the personality of the nation, the quality of humans, and the people of a country. However, one factor that influences learning behavior that could be improved is the students’ interest in learning. The use of game-based learning has been proven to be effective in making activities to be more fun to do. Moreover, augmented reality technology also shows enormous potential in the world of education. This research developed a game-based historical learning application using augmented reality to enhance user experience in learning history. The application is built using the Unity Game Engine and Vuforia. Furthermore, the application was tested and evaluated by measuring the perceived usefulness and perceived ease of use following the guidance in the Technology Acceptance Model. The result shows that the application achieves 89.5% for perceived usefulness and 86.33% for perceived ease of use. © 2020, Institute of Advanced Engineering and Science. All rights reserved.},
author_keywords={Augmented reality;  Behavioral intention to use;  Game-based learning;  Indonesian history;  User experience},
document_type={Article},
source={Scopus},
}

@ARTICLE{SerranoVergel2020337,
author={Serrano Vergel, R. and Morillo Tena, P. and Casas Yrurzum, S. and Cruz-Neira, C.},
title={A Comparative Evaluation of a Virtual Reality Table and a HoloLens-Based Augmented Reality System for Anatomy Training},
journal={IEEE Transactions on Human-Machine Systems},
year={2020},
volume={50},
number={4},
pages={337-348},
doi={10.1109/THMS.2020.2984746},
art_number={9106786},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088498153&doi=10.1109%2fTHMS.2020.2984746&partnerID=40&md5=d219de3fe6e55cc53862301036e972ff},
affiliation={Emerging Analytics Center, University of Arkansas at Little Rock, Little Rock, AR, United States; Institute on Robotics and Information and Communication Technologies, University of Valencia, València, Spain; Agere Chair in Computer Science, University of Central Florida, Orlando, FL, United States},
abstract={Anatomy training with real cadavers poses many practical problems for which new training and educational solutions have been developed making use of technologies based on real-time 3-D graphics. Although virtual reality (VR) and augmented reality (AR) have been previously used in the medical field, it is not easy to select the right 3-D technology or setup for each particular problem. For this reason, this article presents a comprehensive comparative study with 82 participants between two different 3-D interactive setups: an optical-based AR setup, implemented with a Microsoft HoloLens device, and a semi-immersive setup based on a VR Table. Both setups are tested using an anatomy training software application. Our primary hypothesis is that there would be statistically significant differences between the use of the AR application and the use of the VR Table. Our secondary hypothesis is that user preference and recommendation for the VR setup would be higher than for the HoloLens-based system. After completing two different tasks with both setups, the participants filled two questionnaires about the use of the anatomy training application. Three objective measures are also recorded (time, number of movements, and a score). The results of the experiments show that more than two-thirds of the users prefer, recommend, and find more useful the VR setup. The results also show that there are statistically significant differences in the use of both systems in favor of the VR Table. © 2013 IEEE.},
author_keywords={Anatomy;  augmented reality;  comparative study;  Microsoft HoloLens;  training;  virtual reality (VR);  VR table},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Yin2020,
author={Yin, X. and Hou, S. and Hu, H.},
title={Research on interactive design of social interaction training APP for children with autistic spectrum disorder (ASD) based on multi-modal interaction},
journal={E3S Web of Conferences},
year={2020},
volume={179},
doi={10.1051/e3sconf/202017902044},
art_number={02044},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089680937&doi=10.1051%2fe3sconf%2f202017902044&partnerID=40&md5=c21d8fb10d6588da020265ddd691124c},
affiliation={Harbin Institute of Techonology, Shenzhen, Shenzhen, China},
abstract={A number of studies have found that the difficulty in social interactive behaviors and recognize items are two core syndromes of Autistic Spectrum Disorder (ASD) children. Previous research has found that ASD children paid more attention to robots comparing to people.Intervention programs with robots as instructors or partners were also proved to be effective in improving ASD children's social skills.Yet, few studies find robot intervention works in ASD children training.So research explore the possibility of apply such intervention programs into product design.The present study aimed at involving an animated character of robot in an application (APP) of intervention program to facilitate ASD children's learning of social interactive skills.In order to achieve the goal, a training system based on sensory integration training was established by the design software of Sketch.Augmented Reality (AR) technology was used to create a multi-modal interactive environment of the APP.The present study is among the first attempt to apply sensory integration training in APP design, aiming at promoting social and cognitive performance in ASD children. © The Authors, published by EDP Sciences, 2020.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Rane2020254,
author={Rane, A. and John, V.N. and Murthy, S.},
title={GeoMaps: An interactive application to enhance map comprehension skills of students},
journal={Proceedings - IEEE 20th International Conference on Advanced Learning Technologies, ICALT 2020},
year={2020},
pages={254-258},
doi={10.1109/ICALT49669.2020.00083},
art_number={9156000},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091163811&doi=10.1109%2fICALT49669.2020.00083&partnerID=40&md5=a454c1202467776b70d3c3b36599ecf9},
affiliation={Iit Bombay, IDP-Educational Technology, Mumbai, India},
abstract={Geography education requires the use of spatial thinking and reasoning to understand and interpret maps. Effective usage of geographical maps is a crucial skill to be developed for students. However, it has been found that students' ability to use maps to describe and analyze natural phenomena to find solutions to geographical problems is inadequate. One reason for this shortcoming is difficulty in comprehension of maps given in textbooks or reference books, which is preliminarily due to inherent limitations with paper-based maps. Sophisticated technology-based map applications are available like interactive maps, Augmented reality-based maps, 3D view maps, etc. But there are few learning activities around these, leaving the students confused as to how these can be used in different contexts to solve problems. GeoMaps is an interactive application to improve map comprehension skills of students, which includes ability to identify, correlate and synthesize information from multiple perspectives in a map. The activities in GeoMaps are based on authentic geography problems. To solve these problems, students can overlay multiple maps to correlate various features, and choose corresponding filters to focus on particular information. The preliminary feedback from potential users is promising, encouraging us to explore this idea at a broader context. © 2020 IEEE.},
author_keywords={Component;  Geography;  Interactive Maps;  Map comprehension skills;  Maps;  Spatial skills},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{NoAuthor2020,
title={Proceedings - IEEE 20th International Conference on Advanced Learning Technologies, ICALT 2020},
journal={Proceedings - IEEE 20th International Conference on Advanced Learning Technologies, ICALT 2020},
year={2020},
page_count={412},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091186939&partnerID=40&md5=980609282f00dcf34cf7ec02c8ccba55},
abstract={The proceedings contain 118 papers. The topics discussed include: Hindi-CNL coder - a desktop application for learning programming using native controlled natural language; improving the readability of dyslexic learners with mobile game-based sight-word training; development of computational thinking education system for elementary school class; assessing the impact of controllable open learner models on student engagement; four steps towards implementing citizen science approach in school; augmented reality-based application to foster sustainable agriculture in the context of aquaponics; XMDD as key enabling technology for integration of large scale elearning based on NRENs; the relationship between self-regulation and flow experience in online learning: a case study of global competition on design for future education; individual versus computer-supported collaborative self-explanations: how do their writing analytics differ?; and a digital reality theater with the mechanisms of real-time spoken language evaluation and interactive switching of scenario & virtual costumes: effects on motivation and learning performance.},
document_type={Conference Review},
source={Scopus},
}

@ARTICLE{Al-Imamy20202561,
author={Al-Imamy, S.Y.},
title={Blending printed texts with digital resources through augmented reality interaction},
journal={Education and Information Technologies},
year={2020},
volume={25},
number={4},
pages={2561-2576},
doi={10.1007/s10639-019-10070-w},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076529699&doi=10.1007%2fs10639-019-10070-w&partnerID=40&md5=5c25ce078549e62cd02fde8290455305},
affiliation={MIS Department, Prince Mohammad Bin Fahd University, Half Moon Bay/Al Khobar, Saudi Arabia},
abstract={Traditional printed textbooks represented a static medium of knowledge transfer for many years. The advent of technology introduced several digital material encouraged the educational institution to plan for the transfer to e-book and other related digital media. Both printed and digital materials have their own advantages and disadvantages as explained in the literature review. This work introduces a way to blend both through the augmentation of printed textbook with interactive entries to the digital media. The well planned entries guide the learners into the digital world that is recommended by the expert educators. The learners, however, still have the freedom to select and repeat the material they like to study according to their own learning style. An application was developed and used by a group of students to evaluate the print/digital blending concept. The quantitative measurements proved an increase in the interest, confidence and perceived performance of the learners using proved easy to use useful application. Making the application available to the learners of different disciplines through simple user interface was also recommended as one of the possible future works. © 2019, Springer Science+Business Media, LLC, part of Springer Nature.},
author_keywords={Audio-visual resources;  Augmented reality;  Blended learning;  Computer-assisted learning;  Interactive pedagogy;  Resource based learning},
document_type={Article},
source={Scopus},
}

@ARTICLE{Tamayo202040,
author={Tamayo, J.L.R. and Hernández, M.B. and Gómez, H.G.},
title={Digital data visualization with interactive and virtual reality tools. Review of current state of the art and proposal of a model [Visualización de datos con herramientas interactivas y de realidad virtual. Revisión del estado actual y propuesta de modelo]},
journal={Icono14},
year={2020},
volume={16},
number={2},
pages={40-65},
doi={10.7195/RI14.V16I2.1174},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085893385&doi=10.7195%2fRI14.V16I2.1174&partnerID=40&md5=6f19bba46241f5af4ee4930a1b113af9},
affiliation={Department of Communication Sciences and Sociology, Universidad Rey Juan Carlos - URJC, Spain; Universidad Nacional Autónoma de México - UNAM, Mexico; Universidad Abierta y Educación a Distancia, Mexico; Communication Department, Universidad Europea de Madrid - UEM, Spain},
abstract={Massive and open data constitute a burgeoning field of study in the current context. The evolution of technology is, in turn, increasing its degree of interactivity, configuring several scenarios of great complexity in which data is understood on the basis of our interaction with it at different levels. Technologies such as virtual reality or augmented reality present an emerging framework for visualizing, representing and understanding information. Moreover, new disciplines such as interaction design, human-computer interaction, and user experience are needed to optimally configure the representation and design of data interaction dynamics, so that they can be implemented in contexts such as education. This paper reviews the current state of interactive and immersive technology (including virtual reality and alternative reality games) and of open and massive data, to highlight potential projections and propose models of data representation based on factors such as storytelling or user experience. This paper shows the need to develop models for data use and representation in fields such as education and citizen empowerment. © 2020 Scientific Association Icono14. All rights reserved.},
author_keywords={Data science;  Data visualization;  Educational applications;  Human-computer interaction;  Interaction design;  Open access to data},
document_type={Article},
source={Scopus},
}

@ARTICLE{Alhakamy2020,
author={Alhakamy, A. and Tuceryan, M.},
title={Real-time Illumination and Visual Coherence for Photorealistic Augmented/Mixed Reality},
journal={ACM Computing Surveys},
year={2020},
volume={53},
number={3},
doi={10.1145/3386496},
art_number={49},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089433328&doi=10.1145%2f3386496&partnerID=40&md5=6607e05c055864fa2f857060c6d4083a},
affiliation={Indiana University-Purdue University Indianapolis, Department of Computer and Information Science, 723 W. Michigan St, Indianapolis, IN  SL280, United States},
abstract={A realistically inserted virtual object in the real-time physical environment is a desirable feature in augmented reality (AR) applications and mixed reality (MR) in general. This problem is considered a vital research area in computer graphics, a field that is experiencing ongoing discovery. The algorithms and methods used to obtain dynamic and real-time illumination measurement, estimating, and rendering of augmented reality scenes are utilized in many applications to achieve a realistic perception by humans. We cannot deny the powerful impact of the continuous development of computer vision and machine learning techniques accompanied by the original computer graphics and image processing methods to provide a significant range of novel AR/MR techniques. These techniques include methods for light source acquisition through image-based lighting or sampling, registering and estimating the lighting conditions, and composition of global illumination. In this review, we discussed the pipeline stages with the details elaborated about the methods and techniques that contributed to the development of providing a photo-realistic rendering, visual coherence, and interactive real-time illumination results in AR/MR. © 2020 ACM.},
author_keywords={and shading;  Augmented reality;  illumination;  image-based lighting;  lighting condition;  mixed reality;  photo-realistic;  real time;  reflectance;  visual coherence},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Dewi2020,
author={Dewi, S.P. and Astuti, I.P. and Buntoro, G.A. and Widaningrum, I. and Yusuf, A.R.},
title={Android based learning application for Wudhu and Tayamum using augmented reality technology},
journal={Journal of Physics: Conference Series},
year={2020},
volume={1517},
number={1},
doi={10.1088/1742-6596/1517/1/012068},
art_number={012068},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086392254&doi=10.1088%2f1742-6596%2f1517%2f1%2f012068&partnerID=40&md5=01e2b608ad58fdf665693df2f7248f3c},
affiliation={Department of Informatics Engineering, Universitas Muhammadiyah Ponorogo, Ponorogo, Indonesia},
abstract={Nowadays, wudhu and tayamum are widely found in various media such as books, articles, tutorial videos and internet. Muslims who are new to Islam as children often have difficulty reading books to understand how to learn and practice tayamum, one of the lessons learned in technology development using Augmented Reality based learning. The learning method used in Augmented Reality is the marker method. The marker method step is that the program will read an object from the image marker, the marker uses a downloadable image by clicking the Download Marker button in the main menu, and then it will be displayed as a moving object or an output in the data. This app is implemented for Android-based smartphones, with the help of Blender 3D and Unity 3D software. The results of the questionnaire count conclude that augmented reality learning media applications are easy to use, practical, useful, and effective in supporting children's learning activities as children become more engaged in learning. The attractive interface design makes kids feel comfortable and engaging as they use it and develop their understanding. In addition, this application is also used as an interactive learning medium. © 2019 Published under licence by IOP Publishing Ltd.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Elivera2020,
author={Elivera, A. and Palaoag, T.},
title={Development of an Augmented Reality Mobile Application to Enhance the Pedagogical Approach in Teaching History},
journal={IOP Conference Series: Materials Science and Engineering},
year={2020},
volume={803},
number={1},
doi={10.1088/1757-899X/803/1/012014},
art_number={012014},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086383743&doi=10.1088%2f1757-899X%2f803%2f1%2f012014&partnerID=40&md5=b0ddbee3bcae1cedce2db79ab78a835c},
affiliation={Eastern Samar State University, Guiuan, Eastern Samar, Philippines; University of the Cordilleras, Baguio City, Philippines},
abstract={The rapid advancement of technology nowadays opens new opportunities for schools and universities worldwide to improve the quality of teaching and learning experience using Augmented Reality can help make classes more interactive and allow learners to focus more on practice instead of just theories. The researcher identified the problem that pedagogy has not been learner-cantered in most approaches in teaching and that teachers need to adapt to the new method of teaching. The goal of the study is to develop an Augmented Reality (AR) mobile application to enhance the pedagogical approach in teaching. This will use a marker-based method for transmitting virtual objects into the realworld. Blippar was used in the development of AR. This resulted in the form of instructional material and technology that can be used in teaching. During the testing of the material Students' interest was aroused and it even makes them more eager to learn the subject. End-users and experts also deem that the AR mobile application as usable and acceptable with a rating of 78% using the System Usability Scale (SUS). This is an excellent contribution to the educational domain through augmented reality and improving the pedagogical approach in teaching. © Published under licence by IOP Publishing Ltd.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Kenoui2020260,
author={Kenoui, M. and Mehdi, M.A.},
title={Teach-Me DNA: An interactive course using voice output in an augmented reality system},
journal={CCSSP 2020 - 1st International Conference on Communications, Control Systems and Signal Processing},
year={2020},
pages={260-265},
doi={10.1109/CCSSP49278.2020.9151605},
art_number={9151605},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089956397&doi=10.1109%2fCCSSP49278.2020.9151605&partnerID=40&md5=520a5e58e0a8d68ab762db46e27e2306},
affiliation={CDTA Centre de Développement des Technologies Avancées, Telecom Department, Algiers, Algeria; USTHB Université des Sciences et de la Technologie, Informatics Department, Algiers, Algeria},
abstract={In this paper, we present an interactive system partly based on voice output in an augmented reality environment. Using a chatbot technology, this system allows the user to engage bidirectional communication with a conversational agent. The present system builds upon our previous work in which the user interacts with 3D virtual objects via voice commands. We describe, in the current document, how we integrate speech output using the Text to Speech Service (TTS API) available on the IBM Watson platform, the goal being to obtain an even more interactive system. We also employ Speech Synthesis Markup Language (SSML) to control some features of the natural-sounding speech thus produced. Moreover, we developed Teach-Me DNA, an interactive application that gives the user (pupil, student) the opportunity to learn and/or revise the DNA molecule's basics as a part of a biological course. On one hand, and via voice inputs the user is simply able to perform 3D selections and 3D manipulations of the molecule and its several components in order to learn about their 3D features and properties, this first part dealing with the vocal entries was fully documented in a previous work. On another hand, TeachMe DNA is here enriched by producing a natural speech when reacting to the user's requests. In fact, an agent's voice is used to respond in real time to student's questions. Definitions and/or explanations are thus given in a very natural way which might immerse more significantly the student in the proposed learning environment based on augmented reality technology. © 2020 IEEE.},
author_keywords={Augmented Reality;  Biomedical Course;  Chatbot;  Cloud Application;  Education;  HCI;  IBM Watson;  Natural Interaction;  Pedagogical Agent;  Speech Recognition;  Voice Output},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{López-Faican2020,
author={López-Faican, L. and Jaen, J.},
title={EmoFindAR: Evaluation of a mobile multiplayer augmented reality game for primary school children},
journal={Computers and Education},
year={2020},
volume={149},
doi={10.1016/j.compedu.2020.103814},
art_number={103814},
note={cited By 5},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078496692&doi=10.1016%2fj.compedu.2020.103814&partnerID=40&md5=6ed1ea02efd292c93e97c271e10fd204},
affiliation={Universidad Nacional de Loja, Ecuador; Grupo ISSI, Universitat Politècnica de Valencia, Spain},
abstract={Games are powerful generators of positive emotions in children and are intrinsically satisfying. In this context, our work evaluates the use of mobile augmented reality without markers as the technology to implement a multiplayer game scenario that can be used to improve socialization, communication skills and emotional intelligence in primary school children. The present study addresses the usability of two gameplay styles and their impact on users' communication and motivation: competitive vs collaborative play. The game integrates Mobile Augmented Reality (MAR) technology without markers to create a geolocation scenario with unlimited physical space. The results indicate that both game modes are intrinsically satisfactory for children triggering positive emotions such as enthusiasm, enjoyment and curiosity that improve the participants’ mood and help increase the degree of involvement. Moreover, we observed that the collaborative game version has a greater impact on emotional affection, social interaction and interest. In addition, we observed in our study that the quality of the communication in the collaborative mode is good in terms of several factors such as sustaining mutual understanding, dialogue management, information pooling, reaching consensus, time management and reciprocal interaction. Finally, several design implications and suggestions related to game time management, scaffolding, mixed competitive-collaborative modes, dynamic 3D content and active learning, among others, are discussed. The present evaluation contributes to the identification of the most relevant aspects to be considered in the future design of MAR-based gamification strategies in education. © 2020 Elsevier Ltd},
author_keywords={Architectures for educational technology system;  Augmented and virtual reality;  Cooperative/collaborative learning;  Games;  Mobile learning},
document_type={Article},
source={Scopus},
}

@ARTICLE{Desselle202018,
author={Desselle, M.R. and Brown, R.A. and James, A.R. and Midwinter, M.J. and Powell, S.K. and Woodruff, M.A.},
title={Augmented and Virtual Reality in Surgery},
journal={Computing in Science and Engineering},
year={2020},
volume={22},
number={3},
pages={18-26},
doi={10.1109/MCSE.2020.2972822},
art_number={8993789},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079661155&doi=10.1109%2fMCSE.2020.2972822&partnerID=40&md5=9d285b601a0890d2117ff2fc568797fb},
affiliation={Metro North Hospital and Health Service, Australia; Queensland University of Technology, Australia; University of Queensland, Australia},
abstract={Augmented and virtual reality are transforming the practice of healthcare by providing powerful and intuitive methods of exploring and interacting with digital medical data, as well as integrating data into the physical world to create natural and interactive virtual experiences. These immersive technologies use lightweight stereoscopic head-mounted displays to place users into simulated and realistic three-dimensional digital environments, unlocking significant benefits from the seamless integration of digital information with the healthcare practitioner and patient's experience. This review article explores some of the current and emerging technologies and applications in surgery, their benefits and challenges around immersion, spatial awareness and cognition, and their reported and projected use in learning environments, procedure planning and perioperative contexts and in the surgical theatre. The enhanced access to information, knowledge, and experience enabled by virtual and augmented reality will improve healthcare approaches and lead to better outcomes for patients and the wider community. © 1999-2011 IEEE.},
author_keywords={and Visualization < I Computing Methodologie;  I.6.3 Applications < I.6 Simulation;  J.3.b Health < J.3 Life and Medical Sciences < J Computer Applications;  J.8.h Health care < J.8 Internet Applications < J Computer Applications;  Modeling},
document_type={Article},
source={Scopus},
}

@ARTICLE{Ghani202012319,
author={Ghani, D.B.A. and Abd Samad, Z.I.B. and Ismail, A.H.B.},
title={Using augmented reality image computing on human anatomy},
journal={Test Engineering and Management},
year={2020},
volume={83},
pages={12319-12327},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083672353&partnerID=40&md5=a2f5286acb4a729bb3d0b91d5dfd3a1f},
affiliation={Creative Multimedia, Universiti Kuala Lumpur, Malaysian Institute Information Technology, 1016, Menara Bandar Wawasan, Jalan Sultan Ismail, 53000, Malaysia},
abstract={Augmented reality or (AR) is a live, direct or indirect, view of a physical, real-world environment which elements are augmented by computer-generated sensory input or immersed with graphics and sound. Today medical students have difficulty to understand in detail the concepts and functionality of organs related to human biology studies. Therefore, this research will focus on the development of a learning method which uses Augmented Reality for human anatomy studies. It will focus on the 6 main human organs in human science, using camera, marker (booklet) and software application. We hope that this research will enhance the 3D Human Anatomy model directly with the support of visualization and interactive manipulation. Besides that, this AR application also aims to assist young medical students and doctors to understand the complex human anatomy structure easily compared to using traditional methods.. © 2020 Mattingley Publishing. All rights reserved.},
author_keywords={Anatomy;  Augmented Reality (AR);  Human;  Immersed;  Marker},
document_type={Article},
source={Scopus},
}

@ARTICLE{Czarnowski2020721,
author={Czarnowski, J. and Laidlow, T. and Clark, R. and Davison, A.J.},
title={DeepFactors: Real-Time Probabilistic Dense Monocular SLAM},
journal={IEEE Robotics and Automation Letters},
year={2020},
volume={5},
number={2},
pages={721-728},
doi={10.1109/LRA.2020.2965415},
art_number={8954779},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078536456&doi=10.1109%2fLRA.2020.2965415&partnerID=40&md5=cbceb1fc470ff0c2cdae6a1e62407117},
affiliation={Dyson Robotics Laboratory, Imperial College London, London, SW7 2AZ, United Kingdom},
abstract={The ability to estimate rich geometry and camera motion from monocular imagery is fundamental to future interactive robotics and augmented reality applications. Different approaches have been proposed that vary in scene geometry representation (sparse landmarks, dense maps), the consistency metric used for optimising the multi-view problem, and the use of learned priors. We present a SLAM system that unifies these methods in a probabilistic framework while still maintaining real-time performance. This is achieved through the use of a learned compact depth map representation and reformulating three different types of errors: photometric, reprojection and geometric, which we make use of within standard factor graph software. We evaluate our system on trajectory estimation and depth reconstruction on real-world sequences and present various examples of estimated dense geometry. © 2016 IEEE.},
author_keywords={Deep learning in robotics and automation;  mapping;  SLAM},
document_type={Article},
source={Scopus},
}

@ARTICLE{Cen2020283,
author={Cen, L. and Ruta, D. and Al Qassem, L.M.M.S. and Ng, J.},
title={Augmented Immersive Reality (AIR) for Improved Learning Performance: A Quantitative Evaluation},
journal={IEEE Transactions on Learning Technologies},
year={2020},
volume={13},
number={2},
pages={283-296},
doi={10.1109/TLT.2019.2937525},
art_number={8812921},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071536186&doi=10.1109%2fTLT.2019.2937525&partnerID=40&md5=3080c63161b59bbf3e10f094e40950bb},
affiliation={EBTIC, Khalifa University, Abu Dhabi, 127788, United Arab Emirates},
abstract={Technology-enhanced learning has attracted increasing attention of educational community focused on improvement of traditional classroom learning. Augmented immersive reality (AIR) technologies enhance users' perception of reality by augmenting it with computer-generated components such as audio, video, 2/3-D graphics, GPS data, etc. The AIR introduces new dimensions of learning experience that ensure better attention, focus, and entertainment, thereby boosting students' motivation and attainment. This work presents an award winning AIR-based educational mobile system, code-named AIR-EDUTECH, that was developed to help high school students learn chemistry. The AIR-EDUTECH introduced new AIR features to help students better understand and learn basic concepts of molecular chemistry. It offers immersive 3D visualization and visual interaction with the examined structures that provides a broader and more retentive knowledge and improves intuition around forming basic chemical reactions. The system was introduced and tested in a field study with 45 students in the $11^{th}$ grade chemistry class, and its impact was evaluated by the formal assessment quiz along with the feedback from survey conducted after the trial. Collected data have been subjected to an in-depth multi-modal quantitative analysis that revealed that AIR-EDUTECH stimulated significant improvements in understanding and retention of the taught content as well as turned learning chemistry into a fun, interesting and interactive experience. It also uncovered a hidden structure of taught knowledge dependencies and highlighted the role that AIR technology could play in reinforcing the retention of critical knowledge that may otherwise widen student knowledge gaps. © 2008-2011 IEEE.},
author_keywords={AIR-EDUTECH;  Augmented Immersive Reality (AIR);  Augmented Reality (AR);  education data mining.;  Mobile learning},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Harrington2020813,
author={Harrington, M.C.R.},
title={Observation of Presence in an Ecologically Valid Ethnographic Study Using an Immersive Augmented Reality Virtual Diorama Application},
journal={Proceedings - 2020 IEEE Conference on Virtual Reality and 3D User Interfaces, VRW 2020},
year={2020},
pages={813-814},
doi={10.1109/VRW50115.2020.00257},
art_number={9090465},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085396895&doi=10.1109%2fVRW50115.2020.00257&partnerID=40&md5=8eb7e5a7bf83c68062e97436884d1b4e},
affiliation={University of CentralFL, United States},
abstract={The main research question is centered on the usefulness of immersive Augmented Reality (AR) applications for informal learning activities. Can users experience presence - or a sense of being there - when using AR apps? To begin to approach this question an ethnographic study was conducted in July, 2019 in a museum with 56 volunteer participants to document behavior and measure learning, attitudes, and emotional outcomes of an AR application. Reported are the preliminary results of behavior indicative of presence observed in the study, and insights gained that are useful in understanding future designs. © 2020 IEEE.},
author_keywords={Augmented reality;  bioacoustics;  data visualization;  embodiment;  immersive;  informal learning;  interactive;  multimodal;  museums;  presence},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Jakl2020195,
author={Jakl, A. and Lienhart, A.-M. and Baumann, C. and Jalaeefar, A. and Schlager, A. and Schoffer, L. and Bruckner, F.},
title={Enlightening Patients with Augmented Reality},
journal={Proceedings - 2020 IEEE Conference on Virtual Reality and 3D User Interfaces, VR 2020},
year={2020},
pages={195-203},
doi={10.1109/VR46266.2020.1581532258804},
art_number={9089476},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085526448&doi=10.1109%2fVR46266.2020.1581532258804&partnerID=40&md5=4538f04908530fbf0229b5588000429e},
affiliation={University of Applied Sciences, Institute of Creative\Media/Technologies, St. Pölten, Austria},
abstract={Enlightening Patients with Augmented Reality (EPAR) enhances patient education with new possibilities offered by Augmented Reality. Medical procedures are becoming increasingly complex and printed information sheets are often hard to understand for patients. EPAR developed an augmented reality prototype that helps patients with strabismus to better understand the processes of examinations and eye surgeries. By means of interactive storytelling, three identified target groups based on user personas were able to adjust the level of information transfer based on their interests. We performed a 2-phase evaluation with a total of 24 test subjects, resulting in a final system usability score of 80.0. For interaction prompts concerning virtual 3D content, visual highlights were considered to be sufficient. Overall, participants thought that an AR system as a complementary tool could lead to a better understanding of medical procedures. © 2020 IEEE.},
author_keywords={concepts and paradigms Human-centered computing;  Human-centered computing;  Interaction design theory;  Interface design prototyping Human-centered computing;  Mixed / augmented reality Human-centered computing;  Usability testing},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Pittman2020761,
author={Pittman, C. and Jr, J.J.L.},
title={PhyAR: Determining the Utility of Augmented Reality for Physics Education in the Classroom},
journal={Proceedings - 2020 IEEE Conference on Virtual Reality and 3D User Interfaces, VRW 2020},
year={2020},
pages={761-762},
doi={10.1109/VRW50115.2020.00231},
art_number={9090480},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085374933&doi=10.1109%2fVRW50115.2020.00231&partnerID=40&md5=c4bf63e74da8fbfbda92b79c2d379f89},
affiliation={University of Central Florida, Orlando, FL, United States},
abstract={Physics is frequently cited as a difficult roadblock and hindrance to retention in STEM majors. In this paper, we present the results of a study exploring the potential utility and use cases of augmented reality in secondary and post secondary physics courses. To gather meaningful information, we developed PhyAR, prototype physics education application in augmented reality. We collected feedback and opinions from a qualitative study of university students with STEM backgrounds. Our findings point towards a clear desire to see the use of more interactive 3D AR content in physics courses. © 2020 IEEE.},
author_keywords={Augmented Reality;  Physics Education;  Qualitative Interview},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Perez-Munoz2020,
author={Perez-Munoz, A. and Castro-Idrovo, D. and Robles-Bykbaev, Y. and Robles-Bykbaev, V. and Pesantez-Aviles, F.},
title={An interactive application based on augmented reality and rules-based reasoning to support educational activities of high school students},
journal={EDUNINE 2020 - 4th IEEE World Engineering Education Conference: The Challenges of Education in Engineering, Computing and Technology without Exclusions: Innovation in the Era of the Industrial Revolution 4.0, Proceedings},
year={2020},
doi={10.1109/EDUNINE48860.2020.9149526},
art_number={9149526},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091074010&doi=10.1109%2fEDUNINE48860.2020.9149526&partnerID=40&md5=9cc04e86b97c6b75281e85815ef3f122},
affiliation={Universidad Politécnica Salesiana, GI-IATa, Cátedra UNESCO Tecnologías de Apoyo Para la Inclusión Educativa, Cuenca, Ecuador},
abstract={According to the latest estimates of the United Nations Educational, Scientific and Cultural Organization (UNESCO), in 2017, more than 617 million children and adolescents were not achieving minimum proficiency levels regarding reading and mathematics. In this line, it is essential for children and youth developing mainstays for solving problems and adequately understanding the information around them. These mainstays are strongly related to logical and mathematical skills. Therefore, in this paper, we present an educational tool that uses augmented reality to provide interactive exercises for the following areas: functions, areas, volumes, angles, and the Pythagorean theorem. Similarly, our proposal incorporates a decision support system that suggests to a given student what activities and exercises must solve. The validation process of the tools was carried out with the support of 179 volunteers. © 2020 IEEE.},
author_keywords={Augmented reality;  Children and youth;  Mathematics;  Support Decision System},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Ibáñez2020,
author={Ibáñez, M.B. and Uriarte Portillo, A. and Zatarain Cabada, R. and Barrón, M.L.},
title={Impact of augmented reality technology on academic achievement and motivation of students from public and private Mexican schools. A case study in a middle-school geometry course},
journal={Computers and Education},
year={2020},
volume={145},
doi={10.1016/j.compedu.2019.103734},
art_number={103734},
note={cited By 7},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073815705&doi=10.1016%2fj.compedu.2019.103734&partnerID=40&md5=7a6603962debb3c9ba0162ffad1b0996},
affiliation={Departamento de Ingeniería Telemática, Universidad Carlos III de Madrid, Madrid, Spain; Tecnológico Nacional de México, Instituto Tecnológico de Culiacán, Culiacán, Mexico},
abstract={In this paper, the authors show that augmented reality technology has a positive impact on learning-related outcomes of middle-school Mexican students. However, the impact varies depending on whether students were enrolled in public or private schools. The authors designed an augmented reality application for students to practice the basic principles of geometry, and a similar application which encompasses identical learning objectives and content deployed in a Web-based learning environment. A 2 × 2 × 2 factorial design was employed with 93 participants to investigate the effect of type of technology (web, augmented reality), type of school (private, public), and time of assessment (pre, post) on motivation, and declarative learning. The results show that: (1) there is an interactive effect of type of technology, type of school, and time of assessment when students' achievement scores are measured; (2) students using the augmented reality-based learning environments scored higher in post-test than those using the web-based application; (3) the augmented reality learning environment was more learning effective compared with the web-based learning environment in public schools, but not in private schools; (4) there is not an interactive effect of type of technology, type of school and time of assessment when students' motivation is measured; (5) students from private schools reported higher levels of motivation compared with those from public schools when using the augmented reality learning environment. The research findings imply that in Mexico, augmented reality technology can be exploited as an effective learning environment for helping middle-school students from public and private schools to practice the basic principles of Geometry. © 2019 Elsevier Ltd},
author_keywords={Applications in subject areas;  Augmented reality;  Interactive learning environments;  Motivation},
document_type={Article},
source={Scopus},
}

@ARTICLE{Lam2020351,
author={Lam, M.C. and Tee, H.K. and Muhammad Nizam, S.S. and Hashim, N.C. and Suwadi, N.A. and Tan, S.Y. and Abd Majid, N.A. and Arshad, H. and Liew, S.Y.},
title={Interactive augmented reality with natural action for chemistry experiment learning},
journal={TEM Journal},
year={2020},
volume={9},
number={1},
pages={351-360},
doi={10.18421/TEM91-48},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086515282&doi=10.18421%2fTEM91-48&partnerID=40&md5=2dd8a5e15160302a72ece95b28c1c52c},
affiliation={Mixed Reality and Pervasive Computing Lab, Center for Artificial Intelligence Technology, Faculty of Information Science and Technology, Universiti Kebangsaan Malaysia, Bangi, 43600, Malaysia; Chemistry Division, Centre for Foundation Studies in Science, University of Malaya, Kuala Lumpur, 50603, Malaysia},
abstract={Conventionally, the interaction between a user and augmented reality (AR) application is limited. Mostly, it allows virtual information browsing on the AR marker or basic manipulation such as moving and resizing of the 3D model. This study presents a rich interaction that allows users to mimic physical action such as shaking and pouring in chemistry experiment using card-based or box-based marker design. The user is required to follow the instruction to select the correct AR marker that represents apparatus or solutions and performs the physical action to conduct an experiment. Usability's result showed the respondents were satisfied with the application. © 2020 Meng Chun Lam at al.},
author_keywords={Educational augmented reality;  Human-computer interaction;  Interactive augmented reality;  Tangible augmented reality},
document_type={Article},
source={Scopus},
}

@ARTICLE{CheDalim202044,
author={Che Dalim, C.S. and Sunar, M.S. and Dey, A. and Billinghurst, M.},
title={Using augmented reality with speech input for non-native children's language learning},
journal={International Journal of Human Computer Studies},
year={2020},
volume={134},
pages={44-64},
doi={10.1016/j.ijhcs.2019.10.002},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074369569&doi=10.1016%2fj.ijhcs.2019.10.002&partnerID=40&md5=7c91f641b7113338dde92f687dfa9f37},
affiliation={Faculty of Computer Science and Information Technology, Universiti Tun Hussein Onn Malaysia, Batu Pahat, 86400, Malaysia; Media and Game Innovation Centre of Excellence, Institute of Human Centred Engineering, Universiti Teknologi Malaysia, Johor Bahru, 81310, Malaysia; Faculty of Engineering, School of Computing, Universiti Teknologi Malaysia, Johor Bahru, 81310, Malaysia; Empathic Computing Lab, University of South Australia, Australia; Empathic XR and Pervasive Computing Lab, University of Queensland, Australia},
abstract={Augmented Reality (AR) offers an enhanced learning environment which could potentially influence children's experience and knowledge gain during the language learning process. Teaching English or other foreign languages to children with different native language can be difficult and requires an effective strategy to avoid boredom and detachment from the learning activities. With the growing numbers of AR education applications and the increasing pervasiveness of speech recognition, we are keen to understand how these technologies benefit non-native young children in learning English. In this paper, we explore children's experience in terms of knowledge gain and enjoyment when learning through a combination of AR and speech recognition technologies. We developed a prototype AR interface called TeachAR, and ran two experiments to investigate how effective the combination of AR and speech recognition was towards the learning of 1) English terms for color and shapes, and 2) English words for spatial relationships. We found encouraging results by creating a novel teaching strategy using these two technologies, not only in terms of increase in knowledge gain and enjoyment when compared with traditional strategy but also enables young children to finish the certain task faster and easier. © 2019 Elsevier Ltd},
author_keywords={Human-computer interface;  Improving classroom teaching;  Interactive learning environments;  Teaching/learning strategies},
document_type={Article},
source={Scopus},
}

@ARTICLE{Andriyandi2020208,
author={Andriyandi, A.P. and Darmalaksana, W. and Maylawati, D.S. and Irwansyah, F.S. and Mantoro, T. and Ramdhani, M.A.},
title={Augmented reality using features accelerated segment test for learning tajweed},
journal={Telkomnika (Telecommunication Computing Electronics and Control)},
year={2020},
volume={18},
number={1},
pages={208-216},
doi={10.12928/TELKOMNIKA.V18I1.14750},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084088515&doi=10.12928%2fTELKOMNIKA.V18I1.14750&partnerID=40&md5=0fd6ad1d139c09e1b169cfa7b5fc964c},
affiliation={Department of Informatics, UIN Sunan Gunung Djati, Bandung, Indonesia; Department of llmu Hadits, UIN Sunan Gunung Djati, Bandung, Indonesia; Faculty of Information and Communication Technology, Universiti Teknikal Malaysia, Melaka, Malaysia; Faculty of Tarbiyah and Education, UIN Sunan Gunung Djati, Bandung, Indonesia; Department of Computer Science, Sampoerna University, Indonesia},
abstract={Currently, education forms students to think creatively and critically, this can be supported by the multimedia technology for education, including Islamic religious education. Islam requires all of its Muslim to read the Qur'an. Tajweed is an important because it is related to the articulation of reading the Qur'an properly and correctly. This article discusses the application of augmented reality (AR) as one of the multimedia technologies that can be used as an interactive educational medium to help study the tajweed of Qur'an. The method used in this research is Features from accelerated segment test (FAST) corner detection. The testing result with 31 tajweed objects show that FAST is able to recognize all Tajweed objects and display their AR. Besides, based on a survey with questionnaires to several students, the result shows that 88.2% of students responded very well and judged that it was sufficient to help study the tajweed. © 2020, Universitas Ahmad Dahlan.},
author_keywords={Augmented reality;  FAST corner detection;  Multimedia},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Chen2020767,
author={Chen, D. and Xie, L.J. and Kim, B. and Wang, L. and Hong, C.S. and Wang, L.-C. and Han, Z.},
title={Federated Learning Based Mobile Edge Computing for Augmented Reality Applications},
journal={2020 International Conference on Computing, Networking and Communications, ICNC 2020},
year={2020},
pages={767-773},
doi={10.1109/ICNC47757.2020.9049708},
art_number={9049708},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083449170&doi=10.1109%2fICNC47757.2020.9049708&partnerID=40&md5=23d16870f24d7d381d2d5b01978f154a},
affiliation={University of Houston, Department of Electrical and Computer Engineering, Houston, TX, United States; University of North Carolina at Charlotte, Department of Electrical and Computer Engineering, Charlotte, NC, United States; Toyota Motor North America RandD, InfoTech Labs, Mountain View, CA, United States; Beijing University of Posts and Telecommunications, School of Electronic Engineering, Beijing, China; Kyung Hee University, Department of Computer Science and Engineering, Seoul, South Korea; National Chiao Tung University, Department of Electrical and Computer Engineering, Hsinchu, Taiwan},
abstract={The past decade has witnessed the prosperous growth of augmented reality (AR) devices, as they provide immersive and interactive experience for customers. AR applications have the properties of high data rate and latency sensitivity. Currently, the available bandwidth is relatively limited to transmit and process enormous generated data. Meanwhile, it is challenging for AR to accurately detect and classify the object in order to perfectly combine the corresponding virtual contents with the real world. In this work, we focus on how to solve the computation efficiency, low-latency object detection and classification problems of AR applications. Firstly, we introduce and analyze the practical mathematical model of AR, and connect the AR operating principles with the object detection and classification problem. To address this problem and reduce the executing latency simultaneously, we propose a framework collaborating mobile edge computing paradigm with federated learning, both of which are decentralized configurations. To evaluate our method, numerical results are calculated based on the open source data CIFAR-10. Compared to centralized learning, our proposed framework requires significantly fewer training iterations. © 2020 IEEE.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Hussien20202104,
author={Hussien, N.S. and Kadir, Z.A. and Jaafar, R. and Wan Muhd Nazmi, W.A.A.A.},
title={An exploration on recycling paper education in gaming based for integrated with augmented reality technology},
journal={Test Engineering and Management},
year={2020},
volume={82},
number={2-2},
pages={2104-2107},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85080062560&partnerID=40&md5=cefed56c68ac5bda5fd428bbd4d1be55},
affiliation={Malaysian Institute of Information Technology, University Kuala Lumpur, 1016 Jalan Sultan Ismail, Kuala Lumpur, 50250, Malaysia},
abstract={Paper is the most important thing in our lives and has been promoted in many years to recycle paper but still, the attention is lacking. Most of our daily routine will probably start using paper and end with the use of paper as well. Waste paper will grow more and cause pollution of the environment. Therefore, in this paper have proposed to use a game in educate students about the paper recycling paper method and the importance of recycling paper through Augmented Reality (AR) pop-up book games assisted by AR technology and pop-up book. AR pop-up book game is designed to create interactive and increase awareness among students about the significance of paper recycling. It also determines the needs and problem of the affective recycling of paper in the way it facilitates learning for people. It also emphasizes the importance of recycling paper and the need for this technology and how it represents the different applications of the technology in the future of technology and communication. AR can help the university improvise or learn to attract more students at university level. © 2020 Mattingley Publishing. All rights reserved.},
author_keywords={Augmented Reality;  Education Game;  Pop-up Book;  Recycle;  Waste Paper},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Bhatti2020,
author={Bhatti, Z. and Bibi, M. and Shabbir, N.},
title={Augmented Reality based Multimedia Learning for Dyslexic Children},
journal={2020 3rd International Conference on Computing, Mathematics and Engineering Technologies: Idea to Innovation for Building the Knowledge Economy, iCoMET 2020},
year={2020},
doi={10.1109/iCoMET48670.2020.9073879},
art_number={9073879},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084646253&doi=10.1109%2fiCoMET48670.2020.9073879&partnerID=40&md5=286e3896fa02a48ba1ecbd3e04b5324b},
affiliation={Technology University of Sindh, Institute of Information and Communication, Jamshoro, Pakistan},
abstract={Augmented reality is a visual technology which combines virtual objects into the real environment, in real time. In this research work, a heuristic model of multimedia learning would be developed using Augmented Reality for a type of neurological disorder known as Dyslexia. Dyslexia is complex mental brain related syndromes, affecting the children in various ways including verbal and nonverbal communications, social interactions, understanding instructions, reading, writing, learning, problems, etc. The use of interactive Augmented Reality based multimedia application to facilitate and provide pedagogy for such type of special children would ascertain a unique and new dimension of treating and helping such young hearts in overcoming their disabilities in a very fun and easy way. The research encompasses designing a framework based on cognitive learning for interactive multimedia learning app using augmented reality technology, that would be centric to autism effected children's and would enable them to interact with such system. © 2020 IEEE.},
author_keywords={Augmented Reality;  Dyslexia;  Multimedia Learning;  Serious Games},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Sarsimbayeva2020142,
author={Sarsimbayeva, S. and Dimitrov, V.},
title={Research on the development and implementation of augmented reality technologies},
journal={CEUR Workshop Proceedings},
year={2020},
volume={2656},
pages={142-147},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090890874&partnerID=40&md5=3f3b32069a66bed355429d91911db2b6},
affiliation={Aktobe Regional State University K. Zhubanov, Aktobe, Kazakhstan; University of Sofia St. Kliment Ohridski, 5 James Bourchier Blvd., Sofia, 1164, Bulgaria},
abstract={The article deals with the development of augmented reality applications on the Vuforia platform, as well as the use of augmented reality technology in the educational process for visual modeling of educational material to supplement the material with visual information. The results of the analysis of existing approaches to the development of augmented reality applications, platforms, tool development environments such as Vuforia, with the ability to connect Unity, and the implementation of augmented reality technology are shown. The importance of using high-level augmented reality technologies, the prospects for using augmented reality technology, and the opportunities and advantages of using it in the educational process are highlighted. It is noted that the situation in the field of education determines the relevance of the use of new information technologies in the field of education and one of the promising areas of development of innovative educational technologies is the use of augmented reality in the learning process. An augmented reality application to great Kazakh poet Abay Kunanbayev's poems created based on marker technology is proposed. Copyright © 2020 for this paper by its authors.},
author_keywords={Augmented reality;  Interactive technology;  Recognition;  Vuforia},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Mahayuddin2020514,
author={Mahayuddin, Z.R. and Saifuddin Saif, A.F.M.},
title={Augmented reality based AR alphabets towards improved learning process in primary education system},
journal={Journal of Critical Reviews},
year={2020},
volume={7},
number={19},
pages={514-521},
doi={10.31838/jcr.07.19.66},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090146737&doi=10.31838%2fjcr.07.19.66&partnerID=40&md5=2eb63508e3814f1367c88a44c9b7a166},
affiliation={University Kebangsaan Malaysia, Malaysia; American International University, Bangladesh},
abstract={Education gives the insight to take us to the future which has not been possible to grasp due to lack of research methodologies towards learning process. Traditional formal education methodologies feel like living in the old age as existing learning processes are not advanced like technology which starts from primary education. As a result, children are losing interest in education due to the way of learning. In this context, learning is a continuous process where the quality cannot be justified by just including reading and writing, the overall process should be creative and interactive as well. However, existing primary education system seems to abandon the main idea about education and learning process to lean towards memorization and rote learning. The way of acquisition of education should be through discussion, research, storytelling, training which should be fun and interesting but our traditional primary education is based on two-dimensional materials and does not provide any of these opportunities. In this context, augmented reality or AR can be considered as advanced technology which can revolt the learning through visualization and interaction by engaging various characteristics. Recently, scientists are researching about how to incorporate AR with education where they gained positive results and by taking the positive result from the previous researches, this research proposed an Augmented Reality application: AR Alphabets. This research integrated proposed AR Alphabets with traditional primary education for better and improved learning experience. Experimental evaluation demonstrates effective efficiency to improve the learning process using proposed augmented reality based AR alphabet. © 2020 Innovare Academics Sciences Pvt. Ltd. All rights reserved.},
author_keywords={Augmented reality;  Learning experience;  Primary education},
document_type={Article},
source={Scopus},
}

@ARTICLE{MartinSagayam202077,
author={Martin Sagayam, K. and Jude Hemanth, D. and Andrew, J.A. and Ho, C.C. and Hien, D.},
title={Interactive educational content using marker based augmented reality},
journal={Frontiers in Artificial Intelligence and Applications},
year={2020},
volume={323},
pages={77-85},
doi={10.3233/FAIA200048},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082301956&doi=10.3233%2fFAIA200048&partnerID=40&md5=5609cb03b399a69ec427b82c2bf1bccd},
affiliation={Department of ECE, Karunya Institute of Tehnology and Sciences, India; Department of CSE, Karunya Institute of Tehnology and Sciences, India; Deparment of Computation and Information, Multimedia University, Malaysia; Department of Computer Science and Engineering, ThuyLoi University, HaNoi, Viet Nam},
abstract={Now-a-days augmented reality (AR) has become an interactive and collaborative tool for educational applications. AR makes the teaching and learning process more effective and allows the user to access the virtual objects in the real world. Although AR technology enhances the educational outcome, psychological, and pedagogical aspect for real-time usage in the classroom, the most important problem is the lighting conditions on which the output clarity is dependent. They can be affected by reflections from overhead lights and the light from the windows. Omni directional lighting can be used to avoid this problem. If the marker is moved out of the camera view, then the recognition will fail. Hence, we are using markers with large black and white regions that are low-frequency patterns. An augmented reality application for mathematics and geometry in school level education system is discussed in this paper. © 2020 The authors and IOS Press. All rights reserved.},
author_keywords={AR Toolkit;  Augmented reality;  marker;  mixed reality;  school level education},
document_type={Book Chapter},
source={Scopus},
}

@ARTICLE{Bibi2020200,
author={Bibi, S.H. and Munaf, R.M. and Bawany, N.Z. and Shamim, A. and Saleem, Z.},
title={Smart learning companion (SLAC)},
journal={International Journal of Emerging Technologies in Learning},
year={2020},
volume={15},
number={16},
pages={200-211},
doi={10.3991/ijet.v15i16.14477},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090100587&doi=10.3991%2fijet.v15i16.14477&partnerID=40&md5=d325cb7308d97358e431273bff91fbdd},
affiliation={Jinnah University for Women, Karachi, Pakistan},
abstract={Augmented Reality (AR) tends to merge the computing world with the real world, giving way to an incredible user experience. This field is not only limited to entertainment but has been utilized in various domains including healthcare, education and training. Realizing the potential of Augmented Reality in improving the learning experience, researchers have explored many ways of incorporating AR in the field education. Consequently, this research is focused on providing interactive and customized learning experience to book readers. We present a mobile application, Smart Learning Companion (SLAC), for physical books that provide a virtual content for a book. The virtual content includes, 3D animations, Quizzes, explanation of content in native language and many other features. The virtual content is activated as soon as pages are scanned with a mobile phone or tablet. Smart Learning Companion explains animated educational content and provides an interactive user experience. The aim of SLAC is to encourage students to learn on their own by making books more interactive. Smart Learning Companion provides explanation in Urdu, solutions of exercises with animations, quizzes for each section, and overall result that shows the student progress. This will help to reduce the dependency of students on others for learning making them capable of selflearning. Smart Learning Companion applications are developed for four books to conduct the experiments. Experimental study is conducted to show the effectiveness of Smart Learning Companion application. The results show that our application helped students to understand the concepts more easily as explanation was provided in national language of Pakistan, that is, Urdu. © 2020, Kassel University Press GmbH.},
author_keywords={AR (Augmented reality);  Mobile applications;  Self-Learning;  SLAC (Smart learning companion);  Smart way of learning;  Traditional way of learning},
document_type={Article},
source={Scopus},
}

@ARTICLE{Alzahrani2020282,
author={Alzahrani, N.M. and Lajmi, S.},
title={AugmentedBook: A collaborative e-learning augmented reality platform},
journal={Advances in Intelligent Systems and Computing},
year={2020},
volume={1018},
pages={282-288},
doi={10.1007/978-3-030-25629-6_44},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070019823&doi=10.1007%2f978-3-030-25629-6_44&partnerID=40&md5=8b0cbba42c4eccb44b7f6c4de5805834},
affiliation={Information Technology Department, Faculty of Computer Science and Information Technology, Albaha University, Albaha, Saudi Arabia; MIRACL: Multimedia InfoRmation Systems and Advanced Computing Laboratory, University of Sfax, Technological Pole of Sfax, Sakiet Ezzit, Sfax, 3021, Tunisia},
abstract={This paper introduces an augmented reality-based framework (called AugmentedBook) for e-learning that allows the creation of collaborative notes, illustrative media (i.e. video, 2D or 3D image, audio) for mobile devices or Google glass. The augmented content can be added to real-world educational support to make it more comprehensive, interactive and collaborative. In this platform, students and teachers can add collaborative notes to any part of the educational support system. They can also find illustrative media and indicate the pertinence of the result. Using our AugmentedBook platform, students can also download the enriched support using a mobile device. Our framework solves the problem of standard integration of augmented reality applications in education, offering a distributed framework which is e-learning compliant. © 2020, Springer Nature Switzerland AG.},
author_keywords={Augmented reality;  Collaborative annotation;  E-learning;  Mobile device},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{AidaZamnah2020430,
author={Aida Zamnah, Z.A. and Azreena, M.S. and Saputra, M.B.},
title={C-heart: Augmented reality of 3D heart anatomy},
journal={International Journal of Advanced Trends in Computer Science and Engineering},
year={2020},
volume={9},
number={1.1 Special Issue},
pages={430-435},
doi={10.30534/ijatcse/2020/7191.12020},
art_number={71},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082193786&doi=10.30534%2fijatcse%2f2020%2f7191.12020&partnerID=40&md5=ad9c433030f8a779d2d56a7d8d60c073},
affiliation={Faculty of Computing, Engineering and Technology, Asia Pacific University of Technology and Innovation, Technology Park Malaysia, Bukit Jalil, Kuala Lumpur, 57000, Malaysia},
abstract={This research paper is to enable the researchers to create a unique Augmented Reality (AR) internal organ in 3D and mobile e-learning application. This mobile e-learning application will include multimedia elements such as audio, video, graphics, and text. In the other words, the AR mobile application has a trailer, realistic sound effect and 3D interactive model. From adults to children, they are active users using mobile or smartphone as a tool for communication, work, recordings, and entertainment. From that perspectives, the advantages of smartphone will be benefits for educational field, specifically in medical field as many obstacles are experienced by the students in remembering the human body organs structure. ADDIE design methodology; a standard waterfall development model is being used in this research and the data collection is done through interviews with the doctors from Banjarbaru City Hospital, Banjarbaru, Indonesia. As the result, the mobile e-learning application of Augmented Reality is developed and can be implemented to medical e-learning system, especially in Indonesia in order to upgrade the education system. Therefore, the application can facilitate the way of learning and teaching in this modern generation, especially in medical field. © 2020, World Academy of Research in Science and Engineering. All rights reserved.},
author_keywords={3D learning;  Augmented reality;  E-learning;  Interactive learning;  Mobile learning},
document_type={Article},
source={Scopus},
}

@ARTICLE{Mao2020303,
author={Mao, C.-C. and Chen, F.-Y.},
title={Augmented reality and 3-D visualization effects to enhance battlefield situational awareness},
journal={Advances in Intelligent Systems and Computing},
year={2020},
volume={1018},
pages={303-309},
doi={10.1007/978-3-030-25629-6_47},
note={cited By 3},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069981091&doi=10.1007%2f978-3-030-25629-6_47&partnerID=40&md5=be70431fcb1eab38f793370c27d41cf7},
affiliation={Department of Applied Arts, Fu Hsing Kang College, National Defense University, No.70, Sec. 2 Zhongyang N. Rd. Beitou Dist., Taipei, Taiwan},
abstract={This study presents the augmented reality technology and 3D information visualization for Army’s military education to realize the interactive tactical course teaching and consider the user center research and human-computer interaction architecture as a solution to improve the common operational picture. The purpose is to improve the Army’s command and general staff officers in tactical operations to learn battlefield situational awareness to enhance interest in learning and effective decision support. We constructed a prototype augmented reality program, the traditional tactical image and symbols of war games into 3-D virtual images, Which includes military equipment, urban architecture and geography scenes and other models, teaching applications to import tactical operations, not only to break through the limitations of a traditional 2-D image, enhanced visual effects and digital technology information, revealing a more complete battlefield scene. At the same time, through virtual operation, students are more interactive. In order to verify and collect the utility and data of learning, quasi-experimental research has been used. Experiments have shown that using 3-D information Visualization for better understanding of military tasks and space environments can enhance learning interest and perception of situation awareness. © 2020, Springer Nature Switzerland AG.},
author_keywords={3-D animation;  Augmented Reality;  Human-computer interaction;  Information visualization;  Situation awareness},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Duncan-Vaidya2020,
author={Duncan-Vaidya, E.A. and Stevenson, E.L.},
title={The Effectiveness of an Augmented Reality Head-Mounted Display in Learning Skull Anatomy at a Community College},
journal={Anatomical Sciences Education},
year={2020},
doi={10.1002/ase.1998},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088284758&doi=10.1002%2fase.1998&partnerID=40&md5=007b1cf1f0bd33242b3a5136436c0dab},
affiliation={Department of Biology, Cuyahoga Community College – Westshore Campus, Cleveland, OH, United States},
abstract={Despite an increase in the use of technology in undergraduate anatomy education, and the rising popularity of online anatomy courses at community colleges in the United States, there have been no reports on the efficacy of augmented reality on anatomy education in this population. The purpose of this study was to test the hypothesis that augmented reality is an effective and engaging tool for learning anatomy in community college students. Participants recruited from Cuyahoga Community College (Cleveland, OH) studied skull anatomy using either traditional tools (i.e., textbook and plastic skull model) or an augmented reality head-mounted display with an interactive virtual skull application. Comparison of knowledge before and following the study period revealed that augmented reality was an effective tool for learning skull anatomy: pre-quiz = 32.7% (± 25.2); mean (± SD), post-quiz = 61.8% (± 19.5); n = 15; t(28) = 3.53; P = 0.001. The traditional tools were equally effective: pre-quiz = 44.9 % (± 18.6), post-quiz = 67.9 % (± 17.3); n = 17; t(32) = 3.73; P = 0.0007. Students rated the augmented reality device as 9.6 (± 1.0); mean (± SD) when asked if it fit the statement “fun to use” on a semantic differential scale from 1 (poor) to 10 (excellent). In conclusion, this study found that augmented reality is an effective and engaging tool for the instruction of skull anatomy at a community college. © 2020 American Association for Anatomy},
author_keywords={augmented reality;  community college;  gross anatomy education;  hologram;  HoloLens;  skull;  undergraduate education},
document_type={Article},
source={Scopus},
}

@ARTICLE{Yüzüak2020,
author={Yüzüak, Y. and Yiğit, H.},
title={Augmented reality application in engineering education: N-Type MOSFET},
journal={International Journal of Electrical Engineering Education},
year={2020},
doi={10.1177/0020720920954150},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090148417&doi=10.1177%2f0020720920954150&partnerID=40&md5=d9b653e0abb33d9dcbc4517986b73337},
affiliation={Architect İzzet Baysal Vocational and Technical Anatolian High SchoolBolu, Turkey; Kocaeli University, Faculty of Technology Technology, Information Systems Engineering, İzmit, Turkey},
abstract={In a period of rapid adaptation to technology in today’s world, limiting education to traditional methods leads to a rapid decline in the perception and interest of the learner. Augmented Reality (AR), which is among the most interesting technological innovation of the last years, are manifested in many sectors. It is used more widely in the field of education thanks to its superior advantages such as being portable, adapting to different devices/equipment, offering interactive digital content and arousing interest. In this study, AR application has been realized for the modeling of N-type MOSFET element, which is one of the basic courses of Electrical and Electronic Engineering and is widely used in analog and digital circuits. The contribution of the application to students’ perception of theoretical concepts was also examined. It concluded that AR made an important contribution to the concretization of abstract concepts and the developed educational material increased the motivation of the students. © The Author(s) 2020.},
author_keywords={Augmented reality;  education;  engineering;  mobile learning;  N-type MOSFET},
document_type={Article},
source={Scopus},
}

@ARTICLE{Zhang2020,
author={Zhang, J. and Huang, Y.-T. and Liu, T.-C. and Sung, Y.-T. and Chang, K.-E.},
title={Augmented reality worksheets in field trip learning},
journal={Interactive Learning Environments},
year={2020},
doi={10.1080/10494820.2020.1758728},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084837564&doi=10.1080%2f10494820.2020.1758728&partnerID=40&md5=f8cc670b9c214605155821a0e82e5868},
affiliation={Graduate Institute of Information and Computer Education, National Taiwan Normal University, Taipei, Taiwan; Department of Educational Psychology and Counseling, National Taiwan Normal University, Taipei, Taiwan},
abstract={Worksheets are often used during field trips and utilize a learning cycle with three stages (exploration, concept introduction and concept application) to engage learners in the learning activities of observation and exploration. However, traditional paper worksheets do not provide multimedia and interactive presentations with physical objects, which made learners losing interaction with the physical context during field trips and failing to implement all the stages completely. This study designed an augmented reality worksheet with a three-stage learning cycle and applied it to learning about plants, specifically assisting learners in observing and classifying plants. A pretest-posttest quasi-experimental design was used to show the effect of learning when learners used augmented reality worksheets. Lag sequence analysis was used to identify learning behavioral patterns. The findings indicate that the learning effect of using augmented reality worksheets is much better than that of paper worksheets and improves the learners’ interaction with plants. © 2020, © 2020 Informa UK Limited, trading as Taylor & Francis Group.},
author_keywords={Augmented reality;  field trips;  guided discovery learning;  learning cycle;  worksheets},
document_type={Article},
source={Scopus},
}

@ARTICLE{Yan2020684,
author={Yan, H. and He, X.},
title={The impact of interactive ar on learning ability of children’s chinese characters self-learning},
journal={Advances in Intelligent Systems and Computing},
year={2020},
volume={1217 AISC},
pages={684-689},
doi={10.1007/978-3-030-51828-8_90},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088748009&doi=10.1007%2f978-3-030-51828-8_90&partnerID=40&md5=51ceb62a0fdfb1592ba656f8829daecb},
affiliation={School of Mechanical Science and Engineering, Huazhong University of Science and Technology, Wuhan, Hubei, China},
abstract={Augmented reality has become an effective teaching and learning tool to improve children’s engagement and experience during. This study presented 2 kinds of Chinese characters learning method (traditional picture learning and AR-assisted learning), and compared the impact of traditional learning and AR-assisted learning methods on children’s learning ability in the process of learning by applying AR technology to traditional Chinese pictographs learning method. It involves the impact on children’s concentrated ability, cognitive ability and learning initiative. These finds enriches the application and research of AR technology in Chinese language teaching, and provides reference for applied research in other related fields. © The Editor(s) (if applicable) and The Author(s), under exclusive license to Springer Nature Switzerland AG 2020.},
author_keywords={Augmented reality;  Chinese characters;  Learning ability},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Santos2020247,
author={Santos, L. and Silva, N. and Nóbrega, R. and Almeida, R. and Coelho, A.},
title={An interactive application framework for natural parks using serious location-based games with augmented reality},
journal={VISIGRAPP 2020 - Proceedings of the 15th International Joint Conference on Computer Vision, Imaging and Computer Graphics Theory and Applications},
year={2020},
volume={1},
pages={247-254},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083556732&partnerID=40&md5=f121e1538111832cc14f8f13a6a3bb2e},
affiliation={Faculty of Engineering, University of Porto, Porto, Portugal; NOVA-LINCS, DI, Faculdade de Ciências e Tecnologia, Universidade Nova de Lisboa, Caparica, Portugal; INESC TEC - The Institute for Systems and Computer Engineering, Technology and Science, Porto, Portugal; Faculty of Science, University of Porto, Porto, Portugal},
abstract={Park visitors and tourists, in general, seek new experiences, leading to a growing search for ways to create more memorable experiences. Some technological solutions, such as Augmented Reality, have proved that they can be useful to create more immersive and interactive experiences, both in entertainment and education. An application with Augmented Reality, using location-based services in a gamified way, can create pleasant and entertaining outdoor experiences without losing its pedagogical ability, making it a promising fit for a nature park. We propose a conceptual framework for creating these mobile applications for nature parks. From which, a mobile application was prototyped with location-based services and augmented reality interactive experiences, with the purpose of disseminating scientific knowledge about the fauna and flora of a nature park. Gaming elements are also introduced in the application's design to try and improve the engagement and involvement in the various activities of the application and its contents. User tests were performed during the development of the prototype and with the final version. The results allow us to conclude that this type of applications can improve the visitors' experience while at the same time, improve the dissemination of scientific knowledge. Copyright © 2020 by SCITEPRESS - Science and Technology Publications, Lda. All rights reserved.},
author_keywords={Augmented reality;  Interactive applications;  Location-based games;  Mobile games;  Nature parks;  Serious games},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Rosni2020,
author={Rosni, N.S. and Kadir, Z.A. and Mohamed Noor, M.N.M. and Abdul Rahman, Z.H. and Bakar, N.A.},
title={Development of mobile markerless augmented reality for cardiovascular system in anatomy and physiology courses in physiotherapy education},
journal={Proceedings of the 2020 14th International Conference on Ubiquitous Information Management and Communication, IMCOM 2020},
year={2020},
doi={10.1109/IMCOM48794.2020.9001692},
art_number={9001692},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081129276&doi=10.1109%2fIMCOM48794.2020.9001692&partnerID=40&md5=326b40b4629a7faf4641004914ad56f6},
affiliation={Universiti Kuala Lumpur MIIT, Creative Multimedia, Wilayah Persekutuan, Kuala Lumpur, Malaysia; Universiti Kuala Lumpur MIIT, Computer Engineering, Wilayah Persekutuan, Kuala Lumpur, Malaysia; Universiti Kuala Lumpur RCMP, Physiotherapy, Ipoh, Perak, Malaysia},
abstract={This paper focuses on the development of markerless Augmented Reality (AR) using ARCore platform, where interactive three-dimensional (3D) content was designed and developed based on the learning outcome syllabus to enhance the visualization and understanding of the anatomy and physiology for cardiovascular system topic. Currently, learning method is based on 2D images and slides, plastic models and cadavers have to deal with students' experience issues such as lack of interactive, uneasy feeling with dead body and cadavers storing and donation. Therefore, more advances using technology such as Augmented Reality (AR) in learning method are needed to overcome the current gap and enhance the students' learning. Thus, this study aims to develop markerless AR specifically focus on the cardiovascular system for undergraduate physiotherapy program at UniKL, RCMP. In this study, we describe a method used to create markerless AR content using 3D data from MRI images and 3D unity as an authoring tool. We present three processes, where the first design consideration based on author's previous works derived from systematic search strategy were outlined, the second 3D model was developed using a real object and subsequently converted to an AR asset that can be linked to a unique markerless using ARCore platform and the third AR content creation using 3D unity authoring tool. This application provides a better visualization for the anatomical parts to support for an innovative and flexible learning process. We have successfully analyzed the design consideration using a systematic search strategy and developed the markerless AR specifically for cardiovascular system in anatomy and physiology courses. This study has contributed to knowledge in design and development of AR used in physiotherapy education. Therefore, this will be a step forward to an exploration of design-based research for an AR benefit in experienced-learning approach application. © 2020 IEEE.},
author_keywords={anatomy and physiology;  ARCore;  augmented reality;  cardiovascular system;  markerless AR;  physiotherapy education},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Zhu202016,
author={Zhu, M. and Sun, Z. and Zhang, Z. and Shi, Q. and Chen, T. and Liu, H. and Lee, C.},
title={Sensory-Glove-Based Human Machine Interface for Augmented Reality (AR) Applications},
journal={Proceedings of the IEEE International Conference on Micro Electro Mechanical Systems (MEMS)},
year={2020},
volume={2020-January},
pages={16-19},
doi={10.1109/MEMS46641.2020.9056153},
art_number={9056153},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083199598&doi=10.1109%2fMEMS46641.2020.9056153&partnerID=40&md5=ffd5de171ea3b6c0d5a510829aec609b},
affiliation={National University of Singapore, Department of Electrical and Computer Engineering, Singapore, Singapore; Jiangsu Provincial Key Laboratory of Advanced Robotics, School of Mechanical and Electric Engineering, Soochow University, Suzhou, China},
abstract={We propose a glove based Human Machine Interface (HMI) designed for Virtual Reality (VR) and Augmented Reality (AR) applications. The proposed sensory glove uses facile designed triboelectric sensors to realize multi-dimensional motion recognition of gestures, and piezoelectric mechanical stimulators are also equipped for achieving the haptic feedback to user regarding the interactive events from virtual world. The developed HMI leverages machine learning technology to achieve real time object recognition, hence, we can manipulate virtual objects in VR/AR space by projecting sensory information from glove. © 2020 IEEE.},
author_keywords={augmented reality;  human machine interface;  machine learning;  piezoelectric;  Triboelectric},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Abriata2020,
author={Abriata, L.A.},
title={Building blocks for commodity augmented reality-based molecular visualization and modeling in web browsers},
journal={PeerJ Computer Science},
year={2020},
volume={2020},
number={2},
doi={10.7717/peerj-cs.260},
art_number={260},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086507407&doi=10.7717%2fpeerj-cs.260&partnerID=40&md5=3a242fc745ca26151b46eacf962cd2d6},
affiliation={École Polytechnique Fédérale de Lausanne, Lausanne, Switzerland; Swiss Institute of Bioinformatics, Lausanne, Switzerland},
abstract={For years, immersive interfaces using virtual and augmented reality (AR) for molecular visualization and modeling have promised a revolution in the way how we teach, learn, communicate and work in chemistry, structural biology and related areas. However, most tools available today for immersive modeling require specialized hardware and software, and are costly and cumbersome to set up. These limitations prevent wide use of immersive technologies in education and research centers in a standardized form, which in turn prevents large-scale testing of the actual effects of such technologies on learning and thinking processes. Here, I discuss building blocks for creating marker-based AR applications that run as web pages on regular computers, and explore how they can be exploited to develop web content for handling virtual molecular systems in commodity AR with no more than a webcam-and internet-enabled computer. Examples span from displaying molecules, electron microscopy maps and molecular orbitals with minimal amounts of HTML code, to incorporation of molecular mechanics, real-time estimation of experimental observables and other interactive resources using JavaScript. These web apps provide virtual alternatives to physical, plastic-made molecular modeling kits, where the computer augments the experience with information about spatial interactions, reactivity, energetics, etc. The ideas and prototypes introduced here should serve as starting points for building active content that everybody can utilize online at minimal cost, providing novel interactive pedagogic material in such an open way that it could enable mass-testing of the effect of immersive technologies on chemistry education. © 2020 Abriata.},
author_keywords={Augmented reality;  Chemistry;  Education;  Integrative modeling;  Molecular modeling;  Molecular visualization;  Virtual reality},
document_type={Article},
source={Scopus},
}

@ARTICLE{Khowaja2020424,
author={Khowaja, K. and Al-Thani, D. and Hassan, A.O. and Shah, A. and Salim, S.S.},
title={Mobile augmented reality app for children with autism spectrum disorder (asd) to learn vocabulary (marvoc): From the requirement gathering to its initial evaluation},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2020},
volume={12211 LNCS},
pages={424-437},
doi={10.1007/978-3-030-50164-8_31},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088753989&doi=10.1007%2f978-3-030-50164-8_31&partnerID=40&md5=7da8ba510d6ac9faf76192f88575e7b9},
affiliation={Hamad Bin Khalifa University, Doha, Qatar; International Islamic University Malaysia, Kuala Lumpur, Malaysia; University of Malaya, Kuala Lumpur, Malaysia},
abstract={The use of different technologies for the intervention of children with autism spectrum disorder (ASD) has increased over the year with the increase in the number of children diagnosed with ASD. In recent years, among the different technologies, the researchers have started to use the augmented reality (AR) to provide the intervention of different skills to children with ASD. The use of AR has many benefits, including ubiquity, minimally work with a camera, among others. Despite several benefits, AR has been underutilized for the vocabulary learning of children with ASD. This paper presents the initial version of the Mobile augmented reality app for children with autism spectrum disorder (ASD) to learn vocabulary (MARVoc). The purpose of developing MARVoc is to support teaching staff at the centers based in Doha, Qatar, to provide an interactive learning environment to children with ASD. The requirements of the MARVoc were gathered from two centers for ASD in Doha; two specific use cases were created from which one use case was finalized for the development of MARVoc. The initial version of the MARVoc was developed; the feedback was taken from the staff working at centers for ASD in Doha, and MARVoc was updated. © Springer Nature Switzerland AG 2020.},
author_keywords={Autism spectrum disorder (ASD);  Language comprehension;  Mobile augmented reality (AR);  Smartphone;  Tablet;  Vocabulary},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{NoAuthor2020,
title={15th European Conference on Technology Enhanced Learning, EC-TEL 2020},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2020},
volume={12315 LNCS},
page_count={486},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091133891&partnerID=40&md5=4e72a25fe963ee492918e47939524684},
abstract={The proceedings contain 49 papers. The special focus in this conference is on Technology Enhanced Learning. The topics include: Knowledge-driven wikipedia article recommendation for electronic textbooks; infobits: A mobile application to foster digital competencies of senior citizens; human-centered design of a dashboard on students’ revisions during writing; student awareness and privacy perception of learning analytics in higher education; user assistance for serious games using hidden markov model; guiding socio-technical reflection of ethical principles in tel software development: The srep framework; git4school: A dashboard for supporting teacher interventions in software engineering courses; exploring the design and impact of online exercises for teacher training about dynamic models in mathematics; interactive concept cartoons: Exploring an instrument for developing scientific literacy; quality evaluation of open educational resources; designing digital activities to screen locomotor skills in developing children; towards adaptive social comparison for education; simulation based assessment of epistemological beliefs about science; an operational framework for evaluating the performance of learning record stores; an approach to support interactive activities in live stream lectures; educational escape games for mixed reality; measuring learning progress for serving immediate feedback needs: Learning process quantification framework (lpqf); data-driven game design: The case of difficulty in educational games; extracting topics from open educational resources; supporting gamification with an interactive gamification analytics tool (igat); openlair an open learning analytics indicator repository dashboard; casuallearn: A smart application to learn history of art; applying instructional design principles on augmented reality cards for computer science education; what teachers need for orchestrating robotic classrooms; preface.},
document_type={Conference Review},
source={Scopus},
}

@ARTICLE{Sun2020520,
author={Sun, C.-F. and Chan, Y.-C. and Chien, S.-Y. and Lin, Y.-L. and Hsiao, I.-H.},
title={Preschool safety education with digital media-based learning application – kinder},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2020},
volume={12206 LNCS},
pages={520-529},
doi={10.1007/978-3-030-50506-6_35},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088914437&doi=10.1007%2f978-3-030-50506-6_35&partnerID=40&md5=9d98a549fdf181bb9bca9e35dc1d0ec5},
affiliation={University of Washington, Seattle, WA  98195, United States; National Chengchi University, Taipei, 11605, Taiwan; Arizona State University, Tempe, AZ  85281, United States},
abstract={While unintentional injuries are the leading cause of morbidity and mortality among children, reports have shown that unintentional injuries mostly take place at home or school environments with injuries like falls, contact with stationary objects and being caught in hinge side of doors reported frequently. Safety education targeting children is seen as an important intervention of children injury prevention for its direct affect. As there has been a rising usage of digital media devices among children, digital media-based learning has been discussed and researched in recent years. However, few has investigated the value of deploying digital devices in children environment safety education. We developed Kinder, a mobile application using Augmented Reality (AR) and object recognition technology, to support preschool children in identifying potentially dangerous objects in different environments. The ultimate goal of Kinder is to provide an interactive and encouraging learning experience for preschool children to foster their learning motivation and enhance their safety knowledge. Our main focus is to assess the usability and prospects of the application. In this paper, we present the methodology, setup, implementation and results of our preliminary assessment of Kinder. From questionnaire and interviews, the preliminary results have shown valid value of AR with object recognition technology in children safety knowledge learning in home and school environment. The present study also provides useful information for practical design in children learning applications. © Springer Nature Switzerland AG 2020.},
author_keywords={Augmented reality;  Children safety education;  Digital media learning;  Object recognition},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{GonzálezIzard2020199,
author={González Izard, S. and Juanes Méndez, J.A. and García-Peñalvo, F.J. and Moreno Belloso, C.},
title={App Design and Implementation for Learning Human Anatomy Through Virtual and Augmented Reality},
journal={Lecture Notes in Educational Technology},
year={2020},
pages={199-213},
doi={10.1007/978-981-15-4952-6_13},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086102041&doi=10.1007%2f978-981-15-4952-6_13&partnerID=40&md5=68ec951477939dc9017b7511c0692939},
affiliation={University of Salamanca, Ctra Fregeneda 26, Portal 2, 1D, Salamanca, 37008, Spain; IUCE Salamanca University Institute of Educational Science, University of Salamanca, Paseo Canalejas, 169, Salamanca, 37008, Spain; Grupo de Investigación en Interacción y eLearning, Facultad de Ciencias, Plaza de los Caídos s/n, Salamanca, 37008, Spain; Junta Castilla y León, Avenida de Burgos 7-21, Portal 1, Atico B, Santa Marta de Tormes (Salamanca), 37900, Spain},
abstract={The influence on the teaching of Augmented Reality (RA) and Virtual Reality (RV) techniques is analyzed in the process of teaching-learning of the Human Anatomy subject, in health science students. For this purpose, two own applications have been designed, for mobile devices and Virtual Reality glasses, with the purpose of incorporate these techniques in teaching, for the study of human anatomy, that facilitate the students a better learning of anatomical body contents through these technological procedures. In this way it is intended to achieve a better transmission of knowledge to students in an effective, visual, interactive and close the main contents related to human anatomy. We believe that these technological tools constitute an excellent complementary medium to the traditional atlases, facilitating the learning of the anatomical structures. © 2020, Springer Nature Singapore Pte Ltd.},
author_keywords={App;  Human anatomy;  Stereoscopic vision;  Teaching;  Virtual and augmented reality},
document_type={Book Chapter},
source={Scopus},
}

@ARTICLE{Asif2020524,
author={Asif, M.A. and Al Wadhahi, F. and Rehman, M.H. and Kalban, I.A. and Achuthan, G.},
title={Intelligent educational system for autistic children using augmented reality and machine learning},
journal={Lecture Notes on Data Engineering and Communications Technologies},
year={2020},
volume={46},
pages={524-534},
doi={10.1007/978-3-030-38040-3_59},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083423854&doi=10.1007%2f978-3-030-38040-3_59&partnerID=40&md5=aeb26bd60afaf949d1448c173809d0d9},
affiliation={College of Engineering, National University Science and Technology, Muscat, Oman},
abstract={Autism is a severe disorder affecting 1 in 160 children globally. Autism comprises of several development disabilities such as social, communicational and behavioural challenges. Children being diagnosed by the autism mainly face a hard time studying curriculum in inclusive classrooms based on their IQ level and the autism levels. Although, different strategies and learning teaching tools are available to support autistic children, only few systems aid them in learning efficiently, and are not highly interactive. Thus, the proposed Intelligent Education System primarily focuses on providing interactive learning experience to the autistic children with IQ level &gt;50% and efficient teaching assistance to their tutors using augmented reality and machine learning in both English and Arabic The capability of the education system to perform an action, allows the autistic child to interact with the playable sand and gain interest. In learning stage, once the child scribbles on the sandbox, Kinect 3D camera captures and recognizes the drawn image. After the refinement and recognition of the image using OpenCV and classification model, the stored set of real world object are projected on the canvas. Besides, a webcam captures the facial expression of the child, and emotion detection algorithm determines the reaction of the child. Based on the child’s emotion, the current object is projected and pronounced three times to enforce better learning. Once the instructor chooses the language and character to be taught using the developed mobile application, the system displays it over the sandbox and further three objects that starts with the particular character are pronounced and projected. The system is tested rigorously with large set of users, and the results prove the efficiency of the system and happiness of the autistic children in better learning. © Springer Nature Switzerland AG 2020.},
author_keywords={Augmented reality;  Autism spectrum disorder;  Autistic children;  Education;  Image processing;  Machine learning},
document_type={Book Chapter},
source={Scopus},
}

@CONFERENCE{Tuli2020679,
author={Tuli, N. and Mantri, A.},
title={Usability principles for augmented reality based kindergarten applications},
journal={Procedia Computer Science},
year={2020},
volume={172},
pages={679-687},
doi={10.1016/j.procs.2020.05.089},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089026167&doi=10.1016%2fj.procs.2020.05.089&partnerID=40&md5=45d4f6e7e26cb0493786363766d6b554},
affiliation={Chitkara University Institute of Engineering and Technology, Chitkara University, Punjab, 140401, India},
abstract={Augmented Reality (AR) overlays digital information over user's real world. Designing and developing AR applications is a difficult task. It involves user interface designing, content generation according to the target audience so that the application is easy to understand, interactive, consistent and ease to use. To design these applications there are many design principles evidenced in existing literature such as learnability, affordance, simplicity etc. However, there are no studies in the literature which define most appropriate usability principles/guidelines for designing mobile based AR applications for kindergarten kids. Age is a significant factor to be considered in developing applications for kids especially when it comes to interaction techniques to be used in learning applications. The kids may not easily use and interact with the applications developed for the adults. Therefore, there is a need to identify the principles that should be kept in mind while developing AR applications according to the kids. The aim of our research is to develop usability principles for mobile based applications for kindergarten kids using AR. We proposed 23 usability principles by studying the existing literature on usability, design principles for AR applications, guidelines/principles for tangible interfaces. These principles would help other researcher and developers to create more interactive, learnable and easy to understand AR applications for kids solving the identified usability problems. © 2020 The Authors. Published by Elsevier B.V.},
author_keywords={Augmented reality;  Kindergarten;  Systematic process;  Usability principles},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Dave2020942,
author={Dave, A. and Kang, M. and Hwang, J. and Lorenzo, M. and Oh, P.},
title={Towards Smart Classroom: Affordable and Simple Approach to Dynamic Projection Mapping for Education},
journal={2020 10th Annual Computing and Communication Workshop and Conference, CCWC 2020},
year={2020},
pages={942-947},
doi={10.1109/CCWC47524.2020.9031145},
art_number={9031145},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083084386&doi=10.1109%2fCCWC47524.2020.9031145&partnerID=40&md5=d559a97d0e40b8e8c4cb2410de2b2b8b},
affiliation={University of Nevada Las Vegas, Department of Mechanical Engineering, Las Vegas, United States; Beckman High School, California, United States; Diamond Bar High School, California, United States; Ed W. Clark High School, Las Vegas, United States},
abstract={In order to transform the traditional classroom into an interactive space, we developed a projection mapping toolbox: an affordable, simple alternative to complex systems. Our system uses Python and Microsoft Kinect V2 for dynamic projection mapping (PM). We demonstrated three ways PM can be used to make Augmented Reality (AR) applications for classroom use. We projected free body diagrams onto boxes, made AR quiz tacking for teachers, and made an AR game. The goal of the projection mapping toolbox is to help students learn more efficiently and raise academic achievement. © 2020 IEEE.},
author_keywords={augmented reality;  dynamic projection mapping;  education;  marker tracking;  smart classroom},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Sırakaya2020,
author={Sırakaya, M. and Alsancak Sırakaya, D.},
title={Augmented reality in STEM education: a systematic review},
journal={Interactive Learning Environments},
year={2020},
doi={10.1080/10494820.2020.1722713},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079032172&doi=10.1080%2f10494820.2020.1722713&partnerID=40&md5=a4f672bba72f1a341eec64b97a68181d},
affiliation={Department of Computer Technologies, Kırşehir Ahi Evran University, Kırşehir, Turkey},
abstract={This study aimed to systematically investigate the studies in which augmented reality (AR) was used to support Science, Technology, Engineering and Mathematic (STEM) education. In this framework, the general status of AR in STEM education was presented and its advantages and challenges were identified. The study investigated 42 articles published in journals indexed in SSCI database and deemed suitable for the purposes of this research. The obtained data were analyzed by two researchers using content analysis method. It was found that the studies in this field have become more significant and intensive in recent years and that these studies were generally carried out at schools (class, laboratory etc.) using marker-based AR applications. It was concluded that mostly K-12 students were used as samples and quantitative methods were selected. The advantages of AR-STEM studies were summarized and examined in detail in 4 sub-categories such as “contribution to learner, educational outcomes, interaction and other advantages”. On the other hand, some challenges were identified such as teacher resistance and technical problems. © 2020, © 2020 Informa UK Limited, trading as Taylor & Francis Group.},
author_keywords={Augmented reality;  interactive learning environments;  science education;  STEM;  systematic review},
document_type={Review},
source={Scopus},
}

@ARTICLE{Borja-Galeas2020387,
author={Borja-Galeas, C. and Guevara, C. and Amagua, M.},
title={Editorial design of interactive picture book with mobile application based on uxd user experience design},
journal={Advances in Intelligent Systems and Computing},
year={2020},
volume={1217 AISC},
pages={387-393},
doi={10.1007/978-3-030-51828-8_50},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088750042&doi=10.1007%2f978-3-030-51828-8_50&partnerID=40&md5=ef9491f614c4f0b05b8556491ee97bb3},
affiliation={Faculty of Architecture, Arts and Design, Universidad Tecnológica Indoamérica, Ambato, Quito, Ecuador; Faculty of Design and Communication, Universidad de Palermo, Buenos Aires, Argentina; Research Center of Mechatronics and Interactive Systems, Universidad Tecnológica Indoamérica, Ambato, Quito, Ecuador; Faculty of Administrative and Economic Sciences, Universidad Indoamérica, Ambato, Quito, Ecuador},
abstract={This research presents an interactive human-computer learning system model applying adaptive editorial design. The proposal aims to generate an interactive picture book and a mobile application based on user experience design (UxD). The results will be obtained using UX metrics and will have the particularity of working with the technique of participatory design and reticular deconstruction. This book includes its presentation as an audiobook and an editorial composition with pop-ups and pages to paint. © The Editor(s) (if applicable) and The Author(s), under exclusive license to Springer Nature Switzerland AG 2020.},
author_keywords={Augmented reality;  Editorial design;  Interactive editorial design;  Mobile application human interaction computer;  User experience design},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{NoAuthor2020,
title={12th International Conference on Virtual, Augmented and Mixed Reality, VAMR 2020, held as part of the 22nd International Conference on Human-Computer Interaction, HCII 2020},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2020},
volume={12191 LNCS},
page_count={1083},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089138692&partnerID=40&md5=65a0771930a624744738868c645ddb31},
abstract={The proceedings contain 71 papers. The special focus in this conference is on Virtual, Augmented and Mixed Reality. The topics include: Measurement Based AR for Geometric Validation Within Automotive Engineering and Construction Processes; augmented Instructions: Analysis of Performance and Efficiency of Assembly Tasks; interactive Mixed Reality Cooking Assistant for Unskilled Operating Scenario; engaging Place with Mixed Realities: Sharing Multisensory Experiences of Place Through Community-Generated Digital Content and Multimodal Interaction; augmented Reality and Microbit for Project-Based Learning; research on the Perceptual Interaction Model of Virtual Reality Films; interactive Narrative in Augmented Reality: An Extended Reality of the Holocaust; learning in Virtual Reality: Investigating the Effects of Immersive Tendencies and Sense of Presence; Empeiría*: Powering Future Education Training Systems with Device Agnostic Web-VR Apps; A GPU Accelerated Lennard-Jones System for Immersive Molecular Dynamics Simulations in Virtual Reality; did You Say Buttonless? Exploring Alternative Modes of Sensory Engagement for Augmented Reality Storytelling Experiences; using Laser Scans and ‘Life History’ to Remember Heritage in Virtual Environments; study on Learning Effectiveness of Virtual Reality Technology in Retail Store Design Course; Development and Human Factors Considerations for Extended Reality Applications in Medicine: The Enhanced ELectrophysiology Visualization and Interaction System (ĒLVIS); Classifying the Levels of Fear by Means of Machine Learning Techniques and VR in a Holonic-Based System for Treating Phobias. Experiments and Results; multi-channel Interaction Design and Implementation of Medical Pendant Based on Virtual Reality Technology; a Virtual Reality Dental Anxiety Mitigation Tool Based on Computerized Cognitive Behavioral Therapy.},
document_type={Conference Review},
source={Scopus},
}

@ARTICLE{NoAuthor2020,
title={12th International Conference on Virtual, Augmented and Mixed Reality, VAMR 2020, held as part of the 22nd International Conference on Human-Computer Interaction, HCII 2020},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2020},
volume={12190 LNCS},
page_count={1083},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088526457&partnerID=40&md5=dcdde646d63926b634f87227c84ff09e},
abstract={The proceedings contain 71 papers. The special focus in this conference is on Virtual, Augmented and Mixed Reality. The topics include: Arms and hands segmentation for egocentric perspective based on pspnet and deeplab; virtual scenarios for pedestrian research: a matter of complexity?; comparative study design of multiple coordinated views for 2d large high-resolution display with 3d visualization using mixed reality technology; study on assessing user experience of augmented reality applications; how interaction paradigms affect user experience and perceived interactivity in virtual reality environment; mrcat: in situ prototyping of interactive ar environments; augmented reality for city planning; assessing the role of virtual reality with passive haptics in music conductor education: a pilot study; fingertac – a wearable tactile thimble for mobile haptic augmented reality applications; a mixed-reality shop system using spatial recognition to provide responsive store layout; wiknectvr: a gesture-based approach for interacting in virtual reality based on wiknect and gestural writing; an empirical evaluation on arm fatigue in free hand interaction and guidelines for designing natural user interfaces in vr; design and validation of a unity-based simulation to investigate gesture based control of semi-autonomous vehicles; hand gesture recognition for smartphone-based augmented reality applications; user-centric ar sceneized gesture interaction design; towards the specification of an integrated measurement model for evaluating vr cybersickness in real time; cognitive workload monitoring in virtual reality based rescue missions with drones; negative effects associated with hmds in augmented and virtual reality; fake people, real effects: the presence of virtual onlookers can impair performance and learning.},
document_type={Conference Review},
source={Scopus},
}

@ARTICLE{Alce2020215,
author={Alce, G. and Klang, K.-J. and Andersson, D. and Nyström, S. and Wallergård, M. and Niehorster, D.C.},
title={Using augmented reality to train flow patterns for pilot students - an explorative study},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2020},
volume={12242 LNCS},
pages={215-231},
doi={10.1007/978-3-030-58465-8_17},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091186854&doi=10.1007%2f978-3-030-58465-8_17&partnerID=40&md5=916bf2366f1b1208457fd4cd58469156},
affiliation={Department of Design Sciences, Lund University, Lund, Sweden; Lund University School of Aviation, Lund University, Lund, Sweden; Lund University Humanities Lab and Department of Psychology, Lund University, Lund, Sweden},
abstract={Today, just as in the early days of flying, much emphasis is put on the pilot student’s flight training before flying a real commercial aircraft. In the early stages of a pilot student’s education, they must, for example, learn different operating procedures known as flow patterns using very basic tools, such as exhaustive manuals and a so-called paper tiger. In this paper, we present a first design of a virtual and interactive paper tiger using augmented reality (AR), and perform an evaluation of the developed prototype. We evaluated the prototype on twenty-seven pilot students at the Lund University School of Aviation (LUSA), to explore the possibilities and technical advantages that AR can offer, in particular the procedure that is performed before takeoff. The prototype got positive results on perceived workload, and in remembering the flow pattern. The main contribution of this paper is to elucidate knowledge about the value of using AR for training pilot students. © Springer Nature Switzerland AG 2020.},
author_keywords={Augmented reality;  Flight training;  Interaction design;  Method},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Zhang2020,
author={Zhang, G.},
title={Design of virtual reality augmented reality mobile platform and game user behavior monitoring using deep learning},
journal={International Journal of Electrical Engineering Education},
year={2020},
doi={10.1177/0020720920931079},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086520600&doi=10.1177%2f0020720920931079&partnerID=40&md5=4eb76243564cb0c8be13c08fa53005fe},
affiliation={School of Art and Design, Lanzhou Jiaotong University, Lanzhou, China},
abstract={To explore the design of the virtual reality (VR) augmented reality (AR) mobile platform and game decision model based on deep learning (DL), the gesture-based interaction of VR games based on Leap Motion is researched. Based on the interactive features of gestures, a set of general gesture interaction rules in VR games is established. In the meantime, according to the theoretical basis and the characteristics of VR, a set of general models of VR gesture interaction is designed, the factors affecting the efficiency of VR gesture interaction are studied, and reasonable interaction feedback is designed. By using the computer vision and image processing technology, gesture-based interaction can collect natural gestures, extract gesture features, recognize gesture indications, and respond to the user demands. Also, it can extract the basic gestures from gesture-based interaction in VR, analyze the basic features of gestures and gesture-based interaction in VR games, and describes the gesture features by mathematical vectors and sets. The research results show that the application of gesture feature design method in the game can analyze the factors affecting the interaction efficiency. Also, the usability of the gesture-based interaction designed by the gesture design method is verified by tests. Therefore, the AR&DL platform of “AR+DL” establishes a learning platform supported by DL and AR technology. The game decision model is used to describe the process of gesture-based interaction in the game, and the factors affecting the interaction efficiency are reduced, which has certain reference and guidance for VR applications using gesture-based interaction. © The Author(s) 2020.},
author_keywords={augmented reality;  Deep learning;  gesture-based interaction;  Leap Motion;  Unity3D},
document_type={Article},
source={Scopus},
}

@ARTICLE{Huerta2020836,
author={Huerta, O. and Unver, E. and Arslan, R. and Kus, A. and Allen, J.},
title={An approach to improve technical drawing using VR and AR tools},
journal={Computer-Aided Design and Applications},
year={2020},
volume={17},
number={4},
pages={836-849},
doi={10.14733/cadaps.2020.836-849},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075360494&doi=10.14733%2fcadaps.2020.836-849&partnerID=40&md5=56b5c247d78ba1293b7697130f761412},
affiliation={University of Huddersfield, United Kingdom; Uludag University, Turkey},
abstract={In this paper, the authors present the development of 3D interactive AR/VR teaching system from a design-based method to help engineering and product design students improve on critical and complex topics related to TD skills according to an international survey and as part of a broader European funded research project. This work shows that human-centred approaches can improve the understanding of students needs and facilitate the development of AR/VR technology applications for T&L within an international and multidisciplinary team. © 2020 CAD Solutions, LLC.},
author_keywords={Augmented Reality;  Teaching and Learning;  Technical Drawings;  Virtual Reality},
document_type={Article},
source={Scopus},
}

@ARTICLE{RibeiroAmantini2020,
author={Ribeiro Amantini, S.N.S. and Pascotto Montilha, A.A. and Antonelli, B.C. and Leite, K.T.M. and Rios, D. and Cruvinel, T. and Neto, N.L. and Oliveira, T.M. and Moreira Machado, M.A.A.},
title={Using augmented reality to motivate oral hygiene practice in children: Protocol for the development of a serious game},
journal={JMIR Research Protocols},
year={2020},
volume={9},
number={1},
doi={10.2196/10987},
art_number={e10987},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083209696&doi=10.2196%2f10987&partnerID=40&md5=db8f1464960d9ee986a2ddd0b74fb900},
affiliation={Department of Pediatric Dentistry, Orthodontics and Community Health, Bauru School of Dentistry, University of Sao Paulo, Bauru, Brazil; Educational Technology Section, Bauru School of Dentistry, University of Sao Paulo, Bauru, Brazil; Department of Pediatric Dentistry, Orthodontics and Community Health, Bauru School of Dentistry, University of Sao Paulo, Alameda Octávio Pinheiro Brisolla, n, Bauru, 9-75, Brazil},
abstract={Background: New technologies create possible new ways of action, interaction, and learning which is extremely relevant in the field of oral health education. There is a lack of protocol in using an immersive interactive ludic-educational interface to motivate oral hygiene practice in children by means of augmented reality. Objective: This study aims to present a protocol on the development of a serious game to motivate oral hygiene practice in children. Methods: A serious game will be designed by augmented reality techniques to improve toothbrushing effectiveness of children aged 6 to 10 years. The functional structure of this interface is activated by means of movements recognized by Kinect (Microsoft Corp). The toothbrushing technique will be available in the game, enabling the children to execute the movement in the virtual environment. By identifying errors, this game will be tailored to improve the oral health of children by correcting the technique and teaching the user the adequate toothbrushing method. A template analysis will be performed to identify barriers and facilitators in each scenario. Results: After the implementation of the virtual interactive and immersive panels, enrollment will begin and evaluations will be made by means of questionnaires distributed to participants who interact with the game. Thus, an analysis of the product efficacy will be conducted. The expected outcome will be to obtain a digital instrument to motivate oral hygiene practice and enhance health awareness in children. Conclusions: The serious game will support the prevention of oral diseases by sharing scientific research in the school environment and community. © Susy Nazaré Silva Ribeiro Nazaré Silva Ribeiro Amantini, Alexandre Alberto Pascotto Montilha, Bianca Caseiro Antonelli, Kim Tanabe Moura Leite, Daniela Rios, Thiago Cruvinel, Natalino Lourenço Neto, Thais Marchini Oliveira, Maria Aparecida Andrade Moreira Machado.},
author_keywords={Computer simulation;  Dental;  Education;  Pediatric dentistry;  User-computer interface;  Video games},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Symonenko202037,
author={Symonenko, S.V. and Zaitseva, N.V. and Osadchyi, V.V. and Osadcha, K.P. and Shmeltser, E.O.},
title={Virtual reality in foreign language training at higher educational institutions},
journal={CEUR Workshop Proceedings},
year={2020},
volume={2547},
pages={37-49},
note={cited By 8},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079570906&partnerID=40&md5=130df2381737046c4dc50b32ba6fc680},
affiliation={Dmytro Motornyi Tavria State Agrotechnological University, 18, Bogdan Khmelnitsky Ave., Melitopol, 72312, Ukraine; Bogdan Khmelnitsky Melitopol State Pedagogical University, 20, Hetmanska Str., Melitopol, 72300, Ukraine; Kryvyi Rih Metallurgical Institute, National Metallurgical Academy of Ukraine, 5, Stephana Tilhy Str., Kryvyi Rih, 50006, Ukraine},
abstract={The paper deals with the urgent problem of application of virtual reality in foreign language training. Statistical data confirms that the number of smartphone users, Internet users, including wireless Internet users, has been increasing for recent years in Ukraine and tends to grow. The coherence of quick mobile Internet access and presence of supplementary equipment enables to get trained or to self-dependently advance due to usage of virtual reality possibilities for education in the stationary classrooms, at home and in motion. Several important features of virtual reality, its advantages for education are discussed. It is noted that virtual reality is remaining a relatively new technology in language learning. Benefits from virtual reality implementation into foreign language learning and teaching are given. The aspects of immersion and gamification in foreign language learning are considered. It is emphasized that virtual reality creates necessary preconditions for motivation increasing. The results of the survey at two higher education institution as to personal experience in using VR applications for learning foreign languages are presented. Most students at both universities have indicated quite a low virtual reality application usage. Six popular virtual reality applications for foreign language learning (Mondly, VRSpeech, VR Learn English, Gold Lotus, AltSpaceVR and VirtualSpeech) are analyzed. It is stated that the most preferred VR application for foreign language learning includes detailed virtual environment for maximal immersion, high-level visual effects similar to video games, simple avatar control, thorough material selection and complete complicity level accordance of every element and aspect, affordability, helpful and unobtrusive following up. Copyright © 2020 for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).},
author_keywords={Foreign Language Learning;  Gamification;  Immersion;  Virtual Reality;  Virtual Reality Application},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{NoAuthor2020,
title={10th International Conference in Methodologies and Intelligent Systems for Technology Enhanced Learning, MIS4TEL 2020},
journal={Advances in Intelligent Systems and Computing},
year={2020},
volume={1241 AISC},
page_count={270},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089338845&partnerID=40&md5=1309347233dd094526cecf8b06a9a0f3},
abstract={The proceedings contain 26 papers. The special focus in this conference is on Methodologies and Intelligent Systems for Technology Enhanced Learning. The topics include: Preface; effects of time in virtual reality learning environments linked with materials science and engineering; lessons clustering using topics inferred by unsupervised modeling from textbooks; automatic content analysis of computer-supported collaborative inquiry-based learning using deep networks and attention mechanisms; the impact of personality, attitude and visual decision-making dashboard tools on the learning engagement of economist students; HRS-EDU: Architecture to control social robots in education; authoring interactive videos for e-learning: The elevate tool suite; early detection of gender differences in reading and writing from a smartphone-based performance support system for teachers; an assessment of students’ satisfaction in higher education; methodological guidelines to build collaborative serious games based on intelligent agents; an augmented reality-based mlearning approach to enhance learning and teaching: A case of study in guadalajara; supporting the construction of learning paths in a competency-based informatics curriculum; HEMOT®, helmet for EMOTions: A web application for children on earthquake-related emotional prevention; personalized recommender system using learners’ metacognitive reading activities; technology-enhanced learning (tel) in anaesthesia: Ultrasound simulation training for innovative locoregional anaesthesia; profiles in brain type in programming performance for non-vocational courses; Towards a gamified musical skill learning model (MUS-LM): Structural aspects; philosophical approaches to smart education and smart cities; experiences in a differential equations massive course; a protocol for simulated experimentation of automated grading systems; social video learning – creation of a reflection-based course design in teacher education.},
document_type={Conference Review},
source={Scopus},
}

@ARTICLE{Zurowski2020149,
author={Zurowski, J. and Poyade, M. and Bennett, L.},
title={Understanding the Brain and Exploring the Effects of Clinical Fatigue: From a Patient’s Perspective},
journal={Advances in Experimental Medicine and Biology},
year={2020},
volume={1262},
pages={149-181},
doi={10.1007/978-3-030-43961-3_7},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087472882&doi=10.1007%2f978-3-030-43961-3_7&partnerID=40&md5=0ca9c8174410edf4521a82ae5f50250d},
affiliation={Anatomy Facility, School of Life Sciences, College of Medical, Veterinary and Life Sciences, University of Glasgow, Glasgow, United Kingdom; School of Simulation and Visualisation, The Glasgow School of Art, Glasgow, United Kingdom; Institute of Infection, Immunity and Inflammation, College of Medical, Veterinary and Life Sciences, University of Glasgow, Glasgow, United Kingdom},
abstract={Rheumatic and musculoskeletal diseases are a group of devastating autoimmune disorders that all share a common debilitating symptom fatigue. Fatigue is not widely understood and is often underrepresented in treatment regimes. Fatigue is the least successfully managed symptom of these conditions; however, it can often be the one of the greatest impairments. Augmented reality (AR) enhances a person’s reality showing a hybrid environment where real and virtual objects coexist. Currently educational AR applications are saturating the application market, as they have shown great potential for increasing comprehension and understanding of complex concepts. AR expands user engagement by enhancing the learner’s enjoyment and enriching their learning environment. This research explores the development and subsequent effect of an AR application on education around fatigue and basic neuroanatomy within the general population. The application was created using medical scan dataset, a variety of 3D modelling software and a game engine to create a functional and interactive augmented application. The application explores the effects of fatigue on a person’s daily life while also laying a foundation of basic neuroanatomy. A pilot test conducted on 14 participants (8 males, 5 females and 1 other), with ages ranged 16–64 (4 form range 16 to 24, 5 from range 25 to 34, 1 from range 35 to 44, 3 from range 45 to 54, 1 from 55 to 64), shows the application is highly usable, increases understanding of basic neuroanatomical concepts and has the potential to improve understanding of fatigue. Nonetheless, further development and testing of the application are imperative so that we can gain a better understanding of the usability of the application with wider audiences. Future developments will aim to further aid knowledge acquisition and enhance understanding of fatigue, a complex and widely misunderstood concept. © 2020, Springer Nature Switzerland AG.},
author_keywords={Augmented reality;  Patient perspective;  Public engagement;  Rheumatic fatigue},
document_type={Book Chapter},
source={Scopus},
}

@ARTICLE{Šulek2020183,
author={Šulek, N. and Poyade, M. and Ferguson, E.},
title={A Methodology for Visualising Growth and Development of the Human Temporal Bone},
journal={Advances in Experimental Medicine and Biology},
year={2020},
volume={1262},
pages={183-202},
doi={10.1007/978-3-030-43961-3_8},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087474324&doi=10.1007%2f978-3-030-43961-3_8&partnerID=40&md5=836e96def97c76476451b44a79347f36},
affiliation={School of Simulation and Visualisation, The Glasgow School of Art, Glasgow, United Kingdom; Anatomy Facility, School of Life Sciences, College of Medical, Veterinary and Life Sciences, University of Glasgow, Glasgow, United Kingdom},
abstract={This chapter presents a methodological framework which could be used to produce accurate anatomical 3D models and animations of the developing skull, with a focus on the temporal bone. Initial modelling is based on information from core texts and visual references, before optimising these models for use in interactive real-time applications. A series of 3D modelling and animation workflows typically used in computer games and animation industry were tested and compared. Workflows most suitable for the production of a 3D visualisation of the developing temporal bone were documented in detail and used to produce the final 3D models. 3D models of the developing temporal bone were then implemented in an interactive mobile application, which allowed users to explore the 3D models on their Android mobile device and use augmented reality to enhance real-world information. Results of tests conducted in this research suggest that 3D modelling workflows which mimic the processes occurring during development of the temporal bone are most suitable for producing realistic 3D models. Animation workflows tested in this research have all shown potential to produce morphing animations of the developing temporal bone. The significant time required to create deformation setups and animations themselves however suggests that using scripting to automate these workflows would increase their usability in projects with a limited timeframe. © 2020, Springer Nature Switzerland AG.},
author_keywords={Anatomical 3D model;  Augmented reality;  Digital teaching tool;  Interactive visualisation;  Mobile application;  Temporal bone development},
document_type={Book Chapter},
source={Scopus},
}

@CONFERENCE{Syal20202720,
author={Syal, S. and Mathew, R.},
title={Threats Faced by Mixed Reality and Countermeasures},
journal={Procedia Computer Science},
year={2020},
volume={171},
pages={2720-2728},
doi={10.1016/j.procs.2020.04.295},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086630253&doi=10.1016%2fj.procs.2020.04.295&partnerID=40&md5=e66e9b1297c29997e0f18beaf041391c},
affiliation={IT Department, Mukesh Patel School of Technology Management and Engineering, Mumbai, 400056, India},
abstract={Mixed Reality, MR, is defined as the integration of real and virtual worlds to create an environment which allows co-existing of physical and digital objects enabling users to interact with both. MR is a cross of reality, virtual reality including augmented reality and augmented virtuality. With the advent of wireless technologies and ever-increasing integration of the virtual world with the real world, MR has gained more significance in the last 5 years. Also, because of its real-life applications in education, gaming, entertainment, medicine, and military. But no technology comes without risks and shortcomings. Thus, MR also faces many threats and attacks which are broadly classified into 5 types namely, input, output, data, user interaction and device protection some of which include latency, data collection, physical device threats, user threats etc. This paper presents a comprehensive analysis of these threats on MR and solutions to mitigate the effects of it. © 2020 The Authors. Published by Elsevier B.V.},
author_keywords={Augmented Reality;  HMDs;  Input protection;  Latent Data;  Mixed Reality;  Non-Repudiation;  RAPPOR},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Martinez2020186,
author={Martinez, K. and Menéndez-Menéndez, M.I. and Bustillo, A.},
title={Considering user experience parameters in the evaluation of vr serious games},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2020},
volume={12242 LNCS},
pages={186-193},
doi={10.1007/978-3-030-58465-8_14},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091163504&doi=10.1007%2f978-3-030-58465-8_14&partnerID=40&md5=076beae7b36d1f8d7259009519a2024e},
affiliation={Department of History, Geography and Communication, University of Burgos, Burgos, Spain; Department of Civil Engineering, University of Burgos, Burgos, Spain},
abstract={Serious Games for Virtual Reality (SG-VR) is still a new subject that needs to be explored. Achieving the optimal fun and learning results depends on the application of the most suitable metrics. Virtual Reality environments offer great capabilities but at the same time make difficult to record User Experience (UX) to improve it. Moreover, the continuous evolution of Virtual Reality technologies and video game industry tendencies constantly change these metrics. This paper studies the Mechanics, Dynamics and Aesthetic (MDA) framework and User Experience metrics to develop new ones for SG-VR. These new parameters are focused on the intrinsic motivations the players need so they engage with the game. However, the development team budget must be taken into account, since it limits items and interactions but still have to aim to the learning goals. New VR metrics will be 1) UX features: chosen VR headsets, training interactions tutorials to learn control and interactive adaptions to avoid VR inconveniences; and 2) MDA features: exclusive VR aesthetical elements and its interactions. © Springer Nature Switzerland AG 2020.},
author_keywords={Game design;  Game evaluation;  Serious games;  Virtual reality},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Llerena-Izquierdo2020593,
author={Llerena-Izquierdo, J. and Cedeño-Gonzabay, L.},
title={Photogrammetry and Augmented Reality to Promote the Religious Cultural Heritage of San Pedro Cathedral in Guayaquil, Ecuador},
journal={Communications in Computer and Information Science},
year={2020},
volume={1194 CCIS},
pages={593-606},
doi={10.1007/978-3-030-42520-3_47},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082384127&doi=10.1007%2f978-3-030-42520-3_47&partnerID=40&md5=da6bd49e31445c60d457fbc45a3e5bbc},
affiliation={Universidad Politécnica Salesiana, Guayaquil, Ecuador},
abstract={This innovative proposal combines the use of the biggest reality and photogrammetry for modeling structures in digital format. It addresses two themes the use of technologies for the restoration of heritage structures in the event of a fortuitous event and the use of a technological tool that allows the dissemination of the religious cultural heritage of the Cathedral of San Pedro in Guayaquil, Ecuador to national and foreign tourists, the interest in knowing a little more about the history of culture and art is encouraged when effective conservation strategies are involved and even more by incorporating the use of technology in smart devices. This allows easy quick access with proper visualization, the use of photogrammetry technique is adopted in several museums around the world and allow tourists to learn about a specific topic in a didactic and interactive way. Another technique is the increasing reality technique, this technique incorporates data in virtual form links on the web audio video, video text or other multimedia through markers to objects serving as a tool that encourages learning more about different topics. The one chosen in this work is the religious cultural heritage. The interface developed in Unity, and the use of the Vuforia development kit, through the mobile application “My Cathedral”, allows users to access relevant historical information, visualizing the photogrammetric images in increasing reality, precisely on the most representative objects of the cathedral of San Pedro in Guayaquil. © 2020, Springer Nature Switzerland AG.},
author_keywords={Augmented reality;  Photogrammetry;  Religious cultural heritage},
document_type={Conference Paper},
source={Scopus},
}
