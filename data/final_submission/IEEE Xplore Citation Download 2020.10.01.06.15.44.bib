@InProceedings{Martin2020,
author={Martin, S.
and Parra, G.
and Cubillo, J.
and Quintana, B.
and Gil, R.
and Perez, C.
and Castro, M.},
title={Design of an Augmented Reality System for Immersive Learning of Digital Electronic},
booktitle={2020 XIV Technologies Applied to Electronics Teaching Conference (TAEE)},
year={2020},
pages={1-6},
keywords={augmented reality},
keywords={computer aided instruction},
keywords={electronic engineering computing},
keywords={electronic engineering education},
keywords={interactive systems},
keywords={mobile computing},
keywords={mobile learning},
keywords={multimedia systems},
keywords={augmented reality system},
keywords={immersive learning},
keywords={mobile applications},
keywords={digital electronics},
keywords={interactive app},
keywords={iOS},
keywords={digital circuits},
keywords={Education},
keywords={Logic gates},
keywords={Tools},
keywords={Cameras},
keywords={Libraries},
keywords={Mobile Application},
abstract={This article describes the development of two mobile applications for learning Digital Electronics. The first application is an interactive app for iOS where you can study the different digital circuits, and which will serve as the basis for the second: a game of questions in augmented reality.}
}

@InProceedings{Harrington2020a,
author={Harrington, M. C. R.},
title={Connecting User Experience to Learning in an Evaluation of an Immersive, Interactive, Multimodal Augmented Reality Virtual Diorama in a Natural History Museum \& the Importance of Story},
booktitle={2020 6th International Conference of the Immersive Learning Research Network (iLRN)},
year={2020},
pages={70-78},
keywords={augmented reality},
keywords={bioacoustics},
keywords={computer aided instruction},
keywords={data visualisation},
keywords={history},
keywords={human computer interaction},
keywords={learning (artificial intelligence)},
keywords={museums},
keywords={user interfaces},
keywords={virtual reality},
keywords={user experience},
keywords={natural history museum},
keywords={July 2019 study},
keywords={immersive, interactive, multimodal augmented reality application},
keywords={AR Perpetual Garden App},
keywords={immersive multisensory experience},
keywords={scientifically na{\~A}{\textasciimacron}ve visitors},
keywords={virtual diorama},
keywords={data visualization},
keywords={springtime woodland understory},
keywords={multimodal information},
keywords={user interface},
keywords={audio story},
keywords={interactive access},
keywords={AR app},
keywords={AR experience},
keywords={perceived learning},
keywords={actual learning outcomes},
keywords={Forestry},
keywords={Biomedical acoustics},
keywords={Three-dimensional displays},
keywords={Games},
keywords={immersive},
keywords={information fidelity},
keywords={informal learning},
keywords={interactive},
keywords={multimodal},
keywords={narrative},
keywords={photorealistic},
keywords={place illusion},
keywords={presence},
keywords={virtual dioramas},
abstract={Reported are the findings of user experience and learning outcomes from a July 2019 study of an immersive, interactive, multimodal augmented reality (AR) application, used in the context of a museum. The AR Perpetual Garden App is unique in creating an immersive multisensory experience of data. It allowed scientifically na{\~A}{\textasciimacron}ve visitors to walk into a virtual diorama constructed as a data visualization of a springtime woodland understory and interact with multimodal information directly through their senses. The user interface comprised of two different AR data visualization scenarios reinforced with data based ambient bioacoustics, an audio story of the curator's narrative, and interactive access to plant facts. While actual learning and dwell times were the same between the AR app and the control condition, the AR experience received higher ratings on perceived learning. The AR interface design features of "Story" and "Plant Info" showed significant correlations with actual learning outcomes, while "Ease of Use" and "3D Plants" showed significant correlations with perceived learning. As such, designers and developers of AR apps can generalize these findings to inform future designs.}
}

@InProceedings{Bhatti2020,
author={Bhatti, Z.
and Bibi, M.
and Shabbir, N.},
title={Augmented Reality based Multimedia Learning for Dyslexic Children},
booktitle={2020 3rd International Conference on Computing, Mathematics and Engineering Technologies (iCoMET)},
year={2020},
pages={1-7},
keywords={augmented reality},
keywords={cognition},
keywords={computer aided instruction},
keywords={human computer interaction},
keywords={medical disorders},
keywords={multimedia computing},
keywords={neurophysiology},
keywords={dyslexic children},
keywords={special children},
keywords={cognitive learning},
keywords={interactive augmented reality based multimedia application},
keywords={mental brain related syndromes},
keywords={interactive multimedia learning app},
keywords={heuristic model},
keywords={visual technology},
keywords={virtual objects},
keywords={Three-dimensional displays},
keywords={Education},
keywords={Solid modeling},
keywords={Shape},
keywords={Real-time systems},
keywords={Dyslexia},
keywords={Multimedia Learning},
keywords={Serious Games},
abstract={Augmented reality is a visual technology which combines virtual objects into the real environment, in real time. In this research work, a heuristic model of multimedia learning would be developed using Augmented Reality for a type of neurological disorder known as Dyslexia. Dyslexia is complex mental brain related syndromes, affecting the children in various ways including verbal and nonverbal communications, social interactions, understanding instructions, reading, writing, learning, problems, etc. The use of interactive Augmented Reality based multimedia application to facilitate and provide pedagogy for such type of special children would ascertain a unique and new dimension of treating and helping such young hearts in overcoming their disabilities in a very fun and easy way. The research encompasses designing a framework based on cognitive learning for interactive multimedia learning app using augmented reality technology, that would be centric to autism effected children's and would enable them to interact with such system.}
}

@InProceedings{Pérez-Muñóz2020,
author={P{\~A}{\textcopyright}rez-Mu{\~A}{\textpm}{\~A}{\textthreesuperior}z, A.
and Castro-Idrovo, D.
and Robles-Bykbaev, Y.
and Robles-Bykbaev, V.
and Pes{\~A}{\textexclamdown}ntez-Avil{\~A}{\textcopyright}s, F.},
title={An interactive application based on augmented reality and rules-based reasoning to support educational activities of high school students},
booktitle={2020 IEEE World Conference on Engineering Education (EDUNINE)},
year={2020},
pages={1-5},
keywords={augmented reality},
keywords={computer aided instruction},
keywords={decision support systems},
keywords={mathematics computing},
keywords={logical skills},
keywords={mathematical skills},
keywords={educational tool},
keywords={interactive exercises},
keywords={Pythagorean theorem},
keywords={decision support system},
keywords={mathematics},
keywords={minimum proficiency levels},
keywords={UNESCO},
keywords={United Nations Educational, Scientific and Cultural Organization},
keywords={high school students},
keywords={support educational activities},
keywords={rules-based reasoning},
keywords={interactive application},
keywords={Tools},
keywords={Expert systems},
keywords={Three-dimensional displays},
keywords={Training},
keywords={Support Decision System},
keywords={Children and youth},
abstract={According to the latest estimates of the United Nations Educational, Scientific and Cultural Organization (UNESCO), in 2017, more than 617 million children and adolescents were not achieving minimum proficiency levels regarding reading and mathematics. In this line, it is essential for children and youth developing mainstays for solving problems and adequately understanding the information around them. These mainstays are strongly related to logical and mathematical skills. Therefore, in this paper, we present an educational tool that uses augmented reality to provide interactive exercises for the following areas: functions, areas, volumes, angles, and the Pythagorean theorem. Similarly, our proposal incorporates a decision support system that suggests to a given student what activities and exercises must solve. The validation process of the tools was carried out with the support of 179 volunteers.}
}

@InProceedings{Rosni2020,
author={Rosni, N. S.
and Kadir, Z. A.
and Noor, M. N. M. Mohamed
and Rahman, Z. H. Abdul
and Bakar, N. A.},
title={Development of mobile markerless augmented reality for cardiovascular system in anatomy and physiology courses in physiotherapy education},
booktitle={2020 14th International Conference on Ubiquitous Information Management and Communication (IMCOM)},
year={2020},
pages={1-5},
keywords={augmented reality},
keywords={biomedical education},
keywords={biomedical MRI},
keywords={cardiovascular system},
keywords={computer aided instruction},
keywords={data visualisation},
keywords={educational courses},
keywords={further education},
keywords={mobile learning},
keywords={physiology},
keywords={solid modelling},
keywords={anatomy courses},
keywords={ARCore platform},
keywords={MRI images},
keywords={markerless AR content},
keywords={undergraduate physiotherapy program},
keywords={learning outcome syllabus},
keywords={three-dimensional content},
keywords={mobile markerless augmented reality},
keywords={experienced-learning approach application},
keywords={physiotherapy education},
keywords={physiology courses},
keywords={flexible learning process},
keywords={innovative learning process},
keywords={3D unity authoring tool},
keywords={AR content creation},
keywords={systematic search strategy},
keywords={Three-dimensional displays},
keywords={Search problems},
keywords={Education},
keywords={Systematics},
keywords={Solid modeling},
keywords={markerless AR},
keywords={ARCore},
keywords={anatomy and physiology},
abstract={This paper focuses on the development of markerless Augmented Reality (AR) using ARCore platform, where interactive three-dimensional (3D) content was designed and developed based on the learning outcome syllabus to enhance the visualization and understanding of the anatomy and physiology for cardiovascular system topic. Currently, learning method is based on 2D images and slides, plastic models and cadavers have to deal with students' experience issues such as lack of interactive, uneasy feeling with dead body and cadavers storing and donation. Therefore, more advances using technology such as Augmented Reality (AR) in learning method are needed to overcome the current gap and enhance the students' learning. Thus, this study aims to develop markerless AR specifically focus on the cardiovascular system for undergraduate physiotherapy program at UniKL, RCMP. In this study, we describe a method used to create markerless AR content using 3D data from MRI images and 3D unity as an authoring tool. We present three processes, where the first design consideration based on author's previous works derived from systematic search strategy were outlined, the second 3D model was developed using a real object and subsequently converted to an AR asset that can be linked to a unique markerless using ARCore platform and the third AR content creation using 3D unity authoring tool. This application provides a better visualization for the anatomical parts to support for an innovative and flexible learning process. We have successfully analyzed the design consideration using a systematic search strategy and developed the markerless AR specifically for cardiovascular system in anatomy and physiology courses. This study has contributed to knowledge in design and development of AR used in physiotherapy education. Therefore, this will be a step forward to an exploration of design-based research for an AR benefit in experienced-learning approach application.}
}

@InProceedings{Kenoui2020,
author={Kenoui, M.
and Mehdi, M. A.},
title={Teach-Me DNA: an Interactive Course Using Voice Output in an Augmented Reality System},
booktitle={020 1st International Conference on Communications, Control Systems and Signal Processing (CCSSP)},
year={2020},
pages={260-265},
keywords={augmented reality},
keywords={bioinformatics},
keywords={biomedical education},
keywords={computer aided instruction},
keywords={educational courses},
keywords={interactive systems},
keywords={speech synthesis},
keywords={speech-based user interfaces},
keywords={teaching},
keywords={interactive course},
keywords={voice output},
keywords={augmented reality system},
keywords={interactive system},
keywords={chatbot technology},
keywords={bidirectional communication},
keywords={conversational agent},
keywords={3D virtual objects},
keywords={voice commands},
keywords={text to speech service},
keywords={IBM Watson platform},
keywords={Speech Synthesis Markup Language},
keywords={natural-sounding speech},
keywords={DNA molecule},
keywords={biological course},
keywords={TeachMe DNA},
keywords={Three-dimensional displays},
keywords={Speech recognition},
keywords={Education},
keywords={DNA},
keywords={Real-time systems},
keywords={Tools},
keywords={HCI},
keywords={Natural Interaction},
keywords={Pedagogical Agent},
keywords={Chatbot},
keywords={IBM Watson},
keywords={Cloud Application},
keywords={Biomedical Course},
abstract={In this paper, we present an interactive system partly based on voice output in an augmented reality environment. Using a chatbot technology, this system allows the user to engage bidirectional communication with a conversational agent. The present system builds upon our previous work in which the user interacts with 3D virtual objects via voice commands. We describe, in the current document, how we integrate speech output using the Text to Speech Service (TTS API) available on the IBM Watson platform, the goal being to obtain an even more interactive system. We also employ Speech Synthesis Markup Language (SSML) to control some features of the natural-sounding speech thus produced. Moreover, we developed Teach-Me DNA, an interactive application that gives the user (pupil, student) the opportunity to learn and/or revise the DNA molecule's basics as a part of a biological course. On one hand, and via voice inputs the user is simply able to perform 3D selections and 3D manipulations of the molecule and its several components in order to learn about their 3D features and properties, this first part dealing with the vocal entries was fully documented in a previous work. On another hand, TeachMe DNA is here enriched by producing a natural speech when reacting to the user's requests. In fact, an agent's voice is used to respond in real time to student's questions. Definitions and/or explanations are thus given in a very natural way which might immerse more significantly the student in the proposed learning environment based on augmented reality technology.}
}

@InProceedings{Chung2020,
author={Chung, C.-Y.
and Hsiao, I.-H.},
title={Computational Thinking in Augmented Reality: An Investigation of Collaborative Debugging Practices},
booktitle={2020 6th International Conference of the Immersive Learning Research Network (iLRN)},
year={2020},
pages={54-61},
keywords={augmented reality},
keywords={computer aided instruction},
keywords={computer science education},
keywords={data visualisation},
keywords={program debugging},
keywords={virtual reality},
keywords={mobile AR-enabled application},
keywords={programming debugging task},
keywords={support program editing \& CT learning},
keywords={controlled laboratory study},
keywords={AR support},
keywords={collaborative debugging practices},
keywords={affordance},
keywords={abstract concepts},
keywords={user-content interaction},
keywords={abstract idea},
keywords={invisible phenomena},
keywords={conceptual Computational Thinking},
keywords={algorithm design},
keywords={related programming concepts},
keywords={immersive technology},
keywords={quantitative evidence},
keywords={empirical evidence},
keywords={AR-supported Computer Science discipline-based},
keywords={Visualization},
keywords={Task analysis},
keywords={Debugging},
keywords={Programming profession},
keywords={Problem-solving},
keywords={Computed tomography},
keywords={debugging practices},
keywords={learn to code},
keywords={computational thinking},
keywords={collaborative learning},
keywords={mobile app},
abstract={The uniqueness of Augmented Reality (AR) is its affordance to support learning abstract concepts by rich information, visualization and the integration of user-content interaction. Research has shown that abstract idea and invisible phenomena can be learned better with the support of AR. However, high complexity and conceptual Computational Thinking (CT), such as algorithm design and related programming concepts, are rarely studied empirically in the intersection with immersive technology. This study is aimed at addressing this issue and providing a piece of quantitative and empirical evidence to AR-supported Computer Science discipline-based learning. We designed a mobile AR-enabled application based on a CT framework and related AR affordances in the literature. This app can contextualize a programming debugging task and support program editing \& CT learning. A controlled laboratory study was designed and conducted. The result of statistical analyses shows that participants with the AR support made better quality of programs with lower errors and less amount of code edits, compared to those without the AR support.}
}

@InProceedings{Liu2020,
author={Liu, C.
and Wu, S.
and Cai, S.},
title={An AR-Based Case Study of Using Textual and Collaborative Scaffolding for Students with Different Self-Efficacy to Learn Lever Principles},
booktitle={2020 6th International Conference of the Immersive Learning Research Network (iLRN)},
year={2020},
pages={9-15},
keywords={augmented reality},
keywords={computer aided instruction},
keywords={educational courses},
keywords={teaching},
keywords={self-efficacy},
keywords={lever principle},
keywords={learning results},
keywords={teaching strategies},
keywords={personalized teaching},
keywords={collaborative scaffolding},
keywords={elementary school science classes},
keywords={cognitive load},
keywords={AR teaching},
keywords={low self-efficacy},
keywords={deep learning},
keywords={AR science curriculum},
keywords={textual scaffolding},
keywords={scaffolding teaching strategies},
keywords={students learning conceptions},
keywords={Collaboration},
keywords={Task analysis},
keywords={Instruments},
keywords={Educational technology},
keywords={Tools},
keywords={Real-time systems},
keywords={scaffolding},
keywords={learning conceptions},
abstract={With the deepening application of augmented reality (AR) in education, researches pay more attention to the evaluation of learning results rather than consider how to use teaching strategies to support personalized teaching. This study developed an AR science curriculum incorporating textual and collaborative scaffolding, and taught it in elementary school science classes to help students learn about scientific knowledge of lever principle. To explore the effects of different self-efficacy and scaffolding teaching strategies on students' learning conceptions and cognitive load, a two times two experiment was conducted on an elementary school. The results show that the use of textual and collaborative scaffolding in AR teaching can help students with low self-efficacy to pay attention to the conceptions of deep learning and effectively reduce the cognitive load of students.}
}

@InProceedings{Pittman2020,
author={Pittman, C.
and LaViola, J. J.},
title={PhyAR: Determining the Utility of Augmented Reality for Physics Education in the Classroom},
booktitle={2020 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)},
year={2020},
pages={760-761},
keywords={Augmented reality},
keywords={Physics education},
keywords={Three-dimensional displays},
keywords={Prototypes},
keywords={Visualization},
keywords={Magnetometers},
keywords={Qualitative Interview},
abstract={Physics is frequently cited as a difficult roadblock and hindrance to retention in STEM majors. In this paper, we present the results of a study exploring the potential utility and use cases of augmented reality in secondary and post secondary physics courses. To gather meaningful information, we developed PhyAR, prototype physics education application in augmented reality. We collected feedback and opinions from a qualitative study of university students with STEM backgrounds. Our findings point towards a clear desire to see the use of more interactive 3D AR content in physics courses.}
}

@Article{Cen2020,
author={Cen, L.
and Ruta, D.
and Qassem, L. M. M. S. Al
and Ng, J.},
title={Augmented Immersive Reality (AIR) for Improved Learning Performance: A Quantitative Evaluation},
journal={IEEE Transactions on Learning Technologies},
year={2020},
volume={13},
number={2},
pages={283-296},
keywords={augmented reality},
keywords={chemistry computing},
keywords={computer aided instruction},
keywords={data visualisation},
keywords={mobile learning},
keywords={immersive 3D visualization},
keywords={AIR-EDUTECH},
keywords={AIR technology},
keywords={interactive experience},
keywords={basic chemical reactions},
keywords={visual interaction},
keywords={molecular chemistry},
keywords={AIR features},
keywords={AIR-based educational mobile system},
keywords={GPS data},
keywords={computer-generated components},
keywords={technology-enhanced learning},
keywords={augmented immersive reality},
keywords={Education},
keywords={Chemicals},
keywords={Three-dimensional displays},
keywords={Cameras},
keywords={Visualization},
keywords={Statistical analysis},
keywords={Augmented Reality (AR)},
keywords={Augmented Immersive Reality (AIR)},
keywords={education data mining.},
abstract={Technology-enhanced learning has attracted increasing attention of educational community focused on improvement of traditional classroom learning. Augmented immersive reality (AIR) technologies enhance users' perception of reality by augmenting it with computer-generated components such as audio, video, 2/3-D graphics, GPS data, etc. The AIR introduces new dimensions of learning experience that ensure better attention, focus, and entertainment, thereby boosting students' motivation and attainment. This work presents an award winning AIR-based educational mobile system, code-named AIR-EDUTECH, that was developed to help high school students learn chemistry. The AIR-EDUTECH introduced new AIR features to help students better understand and learn basic concepts of molecular chemistry. It offers immersive 3D visualization and visual interaction with the examined structures that provides a broader and more retentive knowledge and improves intuition around forming basic chemical reactions. The system was introduced and tested in a field study with 45 students in the 11th grade chemistry class, and its impact was evaluated by the formal assessment quiz along with the feedback from survey conducted after the trial. Collected data have been subjected to an in-depth multi-modal quantitative analysis that revealed that AIR-EDUTECH stimulated significant improvements in understanding and retention of the taught content as well as turned learning chemistry into a fun, interesting and interactive experience. It also uncovered a hidden structure of taught knowledge dependencies and highlighted the role that AIR technology could play in reinforcing the retention of critical knowledge that may otherwise widen student knowledge gaps.},
issn={1939-1382},
doi={10.1109/TLT.2019.2937525}
}

@InProceedings{Rane2020,
author={Rane, A.
and John, V. N.
and Murthy, S.},
title={GeoMaps: An interactive application to enhance map comprehension skills of students},
booktitle={2020 IEEE 20th International Conference on Advanced Learning Technologies (ICALT)},
year={2020},
pages={254-258},
keywords={augmented reality},
keywords={cartography},
keywords={computer aided instruction},
keywords={data visualisation},
keywords={geographic information systems},
keywords={geography},
keywords={user interfaces},
keywords={visual databases},
keywords={GeoMaps},
keywords={interactive application},
keywords={map comprehension skills},
keywords={spatial thinking},
keywords={reasoning},
keywords={geographical maps},
keywords={crucial skill},
keywords={students},
keywords={geographical problems},
keywords={paper-based maps},
keywords={sophisticated technology-based map applications},
keywords={interactive maps},
keywords={Augmented reality-based maps},
keywords={3D view maps},
keywords={authentic geography problems},
keywords={multiple maps},
keywords={Rivers},
keywords={Tools},
keywords={Three-dimensional displays},
keywords={Cognition},
keywords={Education},
keywords={Satellites},
keywords={component},
keywords={spatial skills},
keywords={maps},
abstract={Geography education requires the use of spatial thinking and reasoning to understand and interpret maps. Effective usage of geographical maps is a crucial skill to be developed for students. However, it has been found that students' ability to use maps to describe and analyze natural phenomena to find solutions to geographical problems is inadequate. One reason for this shortcoming is difficulty in comprehension of maps given in textbooks or reference books, which is preliminarily due to inherent limitations with paper-based maps. Sophisticated technology-based map applications are available like interactive maps, Augmented reality-based maps, 3D view maps, etc. But there are few learning activities around these, leaving the students confused as to how these can be used in different contexts to solve problems. GeoMaps is an interactive application to improve map comprehension skills of students, which includes ability to identify, correlate and synthesize information from multiple perspectives in a map. The activities in GeoMaps are based on authentic geography problems. To solve these problems, students can overlay multiple maps to correlate various features, and choose corresponding filters to focus on particular information. The preliminary feedback from potential users is promising, encouraging us to explore this idea at a broader context.},
issn={2161-377X}
}

@InProceedings{Harrington2020b,
author={Harrington, M. C. R.},
title={Observation of Presence in an Ecologically Valid Ethnographic Study Using an lmmersive Augmented Reality Virtual Diorama Application},
booktitle={2020 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)},
year={2020},
pages={812-813},
keywords={Conferences},
keywords={Virtual reality},
keywords={Three-dimensional displays},
keywords={User interfaces},
keywords={Augmented reality},
keywords={bioacoustics},
keywords={data visualization},
keywords={embodiment},
keywords={immersive},
keywords={informal learning},
keywords={interactive},
keywords={multimodal},
keywords={museums},
keywords={presence},
abstract={The main research question is centered on the usefulness of immersive Augmented Reality (AR) applications for informal learning activities. Can users experience presence {\^a}?? or a sense of being there - when using AR apps? To begin to approach this question an ethnographic study was conducted in July, 2019 in a museum with 56 volunteer participants to document behavior and measure learning, attitudes, and emotional outcomes of an AR application. Reported are the preliminary results of behavior indicative of presence observed in the study, and insights gained that are useful in understanding future designs.}
}

@InProceedings{Jakl2020,
author={Jakl, A.
and Lienhart, A.
and Baumann, C.
and Jalaeefar, A.
and Schlager, A.
and Sch{\~A}{\textparagraph}ffer, L.
and Bruckner, F.},
title={Enlightening Patients with Augmented Reality},
booktitle={2020 IEEE Conference on Virtual Reality and 3D User Interfaces (VR)},
year={2020},
pages={195-203},
keywords={augmented reality},
keywords={computer aided instruction},
keywords={eye},
keywords={medical computing},
keywords={surgery},
keywords={virtual reality},
keywords={EPAR},
keywords={patient education},
keywords={medical procedures},
keywords={enlightening patients with augmented reality},
keywords={interactive storytelling},
keywords={Education},
keywords={Three-dimensional displays},
keywords={Human computer interaction},
keywords={Usability},
keywords={Prototypes},
keywords={Human-centered computing},
keywords={Mixed / augmented reality Human-centered computing},
keywords={Interface design prototyping Human-centered computing},
keywords={Interaction design theory},
keywords={concepts and paradigms Human-centered computing},
keywords={Usability testing},
abstract={Enlightening Patients with Augmented Reality (EPAR) enhances patient education with new possibilities offered by Augmented Reality. Medical procedures are becoming increasingly complex and printed information sheets are often hard to understand for patients. EPAR developed an augmented reality prototype that helps patients with strabismus to better understand the processes of examinations and eye surgeries. By means of interactive storytelling, three identified target groups based on user personas were able to adjust the level of information transfer based on their interests. We performed a 2-phase evaluation with a total of 24 test subjects, resulting in a final system usability score of 80.0. For interaction prompts concerning virtual 3D content, visual highlights were considered to be sufficient. Overall, participants thought that an AR system as a complementary tool could lead to a better understanding of medical procedures.},
issn={2642-5254}
}

@InProceedings{Wang2020,
author={Wang, G.
and Lu, Z.
and Zhang, Y.
and Qian, Y.
and Zhao, H.
and Liu, D.},
title={Application of Mixed Reality Technology in Education with the case of a Huangmei Opera Cultural Education System},
booktitle={2020 IEEE 2nd International Conference on Computer Science and Educational Informatization (CSEI)},
year={2020},
pages={301-305},
keywords={augmented reality},
keywords={computer aided instruction},
keywords={computer games},
keywords={museums},
keywords={virtual reality},
keywords={mainstream mixed reality hardware platform},
keywords={virtual museums},
keywords={Huangmei Opera cultural educational system},
keywords={virtual world objects},
keywords={Huangmei Opera cultural education system},
keywords={mixed reality technology},
keywords={Cultural differences},
keywords={Solid modeling},
keywords={Spatial databases},
keywords={Education},
keywords={Three-dimensional displays},
keywords={Mathematical model},
keywords={Mixed Reality},
keywords={Hololens},
keywords={Huangmei opera},
keywords={Unity},
keywords={Virtual museum},
keywords={Cultural Education},
abstract={Mixed reality is an emerging technology that allows virtual world objects and real world objects to coexist and interact in real time. Its positioning lies between virtual reality and augmented reality, providing users with an immersive experience of combining virtual and real. In this article, we take the Huangmei Opera cultural educational system as an example, and use the current mainstream mixed reality hardware platform and its supporting content production softwares to implement interactive games and virtual museums about Huangmei Opera culture and knowledge. And to explore the application of mixed reality in education.}
}

@Article{Keighrey2020,
author={Keighrey, C.
and Flynn, R.
and Murray, S.
and Murray, N.},
title={A Physiology-based QoE Comparison of Interactive Augmented Reality, Virtual Reality and Tablet-based Applications},
journal={IEEE Transactions on Multimedia},
year={2020},
pages={1-1},
keywords={Quality of experience},
keywords={Semantics},
keywords={Multimedia systems},
keywords={Augmented reality},
keywords={Biomedical monitoring},
keywords={virtual reality},
keywords={physiological},
keywords={speech language pathology},
keywords={aphasia},
abstract={The availability of affordable head-mounted display technology has facilitated new, potentially more immersive, interactive multimedia experiences. These technologies were traditionally focused on entertainment; however, academia and industry are now exploring applications in other domains such as health, learning and training. Key to the success of these new multimedia experiences is the understanding of a user's perceived quality of experience (QoE). Subjective user ratings have been the primary mechanism to capture insights into a user's experience. Such ratings have generally been captured post experience and reflected using a mean opinion score (MOS). However, user perception is multifactorial and subjective ratings alone do not express the true measure of an experience. As a result, recent efforts to capture QoE have included exploring the use of implicit metrics (e.g. physiological measures). This article presents the results of an experimental QoE evaluation and comparison of immersive applications delivered across three multimedia platforms. The platforms compared were augmented reality, tablet and virtual reality. The QoE methodology employed considered explicit (post-test questionnaire) and implicit (heart rate and electrodermal activity) assessment methods. The results indicate comparatively higher levels of QoE for users of the augmented reality and tablet platforms.},
issn={1941-0077},
doi={10.1109/TMM.2020.2982046}
}

@Article{Chiu2020,
author={Chiu, P.
and Chang, J.
and Lee, M.
and Chen, C.
and Lee, D.},
title={Enabling Intelligent Environment by the Design of Emotionally Aware Virtual Assistant: A Case of Smart Campus},
journal={IEEE Access},
year={2020},
volume={8},
pages={62032-62041},
keywords={artificial intelligence},
keywords={Big Data},
keywords={cloud computing},
keywords={data analysis},
keywords={emotion recognition},
keywords={interactive systems},
keywords={Internet},
keywords={mobile computing},
keywords={natural language interfaces},
keywords={natural language processing},
keywords={neural nets},
keywords={user interfaces},
keywords={input sentence},
keywords={complex web pages},
keywords={app menus},
keywords={intelligent environment},
keywords={emotionally aware virtual assistant},
keywords={Internet of Things},
keywords={big data analysis},
keywords={cloud applications},
keywords={broad prospects},
keywords={smart homes},
keywords={autonomous vehicles},
keywords={smart cities},
keywords={smart campus},
keywords={university campus app},
keywords={deep neural network},
keywords={emotionally aware campus virtual assistant},
keywords={Chinese word embedding},
keywords={robot dialogue system},
keywords={dialogue tolerance},
keywords={semantic interpretation},
keywords={emotion identification},
keywords={Chinese sentence},
keywords={clauses},
keywords={emotional keywords},
keywords={expert system},
keywords={convolutional neural network},
keywords={artificial Intelligence of Things era},
keywords={AIoT era},
keywords={static Web pages},
keywords={app mode},
keywords={Speech recognition},
keywords={Mobile handsets},
keywords={Deep learning},
keywords={Neural networks},
keywords={Education},
keywords={Augmented reality},
keywords={recurrent neural network},
keywords={emotional recognition},
abstract={With the advent of the 5G and Artificial Intelligence of Things (AIoT) era, related technologies such as the Internet of Things, big data analysis, cloud applications, and artificial intelligence have brought broad prospects to many application fields, such as smart homes, autonomous vehicles, smart cities, healthcare, and smart campus. At present, most university campus app is presented in the form of static web pages or app menus. This study mainly developed a Deep Neural Network (DNN) based emotionally aware campus virtual assistant. The main contributions of this research are: (1) This study introduces the Chinese Word Embedding to the robot dialogue system, effectively improving dialogue tolerance and semantic interpretation. (2) The traditional method of emotion identification must first tokenize the Chinese sentence, analyze the clauses and part of speech, and capture the emotional keywords before being interpreted by the expert system. Different from the traditional method, this study classifies the input directly through the convolutional neural network after the input sentence is converted into a spectrogram by Fourier Transform. (3) This study is presented in App mode, which is easier to use and economical. (4) This system provides a simple voice response interface, without the need for users to find information in complex web pages or app menus.},
issn={2169-3536},
doi={10.1109/ACCESS.2020.2984383}
}

@Article{Asgary2020,
author={Asgary, A.
and Bonadonna, C.
and Frischknecht, C.},
title={Simulation and Visualization of Volcanic Phenomena Using Microsoft Hololens: Case of Vulcano Island (Italy)},
journal={IEEE Transactions on Engineering Management},
year={2020},
volume={67},
number={3},
pages={545-553},
keywords={augmented reality},
keywords={virtual reality},
keywords={volcanology},
keywords={explosive eruptions},
keywords={eruptive plumes},
keywords={pyroclastic density currents},
keywords={eruption types},
keywords={Microsoft HoloLens device application},
keywords={volcanic phenomena},
keywords={Microsoft Visual Studio},
keywords={Unity game engine},
keywords={La Fossa volcano},
keywords={preparedness planning purposes},
keywords={emergency training},
keywords={active volcano},
keywords={eruptive phenomena},
keywords={volcanic eruption application},
keywords={interactive holographic visualization},
keywords={Vulcano island},
keywords={public education},
keywords={HoloVulcano},
keywords={Visualization},
keywords={Training},
keywords={Volcanoes},
keywords={Solid modeling},
keywords={Explosions},
keywords={microsoft hololens},
keywords={modeling and simulation},
keywords={virtual reality (VR)},
abstract={This article describes an interactive holographic visualization of volcanic eruption application for Microsoft HoloLens device. The aim of the project is to use this technology to visualize different eruptive phenomena on an active volcano for public education, emergency training, preparedness planning purposes, and raising awareness among tourists. We have selected La Fossa volcano on Vulcano island (Italy) as a case study and, thus, the application is named HoloVulcano. Unity game engine and Microsoft Visual Studio were used to develop the HoloVulcano augmented/virtual reality visualization application. The current version of HoloVulcano visualizes volcanic phenomena typically associated with unrest (fumaroles) and explosive eruptions (e.g. eruptive plumes, ejection of ballistic blocks, bombs, and pyroclastic density currents). The eruption types are developed based on existing literature using Unity game engine's particle systems component. HoloVulcano is a Microsoft HoloLens device application. Wearing the HoloLens, users can interact with the application through voice, gazing, and gestures and view different volcanic phenomena from different sites and angles on the island. HoloVulcano can be used by emergency managers and teachers for training, emergency exercises, and public education.},
issn={1558-0040},
doi={10.1109/TEM.2019.2932291}
}

@Article{Shaker2020,
author={Shaker, A.
and Lin, X.
and Kim, D. Y.
and Kim, J.
and Sharma, G.
and Devine, M. A.},
title={Design of a Virtual Reality Tour System for People With Intellectual and Developmental Disabilities: A Case Study},
journal={Computing in Science \& Engineering},
year={2020},
volume={22},
number={3},
pages={7-17},
keywords={handicapped aids},
keywords={interactive systems},
keywords={virtual reality},
keywords={virtual reality tour system},
keywords={intellectual disabilities},
keywords={developmental disabilities},
keywords={IDD},
keywords={immersive VR system},
keywords={interactive VR system},
keywords={hotspot-based VR tour system},
keywords={VR experience systems},
keywords={Virtual environments},
keywords={Medical treatment},
keywords={Task analysis},
keywords={Autism},
keywords={Testing},
keywords={Augmented reality},
abstract={This study focuses on VR as a form of therapy for individuals with intellectual and developmental disabilities (IDDs). The research aim is to develop an immersive and interactive VR system that is tailored for IDD individuals, for which most currently available VR experience systems are not optimized. Being intimately familiar with a place through an interactive VR tour will help alleviate social anxiety-very provident to IDD individuals. Accordingly, we create a hotspot-based VR tour system, which can provide an almost lifelike experience of visiting and learning about the location. We have conducted experiments with nondisabled individuals, acting as the control group, and IDD individuals, acting as the experimental group, to evaluate the tour system and compare the results between two groups. Our experiments show that the VR tour has a positive impact on the IDD individuals. In this article, we present the design of our VR tour system and its evaluation results.},
issn={1558-366X},
doi={10.1109/MCSE.2019.2961352}
}

