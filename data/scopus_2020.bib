
@CONFERENCE{Symonenko202037,
author={Symonenko, S.V. and Zaitseva, N.V. and Osadchyi, V.V. and Osadcha, K.P. and Shmeltser, E.O.},
title={Virtual reality in foreign language training at higher educational institutions},
journal={CEUR Workshop Proceedings},
year={2020},
volume={2547},
pages={37-49},
note={cited By 24},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079570906&partnerID=40&md5=130df2381737046c4dc50b32ba6fc680},
affiliation={Dmytro Motornyi Tavria State Agrotechnological University, 18, Bogdan Khmelnitsky Ave., Melitopol, 72312, Ukraine; Bogdan Khmelnitsky Melitopol State Pedagogical University, 20, Hetmanska Str., Melitopol, 72300, Ukraine; Kryvyi Rih Metallurgical Institute, National Metallurgical Academy of Ukraine, 5, Stephana Tilhy Str., Kryvyi Rih, 50006, Ukraine},
abstract={The paper deals with the urgent problem of application of virtual reality in foreign language training. Statistical data confirms that the number of smartphone users, Internet users, including wireless Internet users, has been increasing for recent years in Ukraine and tends to grow. The coherence of quick mobile Internet access and presence of supplementary equipment enables to get trained or to self-dependently advance due to usage of virtual reality possibilities for education in the stationary classrooms, at home and in motion. Several important features of virtual reality, its advantages for education are discussed. It is noted that virtual reality is remaining a relatively new technology in language learning. Benefits from virtual reality implementation into foreign language learning and teaching are given. The aspects of immersion and gamification in foreign language learning are considered. It is emphasized that virtual reality creates necessary preconditions for motivation increasing. The results of the survey at two higher education institution as to personal experience in using VR applications for learning foreign languages are presented. Most students at both universities have indicated quite a low virtual reality application usage. Six popular virtual reality applications for foreign language learning (Mondly, VRSpeech, VR Learn English, Gold Lotus, AltSpaceVR and VirtualSpeech) are analyzed. It is stated that the most preferred VR application for foreign language learning includes detailed virtual environment for maximal immersion, high-level visual effects similar to video games, simple avatar control, thorough material selection and complete complicity level accordance of every element and aspect, affordability, helpful and unobtrusive following up. Copyright © 2020 for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).},
author_keywords={Foreign Language Learning;  Gamification;  Immersion;  Virtual Reality;  Virtual Reality Application},
keywords={Augmented reality;  E-learning;  Gamification;  Interactive computer graphics;  User experience;  Visual languages, Educational institutions;  Foreign language learning;  Higher education institutions;  Immersion;  Important features;  Material selection;  Personal experience;  Wireless internet, Virtual reality},
editor={Kiv A.E., Shyshkina M.P.},
publisher={CEUR-WS},
issn={16130073},
language={English},
abbrev_source_title={CEUR Workshop Proc.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Ye2020,
author={Ye, J.},
title={Pediatric mental and behavioral health in the period of quarantine and social distancing with COVID-19},
journal={JMIR Pediatrics and Parenting},
year={2020},
volume={3},
number={2},
doi={10.2196/19867},
art_number={e19867},
note={cited By 23},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090984428&doi=10.2196%2f19867&partnerID=40&md5=a68269b5341b3cb1a0d8deddda24fcbe},
affiliation={Feinberg School of Medicine, Northwestern University, 633 N Saint Clair St, Chicago, IL, United States},
abstract={The coronavirus disease (COVID-19) pandemic has spread rapidly throughout the world and has had a long-term impact. The pandemic has caused great harm to society and caused serious psychological trauma to many people. Children are a vulnerable group in this global public health emergency, as their nervous systems, endocrine systems, and hypothalamic-pituitary-adrenal axes are not well developed. Psychological crises often cause children to produce feelings of abandonment, despair, incapacity, and exhaustion, and even raise the risk of suicide. Children with mental illnesses are especially vulnerable during the quarantine and social distancing period. The inclusion of psychosocial support for children and their families are part of the health responses to disaster and disaster recovery. Based on the biopsychosocial model, some children may have catastrophic thoughts and be prone to experience despair, numbness, flashbacks, and other serious emotional and behavioral reactions. In severe cases, there may be symptoms of psychosis or posttraumatic stress disorder. Timely and appropriate protections are needed to prevent the occurrence of psychological and behavioral problems. The emerging digital applications and health services such as telehealth, social media, mobile health, and remote interactive online education are able to bridge the social distance and support mental and behavioral health for children. Based on the psychological development characteristics of children, this study also illustrates interventions on the psychological impact from the COVID-19 pandemic. Even though the world has been struggling to curb the influences of the pandemic, the quarantine and social distancing policies will have long-term impacts on children. Innovative digital solutions and informatics tools are needed more than ever to mitigate the negative consequences on children. Health care delivery and services should envision and implement innovative paradigms to meet broad well-being needs and child health as the quarantine and social distancing over a longer term becomes a new reality. Future research on children's mental and behavioral health should pay more attention to novel solutions that incorporate cutting edge interactive technologies and digital approaches, leveraging considerable advances in pervasive and ubiquitous computing, human-computer interaction, and health informatics among many others. Digital approaches, health technologies, and informatics are supposed to be designed and implemented to support public health surveillance and critical responses to children's growth and development. For instance, human-computer interactions, augmented reality, and virtual reality could be incorporated to remote psychological supporting service for children's health; mobile technologies could be used to monitor children's mental and behavioral health while protecting their individual privacy; big data and artificial intelligence could be used to support decision making on whether children should go out for physical activities and whether schools should be reopened. Implications to clinical practices, psychological therapeutic practices, and future research directions to address current effort gaps are highlighted in this study. © 2020 JMIR Publications. All rights reserved.},
author_keywords={COVID-19;  Digital interventions;  Health technology;  Mental health;  Pediatrics;  Social distancing;  Stay-at-home orders},
correspondence_address1={Ye, J.; Feinberg School of Medicine, 633 N Saint Clair St, United States; email: jiancheng.ye@u.northwestern.edu},
publisher={JMIR Publications Inc.},
issn={25616722},
language={English},
abbrev_source_title={JMIR Pediatr. Parent.},
document_type={Review},
source={Scopus},
}

@ARTICLE{Ibáñez2020,
author={Ibáñez, M.B. and Uriarte Portillo, A. and Zatarain Cabada, R. and Barrón, M.L.},
title={Impact of augmented reality technology on academic achievement and motivation of students from public and private Mexican schools. A case study in a middle-school geometry course},
journal={Computers and Education},
year={2020},
volume={145},
doi={10.1016/j.compedu.2019.103734},
art_number={103734},
note={cited By 17},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073815705&doi=10.1016%2fj.compedu.2019.103734&partnerID=40&md5=7a6603962debb3c9ba0162ffad1b0996},
affiliation={Departamento de Ingeniería Telemática, Universidad Carlos III de Madrid, Madrid, Spain; Tecnológico Nacional de México, Instituto Tecnológico de Culiacán, Culiacán, Mexico},
abstract={In this paper, the authors show that augmented reality technology has a positive impact on learning-related outcomes of middle-school Mexican students. However, the impact varies depending on whether students were enrolled in public or private schools. The authors designed an augmented reality application for students to practice the basic principles of geometry, and a similar application which encompasses identical learning objectives and content deployed in a Web-based learning environment. A 2 × 2 × 2 factorial design was employed with 93 participants to investigate the effect of type of technology (web, augmented reality), type of school (private, public), and time of assessment (pre, post) on motivation, and declarative learning. The results show that: (1) there is an interactive effect of type of technology, type of school, and time of assessment when students' achievement scores are measured; (2) students using the augmented reality-based learning environments scored higher in post-test than those using the web-based application; (3) the augmented reality learning environment was more learning effective compared with the web-based learning environment in public schools, but not in private schools; (4) there is not an interactive effect of type of technology, type of school and time of assessment when students' motivation is measured; (5) students from private schools reported higher levels of motivation compared with those from public schools when using the augmented reality learning environment. The research findings imply that in Mexico, augmented reality technology can be exploited as an effective learning environment for helping middle-school students from public and private schools to practice the basic principles of Geometry. © 2019 Elsevier Ltd},
author_keywords={Applications in subject areas;  Augmented reality;  Interactive learning environments;  Motivation},
keywords={Augmented reality;  E-learning;  Engineering education;  Geometry;  Motivation;  School buildings;  Students;  Websites, Applications in subject areas;  Augmented reality applications;  Augmented reality technology;  Effective Learning Environment;  Interactive learning environment;  Middle school students;  Web-based applications;  Web-based learning environment, Computer aided instruction},
correspondence_address1={Ibáñez, M.B.; Departamento de Ingeniería Telemática, Leganés, Spain; email: mbibanez@it.uc3m.es},
publisher={Elsevier Ltd},
issn={03601315},
coden={COMED},
language={English},
abbrev_source_title={Comput Educ},
document_type={Article},
source={Scopus},
}

@ARTICLE{López-Faican2020,
author={López-Faican, L. and Jaen, J.},
title={EmoFindAR: Evaluation of a mobile multiplayer augmented reality game for primary school children},
journal={Computers and Education},
year={2020},
volume={149},
doi={10.1016/j.compedu.2020.103814},
art_number={103814},
note={cited By 16},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078496692&doi=10.1016%2fj.compedu.2020.103814&partnerID=40&md5=6ed1ea02efd292c93e97c271e10fd204},
affiliation={Universidad Nacional de Loja, Ecuador; Grupo ISSI, Universitat Politècnica de Valencia, Spain},
abstract={Games are powerful generators of positive emotions in children and are intrinsically satisfying. In this context, our work evaluates the use of mobile augmented reality without markers as the technology to implement a multiplayer game scenario that can be used to improve socialization, communication skills and emotional intelligence in primary school children. The present study addresses the usability of two gameplay styles and their impact on users' communication and motivation: competitive vs collaborative play. The game integrates Mobile Augmented Reality (MAR) technology without markers to create a geolocation scenario with unlimited physical space. The results indicate that both game modes are intrinsically satisfactory for children triggering positive emotions such as enthusiasm, enjoyment and curiosity that improve the participants’ mood and help increase the degree of involvement. Moreover, we observed that the collaborative game version has a greater impact on emotional affection, social interaction and interest. In addition, we observed in our study that the quality of the communication in the collaborative mode is good in terms of several factors such as sustaining mutual understanding, dialogue management, information pooling, reaching consensus, time management and reciprocal interaction. Finally, several design implications and suggestions related to game time management, scaffolding, mixed competitive-collaborative modes, dynamic 3D content and active learning, among others, are discussed. The present evaluation contributes to the identification of the most relevant aspects to be considered in the future design of MAR-based gamification strategies in education. © 2020 Elsevier Ltd},
author_keywords={Architectures for educational technology system;  Augmented and virtual reality;  Cooperative/collaborative learning;  Games;  Mobile learning},
keywords={Emotional intelligence;  Interactive computer graphics;  Scaffolds;  Virtual reality, Architectures for educational technology system;  Augmented and virtual realities;  Cooperative/collaborative learning;  Games;  Mobile Learning, Augmented reality},
correspondence_address1={López-Faican, L.; Universidad Nacional de LojaEcuador; email: lglopezfaican@gmail.com},
publisher={Elsevier Ltd},
issn={03601315},
coden={COMED},
language={English},
abbrev_source_title={Comput Educ},
document_type={Article},
source={Scopus},
}

@ARTICLE{Sırakaya2020,
author={Sırakaya, M. and Alsancak Sırakaya, D.},
title={Augmented reality in STEM education: a systematic review},
journal={Interactive Learning Environments},
year={2020},
doi={10.1080/10494820.2020.1722713},
note={cited By 13},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079032172&doi=10.1080%2f10494820.2020.1722713&partnerID=40&md5=a4f672bba72f1a341eec64b97a68181d},
affiliation={Department of Computer Technologies, Kırşehir Ahi Evran University, Kırşehir, Turkey},
abstract={This study aimed to systematically investigate the studies in which augmented reality (AR) was used to support Science, Technology, Engineering and Mathematic (STEM) education. In this framework, the general status of AR in STEM education was presented and its advantages and challenges were identified. The study investigated 42 articles published in journals indexed in SSCI database and deemed suitable for the purposes of this research. The obtained data were analyzed by two researchers using content analysis method. It was found that the studies in this field have become more significant and intensive in recent years and that these studies were generally carried out at schools (class, laboratory etc.) using marker-based AR applications. It was concluded that mostly K-12 students were used as samples and quantitative methods were selected. The advantages of AR-STEM studies were summarized and examined in detail in 4 sub-categories such as “contribution to learner, educational outcomes, interaction and other advantages”. On the other hand, some challenges were identified such as teacher resistance and technical problems. © 2020, © 2020 Informa UK Limited, trading as Taylor & Francis Group.},
author_keywords={Augmented reality;  interactive learning environments;  science education;  STEM;  systematic review},
correspondence_address1={Sırakaya, M.; Department of Computer Technologies, Turkey; email: mustafasirakaya@gmail.com},
publisher={Routledge},
issn={10494820},
language={English},
abbrev_source_title={Interact. Learn. Environ.},
document_type={Review},
source={Scopus},
}

@ARTICLE{Park20201074,
author={Park, B.J. and Hunt, S.J. and Martin, C., III and Nadolski, G.J. and Wood, B.J. and Gade, T.P.},
title={Augmented and Mixed Reality: Technologies for Enhancing the Future of IR},
journal={Journal of Vascular and Interventional Radiology},
year={2020},
volume={31},
number={7},
pages={1074-1082},
doi={10.1016/j.jvir.2019.09.020},
note={cited By 12},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079272339&doi=10.1016%2fj.jvir.2019.09.020&partnerID=40&md5=0874762eb17c1ba600cbbd1016d87d44},
affiliation={Department of Interventional Radiology, Hospital of the University of Pennsylvania, 3400 Spruce Street, Philadelphia, PA  19104, United States; Department of Interventional Radiology, Cleveland Clinic, Cleveland, OH, United States; Interventional Radiology, National Institutes of Health, Bethesda, MD, United States},
abstract={Augmented and mixed reality are emerging interactive and display technologies. These technologies are able to merge virtual objects, in either 2 or 3 dimensions, with the real world. Image guidance is the cornerstone of interventional radiology. With augmented or mixed reality, medical imaging can be more readily accessible or displayed in actual 3-dimensional space during procedures to enhance guidance, at times when this information is most needed. In this review, the current state of these technologies is addressed followed by a fundamental overview of their inner workings and challenges with 3-dimensional visualization. Finally, current and potential future applications in interventional radiology are highlighted. © 2019 SIR},
keywords={diagnostic imaging;  interventional radiology;  review;  computer assisted diagnosis;  computer assisted therapy;  education;  endovascular surgery;  ergonomics;  human;  mass communication;  medical education;  procedures;  three-dimensional imaging;  virtual reality;  workflow, Augmented Reality;  Diffusion of Innovation;  Education, Medical, Graduate;  Endovascular Procedures;  Ergonomics;  Humans;  Imaging, Three-Dimensional;  Radiographic Image Interpretation, Computer-Assisted;  Radiography, Interventional;  Therapy, Computer-Assisted;  Virtual Reality;  Workflow},
correspondence_address1={Park, B.J.; Department of Interventional Radiology, 3400 Spruce Street, United States; email: bjinwoopark@gmail.com},
publisher={Elsevier Inc.},
issn={10510443},
coden={JVIRE},
pubmed_id={32061520},
language={English},
abbrev_source_title={J. Vasc. Intervent. Radiol.},
document_type={Review},
source={Scopus},
}

@ARTICLE{CheDalim202044,
author={Che Dalim, C.S. and Sunar, M.S. and Dey, A. and Billinghurst, M.},
title={Using augmented reality with speech input for non-native children's language learning},
journal={International Journal of Human Computer Studies},
year={2020},
volume={134},
pages={44-64},
doi={10.1016/j.ijhcs.2019.10.002},
note={cited By 10},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074369569&doi=10.1016%2fj.ijhcs.2019.10.002&partnerID=40&md5=7c91f641b7113338dde92f687dfa9f37},
affiliation={Faculty of Computer Science and Information Technology, Universiti Tun Hussein Onn Malaysia, Batu Pahat, 86400, Malaysia; Media and Game Innovation Centre of Excellence, Institute of Human Centred Engineering, Universiti Teknologi Malaysia, Johor Bahru, 81310, Malaysia; Faculty of Engineering, School of Computing, Universiti Teknologi Malaysia, Johor Bahru, 81310, Malaysia; Empathic Computing Lab, University of South Australia, Australia; Empathic XR and Pervasive Computing Lab, University of Queensland, Australia},
abstract={Augmented Reality (AR) offers an enhanced learning environment which could potentially influence children's experience and knowledge gain during the language learning process. Teaching English or other foreign languages to children with different native language can be difficult and requires an effective strategy to avoid boredom and detachment from the learning activities. With the growing numbers of AR education applications and the increasing pervasiveness of speech recognition, we are keen to understand how these technologies benefit non-native young children in learning English. In this paper, we explore children's experience in terms of knowledge gain and enjoyment when learning through a combination of AR and speech recognition technologies. We developed a prototype AR interface called TeachAR, and ran two experiments to investigate how effective the combination of AR and speech recognition was towards the learning of 1) English terms for color and shapes, and 2) English words for spatial relationships. We found encouraging results by creating a novel teaching strategy using these two technologies, not only in terms of increase in knowledge gain and enjoyment when compared with traditional strategy but also enables young children to finish the certain task faster and easier. © 2019 Elsevier Ltd},
author_keywords={Human-computer interface;  Improving classroom teaching;  Interactive learning environments;  Teaching/learning strategies},
keywords={Augmented reality;  Computer aided instruction;  Learning systems, Enhanced learning;  Human computer interfaces;  Improving classroom teaching;  Interactive learning environment;  Learning Activity;  Spatial relationships;  Speech recognition technology;  Teaching/learning strategy, Speech recognition},
correspondence_address1={Che Dalim, C.S.; Faculty of Engineering, Malaysia; email: csamihah@gmail.com},
publisher={Academic Press},
issn={10715819},
coden={IHSTE},
language={English},
abbrev_source_title={Int J Hum Comput Stud},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Kravtsov2020918,
author={Kravtsov, H. and Pulinets, A.},
title={Interactive augmented reality technologies for model visualization in the school textbook},
journal={CEUR Workshop Proceedings},
year={2020},
volume={2732},
pages={918-933},
note={cited By 9},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096099560&partnerID=40&md5=681600da28b8f12bbbab3e0b2162eb63},
affiliation={Kherson State University, 27, Universitetska St., Kherson, 73000, Ukraine},
abstract={AR-technologies can be widely used in the educational process using ICT. Especially valuable is the use of AR-based applications for the visualization of illustrations of models of objects and processes in school books. The use of electronic educational resources using AR-technologies can improve the quality of students' knowledge, as well as provide teachers with a wide range of new opportunities. Using AR technology allows you to design and create effective learning resources. This develops students' creative thinking and increases their motivation to learn. In this paper, we consider a model of a learning system using augmented reality technologies for visualizing illustrations in school textbooks. A survey of secondary school teachers showed the possibility, interest and effectiveness of using e-learning tools based on AR technology. Pupils can use this electronic resource both in class at school and at home during independent study. Students of Kherson State University, interviewed in the STEM education system, showed a willingness to work with augmented reality technologies. To assess the prospects of using AR-based applications in the educational process, an expert method was used. Experts evaluated the prospects of using AR technology to visualize 2D and 3D models of educational objects. For evaluation, a five-point Likert system was chosen. The developed model can be used as a means to create the basis for future research, development and dissemination in the system of educational institutions. The proposed model of the learning system was tested in the classrooms of students in the learning process at STEM. Copyright © 2020 for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).},
author_keywords={Augmented reality;  ICT;  Mobile application;  School textbook;  Visualization},
keywords={Augmented reality;  E-learning;  Education computing;  Industrial research;  Knowledge management;  Learning systems;  Students;  Textbooks;  Visualization, Augmented reality technology;  Creative thinking;  Educational institutions;  Educational process;  Educational resource;  Effective learning;  Electronic resources;  Model visualization, STEM (science, technology, engineering and mathematics)},
editor={Sokolov O., Zholtkevych G., Yakovyna V., Yakovyna V., Tarasich Y., Kharchenko V., Kobets V., Burov O., Semerikov S., Kravtsov H.},
publisher={CEUR-WS},
issn={16130073},
language={English},
abbrev_source_title={CEUR Workshop Proc.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Andras20202359,
author={Andras, I. and Mazzone, E. and van Leeuwen, F.W.B. and De Naeyer, G. and van Oosterom, M.N. and Beato, S. and Buckle, T. and O’Sullivan, S. and van Leeuwen, P.J. and Beulens, A. and Crisan, N. and D’Hondt, F. and Schatteman, P. and van Der Poel, H. and Dell’Oglio, P. and Mottrie, A.},
title={Artificial intelligence and robotics: a combination that is changing the operating room},
journal={World Journal of Urology},
year={2020},
volume={38},
number={10},
pages={2359-2366},
doi={10.1007/s00345-019-03037-6},
note={cited By 8},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076105418&doi=10.1007%2fs00345-019-03037-6&partnerID=40&md5=0357d4fe422ca1e5582f1fe4edb30841},
affiliation={ORSI Academy, Melle, Belgium; Department of Urology, Iuliu Hatieganu University of Medicine and Pharmacy, Cluj-Napoca, Romania; Department of Urology, Onze Lieve Vrouw Hospital, Aalst, Belgium; Department of Urology and Division of Experimental Oncology, URI, Urological Research Institute, IRCCS San Raffaele Scientific Institute, Milan, Italy; Interventional Molecular Imaging Laboratory, Department of Radiology, Leiden University Medical Centre, Leiden, Netherlands; Department of Urology, Antoni Van Leeuwenhoek Hospital, The Netherlands Cancer Institute, Amsterdam, Netherlands; Department of Pathology, Faculdade de Medicina, Universidade de São Paulo, São Paulo, Brazil; Department of Urology, Catharina Hospital, Eindhoven, Netherlands; Netherlands Institute for Health Services (NIVEL), Utrecht, Netherlands},
abstract={Purpose: The aim of the current narrative review was to summarize the available evidence in the literature on artificial intelligence (AI) methods that have been applied during robotic surgery. Methods: A narrative review of the literature was performed on MEDLINE/Pubmed and Scopus database on the topics of artificial intelligence, autonomous surgery, machine learning, robotic surgery, and surgical navigation, focusing on articles published between January 2015 and June 2019. All available evidences were analyzed and summarized herein after an interactive peer-review process of the panel. Literature review: The preliminary results of the implementation of AI in clinical setting are encouraging. By providing a readout of the full telemetry and a sophisticated viewing console, robot-assisted surgery can be used to study and refine the application of AI in surgical practice. Machine learning approaches strengthen the feedback regarding surgical skills acquisition, efficiency of the surgical process, surgical guidance and prediction of postoperative outcomes. Tension-sensors on the robotic arms and the integration of augmented reality methods can help enhance the surgical experience and monitor organ movements. Conclusions: The use of AI in robotic surgery is expected to have a significant impact on future surgical training as well as enhance the surgical experience during a procedure. Both aim to realize precision surgery and thus to increase the quality of the surgical care. Implementation of AI in master–slave robotic surgery may allow for the careful, step-by-step consideration of autonomous robotic surgery. © 2019, Springer-Verlag GmbH Germany, part of Springer Nature.},
author_keywords={Artificial intelligence;  Autonomous surgery;  Machine learning;  Robotic surgery;  Surgical navigation},
keywords={artificial intelligence;  human;  operating room;  procedures;  robot assisted surgery;  urologic surgery, Artificial Intelligence;  Humans;  Operating Rooms;  Robotic Surgical Procedures;  Urologic Surgical Procedures},
correspondence_address1={Dell’Oglio, P.; ORSI AcademyBelgium; email: paolo.delloglio@gmail.com},
publisher={Springer Science and Business Media Deutschland GmbH},
issn={07244983},
pubmed_id={31776737},
language={English},
abbrev_source_title={World J. Urol.},
document_type={Review},
source={Scopus},
}

@ARTICLE{SerranoVergel2020337,
author={Serrano Vergel, R. and Morillo Tena, P. and Casas Yrurzum, S. and Cruz-Neira, C.},
title={A Comparative Evaluation of a Virtual Reality Table and a HoloLens-Based Augmented Reality System for Anatomy Training},
journal={IEEE Transactions on Human-Machine Systems},
year={2020},
volume={50},
number={4},
pages={337-348},
doi={10.1109/THMS.2020.2984746},
art_number={9106786},
note={cited By 7},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088498153&doi=10.1109%2fTHMS.2020.2984746&partnerID=40&md5=d219de3fe6e55cc53862301036e972ff},
affiliation={Emerging Analytics Center, University of Arkansas at Little Rock, Little Rock, AR, United States; Institute on Robotics and Information and Communication Technologies, University of Valencia, València, Spain; Agere Chair in Computer Science, University of Central Florida, Orlando, FL, United States},
abstract={Anatomy training with real cadavers poses many practical problems for which new training and educational solutions have been developed making use of technologies based on real-time 3-D graphics. Although virtual reality (VR) and augmented reality (AR) have been previously used in the medical field, it is not easy to select the right 3-D technology or setup for each particular problem. For this reason, this article presents a comprehensive comparative study with 82 participants between two different 3-D interactive setups: an optical-based AR setup, implemented with a Microsoft HoloLens device, and a semi-immersive setup based on a VR Table. Both setups are tested using an anatomy training software application. Our primary hypothesis is that there would be statistically significant differences between the use of the AR application and the use of the VR Table. Our secondary hypothesis is that user preference and recommendation for the VR setup would be higher than for the HoloLens-based system. After completing two different tasks with both setups, the participants filled two questionnaires about the use of the anatomy training application. Three objective measures are also recorded (time, number of movements, and a score). The results of the experiments show that more than two-thirds of the users prefer, recommend, and find more useful the VR setup. The results also show that there are statistically significant differences in the use of both systems in favor of the VR Table. © 2013 IEEE.},
author_keywords={Anatomy;  augmented reality;  comparative study;  Microsoft HoloLens;  training;  virtual reality (VR);  VR table},
keywords={Application programs;  Augmented reality;  E-learning;  Software testing;  Surveys, Augmented reality systems;  Comparative evaluations;  Comparative studies;  Objective measure;  Practical problems;  Software applications;  Statistically significant difference;  Training applications, Virtual reality},
correspondence_address1={Casas Yrurzum, S.; Institute on Robotics and Information and Communication Technologies, Spain; email: sergio.casas@uv.es},
publisher={Institute of Electrical and Electronics Engineers Inc.},
issn={21682291},
language={English},
abbrev_source_title={IEEE Trans. Human Mach. Syst.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Sahu2020,
author={Sahu, C.K. and Young, C. and Rai, R.},
title={Artificial intelligence (AI) in augmented reality (AR)-assisted manufacturing applications: a review},
journal={International Journal of Production Research},
year={2020},
doi={10.1080/00207543.2020.1859636},
note={cited By 6},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098500760&doi=10.1080%2f00207543.2020.1859636&partnerID=40&md5=7b8adc9443560bf6e59b6143166d4176},
affiliation={Geometric Reasoning and Artificial Intelligence Lab (GRAIL), Department of Automotive Engineering, Clemson University, Greenville, SC, United States; Manufacturing and Design Lab (MADLab), Department of Mechanical and Aerospace Engineering, University at Buffalo, Buffalo, NY, United States},
abstract={Augmented reality (AR) has proven to be an invaluable interactive medium to reduce cognitive load by bridging the gap between the task-at-hand and relevant information by displaying information without disturbing the user's focus. AR is particularly useful in the manufacturing environment where a diverse set of tasks such as assembly and maintenance must be performed in the most cost-effective and efficient manner possible. While AR systems have seen immense research innovation in recent years, the current strategies utilised in AR for camera calibration, detection, tracking, camera position and orientation (pose) estimation, inverse rendering, procedure storage, virtual object creation, registration, and rendering are still mostly dominated by traditional non-AI approaches. This restricts their practicability to controlled environments with limited variations in the scene. Classical AR methods can be greatly improved through the incorporation of various AI strategies like deep learning, ontology, and expert systems for adapting to broader scene variations and user preferences. This research work provides a review of current AR strategies, critical appraisal for these strategies, and potential AI solutions for every component of the computational pipeline of AR systems. Given the review of current work in both fields, future research work directions are also outlined. © 2020 Informa UK Limited, trading as Taylor & Francis Group.},
author_keywords={artificial intelligence;  Augmented reality;  deep learning;  machine learning;  manufacturing;  tracking},
keywords={Augmented reality;  Cameras;  Cost effectiveness;  Deep learning;  Expert systems;  Inverse problems;  Manufacture;  Object tracking, Camera calibration;  Camera positions;  Cognitive loads;  Controlled environment;  Inverse rendering;  Manufacturing applications;  Manufacturing environments;  Virtual objects, Rendering (computer graphics)},
correspondence_address1={Rai, R.; Geometric Reasoning and Artificial Intelligence Lab (GRAIL), United States; email: rrai@clemson.edu},
publisher={Taylor and Francis Ltd.},
issn={00207543},
coden={IJPRB},
language={English},
abbrev_source_title={Int J Prod Res},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Tuli2020679,
author={Tuli, N. and Mantri, A.},
title={Usability principles for augmented reality based kindergarten applications},
journal={Procedia Computer Science},
year={2020},
volume={172},
pages={679-687},
doi={10.1016/j.procs.2020.05.089},
note={cited By 6},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089026167&doi=10.1016%2fj.procs.2020.05.089&partnerID=40&md5=45d4f6e7e26cb0493786363766d6b554},
affiliation={Chitkara University Institute of Engineering and Technology, Chitkara University, Punjab, 140401, India},
abstract={Augmented Reality (AR) overlays digital information over user's real world. Designing and developing AR applications is a difficult task. It involves user interface designing, content generation according to the target audience so that the application is easy to understand, interactive, consistent and ease to use. To design these applications there are many design principles evidenced in existing literature such as learnability, affordance, simplicity etc. However, there are no studies in the literature which define most appropriate usability principles/guidelines for designing mobile based AR applications for kindergarten kids. Age is a significant factor to be considered in developing applications for kids especially when it comes to interaction techniques to be used in learning applications. The kids may not easily use and interact with the applications developed for the adults. Therefore, there is a need to identify the principles that should be kept in mind while developing AR applications according to the kids. The aim of our research is to develop usability principles for mobile based applications for kindergarten kids using AR. We proposed 23 usability principles by studying the existing literature on usability, design principles for AR applications, guidelines/principles for tangible interfaces. These principles would help other researcher and developers to create more interactive, learnable and easy to understand AR applications for kids solving the identified usability problems. © 2020 The Authors. Published by Elsevier B.V.},
author_keywords={Augmented reality;  Kindergarten;  Systematic process;  Usability principles},
keywords={Augmented reality;  Usability engineering;  User interfaces, AR application;  Design Principles;  Digital information;  Interaction techniques;  Learnability;  Tangible interfaces;  Target audience;  Usability problems, Engineering education},
editor={Jagadeesh Kannan R., Jeganathan L., Nagaraj S.V.},
publisher={Elsevier B.V.},
issn={18770509},
language={English},
abbrev_source_title={Procedia Comput. Sci.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Desselle202018,
author={Desselle, M.R. and Brown, R.A. and James, A.R. and Midwinter, M.J. and Powell, S.K. and Woodruff, M.A.},
title={Augmented and Virtual Reality in Surgery},
journal={Computing in Science and Engineering},
year={2020},
volume={22},
number={3},
pages={18-26},
doi={10.1109/MCSE.2020.2972822},
art_number={8993789},
note={cited By 5},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079661155&doi=10.1109%2fMCSE.2020.2972822&partnerID=40&md5=9d285b601a0890d2117ff2fc568797fb},
affiliation={Metro North Hospital and Health Service, Australia; Queensland University of Technology, Australia; University of Queensland, Australia},
abstract={Augmented and virtual reality are transforming the practice of healthcare by providing powerful and intuitive methods of exploring and interacting with digital medical data, as well as integrating data into the physical world to create natural and interactive virtual experiences. These immersive technologies use lightweight stereoscopic head-mounted displays to place users into simulated and realistic three-dimensional digital environments, unlocking significant benefits from the seamless integration of digital information with the healthcare practitioner and patient's experience. This review article explores some of the current and emerging technologies and applications in surgery, their benefits and challenges around immersion, spatial awareness and cognition, and their reported and projected use in learning environments, procedure planning and perioperative contexts and in the surgical theatre. The enhanced access to information, knowledge, and experience enabled by virtual and augmented reality will improve healthcare approaches and lead to better outcomes for patients and the wider community. © 1999-2011 IEEE.},
author_keywords={and Visualization < I Computing Methodologie;  I.6.3 Applications < I.6 Simulation;  J.3.b Health < J.3 Life and Medical Sciences < J Computer Applications;  J.8.h Health care < J.8 Internet Applications < J Computer Applications;  Modeling},
keywords={Augmented reality;  Computer aided instruction;  Helmet mounted displays;  Metadata;  Models;  Stereo image processing;  Transplantation (surgical);  Virtual reality, Augmented and virtual realities;  Head mounted displays;  Immersive technologies;  Internet application;  Learning environments;  Life and medical science;  Methodologie;  Virtual and augmented reality, Medical computing},
correspondence_address1={Desselle, M.R.; Metro North Hospital and Health ServiceAustralia; email: mathilde.desselle@health.qld.gov.au},
publisher={IEEE Computer Society},
issn={15219615},
coden={CSENF},
language={English},
abbrev_source_title={Comput. Sci. Eng.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Czarnowski2020721,
author={Czarnowski, J. and Laidlow, T. and Clark, R. and Davison, A.J.},
title={DeepFactors: Real-Time Probabilistic Dense Monocular SLAM},
journal={IEEE Robotics and Automation Letters},
year={2020},
volume={5},
number={2},
pages={721-728},
doi={10.1109/LRA.2020.2965415},
art_number={8954779},
note={cited By 5},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078536456&doi=10.1109%2fLRA.2020.2965415&partnerID=40&md5=cbceb1fc470ff0c2cdae6a1e62407117},
affiliation={Dyson Robotics Laboratory, Imperial College London, London, SW7 2AZ, United Kingdom},
abstract={The ability to estimate rich geometry and camera motion from monocular imagery is fundamental to future interactive robotics and augmented reality applications. Different approaches have been proposed that vary in scene geometry representation (sparse landmarks, dense maps), the consistency metric used for optimising the multi-view problem, and the use of learned priors. We present a SLAM system that unifies these methods in a probabilistic framework while still maintaining real-time performance. This is achieved through the use of a learned compact depth map representation and reformulating three different types of errors: photometric, reprojection and geometric, which we make use of within standard factor graph software. We evaluate our system on trajectory estimation and depth reconstruction on real-world sequences and present various examples of estimated dense geometry. © 2016 IEEE.},
author_keywords={Deep learning in robotics and automation;  mapping;  SLAM},
keywords={Augmented reality;  Deep learning;  Geometry;  Mapping, Augmented reality applications;  Geometry representation;  Interactive robotics;  Probabilistic framework;  Real time performance;  Real-world sequences;  SLAM;  Trajectory estimation, Robotics},
correspondence_address1={Czarnowski, J.; Dyson Robotics Laboratory, United Kingdom; email: j.czarnowski15@imperial.ac.uk},
publisher={Institute of Electrical and Electronics Engineers Inc.},
issn={23773766},
language={English},
abbrev_source_title={IEEE Robot. Autom.},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Chen2020767,
author={Chen, D. and Xie, L.J. and Kim, B. and Wang, L. and Hong, C.S. and Wang, L.-C. and Han, Z.},
title={Federated Learning Based Mobile Edge Computing for Augmented Reality Applications},
journal={2020 International Conference on Computing, Networking and Communications, ICNC 2020},
year={2020},
pages={767-773},
doi={10.1109/ICNC47757.2020.9049708},
art_number={9049708},
note={cited By 4},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083449170&doi=10.1109%2fICNC47757.2020.9049708&partnerID=40&md5=23d16870f24d7d381d2d5b01978f154a},
affiliation={University of Houston, Department of Electrical and Computer Engineering, Houston, TX, United States; University of North Carolina at Charlotte, Department of Electrical and Computer Engineering, Charlotte, NC, United States; Toyota Motor North America RandD, InfoTech Labs, Mountain View, CA, United States; Beijing University of Posts and Telecommunications, School of Electronic Engineering, Beijing, China; Kyung Hee University, Department of Computer Science and Engineering, Seoul, South Korea; National Chiao Tung University, Department of Electrical and Computer Engineering, Hsinchu, Taiwan},
abstract={The past decade has witnessed the prosperous growth of augmented reality (AR) devices, as they provide immersive and interactive experience for customers. AR applications have the properties of high data rate and latency sensitivity. Currently, the available bandwidth is relatively limited to transmit and process enormous generated data. Meanwhile, it is challenging for AR to accurately detect and classify the object in order to perfectly combine the corresponding virtual contents with the real world. In this work, we focus on how to solve the computation efficiency, low-latency object detection and classification problems of AR applications. Firstly, we introduce and analyze the practical mathematical model of AR, and connect the AR operating principles with the object detection and classification problem. To address this problem and reduce the executing latency simultaneously, we propose a framework collaborating mobile edge computing paradigm with federated learning, both of which are decentralized configurations. To evaluate our method, numerical results are calculated based on the open source data CIFAR-10. Compared to centralized learning, our proposed framework requires significantly fewer training iterations. © 2020 IEEE.},
keywords={Augmented reality;  Bandwidth;  Edge computing;  Numerical methods;  Object recognition, AR application;  Augmented reality applications;  Available bandwidth;  Computation efficiency;  Computing paradigm;  Numerical results;  Open source datum;  Operating principles, Object detection},
publisher={Institute of Electrical and Electronics Engineers Inc.},
isbn={9781728149059},
language={English},
abbrev_source_title={Int. Conf. Comput., Netw. Commun., ICNC},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Cen2020283,
author={Cen, L. and Ruta, D. and Al Qassem, L.M.M.S. and Ng, J.},
title={Augmented Immersive Reality (AIR) for Improved Learning Performance: A Quantitative Evaluation},
journal={IEEE Transactions on Learning Technologies},
year={2020},
volume={13},
number={2},
pages={283-296},
doi={10.1109/TLT.2019.2937525},
art_number={8812921},
note={cited By 3},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071536186&doi=10.1109%2fTLT.2019.2937525&partnerID=40&md5=3080c63161b59bbf3e10f094e40950bb},
affiliation={EBTIC, Khalifa University, Abu Dhabi, 127788, United Arab Emirates},
abstract={Technology-enhanced learning has attracted increasing attention of educational community focused on improvement of traditional classroom learning. Augmented immersive reality (AIR) technologies enhance users' perception of reality by augmenting it with computer-generated components such as audio, video, 2/3-D graphics, GPS data, etc. The AIR introduces new dimensions of learning experience that ensure better attention, focus, and entertainment, thereby boosting students' motivation and attainment. This work presents an award winning AIR-based educational mobile system, code-named AIR-EDUTECH, that was developed to help high school students learn chemistry. The AIR-EDUTECH introduced new AIR features to help students better understand and learn basic concepts of molecular chemistry. It offers immersive 3D visualization and visual interaction with the examined structures that provides a broader and more retentive knowledge and improves intuition around forming basic chemical reactions. The system was introduced and tested in a field study with 45 students in the $11^{th}$ grade chemistry class, and its impact was evaluated by the formal assessment quiz along with the feedback from survey conducted after the trial. Collected data have been subjected to an in-depth multi-modal quantitative analysis that revealed that AIR-EDUTECH stimulated significant improvements in understanding and retention of the taught content as well as turned learning chemistry into a fun, interesting and interactive experience. It also uncovered a hidden structure of taught knowledge dependencies and highlighted the role that AIR technology could play in reinforcing the retention of critical knowledge that may otherwise widen student knowledge gaps. © 2008-2011 IEEE.},
author_keywords={AIR-EDUTECH;  Augmented Immersive Reality (AIR);  Augmented Reality (AR);  education data mining.;  Mobile learning},
keywords={Augmented reality;  Chemical analysis;  Data mining;  Three dimensional computer graphics, Educational community;  High school students;  Immersive;  Learning experiences;  Learning performance;  Mobile Learning;  Quantitative evaluation;  Technology enhanced learning, Students},
correspondence_address1={Cen, L.; EBTIC, United Arab Emirates; email: cen.ling@ku.ac.ae},
publisher={Institute of Electrical and Electronics Engineers},
issn={19391382},
language={English},
abbrev_source_title={IEEE Trans. Learn. Technol.},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Harrington2020813,
author={Harrington, M.C.R.},
title={Observation of Presence in an Ecologically Valid Ethnographic Study Using an Immersive Augmented Reality Virtual Diorama Application},
journal={Proceedings - 2020 IEEE Conference on Virtual Reality and 3D User Interfaces, VRW 2020},
year={2020},
pages={813-814},
doi={10.1109/VRW50115.2020.00257},
art_number={9090465},
note={cited By 3},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085396895&doi=10.1109%2fVRW50115.2020.00257&partnerID=40&md5=8eb7e5a7bf83c68062e97436884d1b4e},
affiliation={University of CentralFL, United States},
abstract={The main research question is centered on the usefulness of immersive Augmented Reality (AR) applications for informal learning activities. Can users experience presence - or a sense of being there - when using AR apps? To begin to approach this question an ethnographic study was conducted in July, 2019 in a museum with 56 volunteer participants to document behavior and measure learning, attitudes, and emotional outcomes of an AR application. Reported are the preliminary results of behavior indicative of presence observed in the study, and insights gained that are useful in understanding future designs. © 2020 IEEE.},
author_keywords={Augmented reality;  bioacoustics;  data visualization;  embodiment;  immersive;  informal learning;  interactive;  multimodal;  museums;  presence},
keywords={Augmented reality;  User experience;  User interfaces, AR application;  Document behaviors;  Ethnographic study;  Future designs;  Immersive augmented realities;  Informal learning;  Research questions, Virtual reality},
correspondence_address1={Harrington, M.C.R.; University of CentralUnited States},
publisher={Institute of Electrical and Electronics Engineers Inc.},
isbn={9781728165325},
language={English},
abbrev_source_title={Proc. - IEEE Conf. Virtual Real. 3D User Interfaces, VRW},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Llerena-Izquierdo2020593,
author={Llerena-Izquierdo, J. and Cedeño-Gonzabay, L.},
title={Photogrammetry and Augmented Reality to Promote the Religious Cultural Heritage of San Pedro Cathedral in Guayaquil, Ecuador},
journal={Communications in Computer and Information Science},
year={2020},
volume={1194 CCIS},
pages={593-606},
doi={10.1007/978-3-030-42520-3_47},
note={cited By 3},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082384127&doi=10.1007%2f978-3-030-42520-3_47&partnerID=40&md5=da6bd49e31445c60d457fbc45a3e5bbc},
affiliation={Universidad Politécnica Salesiana, Guayaquil, Ecuador},
abstract={This innovative proposal combines the use of the biggest reality and photogrammetry for modeling structures in digital format. It addresses two themes the use of technologies for the restoration of heritage structures in the event of a fortuitous event and the use of a technological tool that allows the dissemination of the religious cultural heritage of the Cathedral of San Pedro in Guayaquil, Ecuador to national and foreign tourists, the interest in knowing a little more about the history of culture and art is encouraged when effective conservation strategies are involved and even more by incorporating the use of technology in smart devices. This allows easy quick access with proper visualization, the use of photogrammetry technique is adopted in several museums around the world and allow tourists to learn about a specific topic in a didactic and interactive way. Another technique is the increasing reality technique, this technique incorporates data in virtual form links on the web audio video, video text or other multimedia through markers to objects serving as a tool that encourages learning more about different topics. The one chosen in this work is the religious cultural heritage. The interface developed in Unity, and the use of the Vuforia development kit, through the mobile application “My Cathedral”, allows users to access relevant historical information, visualizing the photogrammetric images in increasing reality, precisely on the most representative objects of the cathedral of San Pedro in Guayaquil. © 2020, Springer Nature Switzerland AG.},
author_keywords={Augmented reality;  Photogrammetry;  Religious cultural heritage},
keywords={Augmented reality;  Historic preservation, Conservation strategies;  Cultural heritages;  Heritage structures;  Historical information;  Mobile applications;  Modeling structures;  Representative object;  Technological tools, Photogrammetry},
correspondence_address1={Llerena-Izquierdo, J.; Universidad Politécnica SalesianaEcuador; email: jllerena@ups.edu.ec},
editor={Botto-Tobar M., Zambrano Vizuete M., Torres-Carrion P., Montes Leon S., Pizarro Vasquez G., Durakovic B.},
publisher={Springer},
issn={18650929},
isbn={9783030425197},
language={English},
abbrev_source_title={Commun. Comput. Info. Sci.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Alzahrani2020282,
author={Alzahrani, N.M. and Lajmi, S.},
title={AugmentedBook: A collaborative e-learning augmented reality platform},
journal={Advances in Intelligent Systems and Computing},
year={2020},
volume={1018},
pages={282-288},
doi={10.1007/978-3-030-25629-6_44},
note={cited By 3},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070019823&doi=10.1007%2f978-3-030-25629-6_44&partnerID=40&md5=8b0cbba42c4eccb44b7f6c4de5805834},
affiliation={Information Technology Department, Faculty of Computer Science and Information Technology, Albaha University, Albaha, Saudi Arabia; MIRACL: Multimedia InfoRmation Systems and Advanced Computing Laboratory, University of Sfax, Technological Pole of Sfax, Sakiet Ezzit, Sfax, 3021, Tunisia},
abstract={This paper introduces an augmented reality-based framework (called AugmentedBook) for e-learning that allows the creation of collaborative notes, illustrative media (i.e. video, 2D or 3D image, audio) for mobile devices or Google glass. The augmented content can be added to real-world educational support to make it more comprehensive, interactive and collaborative. In this platform, students and teachers can add collaborative notes to any part of the educational support system. They can also find illustrative media and indicate the pertinence of the result. Using our AugmentedBook platform, students can also download the enriched support using a mobile device. Our framework solves the problem of standard integration of augmented reality applications in education, offering a distributed framework which is e-learning compliant. © 2020, Springer Nature Switzerland AG.},
author_keywords={Augmented reality;  Collaborative annotation;  E-learning;  Mobile device},
keywords={Augmented reality;  E-learning;  Mobile computing, 3-D image;  Augmented reality applications;  Collaborative annotation;  Collaborative e-Learning;  Distributed framework;  Educational support systems;  Real-world, Students},
correspondence_address1={Alzahrani, N.M.; Information Technology Department, Saudi Arabia; email: noufalzahrani@bu.edu.sa},
editor={Ahram T., Taiar R., Colson S., Choplin A.},
publisher={Springer Verlag},
issn={21945357},
isbn={9783030256289},
language={English},
abbrev_source_title={Adv. Intell. Sys. Comput.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Mao2020303,
author={Mao, C.-C. and Chen, F.-Y.},
title={Augmented reality and 3-D visualization effects to enhance battlefield situational awareness},
journal={Advances in Intelligent Systems and Computing},
year={2020},
volume={1018},
pages={303-309},
doi={10.1007/978-3-030-25629-6_47},
note={cited By 3},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069981091&doi=10.1007%2f978-3-030-25629-6_47&partnerID=40&md5=be70431fcb1eab38f793370c27d41cf7},
affiliation={Department of Applied Arts, Fu Hsing Kang College, National Defense University, No.70, Sec. 2 Zhongyang N. Rd. Beitou Dist., Taipei, Taiwan},
abstract={This study presents the augmented reality technology and 3D information visualization for Army’s military education to realize the interactive tactical course teaching and consider the user center research and human-computer interaction architecture as a solution to improve the common operational picture. The purpose is to improve the Army’s command and general staff officers in tactical operations to learn battlefield situational awareness to enhance interest in learning and effective decision support. We constructed a prototype augmented reality program, the traditional tactical image and symbols of war games into 3-D virtual images, Which includes military equipment, urban architecture and geography scenes and other models, teaching applications to import tactical operations, not only to break through the limitations of a traditional 2-D image, enhanced visual effects and digital technology information, revealing a more complete battlefield scene. At the same time, through virtual operation, students are more interactive. In order to verify and collect the utility and data of learning, quasi-experimental research has been used. Experiments have shown that using 3-D information Visualization for better understanding of military tasks and space environments can enhance learning interest and perception of situation awareness. © 2020, Springer Nature Switzerland AG.},
author_keywords={3-D animation;  Augmented Reality;  Human-computer interaction;  Information visualization;  Situation awareness},
keywords={Animation;  Application programs;  Augmented reality;  Decision support systems;  Education computing;  Engineering education;  Human computer interaction;  Image enhancement;  Information analysis;  Information systems;  Military applications;  Military photography;  Visualization, 3-D information visualization;  3D animation;  Augmented reality technology;  Common operational picture;  Information visualization;  Situation awareness;  Situational awareness;  Teaching applications, Three dimensional computer graphics},
correspondence_address1={Mao, C.-C.; Department of Applied Arts, No.70, Sec. 2 Zhongyang N. Rd. Beitou Dist., Taiwan; email: Chia-ChiMao@gmail.com},
editor={Ahram T., Taiar R., Colson S., Choplin A.},
publisher={Springer Verlag},
issn={21945357},
isbn={9783030256289},
language={English},
abbrev_source_title={Adv. Intell. Sys. Comput.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Yakura2020555,
author={Yakura, H. and Goto, M.},
title={Enhancing Participation Experience in VR Live Concerts by Improving Motions of Virtual Audience Avatars},
journal={Proceedings - 2020 IEEE International Symposium on Mixed and Augmented Reality, ISMAR 2020},
year={2020},
pages={555-565},
doi={10.1109/ISMAR50242.2020.00083},
art_number={9284728},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099316694&doi=10.1109%2fISMAR50242.2020.00083&partnerID=40&md5=17c612b28296a3c652017eed66679f3f},
affiliation={University of Tsukuba National, Institute of Advanced Industrial Science and Technology (AIST), Japan; National Institute of Advanced, Industrial Science and Technology (AIST), Japan},
abstract={While participating in live concerts is a promising application of virtual reality (VR), it falls short of our participation experience in the real world. In particular, to increase the engagement of participants, previous studies emphasized the importance of social experience among audience members, such as the sense of co-presence elicited by sharing physical reactions or body movements synchronized with music. In this respect, a common strategy in existing platforms is to present avatars of remote human participants in a VR venue and make every avatar imitate movements of the corresponding participant. However, this strategy implicitly assumes that a not small number of users connect simultaneously to watch the same content and thus is not applicable when only a few users gather or a user is watching alone. Therefore, with the aim of providing better experience to a user who participates in live concerts as one of the audience, we examine computational approaches to enhancing the sense of co-presence through virtual audience avatars. We propose four methods of presenting avatar movements: copying the user's own movements, copying other users' movements, repeating beat-synchronous movements, and synthesizing machine-learning-based movements. We compare their effectiveness in a user experiment and discuss application scenarios and design implications that open up new ways of active media consumption in VR environments. © 2020 IEEE.},
author_keywords={Applied computing;  Arts and humanities;  Human computer interaction (HCI);  Human computer interaction (HCI);  Human-centered computing;  Interaction paradigms;  Interactive systems and tools;  Performing arts;  Virtual reality; Human-centered computing},
keywords={Augmented reality, Active media;  Application scenario;  Body movements;  Common strategy;  Computational approach;  Design implications;  Synchronous movement;  User experiments, User experience},
publisher={Institute of Electrical and Electronics Engineers Inc.},
isbn={9781728185088},
language={English},
abbrev_source_title={Proc. - IEEE Int. Symp. Mixed Augment. Real., ISMAR},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Suzuki2020166,
author={Suzuki, R. and Kazi, R.H. and Wei, L.-Y. and Diverdi, S. and Li, W. and Leithinger, D.},
title={RealitySketch: Embedding responsive graphics and visualizations in AR through dynamic sketching},
journal={UIST 2020 - Proceedings of the 33rd Annual ACM Symposium on User Interface Software and Technology},
year={2020},
pages={166-181},
doi={10.1145/3379337.3415892},
art_number={3415892},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096989074&doi=10.1145%2f3379337.3415892&partnerID=40&md5=b05d502d94af27233f717c0f6c835041},
affiliation={University of Calgary, Canada; Adobe Research; University of Colorado Boulder, United States},
abstract={We present RealitySketch, an augmented reality interface for sketching interactive graphics and visualizations. In recent years, an increasing number of AR sketching tools enable users to draw and embed sketches in the real world. However, with the current tools, sketched contents are inherently static, floating in mid-air without responding to the real world. This paper introduces a new way to embed dynamic and responsive graphics in the real world. In RealitySketch, the user draws graphical elements on a mobile AR screen and binds them with physical objects in real-time and improvisational ways, so that the sketched elements dynamically move with the corresponding physical motion. The user can also quickly visualize and analyze real-world phenomena through responsive graph plots or interactive visualizations. This paper contributes to a set of interaction techniques that enable capturing, parameterizing, and visualizing real-world motion without pre-defined programs and configurations. Finally, we demonstrate our tool with several application scenarios, including physics education, sports training, and in-situ tangible interfaces. © 2020 ACM.},
author_keywords={Augmented reality;  Embedded data visualization;  Real-time authoring;  Sketching interfaces;  Tangible interaction},
keywords={Augmented reality;  Drawing (graphics);  Dynamics;  Visualization, Application scenario;  Graphical elements;  Interaction techniques;  Interactive graphics;  Interactive visualizations;  Physical objects;  Physics education;  Tangible interfaces, User interfaces},
publisher={Association for Computing Machinery, Inc},
isbn={9781450375146},
language={English},
abbrev_source_title={UIST - Proc. Annu. ACM Symp. User Interface Softw. Technol.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Begic2020446,
author={Begic, M. and Cirimotic, M. and Farkas, I. and Skoric, I. and Car, Z. and Rasan, I. and Zilak, M.},
title={Software prototype based on augmented reality for mastering vocabulary},
journal={2020 43rd International Convention on Information, Communication and Electronic Technology, MIPRO 2020 - Proceedings},
year={2020},
pages={446-451},
doi={10.23919/MIPRO48935.2020.9245260},
art_number={9245260},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096365126&doi=10.23919%2fMIPRO48935.2020.9245260&partnerID=40&md5=ce95d25b73eea99e2e689517dc1d7d6b},
affiliation={University of Zagreb, Faculty of Electrical Engineering and Computing, Zagreb, Croatia},
abstract={Interactive experience of Augmented Reality that is created by deploying virtual objects in a real user environment, and its augmentation by audio-visual elements as well as the possibility of touch, provides added value for learning, especially regarding content multimodal presentation, increasing learner's motivation and level of engagement. This is very promising, especially in the field of education and rehabilitation, where current research slightly takes focus in this technological direction. To conduct this type of research, the prerequisite is to have a quality prototype with features, easy to understand and use by users of different cognitive skills, and yet sophisticated enough to carry out the research. The paper presents software prototype based on Augmented Reality aimed for mastering vocabulary for children with complex communication needs. The solution was developed in the multidisciplinary cooperation of students and teachers from the technical field and professionals from the education and rehabilitation field. The overall development process and initial evaluation are described, as well as the developed prototype from the technological and user perspective. © 2020 Croatian Society MIPRO.},
author_keywords={Augmented Reality;  Children;  Education;  Learning;  Mastering vocabulary;  Rehabilitation;  Virtual objects},
keywords={Augmented reality;  Petroleum reservoir evaluation, Added values;  Cognitive skill;  Complex communication needs;  Development process;  Learner's motivations;  Technical fields;  User perspectives;  Virtual objects, Software prototyping},
editor={Koricic M., Skala K., Car Z., Cicin-Sain M., Sruk V., Skvorc D., Ribaric S., Jerbic B., Gros S., Vrdoljak B., Mauher M., Tijan E., Katulic T., Pale P., Grbac T.G., Fijan N.F., Boukalov A., Cisic D., Gradisnik V.},
publisher={Institute of Electrical and Electronics Engineers Inc.},
isbn={9789532330991},
language={English},
abbrev_source_title={Int. Conv. Inf., Commun. Electron. Technol., MIPRO - Proc.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Harrington202070,
author={Harrington, M.C.R.},
title={Connecting User Experience to Learning in an Evaluation of an Immersive, Interactive, Multimodal Augmented Reality Virtual Diorama in a Natural History Museum & the Importance of Story},
journal={Proceedings of 6th International Conference of the Immersive Learning Research Network, iLRN 2020},
year={2020},
pages={70-78},
doi={10.23919/iLRN47897.2020.9155202},
art_number={9155202},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091628294&doi=10.23919%2fiLRN47897.2020.9155202&partnerID=40&md5=f7fa4d4c17bd27da4a85962abc7a79ac},
affiliation={University of Central Florida, Games and Interactive Media, Orlando, FL, United States},
abstract={Reported are the findings of user experience and learning outcomes from a July 2019 study of an immersive, interactive, multimodal augmented reality (AR) application, used in the context of a museum. The AR Perpetual Garden App is unique in creating an immersive multisensory experience of data. It allowed scientifically naïve visitors to walk into a virtual diorama constructed as a data visualization of a springtime woodland understory and interact with multimodal information directly through their senses. The user interface comprised of two different AR data visualization scenarios reinforced with data based ambient bioacoustics, an audio story of the curator's narrative, and interactive access to plant facts. While actual learning and dwell times were the same between the AR app and the control condition, the AR experience received higher ratings on perceived learning. The AR interface design features of "Story"and "Plant Info"showed significant correlations with actual learning outcomes, while "Ease of Use"and "3D Plants"showed significant correlations with perceived learning. As such, designers and developers of AR apps can generalize these findings to inform future designs. © 2020 Immersive Learning Research Network.},
author_keywords={augmented reality;  bioacoustics;  data visualization;  immersive;  informal learning;  information fidelity;  interactive;  multimodal;  museums;  narrative;  photorealistic;  place illusion;  presence;  virtual dioramas;  virtual reality},
keywords={Augmented reality;  Data visualization;  Museums;  User experience;  User interfaces;  Virtual reality;  Visualization, Ease-of-use;  Future designs;  Interface design features;  Learning outcome;  Multi-modal information;  Multisensory;  Natural history;  Perceived learning, E-learning},
correspondence_address1={Harrington, M.C.R.; University of Central Florida, United States; email: maria.harrington@ucf.edu},
editor={Economou D., Klippel A., Dodds H., Pena-Rios A., Lee M.J.W., Beck D., Pirker J., Dengel A., Peres T.M., Richter J.},
publisher={Institute of Electrical and Electronics Engineers Inc.},
isbn={9781734899504},
language={English},
abbrev_source_title={Proc. Int. Conf. Immersive Learn. Res. Netw., iLRN},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Pittman2020761,
author={Pittman, C. and Jr, J.J.L.},
title={PhyAR: Determining the Utility of Augmented Reality for Physics Education in the Classroom},
journal={Proceedings - 2020 IEEE Conference on Virtual Reality and 3D User Interfaces, VRW 2020},
year={2020},
pages={761-762},
doi={10.1109/VRW50115.2020.00231},
art_number={9090480},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085374933&doi=10.1109%2fVRW50115.2020.00231&partnerID=40&md5=c4bf63e74da8fbfbda92b79c2d379f89},
affiliation={University of Central Florida, Orlando, FL, United States},
abstract={Physics is frequently cited as a difficult roadblock and hindrance to retention in STEM majors. In this paper, we present the results of a study exploring the potential utility and use cases of augmented reality in secondary and post secondary physics courses. To gather meaningful information, we developed PhyAR, prototype physics education application in augmented reality. We collected feedback and opinions from a qualitative study of university students with STEM backgrounds. Our findings point towards a clear desire to see the use of more interactive 3D AR content in physics courses. © 2020 IEEE.},
author_keywords={Augmented Reality;  Physics Education;  Qualitative Interview},
keywords={Augmented reality;  Curricula;  Software prototyping;  User interfaces;  Virtual reality, Physics education;  Potential utility;  Qualitative study;  University students, STEM (science, technology, engineering and mathematics)},
publisher={Institute of Electrical and Electronics Engineers Inc.},
isbn={9781728165325},
language={English},
abbrev_source_title={Proc. - IEEE Conf. Virtual Real. 3D User Interfaces, VRW},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Andriyandi2020208,
author={Andriyandi, A.P. and Darmalaksana, W. and Maylawati, D.S. and Irwansyah, F.S. and Mantoro, T. and Ramdhani, M.A.},
title={Augmented reality using features accelerated segment test for learning tajweed},
journal={Telkomnika (Telecommunication Computing Electronics and Control)},
year={2020},
volume={18},
number={1},
pages={208-216},
doi={10.12928/TELKOMNIKA.V18I1.14750},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084088515&doi=10.12928%2fTELKOMNIKA.V18I1.14750&partnerID=40&md5=0fd6ad1d139c09e1b169cfa7b5fc964c},
affiliation={Department of Informatics, UIN Sunan Gunung Djati, Bandung, Indonesia; Department of llmu Hadits, UIN Sunan Gunung Djati, Bandung, Indonesia; Faculty of Information and Communication Technology, Universiti Teknikal Malaysia, Melaka, Malaysia; Faculty of Tarbiyah and Education, UIN Sunan Gunung Djati, Bandung, Indonesia; Department of Computer Science, Sampoerna University, Indonesia},
abstract={Currently, education forms students to think creatively and critically, this can be supported by the multimedia technology for education, including Islamic religious education. Islam requires all of its Muslim to read the Qur'an. Tajweed is an important because it is related to the articulation of reading the Qur'an properly and correctly. This article discusses the application of augmented reality (AR) as one of the multimedia technologies that can be used as an interactive educational medium to help study the tajweed of Qur'an. The method used in this research is Features from accelerated segment test (FAST) corner detection. The testing result with 31 tajweed objects show that FAST is able to recognize all Tajweed objects and display their AR. Besides, based on a survey with questionnaires to several students, the result shows that 88.2% of students responded very well and judged that it was sufficient to help study the tajweed. © 2020, Universitas Ahmad Dahlan.},
author_keywords={Augmented reality;  FAST corner detection;  Multimedia},
correspondence_address1={Maylawati, D.S.; Department of Informatics, Indonesia; email: diansm@uinsgd.ac.id},
publisher={Universitas Ahmad Dahlan},
issn={16936930},
language={English},
abbrev_source_title={Telkomnika Telecomun. Compt. Electr. Control},
document_type={Article},
source={Scopus},
}

@ARTICLE{Madi202035,
author={Madi, N.A.M. and Albakry, N.S. and Ibrahim, N.},
title={AR mobile application in learning Hajj for children in Malaysia},
journal={International Journal of Interactive Mobile Technologies},
year={2020},
volume={14},
number={16},
pages={35-51},
doi={10.3991/ijim.v14i16.12807},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092468986&doi=10.3991%2fijim.v14i16.12807&partnerID=40&md5=ed2fa59afcffabb8db63d8479c5dcde0},
affiliation={Application Multimedia program at Faculty of Art, Computing and Creative Industry, Universiti Pendidikan Sultan Idris, Tanjung Malim, Perak, Malaysia; Computing and Creative Industry, Department of Creative Multimedia, Universiti Pendidikan Sultan Idris, Tanjung Malim, Perak, Malaysia},
abstract={Education is experiencing rapid revolution from the chalk to the computer. Since then, education and technology are moving forward with advanced technology. Furthermore, with the positive impact derived from previous research, Augmented Reality (AR) started to play a role in education either in learning or teaching. Thus, the aim of this paper is to explore the elements will be implemented in the development of Hajj AR mobile application for learning Hajj among the children in Malaysia. In the preliminary study, a survey using an open-ended and closed-ended questionnaire was conducted among experienced teachers. The findings from the survey revealed that the elements of AR could beimplemented in the Hajj AR mobile application as an interactive learning tool. Thus, a Hajj AR mobile application will be developed by implementing the findings obtained in the preliminary study to evaluate the user-experience among the children who are using the AR mobile application when learning Hajj. In conclusion, this mobile application could attract and provide creative information to children in learning about Hajj through AR. © 2020 by the authors.},
author_keywords={Augmented reality (AR);  Children;  Early childhood education;  Hajj;  Mobile learning application},
correspondence_address1={Madi, N.A.M.; Application Multimedia program at Faculty of Art, Malaysia; email: M20171000472@siswa.upsi.edu.my},
publisher={International Association of Online Engineering},
issn={18657923},
language={English},
abbrev_source_title={Int. J. Interact. Mob. Technol.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Mahayuddin2020514,
author={Mahayuddin, Z.R. and Saifuddin Saif, A.F.M.},
title={Augmented reality based AR alphabets towards improved learning process in primary education system},
journal={Journal of Critical Reviews},
year={2020},
volume={7},
number={19},
pages={514-521},
doi={10.31838/jcr.07.19.66},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090146737&doi=10.31838%2fjcr.07.19.66&partnerID=40&md5=2eb63508e3814f1367c88a44c9b7a166},
affiliation={University Kebangsaan Malaysia, Malaysia; American International University, Bangladesh},
abstract={Education gives the insight to take us to the future which has not been possible to grasp due to lack of research methodologies towards learning process. Traditional formal education methodologies feel like living in the old age as existing learning processes are not advanced like technology which starts from primary education. As a result, children are losing interest in education due to the way of learning. In this context, learning is a continuous process where the quality cannot be justified by just including reading and writing, the overall process should be creative and interactive as well. However, existing primary education system seems to abandon the main idea about education and learning process to lean towards memorization and rote learning. The way of acquisition of education should be through discussion, research, storytelling, training which should be fun and interesting but our traditional primary education is based on two-dimensional materials and does not provide any of these opportunities. In this context, augmented reality or AR can be considered as advanced technology which can revolt the learning through visualization and interaction by engaging various characteristics. Recently, scientists are researching about how to incorporate AR with education where they gained positive results and by taking the positive result from the previous researches, this research proposed an Augmented Reality application: AR Alphabets. This research integrated proposed AR Alphabets with traditional primary education for better and improved learning experience. Experimental evaluation demonstrates effective efficiency to improve the learning process using proposed augmented reality based AR alphabet. © 2020 Innovare Academics Sciences Pvt. Ltd. All rights reserved.},
author_keywords={Augmented reality;  Learning experience;  Primary education},
publisher={Innovare Academics Sciences Pvt. Ltd},
issn={23945125},
language={English},
abbrev_source_title={J. Crit. Rev.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Zhang2020,
author={Zhang, G.},
title={Design of virtual reality augmented reality mobile platform and game user behavior monitoring using deep learning},
journal={International Journal of Electrical Engineering Education},
year={2020},
doi={10.1177/0020720920931079},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086520600&doi=10.1177%2f0020720920931079&partnerID=40&md5=4eb76243564cb0c8be13c08fa53005fe},
affiliation={School of Art and Design, Lanzhou Jiaotong University, Lanzhou, China},
abstract={To explore the design of the virtual reality (VR) augmented reality (AR) mobile platform and game decision model based on deep learning (DL), the gesture-based interaction of VR games based on Leap Motion is researched. Based on the interactive features of gestures, a set of general gesture interaction rules in VR games is established. In the meantime, according to the theoretical basis and the characteristics of VR, a set of general models of VR gesture interaction is designed, the factors affecting the efficiency of VR gesture interaction are studied, and reasonable interaction feedback is designed. By using the computer vision and image processing technology, gesture-based interaction can collect natural gestures, extract gesture features, recognize gesture indications, and respond to the user demands. Also, it can extract the basic gestures from gesture-based interaction in VR, analyze the basic features of gestures and gesture-based interaction in VR games, and describes the gesture features by mathematical vectors and sets. The research results show that the application of gesture feature design method in the game can analyze the factors affecting the interaction efficiency. Also, the usability of the gesture-based interaction designed by the gesture design method is verified by tests. Therefore, the AR&DL platform of “AR+DL” establishes a learning platform supported by DL and AR technology. The game decision model is used to describe the process of gesture-based interaction in the game, and the factors affecting the interaction efficiency are reduced, which has certain reference and guidance for VR applications using gesture-based interaction. © The Author(s) 2020.},
author_keywords={augmented reality;  Deep learning;  gesture-based interaction;  Leap Motion;  Unity3D},
keywords={Augmented reality;  Behavioral research;  Design;  Drilling platforms;  E-learning;  Efficiency;  Image processing;  Virtual reality, Decision modeling;  Gesture interaction;  Gesture-based interaction;  Image processing technology;  Interaction efficiency;  Interactive features;  Learning platform;  User behavior monitoring, Deep learning},
correspondence_address1={Zhang, G.; School of Art and Design, China; email: animo@mail.lzjtu.cn},
publisher={SAGE Publications Inc.},
issn={00207209},
coden={IJEEA},
language={English},
abbrev_source_title={Int J Electr Eng Educ},
document_type={Article},
source={Scopus},
}

@ARTICLE{Zhang2020,
author={Zhang, J. and Huang, Y.-T. and Liu, T.-C. and Sung, Y.-T. and Chang, K.-E.},
title={Augmented reality worksheets in field trip learning},
journal={Interactive Learning Environments},
year={2020},
doi={10.1080/10494820.2020.1758728},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084837564&doi=10.1080%2f10494820.2020.1758728&partnerID=40&md5=f8cc670b9c214605155821a0e82e5868},
affiliation={Graduate Institute of Information and Computer Education, National Taiwan Normal University, Taipei, Taiwan; Department of Educational Psychology and Counseling, National Taiwan Normal University, Taipei, Taiwan},
abstract={Worksheets are often used during field trips and utilize a learning cycle with three stages (exploration, concept introduction and concept application) to engage learners in the learning activities of observation and exploration. However, traditional paper worksheets do not provide multimedia and interactive presentations with physical objects, which made learners losing interaction with the physical context during field trips and failing to implement all the stages completely. This study designed an augmented reality worksheet with a three-stage learning cycle and applied it to learning about plants, specifically assisting learners in observing and classifying plants. A pretest-posttest quasi-experimental design was used to show the effect of learning when learners used augmented reality worksheets. Lag sequence analysis was used to identify learning behavioral patterns. The findings indicate that the learning effect of using augmented reality worksheets is much better than that of paper worksheets and improves the learners’ interaction with plants. © 2020, © 2020 Informa UK Limited, trading as Taylor & Francis Group.},
author_keywords={Augmented reality;  field trips;  guided discovery learning;  learning cycle;  worksheets},
correspondence_address1={Chang, K.-E.; Graduate Institute of Information and Computer Education, Taiwan; email: kchang@ntnu.edu.tw},
publisher={Routledge},
issn={10494820},
language={English},
abbrev_source_title={Interact. Learn. Environ.},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Rosni2020,
author={Rosni, N.S. and Kadir, Z.A. and Mohamed Noor, M.N.M. and Abdul Rahman, Z.H. and Bakar, N.A.},
title={Development of mobile markerless augmented reality for cardiovascular system in anatomy and physiology courses in physiotherapy education},
journal={Proceedings of the 2020 14th International Conference on Ubiquitous Information Management and Communication, IMCOM 2020},
year={2020},
doi={10.1109/IMCOM48794.2020.9001692},
art_number={9001692},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081129276&doi=10.1109%2fIMCOM48794.2020.9001692&partnerID=40&md5=326b40b4629a7faf4641004914ad56f6},
affiliation={Universiti Kuala Lumpur MIIT, Creative Multimedia, Wilayah Persekutuan, Kuala Lumpur, Malaysia; Universiti Kuala Lumpur MIIT, Computer Engineering, Wilayah Persekutuan, Kuala Lumpur, Malaysia; Universiti Kuala Lumpur RCMP, Physiotherapy, Ipoh, Perak, Malaysia},
abstract={This paper focuses on the development of markerless Augmented Reality (AR) using ARCore platform, where interactive three-dimensional (3D) content was designed and developed based on the learning outcome syllabus to enhance the visualization and understanding of the anatomy and physiology for cardiovascular system topic. Currently, learning method is based on 2D images and slides, plastic models and cadavers have to deal with students' experience issues such as lack of interactive, uneasy feeling with dead body and cadavers storing and donation. Therefore, more advances using technology such as Augmented Reality (AR) in learning method are needed to overcome the current gap and enhance the students' learning. Thus, this study aims to develop markerless AR specifically focus on the cardiovascular system for undergraduate physiotherapy program at UniKL, RCMP. In this study, we describe a method used to create markerless AR content using 3D data from MRI images and 3D unity as an authoring tool. We present three processes, where the first design consideration based on author's previous works derived from systematic search strategy were outlined, the second 3D model was developed using a real object and subsequently converted to an AR asset that can be linked to a unique markerless using ARCore platform and the third AR content creation using 3D unity authoring tool. This application provides a better visualization for the anatomical parts to support for an innovative and flexible learning process. We have successfully analyzed the design consideration using a systematic search strategy and developed the markerless AR specifically for cardiovascular system in anatomy and physiology courses. This study has contributed to knowledge in design and development of AR used in physiotherapy education. Therefore, this will be a step forward to an exploration of design-based research for an AR benefit in experienced-learning approach application. © 2020 IEEE.},
author_keywords={anatomy and physiology;  ARCore;  augmented reality;  cardiovascular system;  markerless AR;  physiotherapy education},
keywords={3D modeling;  Augmented reality;  Cardiovascular system;  Curricula;  Design;  Education computing;  Information management;  Magnetic resonance imaging;  Physical therapy;  Students;  Three dimensional computer graphics;  Visualization, ARCore;  Design and Development;  Design considerations;  Design-based research;  Flexible Learning;  Markerless;  Systematic searches;  Threedimensional (3-d), Learning systems},
editor={Lee S., Choo H., Ismail R.},
publisher={Institute of Electrical and Electronics Engineers Inc.},
isbn={9781728154534},
language={English},
abbrev_source_title={Proc. Int. Conf. Ubiquitous Inf. Manag. Commun., IMCOM},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Huerta2020836,
author={Huerta, O. and Unver, E. and Arslan, R. and Kus, A. and Allen, J.},
title={An approach to improve technical drawing using VR and AR tools},
journal={Computer-Aided Design and Applications},
year={2020},
volume={17},
number={4},
pages={836-849},
doi={10.14733/cadaps.2020.836-849},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075360494&doi=10.14733%2fcadaps.2020.836-849&partnerID=40&md5=56b5c247d78ba1293b7697130f761412},
affiliation={University of Huddersfield, United Kingdom; Uludag University, Turkey},
abstract={In this paper, the authors present the development of 3D interactive AR/VR teaching system from a design-based method to help engineering and product design students improve on critical and complex topics related to TD skills according to an international survey and as part of a broader European funded research project. This work shows that human-centred approaches can improve the understanding of students needs and facilitate the development of AR/VR technology applications for T&L within an international and multidisciplinary team. © 2020 CAD Solutions, LLC.},
author_keywords={Augmented Reality;  Teaching and Learning;  Technical Drawings;  Virtual Reality},
keywords={Augmented reality;  Students;  Virtual reality, Interactive ar;  International survey;  Multi-disciplinary teams;  Teaching and learning;  Teaching systems;  Technical drawing;  Technology application, Product design},
correspondence_address1={Huerta, O.; University of HuddersfieldUnited Kingdom; email: o.huertacardoso@hud.ac.uk},
publisher={CAD Solutions, LLC},
issn={16864360},
language={English},
abbrev_source_title={Comput.-Aided Des. Appl.},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Fadzli2020,
author={Fadzli, F.E. and Yusof, M.A.M. and Ismail, A.W. and Salam, M.S.H. and Ismail, N.A.},
title={ARGarden: 3D outdoor landscape design using handheld augmented reality with multi-user interaction},
journal={IOP Conference Series: Materials Science and Engineering},
year={2020},
volume={979},
number={1},
doi={10.1088/1757-899X/979/1/012001},
art_number={012001},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097264096&doi=10.1088%2f1757-899X%2f979%2f1%2f012001&partnerID=40&md5=c6ae98d0d19767062ce9582c444ce483},
affiliation={Mixed and Virtual Environment Research Lab (Mivielab), ViCubeLab, Universiti Teknologi Malaysia, Johore, 81310, Malaysia; School of Computing, Faculty of Engineering, Universiti Teknologi MalaysiaJohor, Malaysia},
abstract={Augmented Reality (AR) is a technology to display the virtual object by overlaying on the physical marker in the real environment. Nowadays, the handheld device becomes a trend in AR since it has high processing power and compatible with the AR system. However, most of the AR applications did not fully support the interaction from multiple users for the collaborative AR interface. Therefore, this research aim is to develop multi-user interaction for collaborative handheld AR. There are a few phases involved to design and develop the collaborative AR application for the handheld device called ARGarden. All the interaction that has been done for the virtual object transformation such as translation, rotation and scaling can be seen by the other users, and this data is synchronized by using a network protocol. Then, a queue system is implemented for the multi-user interaction to allow the virtual object can only be selected by one user at one time, and the other users must wait for their turn. The significance of this research is all the method that has been implemented for the ARGarden can be applied in different fields such as simulation, modelling, medical and education. © Published under licence by IOP Publishing Ltd.},
correspondence_address1={Fadzli, F.E.; Mixed and Virtual Environment Research Lab (Mivielab), Malaysia; email: fazliaty.edora@gmail.com},
publisher={IOP Publishing Ltd},
issn={17578981},
language={English},
abbrev_source_title={IOP Conf. Ser. Mater. Sci. Eng.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Nadeem20201,
author={Nadeem, M. and Chandra, A. and Livirya, A. and Beryozkina, S.},
title={AR-LaBOR: Design and assessment of an augmented reality application for lab orientation},
journal={Education Sciences},
year={2020},
volume={10},
number={11},
pages={1-30},
doi={10.3390/educsci10110316},
art_number={316},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096043631&doi=10.3390%2feducsci10110316&partnerID=40&md5=faff941413824b8ef3e037dad829b6dd},
affiliation={College of Engineering and Technology, American University of the Middle East, Al-Eqaila, 54200, Kuwait; Department of Electrical, Computer, and Software Engineering, The University of Auckland, Auckland, 1010, New Zealand},
abstract={Lab orientation is a vital part of learning for new students entering the university, as it provides the students with all the necessary and important information about the lab. The current orientation is manual, tedious, suffers from logistical constraints, lacks engagement, and provides no way to assess that outcomes have been achieved. This is also supported by the results of a student survey which revealed students’ dissatisfaction with current process of orientation. This study presents the design and development of a sample augmented reality mobile application, AR-LabOr, for the lab orientation that helps students in a quick and easy adaptation to the lab environment by familiarizing them with the lab equipment, staff, and safety rules in a fun and interactive manner. This application makes use of marker-less augmented reality technology and a blend of multimedia information such as sound, text, images, and videos that are superimposed on real-world contents. An experiment with 56 students showed that they found the novel method of orientation using the application more engaging than the traditional instructor-led method. Students also found the application to be more supportive, motivating, and that it helped them in better understanding the lab equipment. © 2020 by the authors. Licensee MDPI, Basel, Switzerland.},
author_keywords={Augmented reality;  Educational technology;  Higher education;  Lab orientation;  Teaching and learning},
correspondence_address1={Nadeem, M.; College of Engineering and Technology, Kuwait; email: Muhammad.Nadeem@aum.edu.kw; Nadeem, M.; Department of Electrical, New Zealand; email: Muhammad.Nadeem@aum.edu.kw},
publisher={MDPI AG},
issn={22277102},
language={English},
abbrev_source_title={Educ. Sci.},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Louis20201248,
author={Louis, T. and Troccaz, J. and Rochet-Capellan, A. and Bérard, F.},
title={GyroSuite: General-purpose interactions for handheld perspective corrected displays},
journal={UIST 2020 - Proceedings of the 33rd Annual ACM Symposium on User Interface Software and Technology},
year={2020},
pages={1248-1260},
doi={10.1145/3379337.3415893},
art_number={3415893},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096958759&doi=10.1145%2f3379337.3415893&partnerID=40&md5=001a996f75c56a5546a7d2db46a209b2},
affiliation={University Grenoble Alpes, CNRS, LIG, TIMC, Gipsa-Lab Grenoble, France},
abstract={Handheld Perspective-Corrected Displays (HPCDs) are physical objects that have a notable volume and that display a virtual 3D scene on their entire surface. Being handheld, they create the illusion of holding the scene in a physical container (the display). This has strong benefits for the intuitiveness of 3D interaction: manipulating objects of the virtual scene amounts to physical manipulations of the display. HPCDs have been limited so far to technical demonstrators and experimental tools to assess their merits. However, they show great potential as interactive systems for actual 3D applications. This requires that novel interactions be created to go beyond object manipulation and to offer general-purpose services such as menu command selection and continuous parameter control. Working with a two-handed spherical HPCD, we report on the design and informal evaluations of various interaction techniques for distant object selection, scene scaling, menu interaction and continuous parameter control. In particular, our design leverages the efficient two-handed control of the rotations of the display. We demonstrate how some of these techniques can be assemble in a self-contained anatomy learning application. Novice participants used the application in a qualitative user experiment. Most participants used the application effortlessly without any training or explanations. © 2020 ACM.},
author_keywords={Gui;  Hpcd;  Spatial augmented reality},
keywords={Computer aided instruction;  User interfaces;  Virtual reality, 3D interactions;  Continuous parameters;  Interaction techniques;  Interactive system;  Object manipulation;  Object selection;  Physical objects;  User experiments, Three dimensional displays},
publisher={Association for Computing Machinery, Inc},
isbn={9781450375146},
language={English},
abbrev_source_title={UIST - Proc. Annu. ACM Symp. User Interface Softw. Technol.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Suzuki2020135,
author={Suzuki, R. and Kazi, R.H. and Wei, L.-Y. and Diverdi, S. and Li, W. and Leithinger, D.},
title={RealitySketch: Embedding Responsive Graphics and Visualizations in AR with Dynamic Sketching},
journal={UIST 2020 - Adjunct Publication of the 33rd Annual ACM Symposium on User Interface Software and Technology},
year={2020},
pages={135-138},
doi={10.1145/3379350.3416155},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095594646&doi=10.1145%2f3379350.3416155&partnerID=40&md5=fd47d4d1738488e7ef28f332eb6265da},
affiliation={University of Calgary, Calgary, AB, Canada; Adobe Research, Seattle, WA, United States; University of Colorado Boulder, Boulder, CO, United States},
abstract={We present RealitySketch, an augmented reality interface for sketching interactive graphics and visualizations. In recent years, an increasing number of AR sketching tools enable users to draw and embed sketches in the real world. However, with the current tools, sketched contents are inherently static, floating in mid air without responding to the real world. This paper introduces a new way to embed dynamic and responsive graphics in the real world. In RealitySketch, the user draws graphical elements on a mobile AR screen and binds them with physical objects in real-time and improvisational ways, so that the sketched elements dynamically move with the corresponding physical motion. The user can also quickly visualize and analyze real-world phenomena through responsive graph plots or interactive visualizations. This paper contributes to a set of interaction techniques that enable capturing, parameterizing, and visualizing real-world motion without pre-defined programs and configurations. Finally, we demonstrate our tool with several application scenarios, including physics education, sports training, and in-situ tangible interfaces. © 2020 Owner/Author.},
author_keywords={augmented reality;  embedded data visualization;  real-time authoring;  sketching interfaces;  tangible interaction},
keywords={Augmented reality;  Drawing (graphics);  Dynamics;  Visualization, Application scenario;  Graphical elements;  Interaction techniques;  Interactive graphics;  Interactive visualizations;  Physical objects;  Physics education;  Tangible interfaces, User interfaces},
publisher={Association for Computing Machinery, Inc},
isbn={9781450375153},
language={English},
abbrev_source_title={UIST - Adjun. Publ. Annu. ACM Sym. User Interface Softw. Technol.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Wang20201493,
author={Wang, X. and Chen, C. and Li, Z.},
title={Augmented Reality and Quick Response Code Technology in Engineering Drawing Course},
journal={2020 IEEE International Conference on Mechatronics and Automation, ICMA 2020},
year={2020},
pages={1493-1498},
doi={10.1109/ICMA49215.2020.9233543},
art_number={9233543},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096518434&doi=10.1109%2fICMA49215.2020.9233543&partnerID=40&md5=764f0bce02eb4ade7f3d3e301953ae0d},
affiliation={Tianjin University of Technology, Tianjin Key Laboratory for Advanced Mechatronic System Design and Intelligent Control, School of Mechanical Engineering, Tianjin, 300384, China},
abstract={Augmented reality (AR) technology is a cutting technology. It can enhance the perception of reality and provide more information of the real world. AR technology is used in many fields, like medical, industry, and education. In this paper, AR is introduced into engineering drawing course. Engineering drawing course is difficult to learn as it is a knowledge that students rarely contact with. To have a close contact with the models and the views, a convenient AR application (AR app) is proposed in the paper. With the help of the AR app, virtual models and real views are combined well. The models can be moved and rotated by touching the screen. Some videos of model assembly and disassembly can be obtained when scanning the quick response code (QR code). Thus, it is convenient for students to use mobile phone to study engineering drawing effectively. The interactive teaching environment enhances students' spatial thinking and cultivates their sense of innovation. © 2020 IEEE.},
keywords={Augmented reality;  E-learning;  Education computing;  mHealth;  Students;  Touch screens, AR application;  Cutting technology;  Engineering drawing;  Interactive teaching environment;  Model assembly;  Quick response code;  Spatial thinking;  Virtual models, Engineering education},
publisher={Institute of Electrical and Electronics Engineers Inc.},
isbn={9781728164151},
language={English},
abbrev_source_title={IEEE Int. Conf. Mechatronics Autom., ICMA},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Harrington2020,
author={Harrington, M.},
title={Augmented and virtual reality application design for immersive learning research using virtual nature: Making knowledge beautiful and accessible with information fidelity},
journal={Special Interest Group on Computer Graphics and Interactive Techniques Conference Talks, SIGGRAPH 2020},
year={2020},
doi={10.1145/3388767.3407318},
art_number={56},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091964434&doi=10.1145%2f3388767.3407318&partnerID=40&md5=ed844b2164185d1365868235d77d4e6f},
affiliation={University of Central Florida, United States},
abstract={Described are two applications using immersive augmented reality (AR) and virtual reality (VR) for informal learning research. A critical design factor resulting from the authentication process in sourcing all text, media, and data is the high information fidelity (truth) in all signals transmitted to the human. The AR Perpetual Garden App was developed to annotate the Carnegie Museum of Natural History's dioramas and gardens to bring learning to all visitors. The Virtual UCF Arboretum was developed to represent the real UCF Arboretum in VR for immersive learning research. More like a virtual diorama or virtual field trip, they are open to independent exploration and learning. Unlike fantasy games or creative animations, these environments used accurate content, high information fidelity, to enhance immersion and presence. As data visualizations or simulations, and not point-clouds or interactive 360 VR video, they can show past, present, and future scenarios from data. As an application intended for informal learning, the needs of learners as well as the institutional stakeholders were integrated in a participatory design process by extending traditional user-centered design with expert-learner-user-centered design. The design patterns will be of interest to a broad community concerned with perception, emotions, learning, immersion and presence, and any who are developing educational, training and certification, or decision support applications with respect to improving natural knowledge. © 2020 Owner/Author.},
author_keywords={Aesthetics;  Augmented reality;  Beauty;  Bioacoustics;  Data visualization;  Geoinformation;  Immersive;  Informal learning;  Interactive;  Knowledge;  Multimodal;  Museums;  User-centered design;  Virtual nature;  Virtual reality;  Wayfinding},
keywords={Animation;  Augmented reality;  Behavioral research;  Decision support systems;  E-learning;  Interactive computer graphics;  User centered design, Application design;  Augmented and virtual realities;  Decision support applications;  Immersive augmented realities;  Immersive learning;  Information fidelity;  Participatory design;  Virtual field trips, Virtual reality},
correspondence_address1={Harrington, M.; University of Central FloridaUnited States; email: maria.harrington@ucf.edu},
publisher={Association for Computing Machinery},
isbn={9781450379717},
language={English},
abbrev_source_title={Spec. Int. Group Comput. Graph. Interact. Tech. Conf. Talks, SIGGRAPH},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Trista20201518,
author={Trista, S. and Rusli, A.},
title={Historiar: Experience indonesian history through interactive game and augmented reality},
journal={Bulletin of Electrical Engineering and Informatics},
year={2020},
volume={9},
number={4},
pages={1518-1524},
doi={10.11591/eei.v9i4.1979},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085608326&doi=10.11591%2feei.v9i4.1979&partnerID=40&md5=8f54ff23af1671f6eb98deb1f61a5e62},
affiliation={Department of Informatics, Universitas Multimedia Nusantara, Indonesia},
abstract={History has a vital function in shaping the personality of the nation, the quality of humans, and the people of a country. However, one factor that influences learning behavior that could be improved is the students’ interest in learning. The use of game-based learning has been proven to be effective in making activities to be more fun to do. Moreover, augmented reality technology also shows enormous potential in the world of education. This research developed a game-based historical learning application using augmented reality to enhance user experience in learning history. The application is built using the Unity Game Engine and Vuforia. Furthermore, the application was tested and evaluated by measuring the perceived usefulness and perceived ease of use following the guidance in the Technology Acceptance Model. The result shows that the application achieves 89.5% for perceived usefulness and 86.33% for perceived ease of use. © 2020, Institute of Advanced Engineering and Science. All rights reserved.},
author_keywords={Augmented reality;  Behavioral intention to use;  Game-based learning;  Indonesian history;  User experience},
correspondence_address1={Rusli, A.; Department of Informatics, Kampus UMN, Scientia Garden, Jl. Boulevard Gading Serpong, Indonesia; email: andre.rusli@umn.ac.id},
publisher={Institute of Advanced Engineering and Science},
issn={20893191},
language={English},
abbrev_source_title={Bull. Electr. Eng. Inform.},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Martin2020,
author={Martin, S. and Parra, G. and Cubillo, J. and Quintana, B. and Gil, R. and Perez, C. and Castro, M.},
title={Design of an augmented reality system for immersive learning of digital electronic},
journal={Proceedings - 2020 14th Technologies Applied to Electronics Teaching Conference, TAEE 2020},
year={2020},
doi={10.1109/TAEE46915.2020.9163704},
art_number={9163704},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091886853&doi=10.1109%2fTAEE46915.2020.9163704&partnerID=40&md5=ea94fd29a5c73a6e666d2a0c2bb6e13c},
affiliation={Universidad Nacional de Educación A Distancia (UNED), Dep. Ing. Electrica, Electronica, Control, Telematica y Quimica Aplicada A la Lngenieria, Madrid, Spain},
abstract={This article describes the development of two mobile applications for learning Digital Electronics. The first application is an interactive app for iOS where you can study the different digital circuits, and which will serve as the basis for the second: a game of questions in augmented reality. © 2020 IEEE.},
author_keywords={Augmented Reality;  Digital Electronics;  Immersive Learning;  Mobile Application},
keywords={Augmented reality;  Digital circuits, Augmented reality systems;  Digital electronics;  Immersive learning;  Mobile applications, E-learning},
correspondence_address1={Martin, S.; Universidad Nacional de Educación A Distancia (UNED), Spain; email: smartin@ieec.uned.es},
editor={Alves G.R., Fidalgo A.V., Felgueiras M.C., Costa R.J.},
publisher={Institute of Electrical and Electronics Engineers Inc.},
isbn={9781728167329},
language={English},
abbrev_source_title={Proc. - Technol. Appl. Electron. Teach. Conf., TAEE},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Tamayo202040,
author={Tamayo, J.L.R. and Hernández, M.B. and Gómez, H.G.},
title={Digital data visualization with interactive and virtual reality tools. Review of current state of the art and proposal of a model [Visualización de datos con herramientas interactivas y de realidad virtual. Revisión del estado actual y propuesta de modelo]},
journal={Icono14},
year={2020},
volume={16},
number={2},
pages={40-65},
doi={10.7195/RI14.V16I2.1174},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085893385&doi=10.7195%2fRI14.V16I2.1174&partnerID=40&md5=6f19bba46241f5af4ee4930a1b113af9},
affiliation={Department of Communication Sciences and Sociology, Universidad Rey Juan Carlos - URJC, Spain; Universidad Nacional Autónoma de México - UNAM, Mexico; Universidad Abierta y Educación a Distancia, Mexico; Communication Department, Universidad Europea de Madrid - UEM, Spain},
abstract={Massive and open data constitute a burgeoning field of study in the current context. The evolution of technology is, in turn, increasing its degree of interactivity, configuring several scenarios of great complexity in which data is understood on the basis of our interaction with it at different levels. Technologies such as virtual reality or augmented reality present an emerging framework for visualizing, representing and understanding information. Moreover, new disciplines such as interaction design, human-computer interaction, and user experience are needed to optimally configure the representation and design of data interaction dynamics, so that they can be implemented in contexts such as education. This paper reviews the current state of interactive and immersive technology (including virtual reality and alternative reality games) and of open and massive data, to highlight potential projections and propose models of data representation based on factors such as storytelling or user experience. This paper shows the need to develop models for data use and representation in fields such as education and citizen empowerment. © 2020 Scientific Association Icono14. All rights reserved.},
author_keywords={Data science;  Data visualization;  Educational applications;  Human-computer interaction;  Interaction design;  Open access to data},
publisher={Scientific Association Icono14},
issn={16978293},
language={English},
abbrev_source_title={Icono14},
document_type={Article},
source={Scopus},
}

@ARTICLE{Al-Imamy20202561,
author={Al-Imamy, S.Y.},
title={Blending printed texts with digital resources through augmented reality interaction},
journal={Education and Information Technologies},
year={2020},
volume={25},
number={4},
pages={2561-2576},
doi={10.1007/s10639-019-10070-w},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076529699&doi=10.1007%2fs10639-019-10070-w&partnerID=40&md5=5c25ce078549e62cd02fde8290455305},
affiliation={MIS Department, Prince Mohammad Bin Fahd University, Half Moon Bay/Al Khobar, Saudi Arabia},
abstract={Traditional printed textbooks represented a static medium of knowledge transfer for many years. The advent of technology introduced several digital material encouraged the educational institution to plan for the transfer to e-book and other related digital media. Both printed and digital materials have their own advantages and disadvantages as explained in the literature review. This work introduces a way to blend both through the augmentation of printed textbook with interactive entries to the digital media. The well planned entries guide the learners into the digital world that is recommended by the expert educators. The learners, however, still have the freedom to select and repeat the material they like to study according to their own learning style. An application was developed and used by a group of students to evaluate the print/digital blending concept. The quantitative measurements proved an increase in the interest, confidence and perceived performance of the learners using proved easy to use useful application. Making the application available to the learners of different disciplines through simple user interface was also recommended as one of the possible future works. © 2019, Springer Science+Business Media, LLC, part of Springer Nature.},
author_keywords={Audio-visual resources;  Augmented reality;  Blended learning;  Computer-assisted learning;  Interactive pedagogy;  Resource based learning},
correspondence_address1={Al-Imamy, S.Y.; MIS Department, Saudi Arabia; email: salimamy@pmu.edu.sa},
publisher={Springer},
issn={13602357},
language={English},
abbrev_source_title={Educ. Inf. Technol.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Alhakamy2020,
author={Alhakamy, A. and Tuceryan, M.},
title={Real-time Illumination and Visual Coherence for Photorealistic Augmented/Mixed Reality},
journal={ACM Computing Surveys},
year={2020},
volume={53},
number={3},
doi={10.1145/3386496},
art_number={49},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089433328&doi=10.1145%2f3386496&partnerID=40&md5=6607e05c055864fa2f857060c6d4083a},
affiliation={Indiana University-Purdue University Indianapolis, Department of Computer and Information Science, 723 W. Michigan St, Indianapolis, IN  SL280, United States},
abstract={A realistically inserted virtual object in the real-time physical environment is a desirable feature in augmented reality (AR) applications and mixed reality (MR) in general. This problem is considered a vital research area in computer graphics, a field that is experiencing ongoing discovery. The algorithms and methods used to obtain dynamic and real-time illumination measurement, estimating, and rendering of augmented reality scenes are utilized in many applications to achieve a realistic perception by humans. We cannot deny the powerful impact of the continuous development of computer vision and machine learning techniques accompanied by the original computer graphics and image processing methods to provide a significant range of novel AR/MR techniques. These techniques include methods for light source acquisition through image-based lighting or sampling, registering and estimating the lighting conditions, and composition of global illumination. In this review, we discussed the pipeline stages with the details elaborated about the methods and techniques that contributed to the development of providing a photo-realistic rendering, visual coherence, and interactive real-time illumination results in AR/MR. © 2020 ACM.},
author_keywords={and shading;  Augmented reality;  illumination;  image-based lighting;  lighting condition;  mixed reality;  photo-realistic;  real time;  reflectance;  visual coherence},
keywords={Augmented reality;  Computer vision;  Light sources;  Mixed reality;  Rendering (computer graphics), Continuous development;  Global illumination;  Image processing - methods;  Image-based lighting;  Lighting conditions;  Machine learning techniques;  Photorealistic rendering;  Physical environments, Learning systems},
publisher={Association for Computing Machinery},
issn={03600300},
coden={ACSUE},
language={English},
abbrev_source_title={ACM Comput Surv},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Jakl2020195,
author={Jakl, A. and Lienhart, A.-M. and Baumann, C. and Jalaeefar, A. and Schlager, A. and Schoffer, L. and Bruckner, F.},
title={Enlightening Patients with Augmented Reality},
journal={Proceedings - 2020 IEEE Conference on Virtual Reality and 3D User Interfaces, VR 2020},
year={2020},
pages={195-203},
doi={10.1109/VR46266.2020.1581532258804},
art_number={9089476},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085526448&doi=10.1109%2fVR46266.2020.1581532258804&partnerID=40&md5=4538f04908530fbf0229b5588000429e},
affiliation={University of Applied Sciences, Institute of Creative\Media/Technologies, St. Pölten, Austria},
abstract={Enlightening Patients with Augmented Reality (EPAR) enhances patient education with new possibilities offered by Augmented Reality. Medical procedures are becoming increasingly complex and printed information sheets are often hard to understand for patients. EPAR developed an augmented reality prototype that helps patients with strabismus to better understand the processes of examinations and eye surgeries. By means of interactive storytelling, three identified target groups based on user personas were able to adjust the level of information transfer based on their interests. We performed a 2-phase evaluation with a total of 24 test subjects, resulting in a final system usability score of 80.0. For interaction prompts concerning virtual 3D content, visual highlights were considered to be sufficient. Overall, participants thought that an AR system as a complementary tool could lead to a better understanding of medical procedures. © 2020 IEEE.},
author_keywords={concepts and paradigms Human-centered computing;  Human-centered computing;  Interaction design theory;  Interface design prototyping Human-centered computing;  Mixed / augmented reality Human-centered computing;  Usability testing},
keywords={Augmented reality;  User interfaces, Complementary tools;  Information sheets;  Information transfers;  Interactive storytelling;  Medical procedures;  Patient education;  System usability;  Target group, Virtual reality},
publisher={Institute of Electrical and Electronics Engineers Inc.},
isbn={9781728156088},
language={English},
abbrev_source_title={Proc. - IEEE Conf. Virtual Real. 3D User Interfaces, VR},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Lam2020351,
author={Lam, M.C. and Tee, H.K. and Muhammad Nizam, S.S. and Hashim, N.C. and Suwadi, N.A. and Tan, S.Y. and Abd Majid, N.A. and Arshad, H. and Liew, S.Y.},
title={Interactive augmented reality with natural action for chemistry experiment learning},
journal={TEM Journal},
year={2020},
volume={9},
number={1},
pages={351-360},
doi={10.18421/TEM91-48},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086515282&doi=10.18421%2fTEM91-48&partnerID=40&md5=2dd8a5e15160302a72ece95b28c1c52c},
affiliation={Mixed Reality and Pervasive Computing Lab, Center for Artificial Intelligence Technology, Faculty of Information Science and Technology, Universiti Kebangsaan Malaysia, Bangi, 43600, Malaysia; Chemistry Division, Centre for Foundation Studies in Science, University of Malaya, Kuala Lumpur, 50603, Malaysia},
abstract={Conventionally, the interaction between a user and augmented reality (AR) application is limited. Mostly, it allows virtual information browsing on the AR marker or basic manipulation such as moving and resizing of the 3D model. This study presents a rich interaction that allows users to mimic physical action such as shaking and pouring in chemistry experiment using card-based or box-based marker design. The user is required to follow the instruction to select the correct AR marker that represents apparatus or solutions and performs the physical action to conduct an experiment. Usability's result showed the respondents were satisfied with the application. © 2020 Meng Chun Lam at al.},
author_keywords={Educational augmented reality;  Human-computer interaction;  Interactive augmented reality;  Tangible augmented reality},
correspondence_address1={Lam, M.C.; Mixed Reality and Pervasive Computing Lab, Malaysia; email: lammc@ukm.edu.my},
publisher={UIKTEN - Association for Information Communication Technology Education and Science},
issn={22178309},
language={English},
abbrev_source_title={TEM J.},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Avanzini202056,
author={Avanzini, F. and Baratè, A. and Cottini, M. and Ludovico, L.A. and Mandanici, M.},
title={Developing Music Harmony Awareness in Young Students through an Augmented Reality Approach},
journal={CHIRA 2020 - Proceedings of the 4th International Conference on Computer-Human Interaction Research and Applications},
year={2020},
pages={56-63},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100328294&partnerID=40&md5=c9582cd17274460bb118fb272fdf20c1},
affiliation={Dipartimento di Informatica Giovanni Degli Antoni, Laboratorio di Informatica Musicale, Universita Degli Studi di Milano, Via G. Celoria 18, Milano, Italy; Dipartimento di Didattica della Musica, Conservatorio di Musica "Luca Marenzio", Piazza A. Benedetti Michelangeli 1, Brescia, Italy},
abstract={This paper presents AREmbody, an augmented-reality mobile application for the development of tonal harmony awareness. Continuing from previous prototypes based on full body and desktop interaction, AREmbody benefits from a very simple portable setup which allows physical interaction and supports the activity of one or more users. The application combines in a single mobile device a video processor, a media player and a movement tracker, opening the way to the design of harmonic games with challenges and recordable scores. Thus the application not only fosters music education activities in the classroom, but also extends them outside the school times and places, promoting educational practices in informal and private contexts. Copyright © 2020 by SCITEPRESS-Science and Technology Publications, Lda. All rights reserved.},
author_keywords={Augmented reality;  Mobile devices;  Physical interaction;  Tonal harmony},
keywords={Augmented reality;  Interactive computer systems, Full body;  Media players;  Mobile applications;  Music education;  Physical interactions;  Video processor, Human computer interaction},
editor={Holzinger A., Silva H.P., Helfert M., Constantine L.},
publisher={SciTePress},
isbn={9789897584800},
language={English},
abbrev_source_title={CHIRA - Proc. Int. Conf. Comput.-Human Interact. Res. Appl.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Suciu2020253,
author={Suciu, G. and Bălănean, C. and Pasat, A. and Istrate, C.},
title={Smart shopping platform based on digital map generation and indoor localization services},
journal={eLearning and Software for Education Conference},
year={2020},
pages={253-260},
doi={10.12753/2066-026X-20-117},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095745302&doi=10.12753%2f2066-026X-20-117&partnerID=40&md5=e3a1a09af3fae3d009858f2144292627},
affiliation={BEIA Consult International, R&D Department, Bucharest, Romania},
abstract={The retail industry has come to a consensus on the use of new ICT technologies, such as Cloud Computing, Big Data, IoT and Artificial Intelligence (AI), to create innovative operational models. Customer targeting has been one of the main marketing dilemmas in the past years, and one of the solutions seems to rely on recent IoT advancement. This paper presents a smart shopping solution architecture that covers image processing techniques used for digital maps generation, smartphone indoor localization using BLE beacons, and indoor routing techniques for finding stores in a shopping center. We discuss the advantages and disadvantages of using BLE technology for indoor localization and the results after experimenting with several BLE devices and mobile application SDKs. Our objective was to advance an innovative solution based on computer vision techniques meant to ease the process of creating indoor maps by hand. Also, we focused on the development of best practices guide for using mobile applications in the retail industry and education of buyers, including an interactive questionnaire for getting feedback regarding improvement of Android application design. Furthermore, the solution can be used to orient and educate customers during their shopping activities for using smart mobile applications. Thus, our smart shopping platform is based on an enriched mobile application (MARA-Mobile Augmented Reality Applications) that offers a range of services and functions based on augmented reality through the implementation of communication interfaces with various IoT devices-beacons or smart parking sensors. WSNs plays a central role in the IoT environment, especially to the advancement of energy-efficient and low latency communications. Our smart shopping solution advances the integration of intelligent parking sensors based on LoRa communication. We will describe the integration of these sensors with TTN (The Things Network) global network and the methodology for LoRa data packages decoding and further integration with a WEB application. © 2020, National Defence University - Carol I Printing House. All rights reserved.},
author_keywords={Android applications;  Beacons;  Image processing;  Indoor location;  Routing algorithms;  Smart shopping},
editor={ROCEANU I.},
publisher={National Defence University - Carol I Printing House},
issn={2066026X},
language={English},
abbrev_source_title={eLearning Softw. Educ. Conf.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Hu2020,
author={Hu, Z. and Shvo, M. and Jepson, A. and Mohomed, I.},
title={Interactive planning-based cognitive assistance on the edge},
journal={HotEdge 2020 - 3rd USENIX Workshop on Hot Topics in Edge Computing},
year={2020},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092238040&partnerID=40&md5=4d3a180894fc1e00e89949875c252179},
affiliation={Samsung AI Center, Toronto, Canada},
abstract={Real-time cognitive assistance is one of the most exciting applications in the age of Augmented Reality (AR). Several research groups have explored the use of cognitive assistants, embodied within smartphones or wearable AR glasses, to guide users through unfamiliar tasks (e.g., assembling a piece of furniture or following a recipe). These systems generally consist of two high-level modules: a perceptual module (e.g., a deep-learning based vision system) and a cognitive module (implemented via a rule-engine or state machine), and must operate in near real-time. As such, cognitive assistants are illustrative use-cases for edge computing. While prior work has focused on pushing the frontier of what is possible, it suffers from some defects that hinder practical deployment. First, much research on cognitive assistants has assumed an accurate visual perception system, which may not be true in practice. Second, while some work has explored user errors in performance of tasks, the manner in which this is done is not scalable (i.e., possible errors are explicitly specified in a state machine representation apriori). To address these limitations, in this paper, we propose (i) to involve users in resolving the ambiguity/uncertainty of visual inputs and (ii) to employ automated planning tools as well as execution monitoring techniques to keep track of the task states, as well as to generate new plans to recover from users' mistakes if necessary. To verify the feasibility of our system, we implemented and tested it on both an Android phone and HoloLens 2, supported by an edge server for off-loading computation. © HotEdge 2020 - 3rd USENIX Workshop on Hot Topics in Edge Computing. All rights reserved.},
keywords={Augmented reality;  Deep learning;  Edge computing;  Real time systems;  Vision, Automated planning;  Cognitive assistance;  Execution monitoring;  Interactive planning;  Near-real time;  Research groups;  Vision systems;  Visual perception, Cognitive systems},
publisher={USENIX Association},
language={English},
abbrev_source_title={HotEdge - USENIX Workshop Hot Top. Edge Comput.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Abriata2020,
author={Abriata, L.A.},
title={Building blocks for commodity augmented reality-based molecular visualization and modeling in web browsers},
journal={PeerJ Computer Science},
year={2020},
volume={2020},
number={2},
doi={10.7717/peerj-cs.260},
art_number={260},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086507407&doi=10.7717%2fpeerj-cs.260&partnerID=40&md5=3a242fc745ca26151b46eacf962cd2d6},
affiliation={École Polytechnique Fédérale de Lausanne, Lausanne, Switzerland; Swiss Institute of Bioinformatics, Lausanne, Switzerland},
abstract={For years, immersive interfaces using virtual and augmented reality (AR) for molecular visualization and modeling have promised a revolution in the way how we teach, learn, communicate and work in chemistry, structural biology and related areas. However, most tools available today for immersive modeling require specialized hardware and software, and are costly and cumbersome to set up. These limitations prevent wide use of immersive technologies in education and research centers in a standardized form, which in turn prevents large-scale testing of the actual effects of such technologies on learning and thinking processes. Here, I discuss building blocks for creating marker-based AR applications that run as web pages on regular computers, and explore how they can be exploited to develop web content for handling virtual molecular systems in commodity AR with no more than a webcam-and internet-enabled computer. Examples span from displaying molecules, electron microscopy maps and molecular orbitals with minimal amounts of HTML code, to incorporation of molecular mechanics, real-time estimation of experimental observables and other interactive resources using JavaScript. These web apps provide virtual alternatives to physical, plastic-made molecular modeling kits, where the computer augments the experience with information about spatial interactions, reactivity, energetics, etc. The ideas and prototypes introduced here should serve as starting points for building active content that everybody can utilize online at minimal cost, providing novel interactive pedagogic material in such an open way that it could enable mass-testing of the effect of immersive technologies on chemistry education. © 2020 Abriata.},
author_keywords={Augmented reality;  Chemistry;  Education;  Integrative modeling;  Molecular modeling;  Molecular visualization;  Virtual reality},
keywords={Augmented reality;  Engineering education;  Molecular graphics;  Molecular orbitals;  Virtual reality;  Visualization;  Websites, Chemistry education;  Education and researches;  Immersive technologies;  Interactive resources;  Molecular visualization;  Real-time estimation;  Specialized hardware;  Virtual and augmented reality, Web browsers},
correspondence_address1={Abriata, L.A.; École Polytechnique Fédérale de LausanneSwitzerland; email: luciano.abriata@epfl.ch},
publisher={PeerJ Inc.},
issn={23765992},
language={English},
abbrev_source_title={PeerJ Comput. Sci.},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Bhatti2020,
author={Bhatti, Z. and Bibi, M. and Shabbir, N.},
title={Augmented Reality based Multimedia Learning for Dyslexic Children},
journal={2020 3rd International Conference on Computing, Mathematics and Engineering Technologies: Idea to Innovation for Building the Knowledge Economy, iCoMET 2020},
year={2020},
doi={10.1109/iCoMET48670.2020.9073879},
art_number={9073879},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084646253&doi=10.1109%2fiCoMET48670.2020.9073879&partnerID=40&md5=286e3896fa02a48ba1ecbd3e04b5324b},
affiliation={Technology University of Sindh, Institute of Information and Communication, Jamshoro, Pakistan},
abstract={Augmented reality is a visual technology which combines virtual objects into the real environment, in real time. In this research work, a heuristic model of multimedia learning would be developed using Augmented Reality for a type of neurological disorder known as Dyslexia. Dyslexia is complex mental brain related syndromes, affecting the children in various ways including verbal and nonverbal communications, social interactions, understanding instructions, reading, writing, learning, problems, etc. The use of interactive Augmented Reality based multimedia application to facilitate and provide pedagogy for such type of special children would ascertain a unique and new dimension of treating and helping such young hearts in overcoming their disabilities in a very fun and easy way. The research encompasses designing a framework based on cognitive learning for interactive multimedia learning app using augmented reality technology, that would be centric to autism effected children's and would enable them to interact with such system. © 2020 IEEE.},
author_keywords={Augmented Reality;  Dyslexia;  Multimedia Learning;  Serious Games},
keywords={Augmented reality;  E-learning;  Engineering research;  Interactive computer systems;  Learning systems;  Multimedia systems, Augmented reality technology;  Cognitive learning;  Interactive multimedia;  Multi-media learning;  Multimedia applications;  Neurological disorders;  Non-verbal communications;  Social interactions, Engineering education},
publisher={Institute of Electrical and Electronics Engineers Inc.},
isbn={9781728149707},
language={English},
abbrev_source_title={Int. Conf. Comput., Math. Eng. Technol.: Idea Innov. Build. Knowl. Econ., iCoMET},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{RibeiroAmantini2020,
author={Ribeiro Amantini, S.N.S. and Pascotto Montilha, A.A. and Antonelli, B.C. and Leite, K.T.M. and Rios, D. and Cruvinel, T. and Neto, N.L. and Oliveira, T.M. and Moreira Machado, M.A.A.},
title={Using augmented reality to motivate oral hygiene practice in children: Protocol for the development of a serious game},
journal={JMIR Research Protocols},
year={2020},
volume={9},
number={1},
doi={10.2196/10987},
art_number={e10987},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083209696&doi=10.2196%2f10987&partnerID=40&md5=db8f1464960d9ee986a2ddd0b74fb900},
affiliation={Department of Pediatric Dentistry, Orthodontics and Community Health, Bauru School of Dentistry, University of Sao Paulo, Bauru, Brazil; Educational Technology Section, Bauru School of Dentistry, University of Sao Paulo, Bauru, Brazil; Department of Pediatric Dentistry, Orthodontics and Community Health, Bauru School of Dentistry, University of Sao Paulo, Alameda Octávio Pinheiro Brisolla, n, Bauru, 9-75, Brazil},
abstract={Background: New technologies create possible new ways of action, interaction, and learning which is extremely relevant in the field of oral health education. There is a lack of protocol in using an immersive interactive ludic-educational interface to motivate oral hygiene practice in children by means of augmented reality. Objective: This study aims to present a protocol on the development of a serious game to motivate oral hygiene practice in children. Methods: A serious game will be designed by augmented reality techniques to improve toothbrushing effectiveness of children aged 6 to 10 years. The functional structure of this interface is activated by means of movements recognized by Kinect (Microsoft Corp). The toothbrushing technique will be available in the game, enabling the children to execute the movement in the virtual environment. By identifying errors, this game will be tailored to improve the oral health of children by correcting the technique and teaching the user the adequate toothbrushing method. A template analysis will be performed to identify barriers and facilitators in each scenario. Results: After the implementation of the virtual interactive and immersive panels, enrollment will begin and evaluations will be made by means of questionnaires distributed to participants who interact with the game. Thus, an analysis of the product efficacy will be conducted. The expected outcome will be to obtain a digital instrument to motivate oral hygiene practice and enhance health awareness in children. Conclusions: The serious game will support the prevention of oral diseases by sharing scientific research in the school environment and community. © Susy Nazaré Silva Ribeiro Nazaré Silva Ribeiro Amantini, Alexandre Alberto Pascotto Montilha, Bianca Caseiro Antonelli, Kim Tanabe Moura Leite, Daniela Rios, Thiago Cruvinel, Natalino Lourenço Neto, Thais Marchini Oliveira, Maria Aparecida Andrade Moreira Machado.},
author_keywords={Computer simulation;  Dental;  Education;  Pediatric dentistry;  User-computer interface;  Video games},
correspondence_address1={Moreira Machado, M.A.A.; Department of Pediatric Dentistry, Alameda Octávio Pinheiro Brisolla, n, Brazil; email: mmachado@fob.usp.br},
publisher={JMIR Publications Inc.},
issn={19290748},
language={English},
abbrev_source_title={JMIR Res. Prot.},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Zhu202016,
author={Zhu, M. and Sun, Z. and Zhang, Z. and Shi, Q. and Chen, T. and Liu, H. and Lee, C.},
title={Sensory-Glove-Based Human Machine Interface for Augmented Reality (AR) Applications},
journal={Proceedings of the IEEE International Conference on Micro Electro Mechanical Systems (MEMS)},
year={2020},
volume={2020-January},
pages={16-19},
doi={10.1109/MEMS46641.2020.9056153},
art_number={9056153},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083199598&doi=10.1109%2fMEMS46641.2020.9056153&partnerID=40&md5=ffd5de171ea3b6c0d5a510829aec609b},
affiliation={National University of Singapore, Department of Electrical and Computer Engineering, Singapore, Singapore; Jiangsu Provincial Key Laboratory of Advanced Robotics, School of Mechanical and Electric Engineering, Soochow University, Suzhou, China},
abstract={We propose a glove based Human Machine Interface (HMI) designed for Virtual Reality (VR) and Augmented Reality (AR) applications. The proposed sensory glove uses facile designed triboelectric sensors to realize multi-dimensional motion recognition of gestures, and piezoelectric mechanical stimulators are also equipped for achieving the haptic feedback to user regarding the interactive events from virtual world. The developed HMI leverages machine learning technology to achieve real time object recognition, hence, we can manipulate virtual objects in VR/AR space by projecting sensory information from glove. © 2020 IEEE.},
author_keywords={augmented reality;  human machine interface;  machine learning;  piezoelectric;  Triboelectric},
keywords={Augmented reality;  Man machine systems;  Mechanics;  Motion estimation;  Object recognition;  Virtual reality, Haptic feedbacks;  Human Machine Interface;  Machine learning technology;  Motion recognition;  Multi dimensional;  Real-time object recognition;  Sensory information;  Virtual objects, MEMS},
correspondence_address1={Lee, C.; National University of Singapore, Singapore; email: elelc@nus.edu.sg},
publisher={Institute of Electrical and Electronics Engineers Inc.},
issn={10846999},
isbn={9781728135809},
coden={PMEME},
language={English},
abbrev_source_title={Proc. IEEE Int. Conf. Micro Electro Mech. Syst. MEMS},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Dave2020942,
author={Dave, A. and Kang, M. and Hwang, J. and Lorenzo, M. and Oh, P.},
title={Towards Smart Classroom: Affordable and Simple Approach to Dynamic Projection Mapping for Education},
journal={2020 10th Annual Computing and Communication Workshop and Conference, CCWC 2020},
year={2020},
pages={942-947},
doi={10.1109/CCWC47524.2020.9031145},
art_number={9031145},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083084386&doi=10.1109%2fCCWC47524.2020.9031145&partnerID=40&md5=d559a97d0e40b8e8c4cb2410de2b2b8b},
affiliation={University of Nevada Las Vegas, Department of Mechanical Engineering, Las Vegas, United States; Beckman High School, California, United States; Diamond Bar High School, California, United States; Ed W. Clark High School, Las Vegas, United States},
abstract={In order to transform the traditional classroom into an interactive space, we developed a projection mapping toolbox: an affordable, simple alternative to complex systems. Our system uses Python and Microsoft Kinect V2 for dynamic projection mapping (PM). We demonstrated three ways PM can be used to make Augmented Reality (AR) applications for classroom use. We projected free body diagrams onto boxes, made AR quiz tacking for teachers, and made an AR game. The goal of the projection mapping toolbox is to help students learn more efficiently and raise academic achievement. © 2020 IEEE.},
author_keywords={augmented reality;  dynamic projection mapping;  education;  marker tracking;  smart classroom},
keywords={Augmented reality;  Molecular physics, Academic achievements;  Dynamic projection;  Free body diagrams;  Interactive spaces;  Microsoft kinect;  Simple approach;  Smart classroom;  System use, Mapping},
editor={Chakrabarti S., Paul R.},
publisher={Institute of Electrical and Electronics Engineers Inc.},
isbn={9781728137834},
language={English},
abbrev_source_title={Annu. Comput. Commun. Workshop Conf., CCWC},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{AidaZamnah2020430,
author={Aida Zamnah, Z.A. and Azreena, M.S. and Saputra, M.B.},
title={C-heart: Augmented reality of 3D heart anatomy},
journal={International Journal of Advanced Trends in Computer Science and Engineering},
year={2020},
volume={9},
number={1.1 Special Issue},
pages={430-435},
doi={10.30534/ijatcse/2020/7191.12020},
art_number={71},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082193786&doi=10.30534%2fijatcse%2f2020%2f7191.12020&partnerID=40&md5=ad9c433030f8a779d2d56a7d8d60c073},
affiliation={Faculty of Computing, Engineering and Technology, Asia Pacific University of Technology and Innovation, Technology Park Malaysia, Bukit Jalil, Kuala Lumpur, 57000, Malaysia},
abstract={This research paper is to enable the researchers to create a unique Augmented Reality (AR) internal organ in 3D and mobile e-learning application. This mobile e-learning application will include multimedia elements such as audio, video, graphics, and text. In the other words, the AR mobile application has a trailer, realistic sound effect and 3D interactive model. From adults to children, they are active users using mobile or smartphone as a tool for communication, work, recordings, and entertainment. From that perspectives, the advantages of smartphone will be benefits for educational field, specifically in medical field as many obstacles are experienced by the students in remembering the human body organs structure. ADDIE design methodology; a standard waterfall development model is being used in this research and the data collection is done through interviews with the doctors from Banjarbaru City Hospital, Banjarbaru, Indonesia. As the result, the mobile e-learning application of Augmented Reality is developed and can be implemented to medical e-learning system, especially in Indonesia in order to upgrade the education system. Therefore, the application can facilitate the way of learning and teaching in this modern generation, especially in medical field. © 2020, World Academy of Research in Science and Engineering. All rights reserved.},
author_keywords={3D learning;  Augmented reality;  E-learning;  Interactive learning;  Mobile learning},
correspondence_address1={Aida Zamnah, Z.A.; Faculty of Computing, Bukit Jalil, Malaysia; email: aida_zamnah@staffemail.apu.edu.my},
publisher={World Academy of Research in Science and Engineering},
issn={22783091},
language={English},
abbrev_source_title={Int. J. Adv. Trends Comput. Sci. Eng.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Moreland20201026,
author={Moreland, J. and Estrada, J. and Mosquera, E. and Toth, K. and Silaen, A.K. and Zhou, C.Q.},
title={Integrating Fluid Simulation with Virtual Die Casting Machine for Industry 4.0 and Operator Training},
journal={Minerals, Metals and Materials Series},
year={2020},
pages={1026-1031},
doi={10.1007/978-3-030-36408-3_139},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079643590&doi=10.1007%2f978-3-030-36408-3_139&partnerID=40&md5=03b4d41599e290e089b53035a4eb450a},
affiliation={Center for Innovation Through Visualization and Simulation, Purdue University Northwest, 2200 169th Street, Hammond, IN  46323, United States},
abstract={High Pressure Die Casting is a complex manufacturing process in which molten metal is forced into a mold cavity under high pressure where it then cools and solidifies. An interactive virtual training simulator is being developed which integrates fluid flow simulations with die casting machine parameters to improve operator understanding of the process and ultimately improve casting quality. Methods for combining fluid simulation results with tools from the game industry for virtual reality and augmented reality applications in industry 4.0 are discussed. © The Minerals, Metals & Materials Society 2020.},
author_keywords={CFD;  Die casting;  Simulation;  Training;  Virtual reality},
keywords={Augmented reality;  Computational fluid dynamics;  Die casting;  Die casting machines;  Die castings;  E-learning;  Flow of fluids;  Industry 4.0;  Light metals;  Liquid metals;  Molds;  Personnel training, Augmented reality applications;  Casting quality;  Complex manufacturing process;  Fluid simulations;  High pressure die casting;  Operator training;  Simulation;  Virtual training simulators, Virtual reality},
correspondence_address1={Moreland, J.; Center for Innovation Through Visualization and Simulation, 2200 169th Street, United States; email: morelanj@pnw.edu},
editor={Tomsett A.},
publisher={Springer Science and Business Media Deutschland GmbH},
issn={23671181},
isbn={9783030364076},
language={English},
abbrev_source_title={Miner. Met. Mater. Ser.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Ali2020,
author={Ali, D.F. and Johari, N. and Omar, M. and Sunar, M.S.},
title={ARMLAAPPS: Augmented Reality Application in Microeconomics},
journal={6th International Conference on Interactive Digital Media, ICIDM 2020},
year={2020},
doi={10.1109/ICIDM51048.2020.9339660},
art_number={9339660},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101538713&doi=10.1109%2fICIDM51048.2020.9339660&partnerID=40&md5=17e0a80e3f5146275329c7a5b3cfbde3},
affiliation={Universiti Teknologi Malaysia, Faculty of Social Sciences and Humanities, School of Education, Johor, Malaysia; Universiti Teknologi Malaysia, Institute of Human Centered Engineering, Johor, Malaysia},
abstract={Augmented Reality (AR) is a technology that combines both virtual and real environments simultaneously. It is designed to let users experience activities in a way close to real-world experience within a safe environment. It can also supplement the difficult information presented in a conventional approach to enhance users' understanding of the complex concept. It has been used widely in various fields due to the effectiveness of this technology. However, the application of AR is scarcely explored, especially for the Microeconomics field. Therefore, this study aims to develop and investigate augmented reality application development to enhance students' visualization skills in Microeconomic courses. Through this study, a mobile augmented reality application called Augmented Reality Mobile Learning Apps (ARMLAAPPS) was developed to give an interactive learning experience that can enhance students' visualization skills and help students learn more efficiently and in a more flexible way. After the development process, the evaluation of ARMLAAPPS is conducted to identify the effectiveness of the ARMLAAPPS in enhancing visualization skills among Microeconomics students in higher institutions. Based on the results, this study has successfully developed the ARMLAAPPS, and it has proven to be effective in improving students' visualization when learning Microeconomics. © 2020 IEEE.},
author_keywords={augmented reality;  higher institutions;  microeconomics;  mobile learning;  visualization skills},
keywords={Augmented reality;  Digital storage;  Economics;  Human computer interaction;  User experience;  Visualization, Augmented reality applications;  Conventional approach;  Development process;  Interactive learning;  Mobile augmented reality;  Real environments;  Real-world experience;  Visualization skills, Students},
publisher={Institute of Electrical and Electronics Engineers Inc.},
isbn={9781728149288},
language={English},
abbrev_source_title={Int. Conf. Interact. Digit. Media, ICIDM},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Yusof2020,
author={Yusof, C.S. and Ahmad, N. and Ismail, A.W. and Sunar, M.S.},
title={Mathematics Lesson using Accelerometer Sensor Interaction in Handheld Augemented Reality Application for Kindergarten},
journal={6th International Conference on Interactive Digital Media, ICIDM 2020},
year={2020},
doi={10.1109/ICIDM51048.2020.9339655},
art_number={9339655},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101517507&doi=10.1109%2fICIDM51048.2020.9339655&partnerID=40&md5=977ee48dee9e44d71bf6469cb193439d},
affiliation={Universiti Teknologi Malaysia, Faculty of Engineering, ViCubeLab, Johor Bahru, Johor, 81310, Malaysia; School of Computing, Faculty of Engineering, Universiti Teknologi Malaysia, Johor Bahru, Johor, 81310, Malaysia; Media and Game Innovation Centre of Excellence, Institute of Human-Centered Engineering, Universiti Teknologi Malaysia, Johor Bahru, Johor, 81310, Malaysia},
abstract={Handheld Augmented Reality (AR) is a combination of the virtual content and real world that gives a chance for the user to interact with virtual objects in real time using handheld device. Recent handheld device equipped with additional sensing like gyroscope, barometer, accelerometer and proximity sensor make possible to explore full potential for interaction in application. This become interesting topic to improve the human perception and to enhance the understanding of complex 3D scenarios. The traditional educational method is not necessarily effective for the children. Sometimes student's incapable to recall the ideas and it seem struggle to solve the problem in learning process. Therefore, the purpose of this project is to develop mathematics lesson using accelerometer sensor interaction in handheld AR application for kindergarten. There are four phases to complete this study. The first phase is preliminary investigation and analyse in handheld application for Mathematics lesson. Then, second phase is to design the details of application operational framework. The third phase is to develop Mathematics lesson application with accelerometer interaction. Last phase is to evaluate the user perception of the application. Unity 3D and Vuforia SDK are used as editors and library respectively through the development process. The evaluation has been done by respondents who are the ages from 6 to 9 years old. The results have proved that the application can help better to improve Mathematics learning skill by using accelerometer interaction through handheld AR application. The application enhances the teaching method for students to learn an addition and subtraction more efficiently and in interactive ways. © 2020 IEEE.},
author_keywords={accelerometer sensor interaction;  augmented reality;  handheld device;  mathematics lesson application},
keywords={Augmented reality;  Digital storage;  Hand held computers;  Human computer interaction, Accelerometer sensor;  Development process;  Hand held device;  Handheld augmented realities;  Human perception;  Learning process;  Mathematics learning;  User perceptions, Accelerometers},
publisher={Institute of Electrical and Electronics Engineers Inc.},
isbn={9781728149288},
language={English},
abbrev_source_title={Int. Conf. Interact. Digit. Media, ICIDM},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Batuwanthudawa2020174,
author={Batuwanthudawa, B.I. and Jayasena, K.P.N.},
title={Real- time location based augmented reality advertising platform},
journal={ICAC 2020 - 2nd International Conference on Advancements in Computing, Proceedings},
year={2020},
pages={174-179},
doi={10.1109/ICAC51239.2020.9357261},
art_number={9357261},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102423396&doi=10.1109%2fICAC51239.2020.9357261&partnerID=40&md5=2a450531191932b2db2f35bf17a8e04f},
affiliation={Sabaragamuwa University of Sri Lanka, Department of Computing and Information Systems, Sri Lanka},
abstract={Augmented Reality (AR) is growing rapidly and is becoming more mature and robust technology, combining virtual information with a real-time performance environment. Most of the Augmented reality applications available today popular because of the interactive virtual objects placed in the real environment. For education, navigation, tourism many sectors use this technology due to clear understand of real objects appear as it is as virtual objects, in front of you. Like that, the Marketing sector also uses AR technology to brand themselves interactively. Most of them are marker-based AR applications which the virtual contents are showing when the AR camera directs to a target such as paper advertisement. On other hand marker-less AR advertising applications are developed for individual businesses from AR supported plugins, apps rare to see as unique published app. From this research, I proposed a real-time marker-less augmented reality platform, streaming showcasing virtual marketing assets in front of shops for common business use. The main objective of this research is to develop a real-time location-based Augmented Reality platform to improve marketing sales aspects of businesses. The users can easily find the exact location of the shop though AR objects. This novel marketing concept engages more customers to business and enhances the usability of AR application among users though easy to access on their selling products. The users can use app in native platforms(both android IOS) and ready to access interactive virtual 3D objects with animation as marketing materials placed in front of shops. This platform solved the existing problems of location-based AR application which are interactivity of AR adequately perform as real-time platform extract data from a live real-time server show the locations through AR camera. © 2020 IEEE.},
author_keywords={Advertising Platform;  Augmented Reality;  Location based AR;  Unity Engine},
keywords={Cameras;  Commerce;  Location;  Sales, Augmented reality applications;  Marketing materials;  Real environments;  Real time performance;  Real-time location;  Real-time platform;  Virtual 3D objects;  Virtual information, Augmented reality},
correspondence_address1={Batuwanthudawa, B.I.; Sabaragamuwa University of Sri Lanka, Sri Lanka; email: binojishara21@gmail.com},
publisher={Institute of Electrical and Electronics Engineers Inc.},
isbn={9781728184128},
language={English},
abbrev_source_title={ICAC - Int. Conf. Adv. Comput., Proc.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Lebedeva2020,
author={Lebedeva, Y. and Belozerova, Y. and Zakharova, M. and Volkova, M.},
title={Methodological efficiency of using virtual and augmented reality in the educational process},
journal={E3S Web of Conferences},
year={2020},
volume={210},
doi={10.1051/e3sconf/202021018077},
art_number={18077},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098525520&doi=10.1051%2fe3sconf%2f202021018077&partnerID=40&md5=b3c34afac09894f4430a85e0e47f8e20},
affiliation={State University of Management, Ryazanskiy prospect, Moscow, 109572, Russian Federation; Institute of Cinema and Tv (GITR) (Ex Named the Humanities Institute of Tv and Radio Broadcasting), 32A Khoroshevskoye road, Moscow, 123007, Russian Federation; Innovations and Technologies in Education and Science Ltd, 125, Varshavskoe road, Moscow, 117857, Russian Federation},
abstract={This article presents the results of an experiment on creating an electronic textbook for universities and programs of additional professional education using virtual and augmented reality technologies and evaluating the results of testing the textbook on the basis of the State University of Management. The topic of the electronic textbook concerns the organization of the security service of accommodation facilities. The authors provide a description of the electronic textbook, its structure, main interactive elements, the progress of work, talk about the difficulties that they encountered. The working group on the creation of the textbook included methodologists, psychologists, specialists from the security services of Moscow hotels and specialists in information technology. Teams of key developers - the State University of Management, the Lotte group of companies, the LLC ITRON limited liability company, and the Rusays Publishing House - worked in partnership. Conclusions are made about the possibilities of using virtual and augmented reality technologies in educational activities. Augmented reality technology is used to create a mobile application that displays educational materials with reference to real-life objects according to special markers. This technology allows you to make the textbook unique for a specific object (office, building, structure, landscape). The results of the training using an electronic participant are presented. The peculiarities of the psychological perception of educational material and the effectiveness of the new format of presentation of the educational environment are noted. © The Authors, published by EDP Sciences, 2020.},
keywords={Augmented reality;  Human resource management;  Textbooks, Augmented reality technology;  Educational activities;  Educational environment;  Educational materials;  Electronic textbooks;  Limited liability companies;  Professional education;  Virtual and augmented reality, E-learning},
correspondence_address1={Belozerova, Y.; Institute of Cinema and Tv (GITR) (Ex Named the Humanities Institute of Tv and Radio Broadcasting), 32A Khoroshevskoye road, Russian Federation; email: avuzto@yandex.ru},
editor={Rudoy D., Olshevskaya A., Kankhva V.},
publisher={EDP Sciences},
issn={25550403},
language={English},
abbrev_source_title={E3S Web Conf.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Zhang2020462,
author={Zhang, X. and Liu, H. and Wang, S.},
title={Design and realization of chinese traditional culture & art interactive system based on VR&AR technologies},
journal={ACM International Conference Proceeding Series},
year={2020},
volume={PartF168986},
pages={462-467},
doi={10.1145/3452940.3453029},
art_number={3453029},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105981005&doi=10.1145%2f3452940.3453029&partnerID=40&md5=ca49f02ef7c7ecbf2b18d3696b931379},
affiliation={School of New Media, Beijing Institute of Graphic Communication, Beijing, China},
abstract={Intangible cultural heritage is the cultural treasure of our country, and it has an important position in the inheritance of traditional culture in our country. However, unlike other cultural heritage, intangible cultural heritage has a large number of reference books. my country has issued documents to protect and inherit intangible cultural heritage, and encourage and support representative inheritors of national intangible cultural heritage projects to carry out learning activities. At present, China' s digital protection of intangible cultural heritage is still in the preliminary stage of exploration. This article proposes a combination of virtual reality technology, augmented reality technology, Founder Flying, and paper books to flexibly apply to the "Yanjing Eight Wonders". New attempts in the protection and inheritance of material cultural heritage. Through the investigation and discussion of the user input habits of users of different ages and different content carriers, a comparative study of different platform differences, three-dimensional modeling technology, image acquisition and tracking and registration technology, shows that the combination of virtual reality and augmented reality makes it easier to understand The material cultural heritage has a more comprehensive and innovative way of experience, which can arouse the enthusiasm of users of all ages, and also ensure that the platform is more stable, more accurate, and experience digital publishing applications more immersively, supplementing traditional Exhibition appreciation and lectures enrich people's understanding of intangible cultural heritage. © 2020 ACM.},
author_keywords={Intangible Cultural Heritage;  Multi-Platform Display;  VR&AR},
keywords={Augmented reality;  Technology transfer;  Three dimensional computer graphics, Augmented reality technology;  Comparative studies;  Digital protection;  Digital publishing;  Intangible cultural heritages;  Three-dimensional model;  Traditional cultures;  Virtual reality technology, Virtual reality},
correspondence_address1={Liu, H.; School of New Media, China; email: lanxin9909@bigc.edu.cn},
publisher={Association for Computing Machinery},
isbn={9781450388665},
language={English},
abbrev_source_title={ACM Int. Conf. Proc. Ser.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Thamrongrat202065,
author={Thamrongrat, P. and Lai-Chong Law, E.},
title={Analysis of the Motivational Effect of Gamified Augmented Reality Apps for Learning Geometry},
journal={ACM International Conference Proceeding Series},
year={2020},
pages={65-77},
doi={10.1145/3441000.3441034},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101778880&doi=10.1145%2f3441000.3441034&partnerID=40&md5=3b2708a309bfac3ab9a0ff32f6f83531},
affiliation={Informatics University of Leicester, United Kingdom},
abstract={Gamification has been recognised for its motivational power and been increasingly integrated into Augmented Reality (AR)-based educational applications. However, results of the existing studies on the effect of gamified AR apps on learning motivation remain inconclusive. To address this issue, we developed an AR learning app and its three gamified variants-Badges, Points, and Timer. Each of the apps was used by a group of 30 students aged 12-16 years to learn 3D geometry. To assess the impact of these AR apps on learning motivation, we constructed a three-item questionnaire, measuring Interest, Confidence and Intention to Use, which was administered after each of the six rounds of interaction with the apps. Results showed that there were no other significant differences in the motivational effect between the gamified and non-gamified apps, and Points had a stronger learning effect than Badges or Timer. Implications for designing the gamification elements are drawn. © 2020 ACM.},
author_keywords={Badge;  Gamification;  Geometry;  Learning;  Motivation;  Point;  Time pressure},
keywords={Augmented reality;  Human computer interaction;  Interactive computer systems;  Motivation, 3D geometry;  Educational Applications;  Intention to use;  Learning effects;  Learning motivation, Gamification},
editor={Ahmadpour N., Leong T., Ploderer B., Parker C., Webber S., Munoz D., Loke L., Tomitsch M.},
publisher={Association for Computing Machinery},
isbn={9781450389754},
language={English},
abbrev_source_title={ACM Int. Conf. Proc. Ser.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Rigby2020481,
author={Rigby, L. and Wünsche, B.C. and Shaw, A.},
title={PiARno-An Augmented Reality Piano Tutor},
journal={ACM International Conference Proceeding Series},
year={2020},
pages={481-491},
doi={10.1145/3441000.3441039},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101767173&doi=10.1145%2f3441000.3441039&partnerID=40&md5=5ada2ae7356d5b9aa73790c9cfb19897},
affiliation={School of Computer Science, University of Auckland, New Zealand},
abstract={Music is an important way for humans to express themselves, unite, relate, and gain enjoyment. While many people desire for themselves, or their loved ones, to achieve some form of musical prowess, the discipline remains encumbered by low motivation and high dropout rates. This is despite long established trends between exposure to learning playing an instrument and enhanced cognitive development. Previous research suggests that one factor associated with motivation loss might be the lack of perceived progress during the early stages of music instruction. In this paper we develop a novel Augmented Reality piano tutor with the primary goal of increasing the effectiveness of self-practice for beginners. Our solution is based on the principle of constant feedback and reducing the level of indirection between instrument, instructions, and feedback, and enables users to learn to read and understand piano sheet music quickly without requiring a private instructor, while maintaining compatibility with the traditional learning process. An evaluation of our solution with a user study containing 22 participants showed that our tool significantly improved motivation and the ability to read piano sheet music. © 2020 ACM.},
author_keywords={augmented reality;  feedback;  learning;  piano;  sheet music;  teaching},
keywords={Augmented reality;  Interactive computer systems;  Motivation;  Musical instruments, Cognitive development;  Constant feedback;  One-factor;  Traditional learning;  User study, Human computer interaction},
editor={Ahmadpour N., Leong T., Ploderer B., Parker C., Webber S., Munoz D., Loke L., Tomitsch M.},
publisher={Association for Computing Machinery},
isbn={9781450389754},
language={English},
abbrev_source_title={ACM Int. Conf. Proc. Ser.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Fernandes20201,
author={Fernandes, J. and Teles, A. and Teixeira, S.},
title={An augmented reality-based mobile application facilitates the learning about the spinal cord},
journal={Education Sciences},
year={2020},
volume={10},
number={12},
pages={1-18},
doi={10.3390/educsci10120376},
art_number={376},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097568312&doi=10.3390%2feducsci10120376&partnerID=40&md5=9dbb45c9d811c65b3bbb11f892f2502f},
affiliation={Northeast Biotechnology Network, Federal University of Piauí, Teresina, PI  64049-550, Brazil; Neuro-Innovation Technology & Brain Mapping Laboratory, Federal University of Delta do Parnaíba, Av. São Sebastião n 2819-Nossa Sra. de Fátima-Parnaíba, Parnaíba, PI  64202-020, Brazil; Federal Institute of Maranhão, Araioses, Maranhão  65570-000, Brazil},
abstract={Health education is one of the knowledge areas in which augmented reality (AR) technology is widespread, and it has been considered as a facilitator of the learning process. In literature, there are still few studies detailing the role of mobile AR in neuroanatomy. Specifically, for the spinal cord, the teaching–learning process may be hindered due to its abstract nature and the absence of three-dimensional models. In this sense, we implemented a mobile application with AR technology named NitLabEduca for studying the spinal cord with an interactive exploration of 3D rotating models in the macroscopic scale, theoretical content of its specificities, animations, and simulations regarding its physiology. To investigate NitLabEduca’s effects, eighty individuals with and without previous neuroanatomy knowledge were selected and grouped into control and experimental groups. Divided, they performed learning tasks through a questionnaire. We used the System Usability Scale (SUS) to evaluate the usability level of the mobile application and a complimentary survey to verify the adherence level to the use of mobile applications in higher education. As a result, we observed that participants of both groups who started the task with the application and finished with text had more correct results in the test (p < 0.001). SUS results were promising in terms of usability and learning factor. We concluded that studying the spinal cord through NitLabEduca seems to favor learning when used as a complement to the printed material. © 2020 by the authors. Licensee MDPI, Basel, Switzerland.},
author_keywords={Augmented reality;  Health education;  Mobile learning;  Neuroanatomy;  Usability},
correspondence_address1={Teles, A.; Neuro-Innovation Technology & Brain Mapping Laboratory, Av. São Sebastião n 2819-Nossa Sra. de Fátima-Parnaíba, Brazil; email: ariel.teles@ifma.edu.br; Teles, A.; Federal Institute of MaranhãoBrazil; email: ariel.teles@ifma.edu.br},
publisher={MDPI AG},
issn={22277102},
language={English},
abbrev_source_title={Educ. Sci.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Zulkifli20202296,
author={Zulkifli, N.F.A. and Asma’, A. and Yusof, H.M. and Khairil-Shazmin, K. and Zakaria, N.S. and Mustafa, M. and Mhd Jalil, A.M.},
title={Evaluation of a voluntary augmented reality nutrition menu labelling application (Nutrilabelapps©) usage in a university café: A cross-sectional study in Terengganu, Malaysia},
journal={Food Research},
year={2020},
volume={4},
number={6},
pages={2296-2305},
doi={10.26656/fr.2017.4(6).313},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096523901&doi=10.26656%2ffr.2017.4%286%29.313&partnerID=40&md5=9f31914fa075446fd4e1b84fa7a11df4},
affiliation={Faculty of Fisheries and Food Science, Universiti Malaysia Terengganu (UMT), Kuala NerusTerengganu Darul Iman  21030, Malaysia; Faculty of Ocean Engineering Technology and Informatics, Universiti Malaysia Terengganu, Kuala NerusTerengganu Darul Iman  21030, Malaysia; School of Nutrition and Dietetics, Faculty of Health Sciences, UniSZA, Gong Badak, 21300 Kuala NerusTerengganu Darul Iman, Malaysia},
abstract={Nutrilabelapps© is an interactive augmented reality mobile application (app) providing nutrition menu labelling specifically built for Mutiara Café, a café in Universiti Malaysia Terengganu. However, no evaluation of the usage of Nutrilabelapps© has been carried out. Therefore, this cross-sectional study was aimed to determine the knowledge and attitude of nutrition menu labelling among Mutiara Café customers; the feasibility and acceptability of the app among customers; and also, the relationships between knowledge, attitude, feasibility and acceptability of this augmented reality nutrition menu labelling app. This study was conducted among 108 Mutiara Café customers who owned a smartphone and were able to download the Nutrilabelapps©. The data were analyzed using SPSS version 25. Findings showed that only 4.6% of Mutiara Café customers had good knowledge of nutrition menu labelling, while 71.3% of them had a positive attitude towards nutrition menu labelling. Nutrilabelapps© was accepted by users based on the feasibility (67.6%) and acceptability (75.9%) of the app. Remarkably, there was a significant association between knowledge, attitude, feasibility, and acceptability of the app at p < 0.05. As a conclusion, Nutrilabelapps© is highly recommended among the café customer despite their low knowledge of the nutrition menu labelling. Therefore, more education of the public about nutrition menu labelling is highly recommended. © 2020 The Authors.},
author_keywords={Acceptability;  Attitude;  Feasibility;  Knowledge;  Malaysia;  Nutrition menu labelling},
keywords={adult;  Article;  attitude to health;  augmented reality;  cross-sectional study;  data analysis;  dietary reference intake;  educational status;  female;  food intake;  human;  information processing;  Likert scale;  macronutrient;  major clinical study;  Malaysia;  male;  mobile application;  nutrient intake;  nutrition labeling;  occupation;  program acceptability;  program feasibility;  questionnaire},
correspondence_address1={Asma’, A.; Faculty of Fisheries and Food Science, Kuala Nerus, Malaysia; email: asma.ali@umt.edu.my},
publisher={Rynnye Lyan Resources},
issn={25502166},
language={English},
abbrev_source_title={Food Res.},
document_type={Article},
source={Scopus},
}

@CONFERENCE{WoÅniak202058,
author={WoÅniak, M. and Lewczuk, A. and Adamkiewicz, K. and Józiewicz, J. and Jaworski, T. and Rowińska, Z.},
title={ARchemist: Towards in-situ experimental guidance using augmented reality technology},
journal={ACM International Conference Proceeding Series},
year={2020},
pages={58-63},
doi={10.1145/3428690.3429168},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100488683&doi=10.1145%2f3428690.3429168&partnerID=40&md5=a70de3f8715765de7a866bed5b4df84a},
affiliation={Lodz University of Technology, Lodz, Poland},
abstract={Blending theoretical knowledge with applicable skills is one of the most important challenges in modern higher education, especially in STEM areas. Therefore, new approaches emerge to develop educational capabilities. We aim to facilitate classes in experimental chemistry to enhance reflection and attitude towards the subject. We present ARchemist - laboratory task management tool, designed to enhance students' self-awareness and control over performed hands-on exercises. ARchemist takes advantage of mobile augmented reality solutions to provide in-situ guidance for laboratory procedures. We contribute a research prototype designed in cooperation with students and lecturers and present reflections from early evaluation in real-case class scenario. Results show that interactive guidance tools may successfully boost students' confidence and contribute to more efficient and organized classroom workflow. © 2020 ACM.},
author_keywords={augmented learning;  augmented reality;  experimental chemistry},
keywords={Augmented reality;  Blending;  Mobile computing;  Multimedia services, Augmented reality technology;  Early evaluation;  Hands-on exercise;  Higher education;  Laboratory procedures;  Mobile augmented reality;  Research prototype;  Task management, Students},
editor={Haghighi P.D., Salvadori I.L., Steinbauer M., Khalil I., Kotsis G.},
publisher={Association for Computing Machinery},
isbn={9781450389242},
language={English},
abbrev_source_title={ACM Int. Conf. Proc. Ser.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{IwinThanakumarJoseph202072,
author={Iwin Thanakumar Joseph, S. and Benson Edwin Raj, S. and Kiyasudeen, J.M.},
title={Virtual reality - A paradigm shift in education pedagogy},
journal={2020 7th International Conference on Information Technology Trends, ITT 2020},
year={2020},
pages={72-79},
doi={10.1109/ITT51279.2020.9320880},
art_number={9320880},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100639120&doi=10.1109%2fITT51279.2020.9320880&partnerID=40&md5=e6060e14072db2124f56b45916e1a983},
affiliation={Karunya Institute of Technology and Sciences, Department of Computer Science and Engineering, Coimbatore, Tamilnadu, India; Higher Colleges of Technology, Department of Computer Information Sciences, Fujairah, United Arab Emirates; Four Kings - Digital Innovation, Dubai, United Arab Emirates},
abstract={Quality and Innovation in the current pedagogical system is the core research topics in recent years for upgrading the life of next generation smart kids. Virtual reality plays a major role in bringing new trends in the education system. The current trend in educational technologies mainly focused on electronic learning and mobile based learning approach to enhance the quality of education in terms of informative and interactive learning. Virtual reality has become predominant in most of the applications such as education, healthcare, training, entertainment and so on. This research article gives the overall view of the impact of virtual reality in pedagogical field, its present and future. © 2020 IEEE.},
author_keywords={Augmented Reality;  Education;  Mixed Reality;  Training;  Virtual Reality},
keywords={Educational technology;  Virtual reality, Education systems;  Electronic learning;  Interactive learning;  Learning approach;  Paradigm shifts;  Pedagogical systems;  Quality of education;  Research topics, E-learning},
publisher={Institute of Electrical and Electronics Engineers Inc.},
isbn={9781728183787},
language={English},
abbrev_source_title={Int. Conf. Inf. Technol. Trends, ITT},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Mohamad2020151,
author={Mohamad, A.M. and Salleh, A.S.M. and Nor, M.Z.M. and Yusuff, Y.M.I.},
title={Impacts of augmented reality in legal studies: Students' reflections},
journal={2020 7th International Conference on Information Technology Trends, ITT 2020},
year={2020},
pages={151-155},
doi={10.1109/ITT51279.2020.9320872},
art_number={9320872},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100614573&doi=10.1109%2fITT51279.2020.9320872&partnerID=40&md5=0bbce0348a902a9df33615b5008fc8e6},
affiliation={Universiti Utara Malaysia, School of Law and Center for Testing Measurement and Appraisal (CeTMA), Kedah, Malaysia; School of Law, Institute for Management and Business Research (IMBRe), Universiti Utara Malaysia, Kedah, Malaysia; Universiti Utara Malaysia, School of Law, Legal and Justice Research Center (LJRC), Kedah, Malaysia},
abstract={The use of augmented reality (AR) in education is relatively new particularly for legal studies. Yet, its use and application may benefit students of law schools not only in helping them to be more interactive in the learning process, but also engaging them in a more experiential education whereby students' learning motivation can be improved. Scarcity of past research and literature on the application of AR in legal studies has led to this study to be carried out primarily to bridge the gaps in the existing literature. Based on the above premises, this article focuses on exploring the impacts of AR in the context of legal studies from the perspective of the students. By employing a pure qualitative methodology, this article engaged with a case study method, whereby one of the law schools of a higher learning institution in Malaysia has been chosen. Survey data from the Google Form was exported for the purpose of analysis in the computer-aided qualitative analysis software (CAQDAS) ATLAS.ti version 8.4. In order to make data ready for analysis, codes were built using a purely inductive approach. It was found that the application of AR has had a significant impact on students of law school particularly within the domains of active learning, unique learning and helpfulness for their studies. The implication for the study is better understanding of the impacts of AR in legal studies among law students. Hopefully, the paper would shed light into the body of literature of technological studies, AR and virtual reality, particularly within the context of higher education. © 2020 IEEE.},
author_keywords={ATLAS.ti;  Augmented reality;  Impact study;  Legal studies;  Reflections},
keywords={Augmented reality;  Computer aided analysis;  Learning systems, Case study methods;  Experiential educations;  Higher education;  Higher learning institutions;  Learning motivation;  Learning process;  Qualitative analysis;  Qualitative methodologies, Students},
publisher={Institute of Electrical and Electronics Engineers Inc.},
isbn={9781728183787},
language={English},
abbrev_source_title={Int. Conf. Inf. Technol. Trends, ITT},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Azawi2020140,
author={Azawi, R.A. and Al-Obaidy, M. and Qaddoum, K.},
title={Mobile Augmented Reality (MAR) in Distance Learning: Present and Future},
journal={2020 7th International Conference on Information Technology Trends, ITT 2020},
year={2020},
pages={140-145},
doi={10.1109/ITT51279.2020.9320889},
art_number={9320889},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100604856&doi=10.1109%2fITT51279.2020.9320889&partnerID=40&md5=ba261cb38026a1ef4834e12ad23d7849},
affiliation={Higher Colleges of Techonlogy, United Arab Emirates},
abstract={Covid-19 pandemic affects our life suddenly and dramatically. The most affected area was our teaching methods. Students and teachers move to distance learning without good experience and background especially for non-IT teachers.In this paper, we will discuss the opportunity to enhance distance learning and how to make it more effective, easier, and more enjoyable by activating Augmented Reality (AR) in the education field.Recently, AR has been used in various contexts to enhance our experience in mobile and wearable devices. This paper discusses the use of AR in the field of education where it has been observed that learning results have been improved. This type of application required specialized teams of software to create and maintain it and we will explain the benefits and limitations of using AR in distance learning. Using AR in education will provide powerful paradigms for the next generation advanced learning system. © 2020 IEEE.},
author_keywords={Augmented reality;  E-learning;  Interactive learning environment;  Teaching strategies;  Virtual Learning Environment and Mobile Learning},
keywords={Application programs;  Augmented reality;  Distance education, Advanced learning;  Affected area;  Mobile augmented reality;  Teaching methods;  Wearable devices, Learning systems},
publisher={Institute of Electrical and Electronics Engineers Inc.},
isbn={9781728183787},
language={English},
abbrev_source_title={Int. Conf. Inf. Technol. Trends, ITT},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Mei-Fern2020627,
author={Mei-Fern, B. and Jie, L.Z. and Fu, G.Q. and Keong, T.H. and Yapp, A. and Kim, L.C.},
title={Integration of face detection and augmented reality into human anatomy education},
journal={ICCE 2020 - 28th International Conference on Computers in Education, Proceedings},
year={2020},
volume={2},
pages={627-634},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099549819&partnerID=40&md5=640e5cc07a64ce492964a301019dd4a2},
affiliation={Faculty of Creative Industries, Universiti Tunku Abdul Rahman, Malaysia; Faculty of Medicine and Health Sciences, Universiti Tunku Abdul Rahman, Malaysia},
abstract={This paper proposes an interactive augmented reality (AR) application to aid medical student in learning the human anatomy. Students will be able to take a photo of their friend using the camera in real time. Then, the system will detect their friend's face and relocate the human anatomy to the approximate position of their friends inside the augmented reality application. With this application, the learning process will be fun and could help in improving the student's retention in their studies while boosting their motivation in getting better in their learning. Besides, teamwork will be fostered along when the students are learning in a group. The experiment is conducted on the first-year medical related student in Universiti Tunku Abdul Rahman (UTAR). The result shows that there are 75% of the students agree and strongly agree that this application is able to facilitate them in the understanding of human anatomy. Based on the survey, it is concluded that the students are satisfied with this application and agreed to the effectiveness of Augmented Reality in their learning process. Copyright © 2020 Asia-Pacific Society for Computers in Education.},
author_keywords={Augmented reality;  Educational game;  Face detection;  Human anatomy;  Serious game},
keywords={Augmented reality;  Face recognition;  Learning systems, Augmented reality applications;  First year;  Human anatomy;  Learning process;  Medical students;  Real time, Students},
correspondence_address1={Mei-Fern, B.; Faculty of Creative Industries, Malaysia; email: bongmf@utar.edu.my},
editor={So H.-J., Rodrigo Ma.M., Mason J., Mitrovic A., Banawan M.P., Khambari M.N.B.M., Dewan A., Gottipati S., Hasnine M.N., Jayakrishnan M.W., Jiang B., Jong M., Kojima K., Agapito J.L., Li P., Matsui T., Ogata H., Panjaburee P., Shadiev R., Sung H.-Y., Supnithi T., Tlili A., Wongwatkit C., Yin C.},
publisher={Asia-Pacific Society for Computers in Education},
isbn={9789869721462},
language={English},
abbrev_source_title={ICCE - Int. Conf. Comput. Educ., Proc.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Aladin2020,
author={Aladin, M.Y.F. and Ismail, A.W. and Salam, M.S.H. and Kumoi, R. and Ali, A.F.},
title={AR-TO-KID: A speech-enabled augmented reality to engage preschool children in pronunciation learning},
journal={IOP Conference Series: Materials Science and Engineering},
year={2020},
volume={979},
number={1},
doi={10.1088/1757-899X/979/1/012011},
art_number={012011},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097288509&doi=10.1088%2f1757-899X%2f979%2f1%2f012011&partnerID=40&md5=8d318217a64ce5005107ad2fd6788013},
affiliation={ViCubeLab Research Group, Universiti Teknologi Malaysia, Johore, 81310, Malaysia; School of Computing, Faculty of Engineering, Universiti Teknologi Malaysia, UTM Johor Bahru, Johor, 81310, Malaysia},
abstract={AR-TO-KID is an application produced for preschool children between ages five to six years old with an Augmented Reality (AR) application. The significant purpose of AR-TO-KID is to improve the pronunciation of the children in English. Hence, this paper discusses an AR application with speech input. The detection of the children speech input when they need to pronounce the words correctly, and they need to have critical thinking to identify the environment suit with the 3D objects that they will utter the word. Educational technology should be interactive and attractive for 5 to 6 years old preschool children learning; however, some at preschool teachers still used the conventional methods in teaching and children are not fully engaged with the method. Therefore, this project is to design and develop an interactive AR tool called AR-TO-KID for preschool children in pronunciation learning and teaching. This paper presents the evaluation and testing for preschool children with non-native English speaking. The article ends with results and discussion. © Published under licence by IOP Publishing Ltd.},
correspondence_address1={Aladin, M.Y.F.; ViCubeLab Research Group, Malaysia; email: yahyfekri@gmail.com},
publisher={IOP Publishing Ltd},
issn={17578981},
language={English},
abbrev_source_title={IOP Conf. Ser. Mater. Sci. Eng.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Mallik20201,
author={Mallik, A. and Kapila, V.},
title={Interactive Learning of Mobile Robots Kinematics Using ARCore},
journal={2020 5th International Conference on Robotics and Automation Engineering, ICRAE 2020},
year={2020},
pages={1-6},
doi={10.1109/ICRAE50850.2020.9310865},
art_number={9310865},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100348747&doi=10.1109%2fICRAE50850.2020.9310865&partnerID=40&md5=c31addd4e664acc4a4e373bf0b863304},
affiliation={Nyu Tandon School of Engineering, Mechanical and Aerospace Engineering Department, Brooklyn, NY, United States},
abstract={Recent years have witnessed several educational innovations to provide effective and engaging classroom instruction with the integration of immersive interactions based on augmented reality and virtual reality (AR/VR). This paper outlines the development of an ARCore-based application (app) that can impart interactive experiences for hands-on learning in engineering laboratories. The ARCore technology enables a smartphone to sense its environment and detect horizontal and vertical surfaces, thus allowing the smartphone to estimate any position in its workspace. In this mobile app, with touch-based interaction and AR feedback, the user can interact with a wheeled mobile robot and reinforce the concepts of kinematics for a differential drive mobile robot. The user experience is evaluated and system performance is validated through a user study with participants. The assessment shows that the proposed AR interface for interacting with the experimental setup is intuitive, easy to use, exciting, and recommendable. © 2020 IEEE.},
author_keywords={ARCore;  augmented reality;  mobile robot kinematics;  robotics education},
keywords={Agricultural robots;  Augmented reality;  E-learning;  Educational robots;  Kinematics;  Laboratories;  Mobile robots;  Robotics;  Smartphones;  Virtual reality, Classroom instruction;  Differential drive;  Educational innovations;  Hands-on learning;  Interactive learning;  Robots kinematics;  Touch based interactions;  Wheeled mobile robot, User experience},
publisher={Institute of Electrical and Electronics Engineers Inc.},
isbn={9781728189819},
language={English},
abbrev_source_title={Int. Conf. Robot. Autom. Eng., ICRAE},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Yuhana2020116,
author={Yuhana, U.L. and Hariadi, R.R. and Mukramin, M. and Fabroyir, H. and Arifiani, S.},
title={AUGGO: Augmented Reality and Marker-based Application for Learning Geometry in Elementary Schools},
journal={CENIM 2020 - Proceeding: International Conference on Computer Engineering, Network, and Intelligent Multimedia 2020},
year={2020},
pages={116-120},
doi={10.1109/CENIM51130.2020.9298003},
art_number={9298003},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099653071&doi=10.1109%2fCENIM51130.2020.9298003&partnerID=40&md5=bbbb9d5670798a357c27260a04958683},
affiliation={Institut Teknologi Sepuluh Nopember, Department of Informatics, Surabaya, Indonesia},
abstract={Suitable learning media can be used to achieve learning goals. The more interactive the learning media, the learning process will be more interactive. This paper proposes a learning media named Auggo. Auggo is an Augmented Reality (AR) and marker-based application as an interactive media to learn geometry in Elementary School. To show the impact of Auggo, this research conducts a test to 14 students in elementary school as participants. The test was carried out using the Two-Group Paired Sample T-Test method with those 14 elementary school students. Participants were divided into 2 groups: 7 participants as Group A (experimental class) and 7 participants as Group B (control class). Assessment of participants showed the results of the pretest to posttest in Group A increased by 26%, while Group B only increased by 10.29%. These results indicate that the AR-based AUGGO application can help students in improving the understanding of space concept. © 2020 IEEE.},
author_keywords={Augmented Reality;  Elementary School;  Geometry;  learning media},
publisher={Institute of Electrical and Electronics Engineers Inc.},
isbn={9781728182834},
language={English},
abbrev_source_title={CENIM - Proceeding: Int. Conf. Comput. Eng., Network, Intell. Multimed.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Patti2020,
author={Patti, B.I.},
title={Standard cataloguing of augmented objects for a design museum},
journal={IOP Conference Series: Materials Science and Engineering},
year={2020},
volume={949},
number={1},
doi={10.1088/1757-899X/949/1/012054},
art_number={012054},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096849183&doi=10.1088%2f1757-899X%2f949%2f1%2f012054&partnerID=40&md5=2b31b0a8b50c4f0d45746ffa87ce552f},
affiliation={DIDA Department of Architecture, University of Florence, Italy},
abstract={Demo-ethno-anthropological assets belonging to the cultural heritage are not "autonomous" but represent the nodes of a complex system of relations. Their narration – for the purposes of knowledge and cultural diffusion – cannot transcend this relational dimension that recognises an enormous potential for development in the application of digital culture and in the prudent use of augmented reality. In the perspective of a design museum, it is therefore necessary to accompany each artefact / asset with a digital matrix that provides accurate information in relation to its critical interpretation. The exposure of an augmented object, in fact, allows to read better its use and social value along specific interpretative lines. This essay summarizes the study of a new type of archive – the animated archive of cultural materials – intended as a system of standard cataloguing of objects for a museum on design. Moreover, it is based on the critical comparison between the contribution of ludic humanism and the augmented narrative. This comparison is necessary because the rhetorical and design systems of the playful narrative offers interesting information for the realization of virtual – and non – exhibits, since the type of involvement and the environment required by the spectator is very similar; but above all because games are an important experimentation of interactive models of learning and cultural production. © 2020 Institute of Physics Publishing. All rights reserved.},
correspondence_address1={Patti, B.I.; DIDA Department of Architecture, Italy; email: Isabella.patti@unifi.it},
publisher={IOP Publishing Ltd},
issn={17578981},
language={English},
abbrev_source_title={IOP Conf. Ser. Mater. Sci. Eng.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Agrawal202023,
author={Agrawal, R. and Pillai, J.S.},
title={Augmented Reality Application in Vocational Education: A Case of Welding Training},
journal={ISS 2020 - Companion - Proceedings of the 2020 Conference on Interactive Surfaces and Spaces},
year={2020},
pages={23-27},
doi={10.1145/3380867.3426199},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096917806&doi=10.1145%2f3380867.3426199&partnerID=40&md5=a787d66711adbd4e2951afd5cb22939a},
affiliation={IDC School of Design, Indian Institute of Technology Bombay, Mumbai, Maharashtra, India},
abstract={This paper embodies the need, design and evaluation of an AR welding mobile application highlighting the potential of mobile AR interactions. There are 36 million unemployed youth in India [6]. One of the reasons for unemployment among youth is the significant disconnect between the school education and the opportunities, skills, and exposure necessary to achieve full potential and earn livelihood [6]. Various NGOs have taken initiatives to introduce vocational training as a part of mainstream education to create employment opportunities for students from low-income backgrounds on completion of schooling. The secondary schools in which such training is imparted often face a lack of space and infrastructure, regulatory restrictions and safety concerns. The objective of this project was to innovate using Augmented Reality (AR) to overcome the spatial and safety barriers that affect the efficiency of these vocational training programs. An interactive learning module was designed using marker-based mobile AR to aid in providing the knowledge as well as learning the skills required for welding. This learning module was evaluated with expert welding instructors and accordingly proposed to be used in government schools providing vocational training in welding. This project opens up the possibility of designing safe and accessible ways to develop vocational skills. © 2020 ACM.},
author_keywords={ar interactions;  ar welding;  vocational education},
keywords={Augmented reality, Augmented reality applications;  Design and evaluations;  Employment opportunities;  Interactive learning;  Mobile applications;  Secondary schools;  Vocational education;  Vocational training, Welding},
publisher={Association for Computing Machinery, Inc},
isbn={9781450375269},
language={English},
abbrev_source_title={ISS Companion - Proc. Conf. Interact. Surfaces Spaces},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Silva2020300,
author={Silva, M. and Teixeira, L.},
title={Developing an eXtended Reality platform for Immersive and Interactive Experiences for Cultural Heritage: Serralves Museum and Coa Archeologic Park},
journal={Adjunct Proceedings of the 2020 IEEE International Symposium on Mixed and Augmented Reality, ISMAR-Adjunct 2020},
year={2020},
pages={300-302},
doi={10.1109/ISMAR-Adjunct51615.2020.00084},
art_number={9288434},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099580226&doi=10.1109%2fISMAR-Adjunct51615.2020.00084&partnerID=40&md5=280c6d491b733f13a846bdbfb61f3f9b},
affiliation={Citar Universidade Católica Portuguesa, School of Arts-Digital Creativity Center, Porto, Portugal},
abstract={Digital Heritage and Digital Humanities focus on distinct typologies of heritage: Tangible and intangible Cultural Heritage (CH) objects and their preservation, education, and research versus the application of digital technologies to support research in the humanities. Both allow scholars to go beyond textual sources to integrate digital tools into the humanistic study. This project aims at supporting a new way of experiencing CH in the Serralves Museum and Coa Archeologic Park through more involving and culturally-qualified user experience. The main goal is to understand the potential of eXtended Reality within CH while also proposing the idea of developing a digital experience platform: An authoring tool based on an engine with core experiences functions that can be applied for developing multiple experiences for CH. This platform will contribute to new approaches, technologies, and tools for creating, processing, and delivering immersive and interactive content for engaging and meaningful experiences in these specific CH environments. © 2020 IEEE.},
author_keywords={Coa Archeological Park;  Cultural Heritage;  eXtended Reality;  Immersive and Interactive Experience;  Platform;  Serralves Museum},
keywords={Augmented reality;  Digital devices;  Historic preservation, Authoring tool;  Cultural heritages;  Digital heritage;  Digital humanities;  Digital technologies;  Intangible cultural heritages;  Interactive contents;  New approaches, User experience},
publisher={Institute of Electrical and Electronics Engineers Inc.},
isbn={9781728176758},
language={English},
abbrev_source_title={Adjun. Proc. IEEE Int. Symp. Mixed Augment. Real., ISMAR-Adjunct},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Gallego2020111,
author={Gallego, N.P.D.},
title={A Proposed Learning Content for Teaching Handheld Augmented Reality in a Classroom Setting},
journal={Proceedings - 2020 22nd Symposium on Virtual and Augmented Reality, SVR 2020},
year={2020},
pages={111-118},
doi={10.1109/SVR51698.2020.00030},
art_number={9262690},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099552291&doi=10.1109%2fSVR51698.2020.00030&partnerID=40&md5=cac19dc48d8bd95be1ebe8e18e08e387},
affiliation={De la Salle University, 2401 Taft Avenue, Malate, Manila, Philippines},
abstract={Augmented reality is an interactive experience wherein digital objects are placed on the physical environment. Augmented reality (AR) applications have gained popularity especially when smartphones gained capable camera sensors, gyroscope, and other sensors. However, there has been a lack of framework or recommendations on how to formally teach developing mobile AR applications in a classroom setting. In this paper, we present a learning content, called ARVRDEV Courseware, that aims to teach undergraduate students how to develop augmented reality applications deployed on handheld devices. We carefully designed the lessons of the course, consistent with AR techniques from literature, and designed hands-on activities not typically presented in publicly available materials. A pilot run of the course was offered at De La Salle University, where a total of 76 undergraduate students took the course as an elective during their 4th year. We analyzed the effectiveness of the hands-on activities based on the assessment results of the students and discussed the outstanding projects developed by the students, which are observed to be inspired by the hands-on activities designed for the course. © 2020 IEEE.},
author_keywords={application;  augmented reality;  computing education;  course design},
keywords={Augmented reality;  Curricula;  Teaching, Augmented reality applications;  Classroom settings;  Hand held device;  Handheld augmented realities;  Hands-on activities;  Learning contents;  Physical environments;  Undergraduate students, Students},
correspondence_address1={Gallego, N.P.D.; De la Salle University, 2401 Taft Avenue, Philippines; email: neil.delgallego@dlsu.edu.ph},
publisher={Institute of Electrical and Electronics Engineers Inc.},
isbn={9781728192314},
language={English},
abbrev_source_title={Proc. - Symp. Virtual Augment. Real., SVR},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Collins2020110,
author={Collins, J. and Langlotz, T. and Regenbrecht, H.},
title={Virtual Reality in Education: A Case Study on Exploring Immersive Learning for Prisoners},
journal={Adjunct Proceedings of the 2020 IEEE International Symposium on Mixed and Augmented Reality, ISMAR-Adjunct 2020},
year={2020},
pages={110-115},
doi={10.1109/ISMAR-Adjunct51615.2020.00042},
art_number={9288462},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099551030&doi=10.1109%2fISMAR-Adjunct51615.2020.00042&partnerID=40&md5=c921fd4247c117dbc8b6fe9248436d63},
affiliation={University of Otago, Information Science, Dunedin, New Zealand},
abstract={Our research presented here tries to bridge the gap between technology-oriented lab work and the praxis of introducing VR technology into difficult to deploy-To contexts-in our case prisoners with high learning needs. We have developed a prototypical immersive VR application designed for delivering low-level literacy and numeracy content to illiterate adults. This development has been taken to the commercial sector and is currently under product development. The target population for the application are those currently held in a correctional facility, but who have the motivation and determination to educate themselves. In this paper we discuss the current lifecycle of this project including the development, initial tests, and an exploratory study we conducted. We conclude with a discussion of logistical issues, potential research opportunities, and current outcomes. © 2020 IEEE.},
author_keywords={Applied computing;  Education;  Human computer interaction (HCI);  Human-centered computing;  in-The-field;  Interaction paradigms;  Interactive learning environments;  learning;  Virtual reality;  VR education},
keywords={Augmented reality;  E-learning;  Engineering education;  Life cycle;  Software prototyping, Commercial sector;  Exploratory studies;  Immersive learning;  Immersive VR;  Potential researches;  VR technology, Virtual reality},
correspondence_address1={Regenbrecht, H.; University of Otago, New Zealand; email: holger.regenbrecht@otago.ac.nz},
publisher={Institute of Electrical and Electronics Engineers Inc.},
isbn={9781728176758},
language={English},
abbrev_source_title={Adjun. Proc. IEEE Int. Symp. Mixed Augment. Real., ISMAR-Adjunct},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Shih20201,
author={Shih, N.-J. and Chen, H.-X. and Chen, T.-Y. and Qiu, Y.-T.},
title={Digital preservation and reconstruction of old cultural elements in augmented reality (AR)},
journal={Sustainability (Switzerland)},
year={2020},
volume={12},
number={21},
pages={1-19},
doi={10.3390/su12219262},
art_number={9262},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096027691&doi=10.3390%2fsu12219262&partnerID=40&md5=c8969f197293ae8d2e7510429d4782ff},
affiliation={Department of Architecture, National Taiwan University of Science and Technology, Taipei, 106, Taiwan},
abstract={This research aimed to preserve traditional elements and urban fabric with enabled interaction in augmented reality (AR). Cultural elements and fabrics are mutually influential in Lukang, Taiwan. Evolved routes for tourism and religious activities have created characteristic elements and activity-based fabrics and facilities. The sustainable promotion of digital cultural assets started from photogrammetry modeling of alley space and shops. The application of AR enabled situated learning of 68 objects, including decorated façades, jar walls, the Lukang Gate, beggar seats, and other creative cultural elements. The heritages were promoted under a new interactive measure of feasibility that facilitated cultural sustainability in a remote site. A mobile interface with a convenient smartphone configured certain settings that were sufficiently flexible and easy to apply. The study presented an effective and efficient remote and situated learning process that correlated the development or setting of both locations. Correlation was achieved with a high fidelity of appearance and utilizing a flexible transformation interface. An approach, which recreated the background and formerly reconstructed objects during AR simulation, was used to verify the outcome of the situated study with conflicting qualitative and quantitative findings. © 2020 by the authors. Licensee MDPI, Basel, Switzerland.},
author_keywords={AR;  Cultural heritage;  Photogrammetry;  Preservation;  Situated learning},
keywords={digitization;  learning;  photogrammetry;  qualitative analysis;  religion;  sustainability;  tourism development;  transformation;  virtual reality, Lukang;  Taiwan},
correspondence_address1={Shih, N.-J.; Department of Architecture, Taiwan; email: shihnj@mail.ntust.edu.tw},
publisher={MDPI AG},
issn={20711050},
language={English},
abbrev_source_title={Sustainability},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Tsvetkova202074,
author={Tsvetkova, I.D. and Borodzhieva, A.N.},
title={Analysis of Measurements for Investigating Amplitude Modulation Using Interactive Methods},
journal={28th National Conference with International Participation, TELECOM 2020 - Proceedings},
year={2020},
pages={74-77},
doi={10.1109/TELECOM50385.2020.9299533},
art_number={9299533},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099458465&doi=10.1109%2fTELECOM50385.2020.9299533&partnerID=40&md5=8dc9adafba47c5da57279512d4d41566},
affiliation={Electronics and Automation University of Ruse 'Angel Kanchev', Faculty of Electrical Engineering, Department of Telecommunications, 8 Studentska Str, Ruse, 7017, Bulgaria},
abstract={Teachers use different approaches to engage students with the learning process and make the material more interesting. Interactive tools and augmented reality (AR) applications are a great way to increase the students' participation. The paper demonstrates the use of AR and the interactive approach in the discipline 'Radio Communication Technologies'. It describes what students need to do in the laboratory exercises on the topic of Amplitude Modulation. © 2020 IEEE.},
author_keywords={amplitude modulation;  augmented reality;  interactive methods;  radio communications},
keywords={Augmented reality;  Radio communication;  Students, Analysis of measurements;  Communication technologies;  Interactive approach;  Interactive methods;  Interactive tool;  Laboratory exercise;  Learning process, Amplitude modulation},
publisher={Institute of Electrical and Electronics Engineers Inc.},
isbn={9781728187174},
language={English},
abbrev_source_title={Natl. Conf. Int. Particip., TELECOM - Proc.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Putze202033,
author={Putze, F. and Küster, D. and Urban, T. and Zastrow, A. and Kampen, M.},
title={Attention Sensing through Multimodal User Modeling in an Augmented Reality Guessing Game},
journal={ICMI 2020 - Proceedings of the 2020 International Conference on Multimodal Interaction},
year={2020},
pages={33-40},
doi={10.1145/3382507.3418865},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096675360&doi=10.1145%2f3382507.3418865&partnerID=40&md5=b31fbf3ac59f0288b7cb189846204695},
affiliation={University of Bremen, Bremen, Germany},
abstract={We developed an attention-sensitive system that is capable of playing the children's guessing game "I spy with my litte eye"with a human user. In this game, the user selects an object from a given scene and provides the system with a single-sentence clue about it. For each trial, the system tries to guess the target object. Our approach combines top-down and bottom-up machine learning for object and color detection, automatic speech recognition, natural language processing, a semantic database, eye tracking, and augmented reality. Our evaluation demonstrates performance significantly above chance level, and results for most of the individual machine learning components are encouraging. Participants reported very high levels of satisfaction and curiosity about the system. The collected data shows that our guessing game generates a complex and rich data set. We discuss the capabilities and challenges of our system and its components with respect to multimodal attention sensing. © 2020 ACM.},
author_keywords={attention;  augmented reality;  gamification;  top-down and bottom-up modeling},
keywords={Augmented reality;  Eye tracking;  Interactive computer systems;  Machine learning;  Natural language processing systems;  Object detection;  Semantics;  Speech recognition, Automatic speech recognition;  Color detection;  Multi-modal;  NAtural language processing;  Semantic database;  Sensitive systems;  Target object;  User Modeling, Object tracking},
publisher={Association for Computing Machinery, Inc},
isbn={9781450375818},
language={English},
abbrev_source_title={ICMI - Proc. Int. Conf. Multimodal Interact.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Lee2020281,
author={Lee, L.S. and Aluwee, S.A.Z.S. and Meng, G.C. and Palanisamy, P. and Subramaniam, R.},
title={Interactive Tool Using Augmented Reality (AR) for Learning Knee and Foot Anatomy Based on CT Images 3D Reconstruction},
journal={2020 International Conference on Computational Intelligence, ICCI 2020},
year={2020},
pages={281-286},
doi={10.1109/ICCI51257.2020.9247820},
art_number={9247820},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097518761&doi=10.1109%2fICCI51257.2020.9247820&partnerID=40&md5=74a73aae2cc2eba91511b64176cc2e1b},
affiliation={Universiti Tunku Abdul Rahman (UTAR), Department of Computer Science, Kampar, Malaysia; Universiti Kuala Lumpur Kampus, Cawangan Royal College of Medicine Perak (RCMP), Department of Anatomy, Ipoh, Malaysia; Universiti Kuala Lumpur Kampus, Cawangan Royal College of Medicine Perak (RCMP), Radiology Discipline Sub Unit, Ipoh, Malaysia},
abstract={Anatomy is the branch of biological science in medical education that focuses on structured parts of living things, especially the human body. Traditional teaching methods and learning materials of human body anatomy are usually available in the form of textbooks with pictures and images or artificial anatomy mannequins. There are still not enough to help the students in understanding it with actual and accurate knowledge about our human body anatomy. It is because students are challenging in learning the human anatomy body part by through imagining it's real and lack of interaction and hard to understand with those 2D images model on the textbooks. Although there are artificial anatomy mannequins available for learning, it is limited in number and access. Technological developments, especially applications based on 3D, are expected to help the learning process of this science subject. In this study, we proposed to develop an augmented reality (AR) mobile application for learning human anatomy knee and foot through medical 3-dimensional (3D) reconstruction based on medical images. By using this application, students expected can easily understand human anatomy using 3D image visualisation on the mobile computing platform. © 2020 IEEE.},
author_keywords={3D visualisation;  augmented reality (AR);  education technology;  knee and foot anatomy;  medical images segmentation;  mobile application},
keywords={Augmented reality;  Computerized tomography;  Education computing;  Intelligent computing;  Learning systems;  Medical education;  Medical imaging;  Mobile computing;  Students;  Textbooks, 3D reconstruction;  Biological science;  Interactive tool;  Learning materials;  Learning process;  Mobile applications;  Teaching methods;  Technological development, Image reconstruction},
publisher={Institute of Electrical and Electronics Engineers Inc.},
isbn={9781728154473},
language={English},
abbrev_source_title={Int. Conf. Comput. Intell., ICCI},
document_type={Conference Paper},
source={Scopus},
}

@BOOK{Vermesan20201,
author={Vermesan, O. and Bacquet, J.},
title={Internet of things - the call of the edge: Everything intelligent everywhere},
journal={Internet of Things - The Call of the Edge: Everything Intelligent Everywhere},
year={2020},
pages={1-392},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104169566&partnerID=40&md5=2da954bb6c0cad2b3ec0dee3da2cb986},
affiliation={SINTEF, Norway; EU, Belgium},
abstract={This book provides an overview of the Internet of Things (IoT) - covering new ideas, concepts, research and innovation to enable the development of IoT technologies in a global context. The work is intended as a standalone book in a series covering the activities of the Internet of Things European Research Cluster (IERC) - including research, technological innovation, validation, and deployment. The book chapters build on the developments and innovative ideas put forward by the IERC, the IoT European Large-Scale Pilots Programme and the IoT European Security and Privacy Projects - presenting new concepts, ideas and future IoT trends and ways of integrating open data frameworks and IoT marketplaces into larger deployment ecosystems. The IoT and Industrial Internet of Things technologies are moving towards hyperautomated solutions - combining hyperconnectivity, artificial intelligence (AI), distributed ledger technologies and virtual/augmented extended reality, with edge computing and deep edge processing becoming an assertive factor across industries for implementing intelligent distributed computing resources and data to keep the efficient data exchange and processing local to reduce latency, exploit the sensing/actuating capabilities and enable greater autonomy. Expanding the adoption of consumer, business, industrial and tactile IoT requires further development of hyperautomated IoT concepts for collaborative solutions involving machines and humans to expand augmented creativity at the application level using AI to optimise the industrial processes and progress towards a symbiotic economy based on distributed federated cloud/edge infrastructure allowing resource sharing in the form of computing, memory and analytics capabilities. The advances of autonomous IoT applications delivering services in real-time encompasses development in servitisation, robotisation, automation and hyperconnectivity, which are essential for the rapid evolution of industrial enterprises in the new digital era. The rise of digital twins integrated into IoT platforms as fully interactive elements embedded into the simulation and optimisation environment, as well as the embedment of AI techniques and methods, enhances the accuracy and performance of models in the various IoT and Industrial Internet of Things applications. The convergence of technologies to provide scalable, interoperable IoT-enabled applications pushed the requirements for high bandwidth, low latency and robust and dependable connectivity to support the industry's demand for deeper integration and improved analytics to deliver sustainable competitive advantage products and services, enabling digital transformation with a focus on new business models. Safety and security are interlinked for the next wave of IoT technologies and applications and combined, prove a greater value for rapid adoption. The new IoT technologies are essential for facilitating sustainable development, reducing energy consumption and, by supporting the optimisation of products and processes, mitigating unnecessary carbon emissions - thereby reducing the environmental impact through real-time data collection, analysis, exchange, and processing. © 2020 River Publishers. All rights reserved.},
author_keywords={Artificial Intelligence (AI);  Artificial Intelligence of Things (AIoT);  Artificial Intelligence of Things Innovation (AIoTI);  Augmented reality (AR);  Autonomous Systems;  Autonomous Vehicles;  Industrial Internet of Things (IIoT);  Information Technology (IT);  Intelligent Internet of Things;  Internet of Robotic Things (IoRT);  Internet of Things (IoT);  Internet of Things Augmentation;  Internet of Thins and Senses (IOTS);  IoT platforms;  IoT technologies;  Machine Learning (ML);  Next Generation Internet (NGI);  Operational Technology (OT);  Tactile Internet;  Tactile Internet of Things;  Virtual Reality (VR)},
correspondence_address1={Vermesan, O.; SINTEFNorway},
publisher={River Publishers},
isbn={9788770221962; 9788770221955},
language={English},
abbrev_source_title={Internet of Things - The Call of the Edge: Everything Intell. Everywhere},
document_type={Book},
source={Scopus},
}

@CONFERENCE{Chen202076,
author={Chen, X. and Liu, G.},
title={Joint Optimization of Task Offloading and Resource Allocation via Deep Reinforcement Learning for Augmented Reality in Mobile Edge Network},
journal={Proceedings - 2020 IEEE 13th International Conference on Edge Computing, EDGE 2020},
year={2020},
pages={76-82},
doi={10.1109/EDGE50951.2020.00019},
art_number={9284282},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100274724&doi=10.1109%2fEDGE50951.2020.00019&partnerID=40&md5=941abba8984b1af42a0e4eda277f65c8},
affiliation={School of Information and Communications Engineering, Xi'an Jiaotong University, Xi'an, China},
abstract={Mobile edge computing (MEC) has been recognized as emerging techniques in 5G to provide powerful computing capabilities for the Ultra Reliable Low Latency Communication (URLLC) applications. In this paper, a MEC enable multi-user wireless network is considered by offloading the computation task to MEC server, reducing latency and energy consumption of user terminal for Augmented Reality (AR) application. The joint optimization problem of resource allocation and task offloading is studied to minimize the energy consumption of each user subject to the delay requirement and the limited resources. We propose a deep reinforcement learning algorithm based on a multi-agent deep deterministic policy gradient (MADDPG) to solve this problem. Simulation results show that the proposed algorithm can greatly reduce energy consumption of the users. © 2020 IEEE.},
author_keywords={Augmented Reality;  Deep Reinforcement Learning;  Mobile Edge Computing},
keywords={5G mobile communication systems;  Augmented reality;  Edge computing;  Energy utilization;  Green computing;  Learning algorithms;  Multi agent systems;  Reinforcement learning;  Resource allocation, Computation tasks;  Computing capability;  Joint optimization;  Low-latency communication;  Policy gradient;  Reduce energy consumption;  Task offloading;  User terminals, Deep learning},
publisher={Institute of Electrical and Electronics Engineers Inc.},
isbn={9781728182544},
language={English},
abbrev_source_title={Proc. - IEEE Int. Conf. Edge Comput., EDGE},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Lu2020433,
author={Lu, F. and Peng, H. and Wu, H. and Yang, J. and Yang, X. and Cao, R. and Zhang, L. and Yang, R. and Zhou, B.},
title={InstanceFusion: Real-time Instance-level 3D Reconstruction Using a Single RGBD Camera},
journal={Computer Graphics Forum},
year={2020},
volume={39},
number={7},
pages={433-445},
doi={10.1111/cgf.14157},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096418871&doi=10.1111%2fcgf.14157&partnerID=40&md5=0b3eb4855a3500dff4ed86fe53180a64},
affiliation={State Key Laboratory of Virtual Reality Technology and Systems, School of Computer Science and Engineering, Beihang University, Beijing, China; Robotics and Autonomous Driving Laboratory, Baidu Research, China; Peng Cheng Laboratory, Shenzhen, China; University of Kentucky, United States},
abstract={We present InstanceFusion, a robust real-time system to detect, segment, and reconstruct instance-level 3D objects of indoor scenes with a hand-held RGBD camera. It combines the strengths of deep learning and traditional SLAM techniques to produce visually compelling 3D semantic models. The key success comes from our novel segmentation scheme and the efficient instance-level data fusion, which are both implemented on GPU. Specifically, for each incoming RGBD frame, we take the advantages of the RGBD features, the 3D point cloud, and the reconstructed model to perform instance-level segmentation. The corresponding RGBD data along with the instance ID are then fused to the surfel-based models. In order to sufficiently store and update these data, we design and implement a new data structure using the OpenGL Shading Language. Experimental results show that our method advances the state-of-the-art (SOTA) methods in instance segmentation and data fusion by a big margin. In addition, our instance segmentation improves the precision of 3D reconstruction, especially in the loop closure. InstanceFusion system runs 20.5Hz on a consumer-level GPU, which supports a number of augmented reality (AR) applications (e.g., 3D model registration, virtual interaction, AR map) and robot applications (e.g., navigation, manipulation, grasping). To facilitate future research and reproduce our system more easily, the source code, data, and the trained model are released on Github: https://github.com/Fancomi2017/InstanceFusion. © 2020 The Author(s) Computer Graphics Forum © 2020 The Eurographics Association and John Wiley & Sons Ltd. Published by John Wiley & Sons Ltd.},
author_keywords={CCS Concepts;  Perception;  Vision for robotics;  • Computing methodologies → Scene understanding},
keywords={3D modeling;  Application programming interfaces (API);  Augmented reality;  Cameras;  Data fusion;  Deep learning;  Image reconstruction;  Interactive computer systems;  Real time systems;  Robot applications;  Robots;  Semantics, 3D reconstruction;  Design and implements;  Model registrations;  Segmentation scheme;  Semantic Model;  Shading languages;  State of the art;  Virtual interactions, Three dimensional computer graphics},
correspondence_address1={Zhou, B.; State Key Laboratory of Virtual Reality Technology and Systems, China; email: zhoubin@buaa.edu.cn; Zhou, B.; Peng Cheng LaboratoryChina; email: zhoubin@buaa.edu.cn},
publisher={Blackwell Publishing Ltd},
issn={01677055},
coden={CGFOD},
language={English},
abbrev_source_title={Comput Graphics Forum},
document_type={Article},
source={Scopus},
}

@ARTICLE{Sanderasagran2020559,
author={Sanderasagran, A.N. and Aziz, A.A. and Idris, D.M.N.D.},
title={Real-time computational fluid dynamics flow response visualisation and interaction application based on augmented reality},
journal={Journal of Information and Communication Technology},
year={2020},
volume={19},
number={4},
pages={559-581},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090223613&partnerID=40&md5=75f5d547ac56b3b00815ff8b62783dc0},
affiliation={Faculty of Mechanical and Automotive Engineering Technology, Universiti Malaysia, Pahang, Malaysia},
abstract={The behaviour of fluid flow is a complex paradigm for cognitive interpretation and visualisation. Engineers need to visualise the behaviour mechanics of flow field response in order to enhance the cognitive ability in problem solving. Therefore, mixed reality related technology is the solution for enhanced virtual interactive learning environment. However, there are limited augmented reality platforms on fluid flow interactive learning. Therefore, an interactive education application is proposed for students and engineers to interact and understand the complex flow behaviour pattern subjected to elementary geometry body relative to external flow. This paper presented the technical development of a real-time flow response visualisation augmented reality application for computational fluid dynamics application. It was developed with the assistance of several applications such as Unity, Vuforia, and Android. Particle system modules available in the Unity engine were used to create a two-dimensional flow stream domain. The flow visualisation and interaction were limited to two-dimensional and the numerical fluid continuum response was not analysed. The physical flow response pattern of three simple geometry bodies was validated against ANSYS simulated results based on visual empirical observation. The particle size and number of particles emitted were adjusted in order to emulate the physical representation of fluid flow. Colour contour was set to change according to fluid velocity. Visual validation indicated trivial dissimilarities between FLUENT generated results and flow response exhibited by the proposed augmented reality application. © 2020 Universiti Utara Malaysia Press.},
author_keywords={Augmented reality;  Computational fluid dynamics;  Image target;  Particle system;  Unity engine;  Vuforia},
publisher={Universiti Utara Malaysia Press},
issn={1675414X},
language={English},
abbrev_source_title={J. Inf. Commu. Technol.},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Chen2020,
author={Chen, H.-Y. and Yang, C.-Y. and Liu, X.-Y. and Chou, C.-F.},
title={On Deep Learning Based Feedback and Precoding for Multi-user Millimeter-Wave Enabled VR/AR},
journal={2020 IEEE International Conference on Consumer Electronics - Taiwan, ICCE-Taiwan 2020},
year={2020},
doi={10.1109/ICCE-Taiwan49838.2020.9258078},
art_number={9258078},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098452822&doi=10.1109%2fICCE-Taiwan49838.2020.9258078&partnerID=40&md5=fb66bc5dcc6bdd7ad09582c161d0aefa},
affiliation={National Taiwan University, Taipei, Taiwan},
abstract={Virtual reality (VR)/augmented reality (AR) and its applications have attracted significant and increasing attention recently. However, the stringent quality of service (QoS) requirements and better spectral efficiency have posed the challenges such as higher bandwidth, lower latency and better reliability on the VR/AR communication system. This paper proposes a deep-learning-based (DL-based) precoding and feedback method for mitigating the channel interference of multi-users VR/AR environments. That is, our DL-based method uses the VR/AR channel state information (CSI) to do radio resource allocation for maximizing the millimeter-wave network throughput. Numerical results show that our DL-based design could significantly enhance the throughput. © 2020 IEEE.},
author_keywords={augmented reality;  Deep Learning;  Massive MIMO;  precoder feedback;  virtual reality},
keywords={Channel state information;  Millimeter waves;  Quality of service, Channel interferences;  ITS applications;  Multi-user;  Network throughput;  Numerical results;  Qualityof-service requirement (QoS);  Radio resource allocation;  Spectral efficiencies, Deep learning},
publisher={Institute of Electrical and Electronics Engineers Inc.},
isbn={9781728173993},
language={English},
abbrev_source_title={IEEE Int. Conf. Consum. Electron. - Taiwan, ICCE-Taiwan},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Brilian202097,
author={Brilian, I. and Bagus Nur Rahma Putra, A. and Suhartadi, S. and Partono, P.},
title={Augmented Reality Based Learning Media as Interactive Learning Innovation to Enhanced Vocational School Learning Outcomes},
journal={4th International Conference on Vocational Education and Training, ICOVET 2020},
year={2020},
pages={97-100},
doi={10.1109/ICOVET50258.2020.9229922},
art_number={9229922},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096543947&doi=10.1109%2fICOVET50258.2020.9229922&partnerID=40&md5=85b772954861d14a6bf5dd8d1b494615},
affiliation={Universitas Negeri Malang, Teknik Mesin, Malang, Indonesia},
abstract={Progress in the industrial world has reached industry 4.0, in this progress it has led to the development of education as well as entering the era of education 4.0. One of the advances in the era of education 4.0 is the Augmented Reality learning media. The purpose of the study was to test the effectiveness of the effects of Augmented Reality Learning media that are in line with the needs of current and future students, the ARTorque application product as an interactive learning innovation to improve the learning outcomes of SMK students. The Quasi Experiment research design with steps: Determination of the experimental and control class, Instrument Testing, The experimental class was given the treatment of Augmented Reality learning media and the control class was not given treatment and used conventional learning. Output results obtained are normality test, homogeneity test and t test results. © 2020 IEEE.},
author_keywords={Augmented Reality;  Impact;  Learning Media;  Learning Outcomes},
keywords={Apprentices;  Augmented reality;  Educational technology;  Instrument testing;  Learning systems, Interactive learning;  Learning media;  Learning outcome;  Normality tests;  Not given;  Quasi-experiments;  Reality learning;  Vocational schools, Students},
publisher={Institute of Electrical and Electronics Engineers Inc.},
isbn={9781728181318},
language={English},
abbrev_source_title={Int. Conf. Vocat. Educ. Train., ICOVET},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Hidayat2020349,
author={Hidayat, W.N. and Damayanti, H. and Pratiwi, L.S. and Sutikno, T.A. and Patmanthara, S.},
title={Fun Learning with Flashcard using Augmented Reality for Learning Daily Prayers of Kindergarten Students},
journal={2020 3rd International Conference on Computer and Informatics Engineering, IC2IE 2020},
year={2020},
pages={349-354},
doi={10.1109/IC2IE50715.2020.9274671},
art_number={9274671},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098973900&doi=10.1109%2fIC2IE50715.2020.9274671&partnerID=40&md5=ff444c3810efdfa607175336860c2d94},
affiliation={Universitas Negeri Malang, Department of Electrical Engineering, Malang, Indonesia},
abstract={Prayer learning is one of the biggest contributors to improving early childhood memorization skills. Prayer learning for kindergarten students is still monotonous and unattractive. Especially during the C-19 pandemic, students cannot memorize together with their classmates. Therefore, there is a need for learning media that can help students to learn and memorize with fun and interesting. The purpose of developing daily prayer learning media by utilizing Augmented Reality (AR) based flash card images is to make it easier for kindergarten students to learn more interesting and interactive prayers. The flash card is an AR marker that can be scanned through the application and brings up videos and 3D animations of daily prayer learning. That way, students become more interested in having interactive multimedia assistance. Media development is carried out with the waterfall method, which is preceded by the need analysis to trials application. Media testing was carried out by individual testing using a questionnaire with two aspects, namely software engineering aspects and visual communication aspects. Overall, media development is in accordance with user needs and can run well on the Android smartphone platform. Based on the results of the media expert's validation, this media was declared valid with a value of the software engineering aspect and the visual communication aspect of 86%. In the future, a large-scale trial will be conducted to determine the effectiveness of the learning implementation using this media. © 2020 IEEE.},
author_keywords={3d animation;  augmented reality;  daily prayer learning;  flashcard;  mobile learning},
keywords={Augmented reality;  Interactive computer systems;  Multimedia systems;  Software testing;  Visual communication, 3D animation;  Android smartphone;  Early childhoods;  Flash card;  Interactive multimedia;  Learning media;  Need analysis;  Waterfall methods, Students},
editor={Hermawan I., Rasyidin M., Huzaifa M., Ermis Ismail I., Muharram A.T., Mardiyono A., Marcheeta N., Kurniawati D., Yuly A.R., Suhanda A.A.},
publisher={Institute of Electrical and Electronics Engineers Inc.},
isbn={9781728182476},
language={English},
abbrev_source_title={Int. Conf. Comput. Informatics Eng., IC2IE},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Shen202046,
author={Shen, J. and Duraiswami, R.},
title={Data-driven feedback delay network construction for real-Time virtual room acoustics},
journal={ACM International Conference Proceeding Series},
year={2020},
pages={46-52},
doi={10.1145/3411109.3411145},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092159238&doi=10.1145%2f3411109.3411145&partnerID=40&md5=a2715803ebd47975cc853d785d8dc3ec},
affiliation={University of Maryland, Perceptual Interfaces and Reality Laboratory, College Park, MD, United States},
abstract={For virtual and augmented reality applications, it is desirable to render audio sources in the space the user is in, in real-Time without sacrificing the perceptual quality of the sound. One aspect of the rendering that is perceptually important for a listener is the late-reverberation, or "echo", of the sound within a room environment. A popular method of generating a plausible late reverberation in realtime is the use of Feedback Delay Networks (FDN). However, its use has the drawback that it first has to be tuned (usually manually) for a particular room before the late-reverberation generated becomes perceptually accurate. In this paper, we propose a data-driven approach to automatically generate a pre-Tuned FDN for any given room described by a set of room parameters. When combined with existing method for rendering the direct path and early reflections of a sound source, we demonstrate the feasibility of being able to render audio source in real-Time for interactive applications. © 2020 ACM.},
author_keywords={artificial reverberation;  augmented reality;  feedback delay network;  machine learning;  real-Time systems;  signal processing;  virtual acoustics;  virtual reality},
keywords={Audio acoustics;  Augmented reality;  Reverberation, Audio sources;  Data-driven approach;  Feedback delay;  Interactive applications;  Perceptual quality;  Room environment;  Virtual and augmented reality;  Virtual rooms, Architectural acoustics},
publisher={Association for Computing Machinery},
isbn={9781450375634},
language={English},
abbrev_source_title={ACM Int. Conf. Proc. Ser.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Wulandari2020,
author={Wulandari, R.A. and Hafidah, R. and Pudyaningtyas, A.R.},
title={The effect of augmented reality (AR) flashcard on early literacy of early childhood},
journal={ACM International Conference Proceeding Series},
year={2020},
doi={10.1145/3452144.3452246},
art_number={103},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107181140&doi=10.1145%2f3452144.3452246&partnerID=40&md5=afc41088f910e86a7a61b83cc7cfcc42},
affiliation={Early Childhood Education, Sebelas Maret University, Surakarta, Indonesia},
abstract={Early literacy for early childhood is important because it is related to reading provisions. This literation ability, should be owned by children at the age of 4-5 years. But the reality shows not all children have this ability. Some children still have difficulty recognizing the alphabet. These conditions need to get attention. This study aims to determine the effect of augmented reality (AR) flashcard media on early childhood literacy. The research design used quasi-experimental quantitative research with non-equivalent design. The research subjects were 24 children aged 4-5 years, which were divided into 2 groups, namely the experimental group and the control group. The experimental group used AR flashcard media that displays 3D images for early literacy learning, while the control group used 2D animation videos. Hypothesis testing used independent sample t-test with SPSS 22 for windows. The results showed that AR flashcard media had a greater influence on children's early literacy than 2D animated video media. This is evidenced by the more developed children's ability of early literacy in the experimental group than in the control group. The conclusion is AR flashcard media is a good media because of its superiority of insert an audio on 3D image that could explain a lot information and increase student's attractiveness. Children could see its shape, imitate it, and listen its name from displayed object. AR flashcard media was also a media with the use of ICT that could be delivered by guessing alphabet so that it became an interactive media and it could make that learning became fun for children. © 2020 ACM.},
author_keywords={AR flashcard;  Early childhood;  Early literacy},
keywords={Computer applications;  Computer programming, Experimental groups;  Hypothesis testing;  Independent samples;  Interactive media;  Literacy learning;  Quantitative research;  Research designs;  Research subjects, Augmented reality},
publisher={Association for Computing Machinery},
isbn={9781450375726},
language={English},
abbrev_source_title={ACM Int. Conf. Proc. Ser.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Yin2020,
author={Yin, X. and Hou, S. and Hu, H.},
title={Research on interactive design of social interaction training APP for children with autistic spectrum disorder (ASD) based on multi-modal interaction},
journal={E3S Web of Conferences},
year={2020},
volume={179},
doi={10.1051/e3sconf/202017902044},
art_number={02044},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089680937&doi=10.1051%2fe3sconf%2f202017902044&partnerID=40&md5=c21d8fb10d6588da020265ddd691124c},
affiliation={Harbin Institute of Techonology, Shenzhen, Shenzhen, China},
abstract={A number of studies have found that the difficulty in social interactive behaviors and recognize items are two core syndromes of Autistic Spectrum Disorder (ASD) children. Previous research has found that ASD children paid more attention to robots comparing to people.Intervention programs with robots as instructors or partners were also proved to be effective in improving ASD children's social skills.Yet, few studies find robot intervention works in ASD children training.So research explore the possibility of apply such intervention programs into product design.The present study aimed at involving an animated character of robot in an application (APP) of intervention program to facilitate ASD children's learning of social interactive skills.In order to achieve the goal, a training system based on sensory integration training was established by the design software of Sketch.Augmented Reality (AR) technology was used to create a multi-modal interactive environment of the APP.The present study is among the first attempt to apply sensory integration training in APP design, aiming at promoting social and cognitive performance in ASD children. © The Authors, published by EDP Sciences, 2020.},
keywords={Application programs;  Educational robots;  Machine design;  Product design;  Water resources, Autistic spectrum disorders;  Cognitive performance;  Interactive behavior;  Interactive Environments;  Intervention programs;  Multi-Modal Interactions;  Sensory integration;  Social interactions, Social robots},
correspondence_address1={Hou, S.; Harbin Institute of TechonologyChina; email: houshumeng@hit.edu.cn},
editor={Ghadouani A., Wu F.},
publisher={EDP Sciences},
issn={25550403},
language={English},
abbrev_source_title={E3S Web Conf.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Velaora2020110,
author={Velaora, M. and Van Roy, R. and Guena, F.},
title={ARtect, an augmented reality educational prototype for architectural design},
journal={Proceedings of the World Conference on Smart Trends in Systems, Security and Sustainability, WS4 2020},
year={2020},
pages={110-115},
doi={10.1109/WorldS450073.2020.9210302},
art_number={9210302},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095716169&doi=10.1109%2fWorldS450073.2020.9210302&partnerID=40&md5=d2209212535c96152301cdd0026b5009},
affiliation={Laboratory Map-Maacc École Nationale Supérieure d'Architecture de Paris-La Villette, Paris, France; Independent Researcher Informatics, Hjotronic Eindhoven, Netherlands},
abstract={ARtect is an Augmented Reality application developed with Unity 3D, which envisions an educational interactive and immersive tool for architects, designers, researchers, and artists. This digital instrument renders the competency to visualize custom-made 3D models and 2D graphics in interior and exterior environments. The user-friendly interface offers an accurate insight before the materialization of any architectural project, enabling evaluation of the design proposal. This practice could be integrated into learning architectural design process, saving resources of printed drawings, and 3D carton models during several stages of spatial conception. © 2020 IEEE.},
author_keywords={2d graphic;  3d models;  Application;  Architecture;  Augmented reality;  design;  Education},
keywords={Augmented reality;  Sustainable development;  User interfaces, 2D graphics;  Architectural projects;  Augmented reality applications;  Design proposal;  Immersive;  Saving resources;  User friendly interface, Architectural design},
editor={Yang X.-S., Fong S.J., Toapanta S.M., Andronache I., Phillips N.},
publisher={Institute of Electrical and Electronics Engineers Inc.},
isbn={9781728168234},
language={English},
abbrev_source_title={Proc. World Conf. Smart Trends Syst., Secur. Sustain., WS4},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Rane2020254,
author={Rane, A. and John, V.N. and Murthy, S.},
title={GeoMaps: An interactive application to enhance map comprehension skills of students},
journal={Proceedings - IEEE 20th International Conference on Advanced Learning Technologies, ICALT 2020},
year={2020},
pages={254-258},
doi={10.1109/ICALT49669.2020.00083},
art_number={9156000},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091163811&doi=10.1109%2fICALT49669.2020.00083&partnerID=40&md5=a454c1202467776b70d3c3b36599ecf9},
affiliation={Iit Bombay, IDP-Educational Technology, Mumbai, India},
abstract={Geography education requires the use of spatial thinking and reasoning to understand and interpret maps. Effective usage of geographical maps is a crucial skill to be developed for students. However, it has been found that students' ability to use maps to describe and analyze natural phenomena to find solutions to geographical problems is inadequate. One reason for this shortcoming is difficulty in comprehension of maps given in textbooks or reference books, which is preliminarily due to inherent limitations with paper-based maps. Sophisticated technology-based map applications are available like interactive maps, Augmented reality-based maps, 3D view maps, etc. But there are few learning activities around these, leaving the students confused as to how these can be used in different contexts to solve problems. GeoMaps is an interactive application to improve map comprehension skills of students, which includes ability to identify, correlate and synthesize information from multiple perspectives in a map. The activities in GeoMaps are based on authentic geography problems. To solve these problems, students can overlay multiple maps to correlate various features, and choose corresponding filters to focus on particular information. The preliminary feedback from potential users is promising, encouraging us to explore this idea at a broader context. © 2020 IEEE.},
author_keywords={Component;  Geography;  Interactive Maps;  Map comprehension skills;  Maps;  Spatial skills},
keywords={Augmented reality;  Interactive devices, Geographical maps;  Geography educations;  Inherent limitations;  Interactive applications;  Interactive maps;  Learning Activity;  Natural phenomena;  Spatial thinking, Students},
editor={Chang M., Sampson D.G., Huang R., Hooshyar D., Chen N.-S., Kinshuk K., Pedaste M.},
publisher={Institute of Electrical and Electronics Engineers Inc.},
isbn={9781728160900},
language={English},
abbrev_source_title={Proc. - IEEE Int. Conf. Adv. Learn. Technol., ICALT},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Hain2020,
author={Hain, A. and Motaref, S.},
title={Implementing interactive 3-d models in an entry level engineering course to enhance students' visualization},
journal={ASEE Annual Conference and Exposition, Conference Proceedings},
year={2020},
volume={2020-June},
art_number={825},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095789558&partnerID=40&md5=d6842aae9b8f272e34ac8a1dadd94db2},
affiliation={University of Connecticut, United States},
abstract={The ability to evaluate engineering elements, identify expected deformations, and predict possible failure mechanisms are critical skills for engineers. However, it has been observed that many undergraduate engineering students in applied mechanics courses struggle with applying these skills in engineering problems. Previous studies have shown that three-dimensional (3D) visualization can help students to improve spatial understanding, learn material more permanently and improve their creativity. In an attempt to build on this phenomenon, interactive 3D models using Augmented Reality (AR) were incorporated in a Mechanics of Materials course. This course is an entry level course and a major requirement for different engineering disciplines such as Civil, Mechanical, Biomedical, Materials Science, and Manufacturing Engineering. Two levels of learning were targeted in this study; applying and creating. For applying, 3D models were made available that could be viewed on a smartphone using an AR application or on a computer. The models were generated for problems that students in previous years found challenging or expressed difficulty in visualizing. Students were then encouraged to use this model to inform their problem solving. For creating, students were given the opportunity to generate 3D models based on textbook examples, indicate types of stresses and display deformed shapes. For both activities, student perceptions, best practices, and lessons learned are noted. Students were also asked to provide feedback about their experience and the effectiveness of AR models in their learning in class evaluation surveys. To evaluate the effect of using 3D models on students' performance, an independent study was conducted with students in the Mechanics of Materials course. In this two-problem study, one group only had access to a traditional two-dimensional (2D) schematic, while the other group had access to a 3D model. The experimental and control groups were then swapped for the second problem. The results of this initial study revealed that 3D models can significantly improve students' performance. It is anticipated that discussing the benefits and challenges associated with incorporating such activities, along with providing suggestions for incorporation, will help other institutions add similar activities to their engineering courses in an effort to improve student learning. © American Society for Engineering Education 2020.},
keywords={3D modeling;  Augmented reality;  Engineering education;  Failure (mechanical);  Mechanics;  Mechanisms;  Students;  Technical presentations;  Visualization, Engineering disciplines;  Engineering problems;  Interactive 3-D models;  Manufacturing engineering;  Mechanics of materials;  Three dimensional (3D) visualization;  Two Dimensional (2 D);  Undergraduate engineering students, Three dimensional computer graphics},
publisher={American Society for Engineering Education},
issn={21535965},
language={English},
abbrev_source_title={ASEE Annu. Conf. Expos. Conf. Proc.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Zhang2020,
author={Zhang, Y. and Liu, T. and Zhu, Y. and Yang, Y.},
title={A Deep Reinforcement Learning Approach for Online Computation Offloading in Mobile Edge Computing},
journal={2020 IEEE/ACM 28th International Symposium on Quality of Service, IWQoS 2020},
year={2020},
doi={10.1109/IWQoS49365.2020.9212868},
art_number={9212868},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094828688&doi=10.1109%2fIWQoS49365.2020.9212868&partnerID=40&md5=c424d346bdd77fe0c89beac2d000bb5a},
affiliation={School of Computer Engineering and Science, Shanghai University, China; Shanghai Engineering Research, Center of Intelligent Computing System, China; Department of Computer Science and Engineering, Shanghai Jiao Tong University, China; Department of Electrical and Computer Engineering, Stony Brook University, United States},
abstract={With the explosion of mobile smart devices, many computation intensive applications have emerged, such as interactive gaming and augmented reality. Mobile edge computing is put forward, as an extension of cloud computing, to meet the low-latency requirements of the applications. In this paper, we consider an edge computing system built in an ultra-dense network with numerous base stations, and heterogeneous computation tasks are successively generated on a smart device moving in the network. An optimal task offloading strategy, as well as optimal CPU frequency and transmit power scheduling, is desired by the device user, to minimize both task completion latency and energy consumption in a long-term. However, due to the stochastic computation tasks and dynamic network conditions, the problem is particularly difficult to solve. Inspired by reinforcement learning, we transform the problem into a Markov decision process. Then, we propose an online offloading approach based on a double deep Q network, in which a specific neural network model is also provided to estimate the cumulative reward achieved by each action. We also conduct extensive simulations to compare the performance of our proposed approach with baselines. © 2020 IEEE.},
author_keywords={computation offloading;  deep reinforcement learning;  Mobile edge computing;  ultra-dense network},
keywords={Augmented reality;  E-learning;  Edge computing;  Energy utilization;  Markov processes;  Quality of service;  Reinforcement learning;  Stochastic systems, Computation intensives;  Extensive simulations;  Heterogeneous computation;  Markov Decision Processes;  Mobile smart devices;  Neural network model;  Reinforcement learning approach;  Stochastic computations, Deep learning},
publisher={Institute of Electrical and Electronics Engineers Inc.},
isbn={9781728168876},
language={English},
abbrev_source_title={IEEE/ACM Int. Symp. Qual. Serv., IWQoS},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Wang2020301,
author={Wang, G. and Lu, Z. and Zhang, Y. and Qian, Y. and Zhao, H. and Liu, D.},
title={Application of mixed reality technology in education with the case of a huangmei opera cultural education system},
journal={Proceedings of 2nd International Conference on Computer Science and Educational Informatization, CSEI 2020},
year={2020},
pages={301-305},
doi={10.1109/CSEI50228.2020.9142502},
art_number={9142502},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092451279&doi=10.1109%2fCSEI50228.2020.9142502&partnerID=40&md5=312a3f58ad9b279ea76bbaa49c99feae},
affiliation={University Key Laboratory of Intelligent Perception and Computing of Anhui Province, Anqing Normal University, Anqing, China; Institute of Network Technology, Beijing University of Posts and Telecommunications, Beijing, China; School of Computer and Information, Anqing Normal University, Anqing, China; Mobile Media and Cultural Calculation Key Laboratory of Beijing, Century College, Beijing University of Posts and Telecommunications, Beijing, China},
abstract={Mixed reality is an emerging technology that allows virtual world objects and real world objects to coexist and interact in real time. Its positioning lies between virtual reality and augmented reality, providing users with an immersive experience of combining virtual and real. In this article, we take the Huangmei Opera cultural educational system as an example, and use the current mainstream mixed reality hardware platform and its supporting content production softwares to implement interactive games and virtual museums about Huangmei Opera culture and knowledge. And to explore the application of mixed reality in education. © 2020 IEEE.},
author_keywords={Cultural Education;  Hololens;  Huangmei opera;  Mixed Reality;  Unity;  Virtual museum},
keywords={Augmented reality;  User experience, Content production;  Cultural education;  Educational systems;  Emerging technologies;  Hardware platform;  Interactive games;  Mixed reality technologies;  Real-world objects, Mixed reality},
correspondence_address1={Lu, Z.; Institute of Network Technology, China; email: bathur@163.com},
publisher={Institute of Electrical and Electronics Engineers Inc.},
isbn={9781728170077},
language={English},
abbrev_source_title={Proc. Int. Conf. Comput. Sci. Educ. Informatiz., CSEI},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Kruger202078,
author={Kruger, J.M. and Bodemer, D.},
title={Different Types of Interaction with Augmented Reality Learning Material},
journal={Proceedings of 6th International Conference of the Immersive Learning Research Network, iLRN 2020},
year={2020},
pages={78-85},
doi={10.23919/iLRN47897.2020.9155148},
art_number={9155148},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091673088&doi=10.23919%2fiLRN47897.2020.9155148&partnerID=40&md5=ef199ad33d5ad1078b05d42a4aa4c9ea},
affiliation={University of Duisburg-Essen, Media-based Knowledge Construction, Duisburg, Germany},
abstract={In this paper, a study with the focus on interactivity in augmented reality (AR) applications concerning the influence of different forms of interaction with AR learning material is presented. While research on multimedia learning often distinguishes between mental and physical interaction with learning material, other research fields state that physical interaction is necessary to interact mentally. To look at how this distinction may play a role in AR-based learning material, an experimental study with a 2x2 design manipulating mental and physical interaction was conducted, including learning material on the topic of power plants. The data (N = 128) were collected and analyzed, showing that, although not expected, learning was better in groups in which either more physical or more mental interaction was applied, but not in groups in which both were high. The results are discussed under the potential idea of cognitive overload. © 2020 Immersive Learning Research Network.},
author_keywords={augmented reality;  interactive learning;  interactivity;  multimedia learning;  technology-enhanced learning},
keywords={Cognitive overload;  Interactivity;  Learning materials;  Multi-media learning;  Physical interactions;  Reality learning;  Research fields, Augmented reality},
editor={Economou D., Klippel A., Dodds H., Pena-Rios A., Lee M.J.W., Beck D., Pirker J., Dengel A., Peres T.M., Richter J.},
publisher={Institute of Electrical and Electronics Engineers Inc.},
isbn={9781734899504},
language={English},
abbrev_source_title={Proc. Int. Conf. Immersive Learn. Res. Netw., iLRN},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Dewi2020,
author={Dewi, S.P. and Astuti, I.P. and Buntoro, G.A. and Widaningrum, I. and Yusuf, A.R.},
title={Android based learning application for Wudhu and Tayamum using augmented reality technology},
journal={Journal of Physics: Conference Series},
year={2020},
volume={1517},
number={1},
doi={10.1088/1742-6596/1517/1/012068},
art_number={012068},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086392254&doi=10.1088%2f1742-6596%2f1517%2f1%2f012068&partnerID=40&md5=01e2b608ad58fdf665693df2f7248f3c},
affiliation={Department of Informatics Engineering, Universitas Muhammadiyah Ponorogo, Ponorogo, Indonesia},
abstract={Nowadays, wudhu and tayamum are widely found in various media such as books, articles, tutorial videos and internet. Muslims who are new to Islam as children often have difficulty reading books to understand how to learn and practice tayamum, one of the lessons learned in technology development using Augmented Reality based learning. The learning method used in Augmented Reality is the marker method. The marker method step is that the program will read an object from the image marker, the marker uses a downloadable image by clicking the Download Marker button in the main menu, and then it will be displayed as a moving object or an output in the data. This app is implemented for Android-based smartphones, with the help of Blender 3D and Unity 3D software. The results of the questionnaire count conclude that augmented reality learning media applications are easy to use, practical, useful, and effective in supporting children's learning activities as children become more engaged in learning. The attractive interface design makes kids feel comfortable and engaging as they use it and develop their understanding. In addition, this application is also used as an interactive learning medium. © 2019 Published under licence by IOP Publishing Ltd.},
keywords={Android (operating system);  Application programs;  Augmented reality;  Computer aided instruction, Augmented reality technology;  Interactive learning;  Interface designs;  Learning Activity;  Learning methods;  Moving objects;  Reality learning;  Technology development, Learning systems},
editor={Setiyo M., Pranolo A., Pambuko Z.B., Setiawan A., Praja C.B.E., Yuliastuti F., Dewi V.S.},
publisher={Institute of Physics Publishing},
issn={17426588},
language={English},
abbrev_source_title={J. Phys. Conf. Ser.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Elivera2020,
author={Elivera, A. and Palaoag, T.},
title={Development of an Augmented Reality Mobile Application to Enhance the Pedagogical Approach in Teaching History},
journal={IOP Conference Series: Materials Science and Engineering},
year={2020},
volume={803},
number={1},
doi={10.1088/1757-899X/803/1/012014},
art_number={012014},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086383743&doi=10.1088%2f1757-899X%2f803%2f1%2f012014&partnerID=40&md5=b0ddbee3bcae1cedce2db79ab78a835c},
affiliation={Eastern Samar State University, Guiuan, Eastern Samar, Philippines; University of the Cordilleras, Baguio City, Philippines},
abstract={The rapid advancement of technology nowadays opens new opportunities for schools and universities worldwide to improve the quality of teaching and learning experience using Augmented Reality can help make classes more interactive and allow learners to focus more on practice instead of just theories. The researcher identified the problem that pedagogy has not been learner-cantered in most approaches in teaching and that teachers need to adapt to the new method of teaching. The goal of the study is to develop an Augmented Reality (AR) mobile application to enhance the pedagogical approach in teaching. This will use a marker-based method for transmitting virtual objects into the realworld. Blippar was used in the development of AR. This resulted in the form of instructional material and technology that can be used in teaching. During the testing of the material Students' interest was aroused and it even makes them more eager to learn the subject. End-users and experts also deem that the AR mobile application as usable and acceptable with a rating of 78% using the System Usability Scale (SUS). This is an excellent contribution to the educational domain through augmented reality and improving the pedagogical approach in teaching. © Published under licence by IOP Publishing Ltd.},
editor={Hidayat T., Idris M., Rahma F.},
publisher={Institute of Physics Publishing},
issn={17578981},
language={English},
abbrev_source_title={IOP Conf. Ser. Mater. Sci. Eng.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Kenoui2020260,
author={Kenoui, M. and Mehdi, M.A.},
title={Teach-Me DNA: An interactive course using voice output in an augmented reality system},
journal={CCSSP 2020 - 1st International Conference on Communications, Control Systems and Signal Processing},
year={2020},
pages={260-265},
doi={10.1109/CCSSP49278.2020.9151605},
art_number={9151605},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089956397&doi=10.1109%2fCCSSP49278.2020.9151605&partnerID=40&md5=520a5e58e0a8d68ab762db46e27e2306},
affiliation={CDTA Centre de Développement des Technologies Avancées, Telecom Department, Algiers, Algeria; USTHB Université des Sciences et de la Technologie, Informatics Department, Algiers, Algeria},
abstract={In this paper, we present an interactive system partly based on voice output in an augmented reality environment. Using a chatbot technology, this system allows the user to engage bidirectional communication with a conversational agent. The present system builds upon our previous work in which the user interacts with 3D virtual objects via voice commands. We describe, in the current document, how we integrate speech output using the Text to Speech Service (TTS API) available on the IBM Watson platform, the goal being to obtain an even more interactive system. We also employ Speech Synthesis Markup Language (SSML) to control some features of the natural-sounding speech thus produced. Moreover, we developed Teach-Me DNA, an interactive application that gives the user (pupil, student) the opportunity to learn and/or revise the DNA molecule's basics as a part of a biological course. On one hand, and via voice inputs the user is simply able to perform 3D selections and 3D manipulations of the molecule and its several components in order to learn about their 3D features and properties, this first part dealing with the vocal entries was fully documented in a previous work. On another hand, TeachMe DNA is here enriched by producing a natural speech when reacting to the user's requests. In fact, an agent's voice is used to respond in real time to student's questions. Definitions and/or explanations are thus given in a very natural way which might immerse more significantly the student in the proposed learning environment based on augmented reality technology. © 2020 IEEE.},
author_keywords={Augmented Reality;  Biomedical Course;  Chatbot;  Cloud Application;  Education;  HCI;  IBM Watson;  Natural Interaction;  Pedagogical Agent;  Speech Recognition;  Voice Output},
keywords={Augmented reality;  Computer aided instruction;  Control systems;  DNA;  Markup languages;  Speech synthesis;  Students;  Teaching, Augmented reality systems;  Augmented reality technology;  Bi-directional communication;  Conversational agents;  Interactive applications;  Interactive system;  Learning environments;  Speech synthesis markup languages, Signal processing},
publisher={Institute of Electrical and Electronics Engineers Inc.},
isbn={9781728158358},
language={English},
abbrev_source_title={CCSSP - Int. Conf. Commun., Control Syst. Signal Process.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Perez-Munoz2020,
author={Perez-Munoz, A. and Castro-Idrovo, D. and Robles-Bykbaev, Y. and Robles-Bykbaev, V. and Pesantez-Aviles, F.},
title={An interactive application based on augmented reality and rules-based reasoning to support educational activities of high school students},
journal={EDUNINE 2020 - 4th IEEE World Engineering Education Conference: The Challenges of Education in Engineering, Computing and Technology without Exclusions: Innovation in the Era of the Industrial Revolution 4.0, Proceedings},
year={2020},
doi={10.1109/EDUNINE48860.2020.9149526},
art_number={9149526},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091074010&doi=10.1109%2fEDUNINE48860.2020.9149526&partnerID=40&md5=9cc04e86b97c6b75281e85815ef3f122},
affiliation={Universidad Politécnica Salesiana, GI-IATa, Cátedra UNESCO Tecnologías de Apoyo Para la Inclusión Educativa, Cuenca, Ecuador},
abstract={According to the latest estimates of the United Nations Educational, Scientific and Cultural Organization (UNESCO), in 2017, more than 617 million children and adolescents were not achieving minimum proficiency levels regarding reading and mathematics. In this line, it is essential for children and youth developing mainstays for solving problems and adequately understanding the information around them. These mainstays are strongly related to logical and mathematical skills. Therefore, in this paper, we present an educational tool that uses augmented reality to provide interactive exercises for the following areas: functions, areas, volumes, angles, and the Pythagorean theorem. Similarly, our proposal incorporates a decision support system that suggests to a given student what activities and exercises must solve. The validation process of the tools was carried out with the support of 179 volunteers. © 2020 IEEE.},
author_keywords={Augmented reality;  Children and youth;  Mathematics;  Support Decision System},
keywords={Augmented reality;  Computation theory;  Decision support systems;  Engineering education, Children and adolescents;  Educational activities;  High school students;  Interactive applications;  Interactive exercise;  Pythagorean theorem;  United Nations educational , Scientific and Cultural Organization;  Validation process, Students},
editor={da Rocha Brito C., Ciampi M.M.},
publisher={Institute of Electrical and Electronics Engineers Inc.},
isbn={9781728166384},
language={English},
abbrev_source_title={EDUNINE - IEEE World Eng. Educ. Conf.: Challenges Educ. Eng., Comput. Technol. Exclusions: Innov. Era Ind. Revolut. 4.0, Proc.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Bakkiyaraj20202464,
author={Bakkiyaraj, M. and Kavitha, G. and Sai Krishnan, G. and Kumar, S.},
title={Impact of Augmented Reality on learning Fused Deposition Modeling based 3D printing Augmented Reality for skill development},
journal={Materials Today: Proceedings},
year={2020},
volume={43},
pages={2464-2471},
doi={10.1016/j.matpr.2021.02.664},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104229671&doi=10.1016%2fj.matpr.2021.02.664&partnerID=40&md5=efb8123cfae09679e8b2202ffc4db8db},
affiliation={Rajalakshmi Institute of Technology, Chennai, India; Rajalakshmi Engineering College, Chennai, India},
abstract={The aim of this study is to evaluate the impact of various modes of Augmented Reality (AR) in learning the skills associated with a 3D printing technology called Fused Deposition Modeling (FDM). Three versions of an AR application named ED-AR (Educational-AR) are created using the software: Unity 3D engine and Vuforia engine. Each version contains different levels of augmentation like meret extual instructions, demonstration videos and interactive 3D (three dimensional) model simulations. Batches of students from different engineering disciplines are exposed to self-learning using the different versions of the developed application. The results show that the version with interactive simulations helped the students to learn the 3D printing skills effectively at a faster rate and also permitted good retention of the learned procedure. © 2020 Elsevier Ltd.},
author_keywords={3D printing;  Augmented Reality;  Fused Deposition Modeling;  Industry 4.0;  Learning 4.0;  Self-learning;  Unity 3D;  Vuforia},
editor={Saravanan I.},
publisher={Elsevier Ltd},
issn={22147853},
language={English},
abbrev_source_title={Mater. Today Proc.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Kuts2020,
author={Kuts, V. and Otto, T. and Bondarenko, Y. and Yu, F.},
title={Digital twin: Collaborative virtual reality environment for multi-purpose industrial applications},
journal={ASME International Mechanical Engineering Congress and Exposition, Proceedings (IMECE)},
year={2020},
volume={2B-2020},
doi={10.1115/IMECE2020-23390},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101232023&doi=10.1115%2fIMECE2020-23390&partnerID=40&md5=3604d7dcd371aad42593df7328ef5df5},
affiliation={Tallinn University of Technology, Department of Mechanical and Industrial Engineering, Tallinn, Estonia; University of Southern Denmark, Mads Clausen Institute, Sønderborg, Denmark},
abstract={Industrial Digital Twins (DT) is the precise virtual representation of the manufacturing environment and mainly consists of the system-level simulation, which combines both manufacturing processes and parametric models of the product. As being one of the pillars of the Industry 4.0 paradigm, DT-s are widely integrated into the existing factories, enhancing the concept of the virtual factories. View from the research perspective is that experiments on the Internet of Things, data acquisition, cybersecurity, telemetry synchronization with physical factories, etc. are being executed in those virtual simulations. Moreover, new ways of interactions and interface to oversee, interact and learn are being developed via the assistance of Virtual Reality (VR) and Augmented Reality (AR) technologies, which are already widely spread on the consumer market. However, already, VR is being used widely in existing commercial software packages and toolboxes to provide students, teachers, operators, engineers, production managers, and researchers with an immersive way of interacting with the factory while the manufacturing simulation is running. This gives a better understanding and more in-depth knowledge of the actual manufacturing processes, not being directly accessing those. However, the virtual presence mentioned above experience is limited to a single person. It does not enable additional functionalities for the simulations, which can be re-planning or even re-programming of the physical factory in an online connection by using VR or AR interfaces. The main aim of the related research paper is to enhance already existing fully synchronized with physical world DT-s with multi-user experience, enabling factory operators to work with and reprogram the real machinery from remote locations in a more intuitive way instead thinking about final aim than about the process itself. Moreover, being developed using real-time platform Unity3D, this multiplayer solution gives opportunities for training and educational purposes and is connecting people from remote locations of the world. Use-cases exploits industrial robots placed in the Industrial Virtual and Augmented Reality Laboratory environment of Tallinn University of Technology and a mobile robot solution developed based on a collaboration between the University of Southern Denmark and a Danish company. Experiments are being performed on the connection between Estonia and Denmark while performing reprogramming tasks of the physical heavy industrial robots. Furthermore, the mobile robot solution is demonstrated in a virtual warehouse environment. Developed methods and environments together with the collected data will enable us to widen the use-cases with non-manufacturing scenarios, i.e., smart city and smart healthcare domains, for the creation of a set of new interfaces and multiplayer experiences. © 2020 The Author(s). This is an Open Access article under the CC BY license.},
author_keywords={Collaboration;  Digital twins;  Industry 4.0;  Multiplayer;  Virtual reality},
keywords={Augmented reality;  Computer software;  Data acquisition;  Digital twin;  Engineering education;  Engineering research;  Industrial robots;  Machinery;  Manufacture;  Mobile robots;  Security of data;  User experience, Collaborative virtual reality environments;  Laboratory environment;  Manufacturing environments;  Manufacturing process;  Manufacturing simulation;  System level simulation;  Virtual and augmented reality;  Virtual representations, Virtual reality},
publisher={American Society of Mechanical Engineers (ASME)},
isbn={9780791884492},
language={English},
abbrev_source_title={ASME Int Mech Eng Congress Expos Proc},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Lee2020,
author={Lee, N. and De Clunie, G.T.},
title={Augmented reality in education: Panama's food guides},
journal={ACM International Conference Proceeding Series},
year={2020},
volume={Part F166737},
doi={10.1145/3401895.3402066},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100507110&doi=10.1145%2f3401895.3402066&partnerID=40&md5=6ad60429fc9297a82b17752cdf677ba3},
affiliation={Universidad Tecnológica de Panamã, Panamã, Panama},
abstract={Augmented reality is part of technological used with the purpose of creating innovative applications that, among others, improve people's well-being. In this paper we describe the use of augmented reality in an application for mobile devices, aimed at improving the teaching and learning of healthy food consumption in the Panamanian population. For the development of the application, the food guides developed by the Ministry of Health of the Republic of Panama were considered, so that the application provides a new way of teaching, learning, and viewing the content of the food guides. © 2020 ACM.},
author_keywords={3d design;  augmented reality;  food guides;  health;  interactive systems;  mobile devices;  virtual objects},
keywords={Food supply, Healthy foods;  Teaching and learning;  Well being, Augmented reality},
publisher={Association for Computing Machinery},
isbn={9781450377119},
language={English},
abbrev_source_title={ACM Int. Conf. Proc. Ser.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Haryani202052,
author={Haryani, P. and Triyono, J.},
title={The designing of interactive learning media at Yogyakarta’s sandi museum based on augmented reality},
journal={International Journal on Informatics Visualization},
year={2020},
volume={4},
number={1},
pages={52-57},
doi={10.30630/joiv.4.1.157},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099069700&doi=10.30630%2fjoiv.4.1.157&partnerID=40&md5=590426afe9210a77c215c5e2ab52a67c},
affiliation={Faculty of Industrial Technology, Institut Sains dan Teknologi AKPRIND, Yogyakarta, Indonesia},
abstract={Sandi Museum is one of museums that exhibits various collections of historical code in the forms of realia, replica, machine, picture and document related to codes. As the information sources of national cultural wealth, the existence of Sandi museum has not been visited by the tourists yet. It is because of the lack of museum promotion to community. Besides that, there is a stigma of community that museum is only the place to store the historical goods, therefore, the community activities when visiting the museum tend to be passive, in which they only look around the collections of historical goods without any interactions happened in visiting the museum. In order to get attraction of tourists when they are visiting the Sandi museum, the museum’s officials are able to use the interactive learning media based on the technology of Augmented Reality in introducing Sandi museum. The visitors are able to visualize the object or historical good in 3 dimension (3-D) which is real time. The museum introduction based on Augmented Reality enables visitors to be able to interact with the objects or the historical goods through intuitive and interesting way. In this research, it is going to make AR-Sandi application as the information media to introduce Sandi museum to the community. The research approach used is research and development approach with the development model of waterfall. The Model of waterfall consists of five phases, namely analysis, design, implementation, testing and maintenance. The result of the research is that the application of AR-Sandi has been successfully developed in accordance to the methodology of waterfall. Based on the acceptance testing of AR-Sandi application with the framework of TAM (Technology Acceptance Method) towards 30 visitors of Sandi museum, it is obtained that the majority of visitors agrees, the AR-Sandi application is acceptable by the users, it has functionality and work performance well. © 2020, Politeknik Negeri Padang. All rights reserved.},
author_keywords={Augmented reality;  Functionality;  Interactive learning media;  Performance;  Technology Acceptance Method;  User acceptance;  Waterfall},
correspondence_address1={Haryani, P.; Faculty of Industrial Technology, Indonesia; email: pritaharyani@akprind.ac.id},
publisher={Politeknik Negeri Padang},
issn={25499904},
language={English},
abbrev_source_title={Int. J. Inform. Vis.},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Ivaschenko2020,
author={Ivaschenko, A.V. and Sitnikov, P.V. and Diyazitdinova, A.R.},
title={Accented visualization application in interactive manuals for technical training and support},
journal={Journal of Physics: Conference Series},
year={2020},
volume={1691},
number={1},
doi={10.1088/1742-6596/1691/1/012122},
art_number={012122},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098089909&doi=10.1088%2f1742-6596%2f1691%2f1%2f012122&partnerID=40&md5=be69950452a33a57d260ba14d3bb7f96},
affiliation={Samara State Technical University, Molodogvardeyskaya str. 244, Samara, Russian Federation; Povolzhskiy State University of Telecommunications and Informatics, L Tolstogo str. 23, Samara, Russian Federation},
abstract={The capabilities of modern information and communication devices (tablets, glasses, helmets, etc.) that provide user interfaces with Augmented Reality (AR) are successfully used in education and maintenance support nowadays. The main benefits are concerned with the possibility to display the required information in the context of operations performed by the user. Technically it is implemented in the form of textual hints or visual 3D objects with highly realistic appearance and behavior. New features prompt new challenges: The user can be easily overloaded with lots of information, and some real objects that require user's attention can be overlapped by virtual ones in one scene. In order to solve this problem and improve the usability and effectiveness of AR devices application in maintenance and education it is proposed to build adaptive user interfaces that consider the context and focus of the user. From information technology perspective this approach forms a promising area of application of high-potential technologies including machine learning and computer vision. In this paper there is presented an example of AR implementation as a part of an interactive manual, which provides adaptation and personalization based on the concept of accented visualization. Identification of objects and their classification is implemented using the artificial neural network. © Published under licence by IOP Publishing Ltd.},
keywords={Augmented reality;  Engineering education;  Neural networks;  Visualization, Adaptive user interface;  Appearance and behavior;  High potential;  Information and communication;  Maintenance supports;  Personalizations;  Technical training;  Visualization application, User interfaces},
correspondence_address1={Ivaschenko, A.V.; Samara State Technical University, Molodogvardeyskaya str. 244, Russian Federation; email: anton.ivashenko@gmail.com},
publisher={IOP Publishing Ltd},
issn={17426588},
language={English},
abbrev_source_title={J. Phys. Conf. Ser.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Bremner202077,
author={Bremner, L. and Fabricatore, C. and Jolliffe, J.},
title={A framework system for the design of a digital augmented-reality pretend play activity for children with ASD},
journal={Proceedings of the 14th International Conference on Game Based Learning, ECGBL 2020},
year={2020},
pages={77-86},
doi={10.34190/GBL.20.113},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097793044&doi=10.34190%2fGBL.20.113&partnerID=40&md5=6607a1fdaf9fb32c331896a61a3b4f23},
affiliation={University of Huddersfield, United Kingdom},
abstract={Pretend play is a key educational strategy for children with Autism Spectrum disorder (ASD). Pretend play interventions lead to improvements including social skills and theory of mind. Prior research has shown benefits of using digital technologies to enhance pretend play, thereby improving skills. This article presents a framework system to support the design of augmented reality pretend play activities. The framework system emerged from a user-centred design process (with proxy users) to meet the complex developmental needs and heterogeneity of children with ASD. The system is aimed at promoting social conversation and theory of mind. It consists of an augmented-reality interactive game using features of the technology to help the child roleplay, complemented by an adult support application. The child is engaged in roleplay through embodying a character, contextualised within a familiar story. The support application allows an adult to monitor, guide and stimulate the child's progress through participating in the activity. The design process comprised of observations, interviews and focus groups with proxy users, involving three schools who provided participants for the focus groups. Individuals with relevant expertise were independently recruited for the interviews. The proposed system presents a novel opportunity to enhance pretend play by leveraging the unique features of augmented reality technologies and can serve as a reference for developing similar products. © ECGBL 2020.All right reserved.},
author_keywords={Augmented-reality;  Autism;  Game-based learning;  Pretend play;  User-centred design},
keywords={Augmented reality, Augmented reality technology;  Children with autisms;  Digital technologies;  Educational strategy;  Interactive games;  Social conversations;  Theory of minds;  Unique features, User centered design},
editor={Fotaris P.},
publisher={Academic Conferences International },
isbn={9781912764716},
language={English},
abbrev_source_title={Proc. Int. Conf. Game Based Learn., ECGBL},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Lin2020398,
author={Lin, Y.-J.},
title={A Study on Framework Development and Augmented Reality Technological Factors Consumers’ Evaluation for Cultural and Creative Products},
journal={Communications in Computer and Information Science},
year={2020},
volume={1294},
pages={398-405},
doi={10.1007/978-3-030-60703-6_51},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097231739&doi=10.1007%2f978-3-030-60703-6_51&partnerID=40&md5=50bf8df50269afc8bf13223e268b8d71},
affiliation={Department of Commercial Design and Management, National Taipei University of Business, Taoyuan, 32462, Taiwan},
abstract={Following the rapid development of high-technology industries, digital applications have been applied in various technologies, bringing people a whole new daily living experience. Interactive technology has led to breakthrough innovations. Application of augmented reality (AR), in addition to people’s approaches to interact with the physical world, has changed industry owners’ methods in designing products. This reveals the criticality of designing products with AR technology and new forms of interactions. This study investigated the current status regarding the cultural and creative products in consumer markets and the effectiveness of incorporating AR technology into cultural and creative product design courses. Data were analyzed to clarify said effectiveness and confirm the feasibility of AR technology in cultural and creative product design. A survey was performed on the cultural and creative products in the National Palace Museum located in Taipei and those designed by university students majoring in design to explore the effect of AR technology employed in cultural and creative product design on consumers’ review of and purchase intentions for the products. The following conclusion was reached: (1) The scale constructed to evaluate the cultural and creative products designed using AR technology was feasible. (2) AR technology positively affected participants’ review of and purchase intentions for cultural and creative products. (3) The products created by students according to the teaching method employed exhibited business value of high interactivity. Future cultural and creative product design courses can employ AR technology in their principles and practices in training innovative talents that satisfy the market demand. The design principles developed thereof can also serve as a reference for industry owners in designing cultural and creative products. © 2020, Springer Nature Switzerland AG.},
author_keywords={Augmented reality (AR);  Cultural and creative product design;  Evaluation;  Purchase intention},
keywords={Augmented reality;  Commerce;  Curricula;  Engineering education;  Human computer interaction;  Purchasing;  Teaching, Breakthrough innovations;  Digital applications;  Framework development;  High technology industries;  Interactive technology;  Principles and practices;  Technological factors;  Various technologies, Product design},
correspondence_address1={Lin, Y.-J.; Department of Commercial Design and Management, Taiwan; email: naralin@ntub.edu.tw},
editor={Stephanidis C., Antona M., Ntoa S.},
publisher={Springer Science and Business Media Deutschland GmbH},
issn={18650929},
isbn={9783030607029},
language={English},
abbrev_source_title={Commun. Comput. Info. Sci.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Bremner202077,
author={Bremner, L. and Fabricatore, C. and Jolliffe, J.},
title={A framework system for the design of a digital augmented-reality pretend play activity for children with ASD},
journal={Proceedings of the European Conference on Games-based Learning},
year={2020},
volume={2020September},
pages={77-86},
doi={10.34190/GBL.20.113},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096709230&doi=10.34190%2fGBL.20.113&partnerID=40&md5=c33763c699aaa3191a04e609e9140a94},
affiliation={University of Huddersfield, United Kingdom},
abstract={Pretend play is a key educational strategy for children with Autism Spectrum disorder (ASD). Pretend play interventions lead to improvements including social skills and theory of mind. Prior research has shown benefits of using digital technologies to enhance pretend play, thereby improving skills. This article presents a framework system to support the design of augmented reality pretend play activities. The framework system emerged from a user-centred design process (with proxy users) to meet the complex developmental needs and heterogeneity of children with ASD. The system is aimed at promoting social conversation and theory of mind. It consists of an augmented-reality interactive game using features of the technology to help the child roleplay, complemented by an adult support application. The child is engaged in roleplay through embodying a character, contextualised within a familiar story. The support application allows an adult to monitor, guide and stimulate the child's progress through participating in the activity. The design process comprised of observations, interviews and focus groups with proxy users, involving three schools who provided participants for the focus groups. Individuals with relevant expertise were independently recruited for the interviews. The proposed system presents a novel opportunity to enhance pretend play by leveraging the unique features of augmented reality technologies and can serve as a reference for developing similar products. © 2020 Dechema e.V.. All rights reserved.},
author_keywords={Augmented-reality;  Autism;  Game-based learning;  Pretend play;  User-centred design},
keywords={Augmented reality, Augmented reality technology;  Children with autisms;  Digital technologies;  Educational strategy;  Interactive games;  Social conversations;  Theory of minds;  Unique features, User centered design},
editor={Fotaris P.},
publisher={Dechema e.V.},
issn={20490992},
isbn={9781912764716},
language={English},
abbrev_source_title={Proc. European Conf. Games-based Learn.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Cristea202092,
author={Cristea, D.S. and Rusu, C.C. and Mistodie, L.R. and Ivanov, M. and Leontin, A.},
title={Immersive data analytics for enhancing organisational knowledge transfer processes through a custom developed virtual reality framework},
journal={eLearning and Software for Education Conference},
year={2020},
pages={92-100},
doi={10.12753/2066-026X-20-097},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096497931&doi=10.12753%2f2066-026X-20-097&partnerID=40&md5=0f6fe1ccb533535691d1258b52874aba},
affiliation={University ‘Dunărea de Jos’, Str. Domnească 47, Galati, Romania; S.C. ALTFACTOR SRL, Str. Domnească 47, Galati, Romania},
abstract={During the past years, virtual reality (VR) and augmented reality (AR) improved a lot from both accessibility and hardware capabilities perspectives. Currently, this type of software applications is encouraged to be part of various domains. This paper presents how virtual reality technologies can provide a novel, immersive, approach of one of the most used data science tasks, respectively data analytics, that can be used to enhance the effectiveness of the organizational knowledge transfer. Knowledge transfer, a process used in various industries including education, business, social and technology, plays an important role in the overall learning process, introducing new ways of sharing resources and people experience. As a data scientist, it is usually said that about 80% of the time will be used doing EDA (exploratory data analytics scenarios). Our research targeted the enhancement of organizational knowledge transfer processes by using immersive EDA. Our paper emphasizes the fact that VR offers extended possibilities for sustaining data analytics strategies, improving them with a new immersive perspective. Virtual learning environments can be used to build skills and one challenge for virtual reality, when applied in education or training, is to assess Virtual Environments effectiveness. Immersive data analytics can ease the effort of quantifying how effective a specific virtual scenario was for a group of users. The presented study also emphasises on how VR technologies can provide more detailed immersive analytics that can be used in optimizing knowledge transfer and implicitly learning processes, by potentially analysing every move of the learners, assessing the evolution of the user learning/performance, respectively understanding user reaction speed (response times) in various contexts similar to real world scenarios. Also, through immersive analytics, it is possible to determine learners emotional state and their level of attention, being possible to provide a more personalised interactive experience for enhancing learning efficiency. © 2020, National Defence University - Carol I Printing House. All rights reserved.},
author_keywords={Data science;  E-learning;  Immersive data analytics;  Knowledge transfer;  Virtual reality},
editor={ROCEANU I.},
publisher={National Defence University - Carol I Printing House},
issn={2066026X},
language={English},
abbrev_source_title={eLearning Softw. Educ. Conf.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Walczak2020128,
author={Walczak, K. and Flotyński, J. and Strugała, D. and Strykowski, S. and Sobociński, P. and Gałązkiewicz, A. and Górski, F. and Buń, P. and Zawadzki, P. and Wielgus, M. and Wojciechowski, R.},
title={Semantic Modeling of Virtual Reality Training Scenarios},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2020},
volume={12499 LNCS},
pages={128-148},
doi={10.1007/978-3-030-62655-6_8},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096486757&doi=10.1007%2f978-3-030-62655-6_8&partnerID=40&md5=f8c0ad736be8af6893ef1540fdb39496},
affiliation={Poznań University of Economics and Business, Niepodległości 10, Poznań, 61-875, Poland; Poznań University of Technology, Piotrowo 3, Poznań, 60-965, Poland; Enea Operator sp. z o.o., Strzeszyńska 58, Poznań, 60-479, Poland},
abstract={Virtual reality can be an effective tool for professional training, especially in the case of complex scenarios, which performed in reality may pose a high risk for the trainee. However, efficient use of VR in practical everyday training requires efficient and easy-to-use methods of designing complex interactive scenarios. In this paper, we propose a new method of creating virtual reality training scenarios, with the use of knowledge representation enabled by semantic web technologies. We have verified the method by implementing and demonstrating an easy-to-use desktop application for designing VR scenarios by domain experts. © 2020, Springer Nature Switzerland AG.},
author_keywords={Scenarios;  Semantic web;  Training;  Virtual reality},
keywords={Augmented reality;  Knowledge representation;  Risk perception;  Virtual reality, Designing complex;  Desktop applications;  Domain experts;  Effective tool;  Professional training;  Semantic Model;  Semantic Web technology;  Virtual reality training, E-learning},
correspondence_address1={Walczak, K.; Poznań University of Economics and Business, Niepodległości 10, Poland; email: walczak@kti.ue.poznan.pl},
editor={Bourdot P., Interrante V., Kopper R., Olivier A., Saito H., Zachmann G.},
publisher={Springer Science and Business Media Deutschland GmbH},
issn={03029743},
isbn={9783030626549},
language={English},
abbrev_source_title={Lect. Notes Comput. Sci.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Ursachi2020504,
author={Ursachi, T.M.},
title={A.R.e.a.-augmented reality educational album for experiential learning},
journal={eLearning and Software for Education Conference},
year={2020},
pages={504-510},
doi={10.12753/2066-026X-20-152},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096477441&doi=10.12753%2f2066-026X-20-152&partnerID=40&md5=61e867eebcb1b706b8b3a922e02c5d35},
affiliation={Department of Engineering in Foreign Language, University POLITEHNICA of Bucharest, Splaiul Independentei 313, Bucharest, Romania},
abstract={The current paper proposes a new approach of experiential learning, by bringing together the concept of immersive education and an emergent technology: augmented reality. The immersive education tends to resolve the main drawback of traditional education, which is the limited experimentation, and with the help of the evolving technologies, the students can understand the school subjects in a different manner. At present, the theoretical part plays the major role in education, while the experimentation is often ignored or treated superficially, especially when it comes to progressive domains, such as engineering or informatics. By bringing the immersive education closer to students and teachers, they might be able to experience the most important aspects of this domain, in real-time, without sacrificing the good parts of traditional education. The approach presented in my paper is accomplished through an augmented reality system called AREA, which combines the digital and non-digital worlds, in order to foster an interactive and educative way of discovering the inventions that have revolutionized the modern world, thus making students curious about the evolution of modern technology. Using augmented reality, students have the chance to experiment the connection between learning and practicing and how they co-work in order to achieve great success. The application was tested on a group of high school students and on a group of adults specialized on engineering and marketing domains, the results being very intriguing. Besides presenting my system and the way it can be integrated to overcome the current educational challenges (e.g. lack of practical exercises), we also analyzed the use of other existing augmented reality systems, from various domains, that offer similar experiences to the one accomplished by AREA. © 2020, National Defence University - Carol I Printing House. All rights reserved.},
author_keywords={Augmented reality;  Immersive education;  Mobile application;  School subjects},
correspondence_address1={Ursachi, T.M.; Department of Engineering in Foreign Language, Splaiul Independentei 313, Romania; email: tudor.ursachi95@gmail.com},
editor={ROCEANU I.},
publisher={National Defence University - Carol I Printing House},
issn={2066026X},
language={English},
abbrev_source_title={eLearning Softw. Educ. Conf.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Bîrsan202011,
author={Bîrsan, J. and Moldoveanu, F. and Moldoveanu, A. and Morar, A. and Butean, A.},
title={Immersive education in smart educational buildings},
journal={eLearning and Software for Education Conference},
year={2020},
pages={11-16},
doi={10.12753/2066-026X-20-087},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096471288&doi=10.12753%2f2066-026X-20-087&partnerID=40&md5=1bb3f0990d4f9a1f4b777f4071ba214d},
affiliation={Faculty of Automatic Control and Computers, University POLITEHNICA of Bucharest, Splaiul Independentei 313, Bucharest, Romania; Lucian Blaga University of Sibiu, Bd-ul Victoriei nr.10, Sibiu, Romania},
abstract={This paper is focused on a new way of learning, based on the concept of immersive education, close related to augmented and virtual reality technologies. These technologies allow young people to experiment, learn and understand many subjects, even in the absence of the supporting physical infrastructure. The concept of immersive education can be implemented using a smart building educational infrastructure. This approach is explained in the paper, using as support the augmented reality and indoor positioning methods. These two main technologies enable teachers and students to experiment a non-traditional way of learning, by using an application which displays interactive content depending on the location of the user: if the student is in the biology lab room, different content regarding biology will be displayed; if the student changes the lab room with the chemistry one, the augmented reality will be full of chemistry experiments, substances and formulas. The goal st h make students learn school subjects with pleasure, to make them understand easily concepts that sometimes cannot be experimented in reality. The mobile application localizes the user in the indoor environment and further augments the reality with different objects, related to the user’s position. When computing the position, the orientation is also a key in this solution, because the user should be able to see the object from any orientation. The paper gives some details about the proposed indoor positioning method, justifying the approach, as well as different aspects related to the importance of immersion in this kind of education. © 2020, National Defence University - Carol I Printing House. All rights reserved.},
editor={ROCEANU I.},
publisher={National Defence University - Carol I Printing House},
issn={2066026X},
language={English},
abbrev_source_title={eLearning Softw. Educ. Conf.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Macariu20202133,
author={Macariu, C. and Iftene, A. and Gîfu, D.},
title={Learn chemistry with augmented reality},
journal={Procedia Computer Science},
year={2020},
volume={176},
pages={2133-2142},
doi={10.1016/j.procs.2020.09.250},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85093365728&doi=10.1016%2fj.procs.2020.09.250&partnerID=40&md5=4fbce9177064c7dea56237b23d8e9a54},
affiliation={Faculty of Computer Science, Alexandru Ioan Cuza University, General Berthelot, 16, Iasi, 700483, Romania; Institute of Computer Science, Romanian Academy - Iasi branch, Bulevardul Carol I, 8700505, Romania},
abstract={Augmented Reality (AR) has been accepted as an effective learning method which means that it becomes complementary to traditional learning, especially in chemistry. In fact, AR is an interactive experience of a real-world environment. Before recent releases of cheap and affordable smart devices, AR large-scale applications in education were almost impossible. After a brief analysis of current trends in the use of AR, we propose a new system, named ARChemistry Learning, to support the Romanian educational system. In this study, we propose a modern AR tool in the chemistry education used to support children or anyone who wants to learn chemistry, to develop logic, and to explore the world seen only on a smart device. The purpose of this research is to demonstrate how effective these AR applications are, even that in Romania they are still in a pioneering phase. © 2020 The Authors. Published by Elsevier B.V.},
author_keywords={Augmented reality;  Chemistry learning;  Human computer interaction;  Instructional design},
keywords={Augmented reality;  Knowledge based systems, AR application;  Chemistry education;  Educational systems;  Effective learning;  Large-scale applications;  Real world environments;  Smart devices;  Traditional learning, Learning systems},
correspondence_address1={Iftene, A.; Faculty of Computer Science, General Berthelot, 16, Romania; email: adiftene@info.uaic.ro; Gîfu, D.; Faculty of Computer Science, General Berthelot, 16, Romania; email: daniela.gifu@info.uaic.ro},
editor={Cristani M., Toro C., Zanni-Merk C., Howlett R.J., Jain L.C., Jain L.C.},
publisher={Elsevier B.V.},
issn={18770509},
language={English},
abbrev_source_title={Procedia Comput. Sci.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Alkadhi20203,
author={Alkadhi, B. and Alnafisi, G. and Aljowair, L. and Alotaibi, L. and Alduaifi, N. and Alhumood, R.},
title={Co-design of Augmented Reality Storybooks for Children with Autism Spectrum Disorder},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2020},
volume={12426 LNCS},
pages={3-13},
doi={10.1007/978-3-030-60149-2_1},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092133947&doi=10.1007%2f978-3-030-60149-2_1&partnerID=40&md5=4f556e22fad220b5478bfd7cbf0623f3},
affiliation={Software Engineering Department, King Saud University, Riyadh, Saudi Arabia; Human-Computer Interaction (HCI) Design Lab, Riyadh, Saudi Arabia},
abstract={Spectrum of autism is one of the most serious disorders that negatively affect the normal development of the brain. Children with autism usually face different levels of difficulties in communication and practicing essential life skills such as reading due to language delays and intellectual disability. The limitations in manipulating written text as well as understanding it make it challenging for them to read and enjoy storybooks, and here where technology-based interventions can take place. Yohka is an Arabic augmented reality storybook application designed for children with Autism Spectrum Disorder (ASD) and their caregivers to enhance their reading experience and communication. It shows a more interactive and animated version of the story that helps the child to understand the story and the interactions between its characters, which make it enjoyable and therapeutic at the same time. The design of reading companions is rapidly growing in the interaction design domains. While the promise of interactive learning technologies has widely been demonstrated and relevant research is proliferating, little is known about how augmented reality applications might play a positive role in this development and the effective design process is not necessarily recognized. This paper describes the collective creative co-design process that was followed in Yohka as a user-centered design project for developing augmented reality application for - and with - children on the autism spectrum and its consequences on the finished application. It discusses the design innovation modules for ASD technologies and the effective role of relevant stakeholders and expert evaluation in achieving high standards while designing such technologies. Children, parents, specialists, and caregivers have been actively involved since early stages of the project as co-designers and have contributed hugely through different ways and mediums that are covered in this paper. Designing with the users through several iterations helps in promoting usability especially for this kind of educational and therapeutic technologies. Design implications and future directions for this work are also discussed. © 2020, Springer Nature Switzerland AG.},
author_keywords={Augmented reality;  Autism Spectrum Disorder;  Children;  Co-create;  Co-design;  User centered design},
keywords={Augmented reality;  Diseases;  Engineering education;  Human computer interaction, Augmented reality applications;  Children with autisms;  Design implications;  Design innovations;  Expert evaluation;  Intellectual disability;  Interaction design;  Interactive learning, User centered design},
correspondence_address1={Alkadhi, B.; Software Engineering Department, Saudi Arabia; email: balkadhi@ksu.edu.sa},
editor={Stephanidis C., Antona M., Gao Q., Zhou J.},
publisher={Springer Science and Business Media Deutschland GmbH},
issn={03029743},
isbn={9783030601485},
language={English},
abbrev_source_title={Lect. Notes Comput. Sci.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Alce2020215,
author={Alce, G. and Klang, K.-J. and Andersson, D. and Nyström, S. and Wallergård, M. and Niehorster, D.C.},
title={Using augmented reality to train flow patterns for pilot students - an explorative study},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2020},
volume={12242 LNCS},
pages={215-231},
doi={10.1007/978-3-030-58465-8_17},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091186854&doi=10.1007%2f978-3-030-58465-8_17&partnerID=40&md5=916bf2366f1b1208457fd4cd58469156},
affiliation={Department of Design Sciences, Lund University, Lund, Sweden; Lund University School of Aviation, Lund University, Lund, Sweden; Lund University Humanities Lab and Department of Psychology, Lund University, Lund, Sweden},
abstract={Today, just as in the early days of flying, much emphasis is put on the pilot student’s flight training before flying a real commercial aircraft. In the early stages of a pilot student’s education, they must, for example, learn different operating procedures known as flow patterns using very basic tools, such as exhaustive manuals and a so-called paper tiger. In this paper, we present a first design of a virtual and interactive paper tiger using augmented reality (AR), and perform an evaluation of the developed prototype. We evaluated the prototype on twenty-seven pilot students at the Lund University School of Aviation (LUSA), to explore the possibilities and technical advantages that AR can offer, in particular the procedure that is performed before takeoff. The prototype got positive results on perceived workload, and in remembering the flow pattern. The main contribution of this paper is to elucidate knowledge about the value of using AR for training pilot students. © Springer Nature Switzerland AG 2020.},
author_keywords={Augmented reality;  Flight training;  Interaction design;  Method},
keywords={Flow patterns;  Students;  Training aircraft;  Virtual reality, Commercial aircraft;  First designs;  Flight training;  Interactive paper;  Lund University;  Training pilots, Augmented reality},
correspondence_address1={Alce, G.; Department of Design Sciences, Sweden; email: gunter.alce@design.lth.se},
editor={De Paolis L.T., Bourdot P.},
publisher={Springer Science and Business Media Deutschland GmbH},
issn={03029743},
isbn={9783030584641},
language={English},
abbrev_source_title={Lect. Notes Comput. Sci.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Martinez2020186,
author={Martinez, K. and Menéndez-Menéndez, M.I. and Bustillo, A.},
title={Considering user experience parameters in the evaluation of vr serious games},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2020},
volume={12242 LNCS},
pages={186-193},
doi={10.1007/978-3-030-58465-8_14},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091163504&doi=10.1007%2f978-3-030-58465-8_14&partnerID=40&md5=076beae7b36d1f8d7259009519a2024e},
affiliation={Department of History, Geography and Communication, University of Burgos, Burgos, Spain; Department of Civil Engineering, University of Burgos, Burgos, Spain},
abstract={Serious Games for Virtual Reality (SG-VR) is still a new subject that needs to be explored. Achieving the optimal fun and learning results depends on the application of the most suitable metrics. Virtual Reality environments offer great capabilities but at the same time make difficult to record User Experience (UX) to improve it. Moreover, the continuous evolution of Virtual Reality technologies and video game industry tendencies constantly change these metrics. This paper studies the Mechanics, Dynamics and Aesthetic (MDA) framework and User Experience metrics to develop new ones for SG-VR. These new parameters are focused on the intrinsic motivations the players need so they engage with the game. However, the development team budget must be taken into account, since it limits items and interactions but still have to aim to the learning goals. New VR metrics will be 1) UX features: chosen VR headsets, training interactions tutorials to learn control and interactive adaptions to avoid VR inconveniences; and 2) MDA features: exclusive VR aesthetical elements and its interactions. © Springer Nature Switzerland AG 2020.},
author_keywords={Game design;  Game evaluation;  Serious games;  Virtual reality},
keywords={Augmented reality;  Budget control;  Human computer interaction;  Serious games;  User experience, Development teams;  Intrinsic motivation;  Learning goals;  New parameters;  User experiences (ux);  Video game industry;  Virtual reality technology;  Virtual-reality environment, Virtual reality},
correspondence_address1={Bustillo, A.; Department of Civil Engineering, Spain; email: abustillo@ubu.es},
editor={De Paolis L.T., Bourdot P.},
publisher={Springer Science and Business Media Deutschland GmbH},
issn={03029743},
isbn={9783030584641},
language={English},
abbrev_source_title={Lect. Notes Comput. Sci.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Sarsimbayeva2020142,
author={Sarsimbayeva, S. and Dimitrov, V.},
title={Research on the development and implementation of augmented reality technologies},
journal={CEUR Workshop Proceedings},
year={2020},
volume={2656},
pages={142-147},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090890874&partnerID=40&md5=3f3b32069a66bed355429d91911db2b6},
affiliation={Aktobe Regional State University K. Zhubanov, Aktobe, Kazakhstan; University of Sofia St. Kliment Ohridski, 5 James Bourchier Blvd., Sofia, 1164, Bulgaria},
abstract={The article deals with the development of augmented reality applications on the Vuforia platform, as well as the use of augmented reality technology in the educational process for visual modeling of educational material to supplement the material with visual information. The results of the analysis of existing approaches to the development of augmented reality applications, platforms, tool development environments such as Vuforia, with the ability to connect Unity, and the implementation of augmented reality technology are shown. The importance of using high-level augmented reality technologies, the prospects for using augmented reality technology, and the opportunities and advantages of using it in the educational process are highlighted. It is noted that the situation in the field of education determines the relevance of the use of new information technologies in the field of education and one of the promising areas of development of innovative educational technologies is the use of augmented reality in the learning process. An augmented reality application to great Kazakh poet Abay Kunanbayev's poems created based on marker technology is proposed. Copyright © 2020 for this paper by its authors.},
author_keywords={Augmented reality;  Interactive technology;  Recognition;  Vuforia},
keywords={Augmented reality;  Information systems;  Information use, Augmented reality applications;  Augmented reality technology;  Educational materials;  Educational process;  Learning process;  Tool development;  Visual information;  Visual model, Engineering education},
editor={Dimitrov V., Georgiev V.},
publisher={CEUR-WS},
issn={16130073},
language={English},
abbrev_source_title={CEUR Workshop Proc.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Yüzüak2020,
author={Yüzüak, Y. and Yiğit, H.},
title={Augmented reality application in engineering education: N-Type MOSFET},
journal={International Journal of Electrical Engineering Education},
year={2020},
doi={10.1177/0020720920954150},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090148417&doi=10.1177%2f0020720920954150&partnerID=40&md5=d9b653e0abb33d9dcbc4517986b73337},
affiliation={Architect İzzet Baysal Vocational and Technical Anatolian High SchoolBolu, Turkey; Kocaeli University, Faculty of Technology Technology, Information Systems Engineering, İzmit, Turkey},
abstract={In a period of rapid adaptation to technology in today’s world, limiting education to traditional methods leads to a rapid decline in the perception and interest of the learner. Augmented Reality (AR), which is among the most interesting technological innovation of the last years, are manifested in many sectors. It is used more widely in the field of education thanks to its superior advantages such as being portable, adapting to different devices/equipment, offering interactive digital content and arousing interest. In this study, AR application has been realized for the modeling of N-type MOSFET element, which is one of the basic courses of Electrical and Electronic Engineering and is widely used in analog and digital circuits. The contribution of the application to students’ perception of theoretical concepts was also examined. It concluded that AR made an important contribution to the concretization of abstract concepts and the developed educational material increased the motivation of the students. © The Author(s) 2020.},
author_keywords={Augmented reality;  education;  engineering;  mobile learning;  N-type MOSFET},
keywords={Augmented reality;  Digital devices;  MOSFET devices, Abstract concept;  Analog and digital circuits;  Augmented reality applications;  Digital contents;  Educational materials;  Electrical and electronic engineerings;  Rapid adaptation;  Technological innovation, Students},
correspondence_address1={Yiğit, H.; Kocaeli University, Turkey; email: halilyigit@kocaeli.edu.tr},
publisher={SAGE Publications Inc.},
issn={00207209},
coden={IJEEA},
language={English},
abbrev_source_title={Int J Electr Eng Educ},
document_type={Article},
source={Scopus},
}

@ARTICLE{Bibi2020200,
author={Bibi, S.H. and Munaf, R.M. and Bawany, N.Z. and Shamim, A. and Saleem, Z.},
title={Smart learning companion (SLAC)},
journal={International Journal of Emerging Technologies in Learning},
year={2020},
volume={15},
number={16},
pages={200-211},
doi={10.3991/ijet.v15i16.14477},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090100587&doi=10.3991%2fijet.v15i16.14477&partnerID=40&md5=d325cb7308d97358e431273bff91fbdd},
affiliation={Jinnah University for Women, Karachi, Pakistan},
abstract={Augmented Reality (AR) tends to merge the computing world with the real world, giving way to an incredible user experience. This field is not only limited to entertainment but has been utilized in various domains including healthcare, education and training. Realizing the potential of Augmented Reality in improving the learning experience, researchers have explored many ways of incorporating AR in the field education. Consequently, this research is focused on providing interactive and customized learning experience to book readers. We present a mobile application, Smart Learning Companion (SLAC), for physical books that provide a virtual content for a book. The virtual content includes, 3D animations, Quizzes, explanation of content in native language and many other features. The virtual content is activated as soon as pages are scanned with a mobile phone or tablet. Smart Learning Companion explains animated educational content and provides an interactive user experience. The aim of SLAC is to encourage students to learn on their own by making books more interactive. Smart Learning Companion provides explanation in Urdu, solutions of exercises with animations, quizzes for each section, and overall result that shows the student progress. This will help to reduce the dependency of students on others for learning making them capable of selflearning. Smart Learning Companion applications are developed for four books to conduct the experiments. Experimental study is conducted to show the effectiveness of Smart Learning Companion application. The results show that our application helped students to understand the concepts more easily as explanation was provided in national language of Pakistan, that is, Urdu. © 2020, Kassel University Press GmbH.},
author_keywords={AR (Augmented reality);  Mobile applications;  Self-Learning;  SLAC (Smart learning companion);  Smart way of learning;  Traditional way of learning},
keywords={Augmented reality;  mHealth;  User experience, Education and training;  Educational contents;  Learning companions;  Learning experiences;  Mobile applications;  National language;  Native language;  Student progress, Students},
correspondence_address1={Bibi, S.H.; Jinnah University for WomenPakistan; email: hamnatariq96@gmail.com},
publisher={Kassel University Press GmbH},
issn={18688799},
language={English},
abbrev_source_title={Int. J. Emerg. Technol. Learn.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Sun2020520,
author={Sun, C.-F. and Chan, Y.-C. and Chien, S.-Y. and Lin, Y.-L. and Hsiao, I.-H.},
title={Preschool safety education with digital media-based learning application – kinder},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2020},
volume={12206 LNCS},
pages={520-529},
doi={10.1007/978-3-030-50506-6_35},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088914437&doi=10.1007%2f978-3-030-50506-6_35&partnerID=40&md5=9d98a549fdf181bb9bca9e35dc1d0ec5},
affiliation={University of Washington, Seattle, WA  98195, United States; National Chengchi University, Taipei, 11605, Taiwan; Arizona State University, Tempe, AZ  85281, United States},
abstract={While unintentional injuries are the leading cause of morbidity and mortality among children, reports have shown that unintentional injuries mostly take place at home or school environments with injuries like falls, contact with stationary objects and being caught in hinge side of doors reported frequently. Safety education targeting children is seen as an important intervention of children injury prevention for its direct affect. As there has been a rising usage of digital media devices among children, digital media-based learning has been discussed and researched in recent years. However, few has investigated the value of deploying digital devices in children environment safety education. We developed Kinder, a mobile application using Augmented Reality (AR) and object recognition technology, to support preschool children in identifying potentially dangerous objects in different environments. The ultimate goal of Kinder is to provide an interactive and encouraging learning experience for preschool children to foster their learning motivation and enhance their safety knowledge. Our main focus is to assess the usability and prospects of the application. In this paper, we present the methodology, setup, implementation and results of our preliminary assessment of Kinder. From questionnaire and interviews, the preliminary results have shown valid value of AR with object recognition technology in children safety knowledge learning in home and school environment. The present study also provides useful information for practical design in children learning applications. © Springer Nature Switzerland AG 2020.},
author_keywords={Augmented reality;  Children safety education;  Digital media learning;  Object recognition},
keywords={Augmented reality;  Computer aided instruction;  Digital devices;  Digital storage;  Human computer interaction;  Object recognition;  Surveys, Children learning;  Learning experiences;  Learning motivation;  Mobile applications;  Preliminary assessment;  Preschool children;  Stationary objects;  Unintentional injuries, E-learning},
correspondence_address1={Chien, S.-Y.; National Chengchi UniversityTaiwan; email: sychien@nccu.edu.tw},
editor={Zaphiris P., Ioannou A., Ioannou A.},
publisher={Springer},
issn={03029743},
isbn={9783030505059},
language={English},
abbrev_source_title={Lect. Notes Comput. Sci.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Khowaja2020424,
author={Khowaja, K. and Al-Thani, D. and Hassan, A.O. and Shah, A. and Salim, S.S.},
title={Mobile augmented reality app for children with autism spectrum disorder (asd) to learn vocabulary (marvoc): From the requirement gathering to its initial evaluation},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2020},
volume={12211 LNCS},
pages={424-437},
doi={10.1007/978-3-030-50164-8_31},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088753989&doi=10.1007%2f978-3-030-50164-8_31&partnerID=40&md5=7da8ba510d6ac9faf76192f88575e7b9},
affiliation={Hamad Bin Khalifa University, Doha, Qatar; International Islamic University Malaysia, Kuala Lumpur, Malaysia; University of Malaya, Kuala Lumpur, Malaysia},
abstract={The use of different technologies for the intervention of children with autism spectrum disorder (ASD) has increased over the year with the increase in the number of children diagnosed with ASD. In recent years, among the different technologies, the researchers have started to use the augmented reality (AR) to provide the intervention of different skills to children with ASD. The use of AR has many benefits, including ubiquity, minimally work with a camera, among others. Despite several benefits, AR has been underutilized for the vocabulary learning of children with ASD. This paper presents the initial version of the Mobile augmented reality app for children with autism spectrum disorder (ASD) to learn vocabulary (MARVoc). The purpose of developing MARVoc is to support teaching staff at the centers based in Doha, Qatar, to provide an interactive learning environment to children with ASD. The requirements of the MARVoc were gathered from two centers for ASD in Doha; two specific use cases were created from which one use case was finalized for the development of MARVoc. The initial version of the MARVoc was developed; the feedback was taken from the staff working at centers for ASD in Doha, and MARVoc was updated. © Springer Nature Switzerland AG 2020.},
author_keywords={Autism spectrum disorder (ASD);  Language comprehension;  Mobile augmented reality (AR);  Smartphone;  Tablet;  Vocabulary},
keywords={Computer aided instruction;  Computer games;  Diseases;  E-learning;  Human computer interaction, Children with autisms;  Interactive learning environment;  Mobile augmented reality;  Requirement gathering;  Teaching staff;  Vocabulary learning, Augmented reality},
correspondence_address1={Khowaja, K.; Hamad Bin Khalifa UniversityQatar; email: kamran.khowaja@gmail.com},
editor={Fang X.},
publisher={Springer},
issn={03029743},
isbn={9783030501631},
language={English},
abbrev_source_title={Lect. Notes Comput. Sci.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Borja-Galeas2020387,
author={Borja-Galeas, C. and Guevara, C. and Amagua, M.},
title={Editorial design of interactive picture book with mobile application based on uxd user experience design},
journal={Advances in Intelligent Systems and Computing},
year={2020},
volume={1217 AISC},
pages={387-393},
doi={10.1007/978-3-030-51828-8_50},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088750042&doi=10.1007%2f978-3-030-51828-8_50&partnerID=40&md5=ef9491f614c4f0b05b8556491ee97bb3},
affiliation={Faculty of Architecture, Arts and Design, Universidad Tecnológica Indoamérica, Ambato, Quito, Ecuador; Faculty of Design and Communication, Universidad de Palermo, Buenos Aires, Argentina; Research Center of Mechatronics and Interactive Systems, Universidad Tecnológica Indoamérica, Ambato, Quito, Ecuador; Faculty of Administrative and Economic Sciences, Universidad Indoamérica, Ambato, Quito, Ecuador},
abstract={This research presents an interactive human-computer learning system model applying adaptive editorial design. The proposal aims to generate an interactive picture book and a mobile application based on user experience design (UxD). The results will be obtained using UX metrics and will have the particularity of working with the technique of participatory design and reticular deconstruction. This book includes its presentation as an audiobook and an editorial composition with pop-ups and pages to paint. © The Editor(s) (if applicable) and The Author(s), under exclusive license to Springer Nature Switzerland AG 2020.},
author_keywords={Augmented reality;  Editorial design;  Interactive editorial design;  Mobile application human interaction computer;  User experience design},
keywords={Human engineering;  Learning systems;  Mobile computing;  User centered design;  Wearable technology, Computer learning;  Editorial designs;  Mobile applications;  Participatory design;  System modeling;  User experience design, User experience},
correspondence_address1={Borja-Galeas, C.; Faculty of Architecture, Ecuador; email: carlosborja@uti.edu.ec},
editor={Ahram T., Falcao C.},
publisher={Springer},
issn={21945357},
isbn={9783030518271},
language={English},
abbrev_source_title={Adv. Intell. Sys. Comput.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Yan2020684,
author={Yan, H. and He, X.},
title={The impact of interactive ar on learning ability of children’s chinese characters self-learning},
journal={Advances in Intelligent Systems and Computing},
year={2020},
volume={1217 AISC},
pages={684-689},
doi={10.1007/978-3-030-51828-8_90},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088748009&doi=10.1007%2f978-3-030-51828-8_90&partnerID=40&md5=51ceb62a0fdfb1592ba656f8829daecb},
affiliation={School of Mechanical Science and Engineering, Huazhong University of Science and Technology, Wuhan, Hubei, China},
abstract={Augmented reality has become an effective teaching and learning tool to improve children’s engagement and experience during. This study presented 2 kinds of Chinese characters learning method (traditional picture learning and AR-assisted learning), and compared the impact of traditional learning and AR-assisted learning methods on children’s learning ability in the process of learning by applying AR technology to traditional Chinese pictographs learning method. It involves the impact on children’s concentrated ability, cognitive ability and learning initiative. These finds enriches the application and research of AR technology in Chinese language teaching, and provides reference for applied research in other related fields. © The Editor(s) (if applicable) and The Author(s), under exclusive license to Springer Nature Switzerland AG 2020.},
author_keywords={Augmented reality;  Chinese characters;  Learning ability},
keywords={Augmented reality;  Human engineering;  Learning systems;  Teaching;  User experience;  Wearable technology, Chinese characters;  Chinese language teachings;  Cognitive ability;  Effective teaching;  Learning abilities;  Learning initiatives;  Process of learning;  Traditional learning, Engineering education},
correspondence_address1={He, X.; School of Mechanical Science and Engineering, China; email: xinh@hust.edu.cn},
editor={Ahram T., Falcao C.},
publisher={Springer},
issn={21945357},
isbn={9783030518271},
language={English},
abbrev_source_title={Adv. Intell. Sys. Comput.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Syal20202720,
author={Syal, S. and Mathew, R.},
title={Threats Faced by Mixed Reality and Countermeasures},
journal={Procedia Computer Science},
year={2020},
volume={171},
pages={2720-2728},
doi={10.1016/j.procs.2020.04.295},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086630253&doi=10.1016%2fj.procs.2020.04.295&partnerID=40&md5=e66e9b1297c29997e0f18beaf041391c},
affiliation={IT Department, Mukesh Patel School of Technology Management and Engineering, Mumbai, 400056, India},
abstract={Mixed Reality, MR, is defined as the integration of real and virtual worlds to create an environment which allows co-existing of physical and digital objects enabling users to interact with both. MR is a cross of reality, virtual reality including augmented reality and augmented virtuality. With the advent of wireless technologies and ever-increasing integration of the virtual world with the real world, MR has gained more significance in the last 5 years. Also, because of its real-life applications in education, gaming, entertainment, medicine, and military. But no technology comes without risks and shortcomings. Thus, MR also faces many threats and attacks which are broadly classified into 5 types namely, input, output, data, user interaction and device protection some of which include latency, data collection, physical device threats, user threats etc. This paper presents a comprehensive analysis of these threats on MR and solutions to mitigate the effects of it. © 2020 The Authors. Published by Elsevier B.V.},
author_keywords={Augmented Reality;  HMDs;  Input protection;  Latent Data;  Mixed Reality;  Non-Repudiation;  RAPPOR},
keywords={Augmented reality;  Interactive computer graphics;  Military applications, Augmented virtualities;  Comprehensive analysis;  Digital Objects;  Physical devices;  Real-life applications;  Threats and attacks;  User interaction;  Wireless technologies, Mixed reality},
editor={Thampi S.M., Madria S., Fernando X., Doss R., Mehta S., Ciuonzo D.},
publisher={Elsevier B.V.},
issn={18770509},
language={English},
abbrev_source_title={Procedia Comput. Sci.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Santos2020247,
author={Santos, L. and Silva, N. and Nóbrega, R. and Almeida, R. and Coelho, A.},
title={An interactive application framework for natural parks using serious location-based games with augmented reality},
journal={VISIGRAPP 2020 - Proceedings of the 15th International Joint Conference on Computer Vision, Imaging and Computer Graphics Theory and Applications},
year={2020},
volume={1},
pages={247-254},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083556732&partnerID=40&md5=f121e1538111832cc14f8f13a6a3bb2e},
affiliation={Faculty of Engineering, University of Porto, Porto, Portugal; NOVA-LINCS, DI, Faculdade de Ciências e Tecnologia, Universidade Nova de Lisboa, Caparica, Portugal; INESC TEC - The Institute for Systems and Computer Engineering, Technology and Science, Porto, Portugal; Faculty of Science, University of Porto, Porto, Portugal},
abstract={Park visitors and tourists, in general, seek new experiences, leading to a growing search for ways to create more memorable experiences. Some technological solutions, such as Augmented Reality, have proved that they can be useful to create more immersive and interactive experiences, both in entertainment and education. An application with Augmented Reality, using location-based services in a gamified way, can create pleasant and entertaining outdoor experiences without losing its pedagogical ability, making it a promising fit for a nature park. We propose a conceptual framework for creating these mobile applications for nature parks. From which, a mobile application was prototyped with location-based services and augmented reality interactive experiences, with the purpose of disseminating scientific knowledge about the fauna and flora of a nature park. Gaming elements are also introduced in the application's design to try and improve the engagement and involvement in the various activities of the application and its contents. User tests were performed during the development of the prototype and with the final version. The results allow us to conclude that this type of applications can improve the visitors' experience while at the same time, improve the dissemination of scientific knowledge. Copyright © 2020 by SCITEPRESS - Science and Technology Publications, Lda. All rights reserved.},
author_keywords={Augmented reality;  Interactive applications;  Location-based games;  Mobile games;  Nature parks;  Serious games},
keywords={Augmented reality;  Computer vision;  Entertainment;  Location;  Mobile computing;  Serious games;  Telecommunication services, Conceptual frameworks;  Interactive applications;  Location based games;  Mobile applications;  Natural park;  Scientific knowledge;  Technological solution;  User tests, Location based services},
editor={Bouatouch K., Sousa A.A., Braz J.},
publisher={SciTePress},
isbn={9789897584022},
language={English},
abbrev_source_title={VISIGRAPP - Proc. Int. Jt. Conf. Comput. Vis., Imaging Comput. Graph. Theory Appl.},
document_type={Conference Paper},
source={Scopus},
}
