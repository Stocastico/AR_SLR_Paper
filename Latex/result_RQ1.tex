\subsection{Interactive and collaborative capabilities of AR applications}

This subsection addresses the first research question. We analysed interactive, multiuser and collaborative capabilities of the \gls{AR} apps described in the selected studies. We categorised the studies into five different clusters, based on how the applications provide interactive functionalities. The categories were chosen by analysing the common traits of each study, as well as considering the characteristics of interactive applications in the context of education (assessment, feedback to the teacher, quizzes) and of user interface elements that enable the interaction.  The five interactivity levels we defined are as follows:

\begin{itemize}
    \item \emph{Basic interactivity}: the student can interact with the app through \gls{UI} elements such as menus and buttons directly in the augmented space.
    \item \emph{Object interaction}: the student can interact directly with the augmented content, without having to use \gls{UI} elements.
    \item \emph{Quiz}: the application provides quizzes (or allows teachers to add new ones) to test the students' understanding of a topic directly within the app, or it includes gamification concepts.
    \item \emph{Behaviour tracking}: the application keeps track of student behaviour. Both the active interactions (questions answered, buttons clicked) as well as passive usage of the app (time spent on each activity, for example) are logged and made available to the teacher so that the lecture can be modified accordingly.
    \item \emph{Augmented interaction}: where the augmented content shown to the student depends on the relative positions of different markers or devices.
\end{itemize}

In addition to these, we also consider \emph{multiuser} \gls{AR} experiences, where multiple students are viewing the same augmented content and any change in it, for example caused by the interactions of one of the students, is visible to all the other students as well.
Finally, we are also interested in \emph{collaborative} \gls{AR} applications, that is multiuser applications where the students share a common goal and work together (or compete against each other) to reach it.

We are particularly interested in these applications because interactive learning environments have been shown to have a positive impact on the students' education \citep{johnson2000animated}. At the same time, collaborative learning offers the students several benefits at the social, psychological, academic and assessment level \citep{laal2012benefits}. In Table \ref{tab:categorize_papers}, we classify the \papersSelected articles we reviewed into the categories described above. Some of the studies can appear on multiple rows in the table, meaning that they may offer multiple interaction types as well as provide multiuser or interaction functionalities.

\begin{table*}[htbp]
\small
\centering
\caption {Classification of articles according to interactivity and collaboration capabilities.}\label{tab:categorize_papers}
\begin{tabular}{|M{2.7cm}||M{14cm}|}
    \hline
    \textbf{Interaction type} & \textbf{Articles} \\
    \hline
    \hline
    Basic interactivity & \citep{lai2015applying, tang2015learning, ang2019enhancing, sorrentino2015speaky, arcos2016playful, zhao2018augmented, chao2018study, costa2019augmented, protopsaltis2016quiz, luna2018words, ramos2019artitser, el2019educational, huang2016animating, wang2017exploring, pombo2017marker, pombo2018edupark, chen2016augmented, liou2017influences, hsu2017learning, mylonas2019educational, khan2018mathland, hrishikesh2016interactive, sarkar2018scholar, chang2018impacts, chen2015construction, huang2019learning, lin2019primary, cao2018research, pombo2019learning, wei2019influence, cerqueira2018learning, klautke2018bridging, chang2019applying, hsieh2019intelligence, yilmaz2017using, lee2018augmented, chen2019effects, liu2020ar, perez2020interactive, yin2020research, mikulowski2020multi, korosidou2019gamifying, estudante2020using}\\
    \hline
    Object interaction & \citep{arcos2016playful, costa2019augmented, iqbal2019exploring}  \citep{cao2019hand, kum2019ar, cen2019augmented, ferrer2017virtual, oh2016designing, tscholl2016designing, laine2016designing, rusinol2018augmented, kurniawan2018human, boonbrahm2016interactive, ibanez2020impact, ManriqueJuan2017APA, chen2018application, mahmoudi2018color, antoniou2017scoping, hsu2018cobochild, thamrongrat2019design, lee2019mobile, amrit2015studies, ortiz2018evaluation, wei2018improving, rammos2019alternative, li2018see, giasiranis2017flow, takahashi2018empathic, lytridis2018artutor, matsutomo2017computer, kenoui2020teach, lopez2020emofindar, carlos2020voluminis}\\
    \hline
    Quiz or gamification &  \citep{lai2015applying, costa2019augmented, protopsaltis2016quiz, ramos2019artitser, laviole2018nectar, limsukhawat2016development, lin2016effect, chang2018impacts, daineko2018development, pombo2019learning, lee2019mobile, ortiz2018evaluation, wei2018improving, li2018see, xefteris2019mixing, oh2017hybrid, dave2020towards}\\
    \hline
    Behaviour tracking & \citep{protopsaltis2016quiz}  \citep{chen2016augmented, mylonas2019educational, chang2018impacts, cao2018research, hsu2018cobochild}\\
    \hline
    Augmented interaction & \citep{chao2018study, cen2019augmented, cai2017applications, ferrer2017virtual, wang2018augmented, laviole2018nectar, nasongkhla2019implementing, gardeli2018effect, xefteris2018learning, boonbrahm2015using, yilmaz2017using, kalpakis2018promoting, lam2020interactive, abriata2020building, dave2020towards}\\
    \hline
    \hline
    \textbf{Multiuser} & \citep{kum2019ar, cai2017applications, oh2016designing, laviole2018nectar, boonbrahm2016interactive, gardeli2018effect, triantafyllidou2017fingertrips, xefteris2018learning, palaigeorgiou2018touching, lee2019mobile, ortiz2018evaluation, xefteris2019mixing, takahashi2018empathic, lee2018augmented, oh2017hybrid, dave2020towards, lopez2020emofindar}\\
    \hline
    \hline
    \textbf{Collaborative} & \citep{cai2017applications, oh2016designing, tscholl2016designing, laviole2018nectar, boonbrahm2016interactive, ManriqueJuan2017APA, gardeli2018effect, lee2019mobile, ortiz2018evaluation, xefteris2019mixing, takahashi2018empathic, oh2017hybrid, lopez2020emofindar}\\
    \hline
    \hline
    
\end{tabular}
\end{table*}

As far as the interactive capabilities of an AR application are concerned, there are a few studies describing innovative ideas. In \citep{khan2018mathland}, the authors implemented a mixed reality system based on HoloLens\footnote{www.microsoft.com/en-us/hololens} smart glasses and several stretch and \gls{IMU} sensors, where the users can control and move augmented objects using their arms or an ad-hoc controller. The multi-user application is used to teach the students physics concepts such as force fields or velocity vectors, without needing to set up a laboratory.
Other studies use multiple markers to increase interactivity. The work of  \citet{wang2018augmented} uses AR to teach the double-slit experiment (a physics experiment demonstrating the characteristic of light being both a wave and a particle). In the application each marker is related to one part of the experimental apparatus. By modifying the distance of each marker from the next one, the augmented animation generated by the app changes its behaviour, visually showing the dual nature of light.
A similar idea is implemented by \citet{boonbrahm2015using}. In the app, which was created to facilitate learning English as a foreign language, each marker by itself only shows a letter in 3D. When multiple markers are combined to create an English word (from a predefined set), the app will show a 3D model of the corresponding word.
In \citep{gardeli2018effect}, the students learn the basics of computer science by visually implementing algorithms. Each marker, besides showing augmented content, represents an instruction in ALGO, a specially developed programming language, and sequences of different markers generate different behaviour from the augmented content.

Only a few studies experiment with other senses beyond sight. The work of \citet{kenoui2020teach} uses the IBM Watson SDK\footnote{www.ibm.com/cloud/watson-speech-to-text} to allow the user to interact by asking questions in English, while the answer is shown both as text above the augmented content and as computer-generated audio. \citet{mikulowski2020multi} designed a system for visually impaired students that detects mathematical formulas and generates both an audio description as well as a Braille representation on the Braille display.
 
In the context of multi-user applications, different studies employed different strategies to foster collaboration. \citet{boonbrahm2016interactive} describe an application where the users aim to solve a jigsaw puzzle. Since students cannot move two pieces in a row but are forced to alternate their moves, the puzzle can only be solved with a joint collaboration. In the work of  \citet{ortiz2018evaluation}, the app is an \gls{ARGBL} where the user learns about different regions of Colombia while competing for resources. In this case, competition with others stimulate the students to learn about the subject. Another form of collaboration is described by \citet{oh2016designing}. The authors created a smart-glasses-based AR application where the user can study properties of light such as reflection and refraction. Each user acts as a light source and sees what happens when light hits a wall or passes through different materials. At the same time, two or more users can generate multiple light rays and see how they interact with each other. Using a projector system, users without smart glasses are able to share the same experience, although not as actively as users wearing them.