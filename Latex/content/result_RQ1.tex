\subsection{Interactive and collaborative capabilities of AR applications}\label{sec:results:RQ1}

This subsection addresses the first research question. We analysed interactive, multi-user and collaborative capabilities of the \gls{AR} apps described in the selected studies. We categorised the studies into five different clusters, based on how the applications provide interactive functionalities. The categories were chosen by analysing the common traits of each study, as well as considering the characteristics of interactive applications in the context of education (assessment, feedback to the teacher, quizzes) and of user interface elements that enable the interaction.  The five interactivity levels we defined are as follows:

\begin{itemize}
    \item \emph{Basic interactivity}: the student can interact with the app through \gls{UI} elements such as menus and buttons directly in the augmented space.
    \item \emph{Object interaction}: the student can interact directly with the augmented content, without having to use \gls{UI} elements.
    \item \emph{Quiz}: the application provides quizzes (or allows teachers to add new ones) to test the students' understanding of a topic directly within the app, or it includes gamification concepts.
    \item \emph{Behaviour tracking}: the application keeps track of student behaviour and, using this information, the teacher can modify the content shown to the user. Both the active interactions (questions answered, buttons clicked) as well as passive usage of the app (time spent on each activity, for example) are logged and made available to the teacher so that the lecture can be modified accordingly.
    \item \emph{Augmented interactions}: the augmented content shown to the user may change depending on the interactions of the user with the environment, for example when changing the relative positions of different markers, or by varying the distance of the device from the markers.
\end{itemize}

In addition to these, we also consider \emph{multi-user} \gls{AR} experiences, where multiple students are viewing the same augmented content from different devices and any change, for example caused by the interactions of one of the students, is visible to all the other students as well.
Finally, we are also interested in \emph{collaborative} \gls{AR} applications, that is applications where the students share a common goal and work together (or compete against each other) to reach it.

We are particularly interested in these applications because interactive learning environments have been shown to have a positive impact on the students' education \cite{johnson2000animated}. At the same time, collaborative learning offers the students several benefits at the social, psychological, academic and assessment level \cite{laal2012benefits}. In Table \ref{tab:categorize_papers}, we classify the \papersSelected articles we reviewed into the categories described above. Some of the studies can appear on multiple rows in the table, meaning that they may offer multiple interaction types as well as provide multi-user or collaboration functionalities. The works of \cite{tscholl2016designing} and \cite{ManriqueJuan2017APA} present collaborative application that were not categorised as multi-user, since only one device is shared by multiple students.

\begin{table*}[htbp]
\small
\begin{tabular}{M{2cm}M{10cm}}
    \toprule
    \textbf{Interaction type} & \textbf{Articles} \\
    \midrule
    Basic interactivity & \cite{lai2015applying, tang2015learning, ang2019enhancing, sorrentino2015speaky, arcos2016playful, zhao2018augmented, chao2018study, costa2019augmented, protopsaltis2016quiz, luna2018words, ramos2019artitser, el2019educational, huang2016animating, wang2017exploring, pombo2017marker, pombo2018edupark, chen2016augmented, liou2017influences, hsu2017learning, mylonas2019educational, khan2018mathland, hrishikesh2016interactive, sarkar2018scholar, chang2018impacts, chen2015construction, huang2019learning, lin2019primary, cao2018research, pombo2019learning, wei2019influence, cerqueira2018learning, klautke2018bridging, chang2019applying, hsieh2019intelligence, yilmaz2017using, lee2018augmented, chen2019effects, liu2020ar, perez2020interactive, yin2020research, mikulowski2020multi, korosidou2019gamifying, estudante2020using, 231-syahidi2020mobile, 232-cruzado2020idear, 236-9298003, 241-MACARIU20202133, 246-10.1145/3379350.3416155, 248-9339655, 251-10.1007/978-3-030-62655-6_9}\\
    \midrule
    Object interaction & \cite{arcos2016playful, costa2019augmented, iqbal2019exploring, cao2019hand, kum2019ar, cen2019augmented, ferrer2017virtual, oh2016designing, tscholl2016designing, laine2016designing, rusinol2018augmented, kurniawan2018human, boonbrahm2016interactive, ibanez2020impact, ManriqueJuan2017APA, chen2018application, mahmoudi2018color, antoniou2017scoping, hsu2018cobochild, thamrongrat2019design, lee2019mobile, amrit2015studies, ortiz2018evaluation, wei2018improving, rammos2019alternative, li2018see, giasiranis2017flow, takahashi2018empathic, lytridis2018artutor, matsutomo2017computer, kenoui2020teach, lopez2020emofindar, carlos2020voluminis, 231-syahidi2020mobile, 233-10.1145/3441000.3441034, 246-10.1145/3379350.3416155, 251-10.1007/978-3-030-62655-6_9}\\
    \midrule
    Quiz or gamification &  \cite{lai2015applying, costa2019augmented, protopsaltis2016quiz, ramos2019artitser, laviole2018nectar, limsukhawat2016development, lin2016effect, chang2018impacts, daineko2018development, pombo2019learning, lee2019mobile, ortiz2018evaluation, wei2018improving, li2018see, xefteris2019mixing, oh2017hybrid, dave2020towards, 232-cruzado2020idear, 233-10.1145/3441000.3441034, 241-MACARIU20202133}\\
    \midrule
    Behaviour tracking & \cite{protopsaltis2016quiz, chen2016augmented, mylonas2019educational, chang2018impacts, cao2018research, hsu2018cobochild}\\
    \midrule
    Augmented interaction & \cite{chao2018study, cen2019augmented, cai2017applications, ferrer2017virtual, wang2018augmented, laviole2018nectar, nasongkhla2019implementing, gardeli2018effect, xefteris2018learning, boonbrahm2015using, yilmaz2017using, kalpakis2018promoting, lam2020interactive, abriata2020building, dave2020towards, 241-MACARIU20202133, 251-10.1007/978-3-030-62655-6_9}\\
    \midrule
    Multi-user & \cite{kum2019ar, cai2017applications, oh2016designing, laviole2018nectar, boonbrahm2016interactive, gardeli2018effect, triantafyllidou2017fingertrips, xefteris2018learning, palaigeorgiou2018touching, lee2019mobile, ortiz2018evaluation, xefteris2019mixing, takahashi2018empathic, lee2018augmented, oh2017hybrid, dave2020towards, lopez2020emofindar}\\
    \midrule
    Collaborative & \cite{cai2017applications, oh2016designing, tscholl2016designing, laviole2018nectar, boonbrahm2016interactive, ManriqueJuan2017APA, gardeli2018effect, lee2019mobile, ortiz2018evaluation, xefteris2019mixing, takahashi2018empathic, oh2017hybrid, lopez2020emofindar}\\
    \bottomrule
\end{tabular}
\caption{\fontsize{10pt}{11pt}\selectfont{\itshape{Classification of articles according to interactivity and collaboration capabilities.}}}
\label{tab:categorize_papers}
\end{table*}

As it is impractical to provide a description of all the selected articles, here we mention the ones we deem as the most interesting. In \cite{khan2018mathland}, the authors implemented a mixed reality system based on HoloLens\footnote{www.microsoft.com/en-us/hololens} smart glasses and several stretch and \gls{IMU} sensors, where the users can control and move augmented objects using their arms or an ad-hoc controller. The multi-user application is used to teach the students physics concepts such as force fields or velocity vectors, without needing to set up a laboratory.
Some studies use multiple markers to increase interactivity. The work of \cite{wang2018augmented} uses AR to teach the double-slit experiment (a physics experiment demonstrating the characteristic of light being both a wave and a particle). In the application each marker is related to one part of the experimental apparatus. By modifying the distance of each marker from the next one, the augmented animation generated by the app changes its behaviour, visually showing the dual nature of light.
A similar idea is implemented by \cite{boonbrahm2015using}. In the app, which was created to facilitate learning English as a foreign language, each marker by itself only shows a letter in 3D. When multiple markers are combined to create an English word (from a predefined set), the app will show a 3D model of the corresponding word.
In \cite{gardeli2018effect}, the students learn the basics of computer science by visually implementing algorithms. Each marker, besides showing augmented content, represents an instruction in ALGO, a specially developed programming language, and sequences of different markers generate different behaviour from the augmented content. \cite{241-MACARIU20202133}, implemented an app for learning Chemistry that includes a text recognition module to provide information on specific Chemistry-related words, as well as 3D animations that show the molecule created when combining different atoms, with each atom using a specific marker.

Only a few studies experiment with other senses beyond sight. The work of \cite{kenoui2020teach} uses the IBM Watson SDK\footnote{www.ibm.com/cloud/watson-speech-to-text} to allow the user to interact by asking questions in English, while the answer is shown both as text above the augmented content and as computer-generated audio. \cite{mikulowski2020multi} designed a system for visually impaired students that detects mathematical formulas and generates both an audio description as well as a Braille representation on the Braille display.
 
In the context of multi-user applications, different studies employed different strategies to foster collaboration. \cite{boonbrahm2016interactive} describe an application where the users aim to solve a jigsaw puzzle. Since students cannot move two pieces in a row but are forced to alternate their moves, the puzzle can only be solved with a joint collaboration. In the work of  \cite{ortiz2018evaluation}, the app is an \gls{ARGBL} where the user learns about different regions of Colombia while competing for resources. In this case, competition with others stimulate the students to learn about the subject. Another form of collaboration is described by \cite{oh2016designing}: the authors created a smart-glasses-based AR application where the user can study properties of light such as reflection and refraction. Each user acts as a light source and sees what happens when light hits a wall or passes through different materials. At the same time, two or more users can generate multiple light rays and see how they interact with each other. Using a projector system, users without smart glasses are able to share the same experience, although not as actively as users wearing them.